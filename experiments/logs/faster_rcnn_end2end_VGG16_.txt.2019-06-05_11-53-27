+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-05_11-53-27
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-05_11-53-27
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
29646 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 29646 -> 29646
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0605 11:53:39.246667 24036 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0605 11:53:39.246687 24036 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0605 11:53:39.248864 24036 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "query_conv_reshape_ch"
  type: "Reshape"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv_reshape_ch"
  reshape_param {
    shape {
      dim: 1
      dim: 512
      dim: -1
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape_ch"
  type: "Reshape"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv_reshape_ch"
  reshape_param {
    shape {
      dim: 1
      dim: 512
      dim: -1
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape_ch"
  type: "Reshape"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv_reshape_ch"
  reshape_param {
    shape {
      dim: 1
      dim: 512
      dim: -1
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm_ch"
  type: "Permute"
  bottom: "query_conv_reshape_ch"
  top: "query_conv_reshape_perm_ch"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "key_conv_reshape_perm_ch"
  type: "Permute"
  bottom: "key_conv_reshape_ch"
  top: "key_conv_reshape_perm_ch"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "energy_ch"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm_ch"
  bottom: "key_conv_reshape_perm_ch"
  top: "energy_ch"
}
layer {
  name: "energy_ch_pool"
  type: "Pooling"
  bottom: "energy_ch"
  top: "energy_ch_pool"
  pooling_param {
    pool: MAX
    kernel_h: 1
    kernel_w: 512
    stride_h: 1
    stride_w: 512
  }
}
layer {
  name: "energy_ch_max"
  type: "Tile"
  bottom: "energy_ch_pool"
  top: "energy_ch_max"
  tile_param {
    axis: 3
    tiles: 512
  }
}
layer {
  name: "energy_ch_minus"
  type: "Power"
  bottom: "energy_ch"
  top: "energy_ch_minus"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "energy_new"
  type: "Eltwise"
  bottom: "energy_ch_max"
  bottom: "energy_ch_minus"
  top: "energy_new"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "attention_ch"
  type: "Softmax"
  bottom: "energy_new"
  top: "attention_ch"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_ch_perm"
  type: "Permute"
  bottom: "value_conv_reshape_ch"
  top: "value_conv_reshape_ch_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_ch_perm"
  type: "Permute"
  bottom: "attention_ch"
  top: "attention_ch_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out_ch"
  type: "MatrixMultiplication"
  bottom: "attention_ch_perm"
  bottom: "value_conv_reshape_ch_perm"
  top: "out_ch"
}
layer {
  name: "out_ch_reshape"
  type: "Reshape"
  bottom: "out_ch"
  top: "out_ch_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_ch_reshape_scale"
  type: "Scale"
  bottom: "out_ch_reshape"
  top: "out_ch_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_ch_x"
  type: "Eltwise"
  bottom: "out_ch_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_ch_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "out_conv_ch_x"
  type: "Convolution"
  bottom: "out_ch_x"
  top: "out_conv_ch_x"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out_conv_x"
  type: "Convolution"
  bottom: "out_x"
  top: "out_conv_x"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out_x_sum"
  type: "Eltwise"
  bottom: "out_conv_x"
  bottom: "out_conv_ch_x"
  top: "out_x_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x_sum"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_mask"
  type: "SoftmaxWithLoss"
  bottom: "mask_score"
  bottom: "mask_targets"
  top: "loss_mask"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
I0605 11:53:39.249208 24036 layer_factory.hpp:77] Creating layer input-data
I0605 11:53:39.356609 24036 net.cpp:106] Creating Layer input-data
I0605 11:53:39.356628 24036 net.cpp:411] input-data -> data
I0605 11:53:39.356638 24036 net.cpp:411] input-data -> im_info
I0605 11:53:39.356644 24036 net.cpp:411] input-data -> gt_boxes
I0605 11:53:39.356649 24036 net.cpp:411] input-data -> seg_mask_inds
I0605 11:53:39.356653 24036 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0605 11:53:39.456113 24036 net.cpp:150] Setting up input-data
I0605 11:53:39.456137 24036 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0605 11:53:39.456151 24036 net.cpp:157] Top shape: 1 3 (3)
I0605 11:53:39.456154 24036 net.cpp:157] Top shape: 1 4 (4)
I0605 11:53:39.456157 24036 net.cpp:157] Top shape: 1 2 (2)
I0605 11:53:39.456161 24036 net.cpp:157] Top shape: 1 1 (1)
I0605 11:53:39.456162 24036 net.cpp:165] Memory required for data: 7200040
I0605 11:53:39.456168 24036 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0605 11:53:39.456737 24036 net.cpp:106] Creating Layer data_input-data_0_split
I0605 11:53:39.456742 24036 net.cpp:454] data_input-data_0_split <- data
I0605 11:53:39.456758 24036 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0605 11:53:39.456764 24036 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0605 11:53:39.456818 24036 net.cpp:150] Setting up data_input-data_0_split
I0605 11:53:39.456823 24036 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0605 11:53:39.456825 24036 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0605 11:53:39.456837 24036 net.cpp:165] Memory required for data: 21600040
I0605 11:53:39.456840 24036 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0605 11:53:39.456845 24036 net.cpp:106] Creating Layer im_info_input-data_1_split
I0605 11:53:39.456857 24036 net.cpp:454] im_info_input-data_1_split <- im_info
I0605 11:53:39.456861 24036 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0605 11:53:39.456867 24036 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0605 11:53:39.456872 24036 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0605 11:53:39.456918 24036 net.cpp:150] Setting up im_info_input-data_1_split
I0605 11:53:39.456923 24036 net.cpp:157] Top shape: 1 3 (3)
I0605 11:53:39.456924 24036 net.cpp:157] Top shape: 1 3 (3)
I0605 11:53:39.456938 24036 net.cpp:157] Top shape: 1 3 (3)
I0605 11:53:39.456939 24036 net.cpp:165] Memory required for data: 21600076
I0605 11:53:39.456941 24036 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0605 11:53:39.456945 24036 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0605 11:53:39.456957 24036 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0605 11:53:39.456964 24036 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0605 11:53:39.456967 24036 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0605 11:53:39.456985 24036 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0605 11:53:39.456998 24036 net.cpp:157] Top shape: 1 4 (4)
I0605 11:53:39.457001 24036 net.cpp:157] Top shape: 1 4 (4)
I0605 11:53:39.457003 24036 net.cpp:165] Memory required for data: 21600108
I0605 11:53:39.457005 24036 layer_factory.hpp:77] Creating layer conv1_1
I0605 11:53:39.457024 24036 net.cpp:106] Creating Layer conv1_1
I0605 11:53:39.457036 24036 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0605 11:53:39.457039 24036 net.cpp:411] conv1_1 -> conv1_1
I0605 11:53:40.209270 24036 net.cpp:150] Setting up conv1_1
I0605 11:53:40.209292 24036 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0605 11:53:40.209295 24036 net.cpp:165] Memory required for data: 175200108
I0605 11:53:40.209307 24036 layer_factory.hpp:77] Creating layer relu1_1
I0605 11:53:40.209327 24036 net.cpp:106] Creating Layer relu1_1
I0605 11:53:40.209331 24036 net.cpp:454] relu1_1 <- conv1_1
I0605 11:53:40.209347 24036 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0605 11:53:40.209522 24036 net.cpp:150] Setting up relu1_1
I0605 11:53:40.209527 24036 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0605 11:53:40.209530 24036 net.cpp:165] Memory required for data: 328800108
I0605 11:53:40.209532 24036 layer_factory.hpp:77] Creating layer conv1_2
I0605 11:53:40.209539 24036 net.cpp:106] Creating Layer conv1_2
I0605 11:53:40.209542 24036 net.cpp:454] conv1_2 <- conv1_1
I0605 11:53:40.209547 24036 net.cpp:411] conv1_2 -> conv1_2
I0605 11:53:40.211575 24036 net.cpp:150] Setting up conv1_2
I0605 11:53:40.211587 24036 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0605 11:53:40.211591 24036 net.cpp:165] Memory required for data: 482400108
I0605 11:53:40.211598 24036 layer_factory.hpp:77] Creating layer relu1_2
I0605 11:53:40.211603 24036 net.cpp:106] Creating Layer relu1_2
I0605 11:53:40.211606 24036 net.cpp:454] relu1_2 <- conv1_2
I0605 11:53:40.211611 24036 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0605 11:53:40.211732 24036 net.cpp:150] Setting up relu1_2
I0605 11:53:40.211738 24036 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0605 11:53:40.211741 24036 net.cpp:165] Memory required for data: 636000108
I0605 11:53:40.211743 24036 layer_factory.hpp:77] Creating layer pool1
I0605 11:53:40.211750 24036 net.cpp:106] Creating Layer pool1
I0605 11:53:40.211766 24036 net.cpp:454] pool1 <- conv1_2
I0605 11:53:40.211771 24036 net.cpp:411] pool1 -> pool1
I0605 11:53:40.212393 24036 net.cpp:150] Setting up pool1
I0605 11:53:40.212399 24036 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0605 11:53:40.212401 24036 net.cpp:165] Memory required for data: 674400108
I0605 11:53:40.212404 24036 layer_factory.hpp:77] Creating layer conv2_1
I0605 11:53:40.212409 24036 net.cpp:106] Creating Layer conv2_1
I0605 11:53:40.212411 24036 net.cpp:454] conv2_1 <- pool1
I0605 11:53:40.212415 24036 net.cpp:411] conv2_1 -> conv2_1
I0605 11:53:40.214208 24036 net.cpp:150] Setting up conv2_1
I0605 11:53:40.214217 24036 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0605 11:53:40.214220 24036 net.cpp:165] Memory required for data: 751200108
I0605 11:53:40.214226 24036 layer_factory.hpp:77] Creating layer relu2_1
I0605 11:53:40.214231 24036 net.cpp:106] Creating Layer relu2_1
I0605 11:53:40.214233 24036 net.cpp:454] relu2_1 <- conv2_1
I0605 11:53:40.214237 24036 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0605 11:53:40.214707 24036 net.cpp:150] Setting up relu2_1
I0605 11:53:40.214716 24036 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0605 11:53:40.214728 24036 net.cpp:165] Memory required for data: 828000108
I0605 11:53:40.214731 24036 layer_factory.hpp:77] Creating layer conv2_2
I0605 11:53:40.214737 24036 net.cpp:106] Creating Layer conv2_2
I0605 11:53:40.214740 24036 net.cpp:454] conv2_2 <- conv2_1
I0605 11:53:40.214745 24036 net.cpp:411] conv2_2 -> conv2_2
I0605 11:53:40.216583 24036 net.cpp:150] Setting up conv2_2
I0605 11:53:40.216593 24036 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0605 11:53:40.216596 24036 net.cpp:165] Memory required for data: 904800108
I0605 11:53:40.216601 24036 layer_factory.hpp:77] Creating layer relu2_2
I0605 11:53:40.216605 24036 net.cpp:106] Creating Layer relu2_2
I0605 11:53:40.216609 24036 net.cpp:454] relu2_2 <- conv2_2
I0605 11:53:40.216612 24036 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0605 11:53:40.216730 24036 net.cpp:150] Setting up relu2_2
I0605 11:53:40.216737 24036 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0605 11:53:40.216740 24036 net.cpp:165] Memory required for data: 981600108
I0605 11:53:40.216743 24036 layer_factory.hpp:77] Creating layer pool2
I0605 11:53:40.216750 24036 net.cpp:106] Creating Layer pool2
I0605 11:53:40.216754 24036 net.cpp:454] pool2 <- conv2_2
I0605 11:53:40.216759 24036 net.cpp:411] pool2 -> pool2
I0605 11:53:40.216787 24036 net.cpp:150] Setting up pool2
I0605 11:53:40.216792 24036 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0605 11:53:40.216794 24036 net.cpp:165] Memory required for data: 1000800108
I0605 11:53:40.216797 24036 layer_factory.hpp:77] Creating layer conv3_1
I0605 11:53:40.216804 24036 net.cpp:106] Creating Layer conv3_1
I0605 11:53:40.216805 24036 net.cpp:454] conv3_1 <- pool2
I0605 11:53:40.216809 24036 net.cpp:411] conv3_1 -> conv3_1
I0605 11:53:40.218796 24036 net.cpp:150] Setting up conv3_1
I0605 11:53:40.218806 24036 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 11:53:40.218809 24036 net.cpp:165] Memory required for data: 1039200108
I0605 11:53:40.218816 24036 layer_factory.hpp:77] Creating layer relu3_1
I0605 11:53:40.218822 24036 net.cpp:106] Creating Layer relu3_1
I0605 11:53:40.218824 24036 net.cpp:454] relu3_1 <- conv3_1
I0605 11:53:40.218827 24036 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0605 11:53:40.218935 24036 net.cpp:150] Setting up relu3_1
I0605 11:53:40.218941 24036 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 11:53:40.218943 24036 net.cpp:165] Memory required for data: 1077600108
I0605 11:53:40.218945 24036 layer_factory.hpp:77] Creating layer conv3_2
I0605 11:53:40.218952 24036 net.cpp:106] Creating Layer conv3_2
I0605 11:53:40.218955 24036 net.cpp:454] conv3_2 <- conv3_1
I0605 11:53:40.218958 24036 net.cpp:411] conv3_2 -> conv3_2
I0605 11:53:40.221026 24036 net.cpp:150] Setting up conv3_2
I0605 11:53:40.221037 24036 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 11:53:40.221040 24036 net.cpp:165] Memory required for data: 1116000108
I0605 11:53:40.221045 24036 layer_factory.hpp:77] Creating layer relu3_2
I0605 11:53:40.221050 24036 net.cpp:106] Creating Layer relu3_2
I0605 11:53:40.221052 24036 net.cpp:454] relu3_2 <- conv3_2
I0605 11:53:40.221056 24036 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0605 11:53:40.221192 24036 net.cpp:150] Setting up relu3_2
I0605 11:53:40.221199 24036 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 11:53:40.221200 24036 net.cpp:165] Memory required for data: 1154400108
I0605 11:53:40.221202 24036 layer_factory.hpp:77] Creating layer conv3_3
I0605 11:53:40.221208 24036 net.cpp:106] Creating Layer conv3_3
I0605 11:53:40.221211 24036 net.cpp:454] conv3_3 <- conv3_2
I0605 11:53:40.221215 24036 net.cpp:411] conv3_3 -> conv3_3
I0605 11:53:40.223659 24036 net.cpp:150] Setting up conv3_3
I0605 11:53:40.223672 24036 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 11:53:40.223675 24036 net.cpp:165] Memory required for data: 1192800108
I0605 11:53:40.223682 24036 layer_factory.hpp:77] Creating layer relu3_3
I0605 11:53:40.223688 24036 net.cpp:106] Creating Layer relu3_3
I0605 11:53:40.223691 24036 net.cpp:454] relu3_3 <- conv3_3
I0605 11:53:40.223695 24036 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0605 11:53:40.223827 24036 net.cpp:150] Setting up relu3_3
I0605 11:53:40.223837 24036 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 11:53:40.223839 24036 net.cpp:165] Memory required for data: 1231200108
I0605 11:53:40.223841 24036 layer_factory.hpp:77] Creating layer pool3
I0605 11:53:40.223846 24036 net.cpp:106] Creating Layer pool3
I0605 11:53:40.223848 24036 net.cpp:454] pool3 <- conv3_3
I0605 11:53:40.223851 24036 net.cpp:411] pool3 -> pool3
I0605 11:53:40.223901 24036 net.cpp:150] Setting up pool3
I0605 11:53:40.223906 24036 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0605 11:53:40.223917 24036 net.cpp:165] Memory required for data: 1240800108
I0605 11:53:40.223919 24036 layer_factory.hpp:77] Creating layer conv4_1
I0605 11:53:40.223925 24036 net.cpp:106] Creating Layer conv4_1
I0605 11:53:40.223927 24036 net.cpp:454] conv4_1 <- pool3
I0605 11:53:40.223942 24036 net.cpp:411] conv4_1 -> conv4_1
I0605 11:53:40.228008 24036 net.cpp:150] Setting up conv4_1
I0605 11:53:40.228029 24036 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 11:53:40.228030 24036 net.cpp:165] Memory required for data: 1260000108
I0605 11:53:40.228039 24036 layer_factory.hpp:77] Creating layer relu4_1
I0605 11:53:40.228047 24036 net.cpp:106] Creating Layer relu4_1
I0605 11:53:40.228052 24036 net.cpp:454] relu4_1 <- conv4_1
I0605 11:53:40.228057 24036 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0605 11:53:40.228196 24036 net.cpp:150] Setting up relu4_1
I0605 11:53:40.228202 24036 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 11:53:40.228204 24036 net.cpp:165] Memory required for data: 1279200108
I0605 11:53:40.228206 24036 layer_factory.hpp:77] Creating layer conv4_2
I0605 11:53:40.228214 24036 net.cpp:106] Creating Layer conv4_2
I0605 11:53:40.228216 24036 net.cpp:454] conv4_2 <- conv4_1
I0605 11:53:40.228220 24036 net.cpp:411] conv4_2 -> conv4_2
I0605 11:53:40.232868 24036 net.cpp:150] Setting up conv4_2
I0605 11:53:40.232887 24036 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 11:53:40.232890 24036 net.cpp:165] Memory required for data: 1298400108
I0605 11:53:40.232903 24036 layer_factory.hpp:77] Creating layer relu4_2
I0605 11:53:40.232910 24036 net.cpp:106] Creating Layer relu4_2
I0605 11:53:40.232914 24036 net.cpp:454] relu4_2 <- conv4_2
I0605 11:53:40.232930 24036 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0605 11:53:40.233455 24036 net.cpp:150] Setting up relu4_2
I0605 11:53:40.233464 24036 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 11:53:40.233466 24036 net.cpp:165] Memory required for data: 1317600108
I0605 11:53:40.233469 24036 layer_factory.hpp:77] Creating layer conv4_3
I0605 11:53:40.233476 24036 net.cpp:106] Creating Layer conv4_3
I0605 11:53:40.233479 24036 net.cpp:454] conv4_3 <- conv4_2
I0605 11:53:40.233494 24036 net.cpp:411] conv4_3 -> conv4_3
I0605 11:53:40.238934 24036 net.cpp:150] Setting up conv4_3
I0605 11:53:40.238965 24036 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 11:53:40.238967 24036 net.cpp:165] Memory required for data: 1336800108
I0605 11:53:40.238976 24036 layer_factory.hpp:77] Creating layer relu4_3
I0605 11:53:40.238996 24036 net.cpp:106] Creating Layer relu4_3
I0605 11:53:40.239001 24036 net.cpp:454] relu4_3 <- conv4_3
I0605 11:53:40.239006 24036 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0605 11:53:40.239137 24036 net.cpp:150] Setting up relu4_3
I0605 11:53:40.239143 24036 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 11:53:40.239156 24036 net.cpp:165] Memory required for data: 1356000108
I0605 11:53:40.239158 24036 layer_factory.hpp:77] Creating layer pool4
I0605 11:53:40.239164 24036 net.cpp:106] Creating Layer pool4
I0605 11:53:40.239166 24036 net.cpp:454] pool4 <- conv4_3
I0605 11:53:40.239181 24036 net.cpp:411] pool4 -> pool4
I0605 11:53:40.239219 24036 net.cpp:150] Setting up pool4
I0605 11:53:40.239223 24036 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 11:53:40.239225 24036 net.cpp:165] Memory required for data: 1360903020
I0605 11:53:40.239238 24036 layer_factory.hpp:77] Creating layer conv5_1
I0605 11:53:40.239245 24036 net.cpp:106] Creating Layer conv5_1
I0605 11:53:40.239248 24036 net.cpp:454] conv5_1 <- pool4
I0605 11:53:40.239261 24036 net.cpp:411] conv5_1 -> conv5_1
I0605 11:53:40.244128 24036 net.cpp:150] Setting up conv5_1
I0605 11:53:40.244163 24036 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 11:53:40.244166 24036 net.cpp:165] Memory required for data: 1365805932
I0605 11:53:40.244174 24036 layer_factory.hpp:77] Creating layer relu5_1
I0605 11:53:40.244194 24036 net.cpp:106] Creating Layer relu5_1
I0605 11:53:40.244199 24036 net.cpp:454] relu5_1 <- conv5_1
I0605 11:53:40.244204 24036 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0605 11:53:40.244341 24036 net.cpp:150] Setting up relu5_1
I0605 11:53:40.244347 24036 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 11:53:40.244360 24036 net.cpp:165] Memory required for data: 1370708844
I0605 11:53:40.244362 24036 layer_factory.hpp:77] Creating layer conv5_2
I0605 11:53:40.244369 24036 net.cpp:106] Creating Layer conv5_2
I0605 11:53:40.244382 24036 net.cpp:454] conv5_2 <- conv5_1
I0605 11:53:40.244387 24036 net.cpp:411] conv5_2 -> conv5_2
I0605 11:53:40.249863 24036 net.cpp:150] Setting up conv5_2
I0605 11:53:40.249927 24036 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 11:53:40.249941 24036 net.cpp:165] Memory required for data: 1375611756
I0605 11:53:40.249959 24036 layer_factory.hpp:77] Creating layer relu5_2
I0605 11:53:40.249977 24036 net.cpp:106] Creating Layer relu5_2
I0605 11:53:40.249990 24036 net.cpp:454] relu5_2 <- conv5_2
I0605 11:53:40.250006 24036 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0605 11:53:40.250206 24036 net.cpp:150] Setting up relu5_2
I0605 11:53:40.250226 24036 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 11:53:40.250236 24036 net.cpp:165] Memory required for data: 1380514668
I0605 11:53:40.250246 24036 layer_factory.hpp:77] Creating layer conv5_3
I0605 11:53:40.250272 24036 net.cpp:106] Creating Layer conv5_3
I0605 11:53:40.250283 24036 net.cpp:454] conv5_3 <- conv5_2
I0605 11:53:40.250296 24036 net.cpp:411] conv5_3 -> conv5_3
I0605 11:53:40.257467 24036 net.cpp:150] Setting up conv5_3
I0605 11:53:40.257498 24036 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 11:53:40.257503 24036 net.cpp:165] Memory required for data: 1385417580
I0605 11:53:40.257516 24036 layer_factory.hpp:77] Creating layer relu5_3
I0605 11:53:40.257529 24036 net.cpp:106] Creating Layer relu5_3
I0605 11:53:40.257550 24036 net.cpp:454] relu5_3 <- conv5_3
I0605 11:53:40.257563 24036 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0605 11:53:40.257704 24036 net.cpp:150] Setting up relu5_3
I0605 11:53:40.257712 24036 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 11:53:40.257716 24036 net.cpp:165] Memory required for data: 1390320492
I0605 11:53:40.257720 24036 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0605 11:53:40.257728 24036 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0605 11:53:40.257737 24036 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0605 11:53:40.257743 24036 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0605 11:53:40.257750 24036 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0605 11:53:40.257761 24036 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0605 11:53:40.257807 24036 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0605 11:53:40.257815 24036 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 11:53:40.257820 24036 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 11:53:40.257825 24036 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 11:53:40.257829 24036 net.cpp:165] Memory required for data: 1405029228
I0605 11:53:40.257833 24036 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0605 11:53:40.257853 24036 net.cpp:106] Creating Layer rpn_conv/3x3
I0605 11:53:40.257858 24036 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0605 11:53:40.257866 24036 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0605 11:53:40.314839 24036 net.cpp:150] Setting up rpn_conv/3x3
I0605 11:53:40.314862 24036 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 11:53:40.314867 24036 net.cpp:165] Memory required for data: 1409932140
I0605 11:53:40.314877 24036 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0605 11:53:40.314898 24036 net.cpp:106] Creating Layer rpn_relu/3x3
I0605 11:53:40.314904 24036 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0605 11:53:40.314923 24036 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0605 11:53:40.315069 24036 net.cpp:150] Setting up rpn_relu/3x3
I0605 11:53:40.315078 24036 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 11:53:40.315081 24036 net.cpp:165] Memory required for data: 1414835052
I0605 11:53:40.315085 24036 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0605 11:53:40.315093 24036 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0605 11:53:40.315096 24036 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0605 11:53:40.315114 24036 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0605 11:53:40.315134 24036 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0605 11:53:40.315201 24036 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0605 11:53:40.315217 24036 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 11:53:40.315220 24036 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 11:53:40.315233 24036 net.cpp:165] Memory required for data: 1424640876
I0605 11:53:40.315238 24036 layer_factory.hpp:77] Creating layer rpn_cls_score
I0605 11:53:40.315274 24036 net.cpp:106] Creating Layer rpn_cls_score
I0605 11:53:40.315279 24036 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0605 11:53:40.315296 24036 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0605 11:53:40.316982 24036 net.cpp:150] Setting up rpn_cls_score
I0605 11:53:40.316992 24036 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0605 11:53:40.316995 24036 net.cpp:165] Memory required for data: 1424928156
I0605 11:53:40.317003 24036 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0605 11:53:40.317010 24036 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0605 11:53:40.317024 24036 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0605 11:53:40.317032 24036 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0605 11:53:40.317049 24036 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0605 11:53:40.317104 24036 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0605 11:53:40.317109 24036 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0605 11:53:40.317114 24036 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0605 11:53:40.317131 24036 net.cpp:165] Memory required for data: 1425502716
I0605 11:53:40.317135 24036 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0605 11:53:40.317157 24036 net.cpp:106] Creating Layer rpn_bbox_pred
I0605 11:53:40.317169 24036 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0605 11:53:40.317176 24036 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0605 11:53:40.318838 24036 net.cpp:150] Setting up rpn_bbox_pred
I0605 11:53:40.318852 24036 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 11:53:40.318856 24036 net.cpp:165] Memory required for data: 1426077276
I0605 11:53:40.318864 24036 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0605 11:53:40.318881 24036 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0605 11:53:40.318887 24036 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0605 11:53:40.318904 24036 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0605 11:53:40.318913 24036 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0605 11:53:40.318982 24036 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0605 11:53:40.318989 24036 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 11:53:40.318992 24036 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 11:53:40.319005 24036 net.cpp:165] Memory required for data: 1427226396
I0605 11:53:40.319010 24036 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0605 11:53:40.319030 24036 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0605 11:53:40.319034 24036 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0605 11:53:40.319052 24036 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0605 11:53:40.319087 24036 net.cpp:150] Setting up rpn_cls_score_reshape
I0605 11:53:40.319092 24036 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0605 11:53:40.319095 24036 net.cpp:165] Memory required for data: 1427513676
I0605 11:53:40.319108 24036 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0605 11:53:40.319115 24036 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0605 11:53:40.319119 24036 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0605 11:53:40.319125 24036 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0605 11:53:40.319133 24036 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0605 11:53:40.319161 24036 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0605 11:53:40.319166 24036 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0605 11:53:40.319171 24036 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0605 11:53:40.319175 24036 net.cpp:165] Memory required for data: 1428088236
I0605 11:53:40.319178 24036 layer_factory.hpp:77] Creating layer rpn-data
I0605 11:53:40.320196 24036 net.cpp:106] Creating Layer rpn-data
I0605 11:53:40.320206 24036 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0605 11:53:40.320214 24036 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0605 11:53:40.320219 24036 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0605 11:53:40.320225 24036 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0605 11:53:40.320232 24036 net.cpp:411] rpn-data -> rpn_labels
I0605 11:53:40.320241 24036 net.cpp:411] rpn-data -> rpn_bbox_targets
I0605 11:53:40.320248 24036 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0605 11:53:40.320256 24036 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0605 11:53:40.321096 24036 net.cpp:150] Setting up rpn-data
I0605 11:53:40.321107 24036 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0605 11:53:40.321112 24036 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 11:53:40.321117 24036 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 11:53:40.321123 24036 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 11:53:40.321126 24036 net.cpp:165] Memory required for data: 1429955556
I0605 11:53:40.321132 24036 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0605 11:53:40.321142 24036 net.cpp:106] Creating Layer rpn_loss_cls
I0605 11:53:40.321146 24036 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0605 11:53:40.321152 24036 net.cpp:454] rpn_loss_cls <- rpn_labels
I0605 11:53:40.321157 24036 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0605 11:53:40.321172 24036 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0605 11:53:40.323026 24036 net.cpp:150] Setting up rpn_loss_cls
I0605 11:53:40.323037 24036 net.cpp:157] Top shape: (1)
I0605 11:53:40.323041 24036 net.cpp:160]     with loss weight 1
I0605 11:53:40.323052 24036 net.cpp:165] Memory required for data: 1429955560
I0605 11:53:40.323056 24036 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0605 11:53:40.323071 24036 net.cpp:106] Creating Layer rpn_loss_bbox
I0605 11:53:40.323074 24036 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0605 11:53:40.323081 24036 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0605 11:53:40.323086 24036 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0605 11:53:40.323091 24036 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0605 11:53:40.323101 24036 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0605 11:53:40.324218 24036 net.cpp:150] Setting up rpn_loss_bbox
I0605 11:53:40.324228 24036 net.cpp:157] Top shape: (1)
I0605 11:53:40.324231 24036 net.cpp:160]     with loss weight 1
I0605 11:53:40.324239 24036 net.cpp:165] Memory required for data: 1429955564
I0605 11:53:40.324244 24036 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0605 11:53:40.324252 24036 net.cpp:106] Creating Layer rpn_cls_prob
I0605 11:53:40.324256 24036 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0605 11:53:40.324262 24036 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0605 11:53:40.324419 24036 net.cpp:150] Setting up rpn_cls_prob
I0605 11:53:40.324426 24036 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0605 11:53:40.324430 24036 net.cpp:165] Memory required for data: 1430242844
I0605 11:53:40.324434 24036 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0605 11:53:40.324440 24036 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0605 11:53:40.324445 24036 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0605 11:53:40.324451 24036 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0605 11:53:40.324476 24036 net.cpp:150] Setting up rpn_cls_prob_reshape
I0605 11:53:40.324482 24036 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0605 11:53:40.324486 24036 net.cpp:165] Memory required for data: 1430530124
I0605 11:53:40.324489 24036 layer_factory.hpp:77] Creating layer proposal
I0605 11:53:40.327502 24036 net.cpp:106] Creating Layer proposal
I0605 11:53:40.327512 24036 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0605 11:53:40.327517 24036 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0605 11:53:40.327523 24036 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0605 11:53:40.327530 24036 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0605 11:53:40.328946 24036 net.cpp:150] Setting up proposal
I0605 11:53:40.328955 24036 net.cpp:157] Top shape: 1 5 (5)
I0605 11:53:40.328958 24036 net.cpp:165] Memory required for data: 1430530144
I0605 11:53:40.328960 24036 layer_factory.hpp:77] Creating layer roi-data
I0605 11:53:40.331879 24036 net.cpp:106] Creating Layer roi-data
I0605 11:53:40.331887 24036 net.cpp:454] roi-data <- rpn_rois
I0605 11:53:40.331892 24036 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0605 11:53:40.331894 24036 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0605 11:53:40.331897 24036 net.cpp:454] roi-data <- seg_mask_inds
I0605 11:53:40.331900 24036 net.cpp:454] roi-data <- flipped
I0605 11:53:40.331914 24036 net.cpp:411] roi-data -> rois
I0605 11:53:40.331920 24036 net.cpp:411] roi-data -> labels
I0605 11:53:40.331925 24036 net.cpp:411] roi-data -> bbox_targets
I0605 11:53:40.331940 24036 net.cpp:411] roi-data -> bbox_inside_weights
I0605 11:53:40.331944 24036 net.cpp:411] roi-data -> bbox_outside_weights
I0605 11:53:40.331949 24036 net.cpp:411] roi-data -> mask_targets
I0605 11:53:40.331954 24036 net.cpp:411] roi-data -> rois_pos
I0605 11:53:40.332258 24036 net.cpp:150] Setting up roi-data
I0605 11:53:40.332265 24036 net.cpp:157] Top shape: 1 5 (5)
I0605 11:53:40.332268 24036 net.cpp:157] Top shape: 1 1 (1)
I0605 11:53:40.332271 24036 net.cpp:157] Top shape: 1 8 (8)
I0605 11:53:40.332273 24036 net.cpp:157] Top shape: 1 8 (8)
I0605 11:53:40.332275 24036 net.cpp:157] Top shape: 1 8 (8)
I0605 11:53:40.332278 24036 net.cpp:157] Top shape: 1 244 244 (59536)
I0605 11:53:40.332290 24036 net.cpp:157] Top shape: 1 5 (5)
I0605 11:53:40.332293 24036 net.cpp:165] Memory required for data: 1430768428
I0605 11:53:40.332295 24036 layer_factory.hpp:77] Creating layer roi_pool5
I0605 11:53:40.332897 24036 net.cpp:106] Creating Layer roi_pool5
I0605 11:53:40.332902 24036 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0605 11:53:40.332916 24036 net.cpp:454] roi_pool5 <- rois
I0605 11:53:40.332919 24036 net.cpp:411] roi_pool5 -> pool5
I0605 11:53:40.332936 24036 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0605 11:53:40.333027 24036 net.cpp:150] Setting up roi_pool5
I0605 11:53:40.333031 24036 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 11:53:40.333045 24036 net.cpp:165] Memory required for data: 1430868780
I0605 11:53:40.333046 24036 layer_factory.hpp:77] Creating layer fc6
I0605 11:53:40.333052 24036 net.cpp:106] Creating Layer fc6
I0605 11:53:40.333065 24036 net.cpp:454] fc6 <- pool5
I0605 11:53:40.333070 24036 net.cpp:411] fc6 -> fc6
I0605 11:53:40.575461 24036 net.cpp:150] Setting up fc6
I0605 11:53:40.575487 24036 net.cpp:157] Top shape: 1 4096 (4096)
I0605 11:53:40.575491 24036 net.cpp:165] Memory required for data: 1430885164
I0605 11:53:40.575506 24036 layer_factory.hpp:77] Creating layer relu6
I0605 11:53:40.575527 24036 net.cpp:106] Creating Layer relu6
I0605 11:53:40.575533 24036 net.cpp:454] relu6 <- fc6
I0605 11:53:40.575551 24036 net.cpp:397] relu6 -> fc6 (in-place)
I0605 11:53:40.575769 24036 net.cpp:150] Setting up relu6
I0605 11:53:40.575778 24036 net.cpp:157] Top shape: 1 4096 (4096)
I0605 11:53:40.575780 24036 net.cpp:165] Memory required for data: 1430901548
I0605 11:53:40.575783 24036 layer_factory.hpp:77] Creating layer fc7
I0605 11:53:40.575788 24036 net.cpp:106] Creating Layer fc7
I0605 11:53:40.575791 24036 net.cpp:454] fc7 <- fc6
I0605 11:53:40.575795 24036 net.cpp:411] fc7 -> fc7
I0605 11:53:40.600216 24036 net.cpp:150] Setting up fc7
I0605 11:53:40.600255 24036 net.cpp:157] Top shape: 1 4096 (4096)
I0605 11:53:40.600258 24036 net.cpp:165] Memory required for data: 1430917932
I0605 11:53:40.600267 24036 layer_factory.hpp:77] Creating layer relu7
I0605 11:53:40.600276 24036 net.cpp:106] Creating Layer relu7
I0605 11:53:40.600281 24036 net.cpp:454] relu7 <- fc7
I0605 11:53:40.600286 24036 net.cpp:397] relu7 -> fc7 (in-place)
I0605 11:53:40.600457 24036 net.cpp:150] Setting up relu7
I0605 11:53:40.600463 24036 net.cpp:157] Top shape: 1 4096 (4096)
I0605 11:53:40.600476 24036 net.cpp:165] Memory required for data: 1430934316
I0605 11:53:40.600478 24036 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0605 11:53:40.600483 24036 net.cpp:106] Creating Layer fc7_relu7_0_split
I0605 11:53:40.600486 24036 net.cpp:454] fc7_relu7_0_split <- fc7
I0605 11:53:40.600491 24036 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0605 11:53:40.600494 24036 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0605 11:53:40.600538 24036 net.cpp:150] Setting up fc7_relu7_0_split
I0605 11:53:40.600543 24036 net.cpp:157] Top shape: 1 4096 (4096)
I0605 11:53:40.600556 24036 net.cpp:157] Top shape: 1 4096 (4096)
I0605 11:53:40.600559 24036 net.cpp:165] Memory required for data: 1430967084
I0605 11:53:40.600561 24036 layer_factory.hpp:77] Creating layer cls_score
I0605 11:53:40.600567 24036 net.cpp:106] Creating Layer cls_score
I0605 11:53:40.600570 24036 net.cpp:454] cls_score <- fc7_relu7_0_split_0
I0605 11:53:40.600577 24036 net.cpp:411] cls_score -> cls_score
I0605 11:53:40.600819 24036 net.cpp:150] Setting up cls_score
I0605 11:53:40.600824 24036 net.cpp:157] Top shape: 1 2 (2)
I0605 11:53:40.600836 24036 net.cpp:165] Memory required for data: 1430967092
I0605 11:53:40.600841 24036 layer_factory.hpp:77] Creating layer bbox_pred
I0605 11:53:40.600845 24036 net.cpp:106] Creating Layer bbox_pred
I0605 11:53:40.600848 24036 net.cpp:454] bbox_pred <- fc7_relu7_0_split_1
I0605 11:53:40.600852 24036 net.cpp:411] bbox_pred -> bbox_pred
I0605 11:53:40.601655 24036 net.cpp:150] Setting up bbox_pred
I0605 11:53:40.601660 24036 net.cpp:157] Top shape: 1 8 (8)
I0605 11:53:40.601672 24036 net.cpp:165] Memory required for data: 1430967124
I0605 11:53:40.601676 24036 layer_factory.hpp:77] Creating layer loss_cls
I0605 11:53:40.601681 24036 net.cpp:106] Creating Layer loss_cls
I0605 11:53:40.601685 24036 net.cpp:454] loss_cls <- cls_score
I0605 11:53:40.601687 24036 net.cpp:454] loss_cls <- labels
I0605 11:53:40.601703 24036 net.cpp:411] loss_cls -> loss_cls
I0605 11:53:40.601711 24036 layer_factory.hpp:77] Creating layer loss_cls
I0605 11:53:40.602488 24036 net.cpp:150] Setting up loss_cls
I0605 11:53:40.602499 24036 net.cpp:157] Top shape: (1)
I0605 11:53:40.602502 24036 net.cpp:160]     with loss weight 3
I0605 11:53:40.602515 24036 net.cpp:165] Memory required for data: 1430967128
I0605 11:53:40.602519 24036 layer_factory.hpp:77] Creating layer loss_bbox
I0605 11:53:40.602536 24036 net.cpp:106] Creating Layer loss_bbox
I0605 11:53:40.602541 24036 net.cpp:454] loss_bbox <- bbox_pred
I0605 11:53:40.602545 24036 net.cpp:454] loss_bbox <- bbox_targets
I0605 11:53:40.602552 24036 net.cpp:454] loss_bbox <- bbox_inside_weights
I0605 11:53:40.602556 24036 net.cpp:454] loss_bbox <- bbox_outside_weights
I0605 11:53:40.602564 24036 net.cpp:411] loss_bbox -> loss_bbox
I0605 11:53:40.602649 24036 net.cpp:150] Setting up loss_bbox
I0605 11:53:40.602656 24036 net.cpp:157] Top shape: (1)
I0605 11:53:40.602661 24036 net.cpp:160]     with loss weight 2
I0605 11:53:40.602677 24036 net.cpp:165] Memory required for data: 1430967132
I0605 11:53:40.602681 24036 layer_factory.hpp:77] Creating layer roi_pool5_2
I0605 11:53:40.602689 24036 net.cpp:106] Creating Layer roi_pool5_2
I0605 11:53:40.602694 24036 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0605 11:53:40.602699 24036 net.cpp:454] roi_pool5_2 <- rois_pos
I0605 11:53:40.602707 24036 net.cpp:411] roi_pool5_2 -> pool5_2
I0605 11:53:40.602716 24036 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0605 11:53:40.602818 24036 net.cpp:150] Setting up roi_pool5_2
I0605 11:53:40.602824 24036 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 11:53:40.602829 24036 net.cpp:165] Memory required for data: 1431067484
I0605 11:53:40.602844 24036 layer_factory.hpp:77] Creating layer pool5_2_conv
I0605 11:53:40.602856 24036 net.cpp:106] Creating Layer pool5_2_conv
I0605 11:53:40.602862 24036 net.cpp:454] pool5_2_conv <- pool5_2
I0605 11:53:40.602869 24036 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0605 11:53:40.609737 24036 net.cpp:150] Setting up pool5_2_conv
I0605 11:53:40.609748 24036 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 11:53:40.609751 24036 net.cpp:165] Memory required for data: 1431167836
I0605 11:53:40.609757 24036 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0605 11:53:40.609774 24036 net.cpp:106] Creating Layer pool5_2_conv_relu
I0605 11:53:40.609777 24036 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0605 11:53:40.609782 24036 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0605 11:53:40.609926 24036 net.cpp:150] Setting up pool5_2_conv_relu
I0605 11:53:40.609932 24036 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 11:53:40.609935 24036 net.cpp:165] Memory required for data: 1431268188
I0605 11:53:40.609937 24036 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0605 11:53:40.609971 24036 net.cpp:106] Creating Layer pool5_2_conv2
I0605 11:53:40.609975 24036 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0605 11:53:40.609979 24036 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0605 11:53:40.661566 24036 net.cpp:150] Setting up pool5_2_conv2
I0605 11:53:40.661584 24036 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 11:53:40.661586 24036 net.cpp:165] Memory required for data: 1431368540
I0605 11:53:40.661595 24036 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0605 11:53:40.661615 24036 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0605 11:53:40.661620 24036 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0605 11:53:40.661638 24036 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0605 11:53:40.661799 24036 net.cpp:150] Setting up pool5_2_conv2_relu
I0605 11:53:40.661808 24036 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 11:53:40.661809 24036 net.cpp:165] Memory required for data: 1431468892
I0605 11:53:40.661813 24036 layer_factory.hpp:77] Creating layer mask_deconv1
I0605 11:53:40.661819 24036 net.cpp:106] Creating Layer mask_deconv1
I0605 11:53:40.661823 24036 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0605 11:53:40.661826 24036 net.cpp:411] mask_deconv1 -> mask_deconv1
I0605 11:53:40.662663 24036 net.cpp:150] Setting up mask_deconv1
I0605 11:53:40.662672 24036 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0605 11:53:40.662673 24036 net.cpp:165] Memory required for data: 1432390492
I0605 11:53:40.662678 24036 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0605 11:53:40.662685 24036 net.cpp:106] Creating Layer pool5_2_conv3
I0605 11:53:40.662688 24036 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0605 11:53:40.662693 24036 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0605 11:53:40.689080 24036 net.cpp:150] Setting up pool5_2_conv3
I0605 11:53:40.689097 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.689100 24036 net.cpp:165] Memory required for data: 1434233692
I0605 11:53:40.689110 24036 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0605 11:53:40.689117 24036 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0605 11:53:40.689122 24036 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0605 11:53:40.689137 24036 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0605 11:53:40.689292 24036 net.cpp:150] Setting up pool5_2_conv3_relu
I0605 11:53:40.689299 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.689302 24036 net.cpp:165] Memory required for data: 1436076892
I0605 11:53:40.689306 24036 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0605 11:53:40.689330 24036 net.cpp:106] Creating Layer pool5_2_conv4
I0605 11:53:40.689337 24036 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0605 11:53:40.689342 24036 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0605 11:53:40.740407 24036 net.cpp:150] Setting up pool5_2_conv4
I0605 11:53:40.740427 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.740429 24036 net.cpp:165] Memory required for data: 1437920092
I0605 11:53:40.740437 24036 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0605 11:53:40.740445 24036 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0605 11:53:40.740451 24036 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0605 11:53:40.740466 24036 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0605 11:53:40.740628 24036 net.cpp:150] Setting up pool5_2_conv4_relu
I0605 11:53:40.740636 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.740638 24036 net.cpp:165] Memory required for data: 1439763292
I0605 11:53:40.740640 24036 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0605 11:53:40.740646 24036 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0605 11:53:40.740649 24036 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0605 11:53:40.740653 24036 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0605 11:53:40.740669 24036 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0605 11:53:40.740674 24036 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0605 11:53:40.740689 24036 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0605 11:53:40.740694 24036 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_4
I0605 11:53:40.740698 24036 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_5
I0605 11:53:40.740702 24036 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_6
I0605 11:53:40.740706 24036 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_7
I0605 11:53:40.740798 24036 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0605 11:53:40.740803 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.740805 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.740808 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.740810 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.740813 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.740814 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.740818 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.740819 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.740821 24036 net.cpp:165] Memory required for data: 1454508892
I0605 11:53:40.740833 24036 layer_factory.hpp:77] Creating layer query_conv
I0605 11:53:40.740854 24036 net.cpp:106] Creating Layer query_conv
I0605 11:53:40.740857 24036 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0605 11:53:40.740861 24036 net.cpp:411] query_conv -> query_conv
I0605 11:53:40.742501 24036 net.cpp:150] Setting up query_conv
I0605 11:53:40.742511 24036 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0605 11:53:40.742512 24036 net.cpp:165] Memory required for data: 1454739292
I0605 11:53:40.742517 24036 layer_factory.hpp:77] Creating layer key_conv
I0605 11:53:40.742525 24036 net.cpp:106] Creating Layer key_conv
I0605 11:53:40.742528 24036 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0605 11:53:40.742533 24036 net.cpp:411] key_conv -> key_conv
I0605 11:53:40.744184 24036 net.cpp:150] Setting up key_conv
I0605 11:53:40.744192 24036 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0605 11:53:40.744194 24036 net.cpp:165] Memory required for data: 1454969692
I0605 11:53:40.744199 24036 layer_factory.hpp:77] Creating layer value_conv
I0605 11:53:40.744206 24036 net.cpp:106] Creating Layer value_conv
I0605 11:53:40.744210 24036 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0605 11:53:40.744215 24036 net.cpp:411] value_conv -> value_conv
I0605 11:53:40.751785 24036 net.cpp:150] Setting up value_conv
I0605 11:53:40.751793 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.751806 24036 net.cpp:165] Memory required for data: 1456812892
I0605 11:53:40.751811 24036 layer_factory.hpp:77] Creating layer query_conv_reshape
I0605 11:53:40.751829 24036 net.cpp:106] Creating Layer query_conv_reshape
I0605 11:53:40.751835 24036 net.cpp:454] query_conv_reshape <- query_conv
I0605 11:53:40.751845 24036 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0605 11:53:40.751881 24036 net.cpp:150] Setting up query_conv_reshape
I0605 11:53:40.751885 24036 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0605 11:53:40.751888 24036 net.cpp:165] Memory required for data: 1457043292
I0605 11:53:40.751899 24036 layer_factory.hpp:77] Creating layer key_conv_reshape
I0605 11:53:40.751905 24036 net.cpp:106] Creating Layer key_conv_reshape
I0605 11:53:40.751909 24036 net.cpp:454] key_conv_reshape <- key_conv
I0605 11:53:40.751925 24036 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0605 11:53:40.751974 24036 net.cpp:150] Setting up key_conv_reshape
I0605 11:53:40.751982 24036 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0605 11:53:40.751996 24036 net.cpp:165] Memory required for data: 1457273692
I0605 11:53:40.752001 24036 layer_factory.hpp:77] Creating layer value_conv_reshape
I0605 11:53:40.752007 24036 net.cpp:106] Creating Layer value_conv_reshape
I0605 11:53:40.752014 24036 net.cpp:454] value_conv_reshape <- value_conv
I0605 11:53:40.752032 24036 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0605 11:53:40.752061 24036 net.cpp:150] Setting up value_conv_reshape
I0605 11:53:40.752068 24036 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0605 11:53:40.752071 24036 net.cpp:165] Memory required for data: 1459116892
I0605 11:53:40.752075 24036 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0605 11:53:40.752508 24036 net.cpp:106] Creating Layer query_conv_reshape_perm
I0605 11:53:40.752516 24036 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0605 11:53:40.752523 24036 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0605 11:53:40.752640 24036 net.cpp:150] Setting up query_conv_reshape_perm
I0605 11:53:40.752648 24036 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0605 11:53:40.752652 24036 net.cpp:165] Memory required for data: 1459347292
I0605 11:53:40.752656 24036 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0605 11:53:40.752661 24036 net.cpp:106] Creating Layer key_conv_reshape_perm
I0605 11:53:40.752665 24036 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0605 11:53:40.752671 24036 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0605 11:53:40.752774 24036 net.cpp:150] Setting up key_conv_reshape_perm
I0605 11:53:40.752784 24036 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0605 11:53:40.752786 24036 net.cpp:165] Memory required for data: 1459577692
I0605 11:53:40.752790 24036 layer_factory.hpp:77] Creating layer energy
I0605 11:53:40.752807 24036 net.cpp:106] Creating Layer energy
I0605 11:53:40.752812 24036 net.cpp:454] energy <- query_conv_reshape_perm
I0605 11:53:40.752817 24036 net.cpp:454] energy <- key_conv_reshape_perm
I0605 11:53:40.752822 24036 net.cpp:411] energy -> energy
I0605 11:53:40.752851 24036 net.cpp:150] Setting up energy
I0605 11:53:40.752859 24036 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0605 11:53:40.752863 24036 net.cpp:165] Memory required for data: 1462817692
I0605 11:53:40.752867 24036 layer_factory.hpp:77] Creating layer attention
I0605 11:53:40.752876 24036 net.cpp:106] Creating Layer attention
I0605 11:53:40.752882 24036 net.cpp:454] attention <- energy
I0605 11:53:40.752888 24036 net.cpp:411] attention -> attention
I0605 11:53:40.753151 24036 net.cpp:150] Setting up attention
I0605 11:53:40.753161 24036 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0605 11:53:40.753166 24036 net.cpp:165] Memory required for data: 1466057692
I0605 11:53:40.753181 24036 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0605 11:53:40.753188 24036 net.cpp:106] Creating Layer value_conv_reshape_perm
I0605 11:53:40.753193 24036 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0605 11:53:40.753204 24036 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0605 11:53:40.753326 24036 net.cpp:150] Setting up value_conv_reshape_perm
I0605 11:53:40.753334 24036 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0605 11:53:40.753347 24036 net.cpp:165] Memory required for data: 1467900892
I0605 11:53:40.753352 24036 layer_factory.hpp:77] Creating layer attention_perm
I0605 11:53:40.753360 24036 net.cpp:106] Creating Layer attention_perm
I0605 11:53:40.753366 24036 net.cpp:454] attention_perm <- attention
I0605 11:53:40.753373 24036 net.cpp:411] attention_perm -> attention_perm
I0605 11:53:40.753521 24036 net.cpp:150] Setting up attention_perm
I0605 11:53:40.753528 24036 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0605 11:53:40.753530 24036 net.cpp:165] Memory required for data: 1471140892
I0605 11:53:40.753533 24036 layer_factory.hpp:77] Creating layer out
I0605 11:53:40.753548 24036 net.cpp:106] Creating Layer out
I0605 11:53:40.753552 24036 net.cpp:454] out <- value_conv_reshape_perm
I0605 11:53:40.753556 24036 net.cpp:454] out <- attention_perm
I0605 11:53:40.753559 24036 net.cpp:411] out -> out
I0605 11:53:40.753576 24036 net.cpp:150] Setting up out
I0605 11:53:40.753581 24036 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0605 11:53:40.753583 24036 net.cpp:165] Memory required for data: 1472984092
I0605 11:53:40.753585 24036 layer_factory.hpp:77] Creating layer out_reshape
I0605 11:53:40.753589 24036 net.cpp:106] Creating Layer out_reshape
I0605 11:53:40.753592 24036 net.cpp:454] out_reshape <- out
I0605 11:53:40.753597 24036 net.cpp:411] out_reshape -> out_reshape
I0605 11:53:40.753614 24036 net.cpp:150] Setting up out_reshape
I0605 11:53:40.753619 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.753621 24036 net.cpp:165] Memory required for data: 1474827292
I0605 11:53:40.753624 24036 layer_factory.hpp:77] Creating layer out_reshape_scale
I0605 11:53:40.753633 24036 net.cpp:106] Creating Layer out_reshape_scale
I0605 11:53:40.753638 24036 net.cpp:454] out_reshape_scale <- out_reshape
I0605 11:53:40.753643 24036 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0605 11:53:40.753712 24036 net.cpp:150] Setting up out_reshape_scale
I0605 11:53:40.753716 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.753718 24036 net.cpp:165] Memory required for data: 1476670492
I0605 11:53:40.753732 24036 layer_factory.hpp:77] Creating layer out_x
I0605 11:53:40.753739 24036 net.cpp:106] Creating Layer out_x
I0605 11:53:40.753744 24036 net.cpp:454] out_x <- out_reshape_scale
I0605 11:53:40.753747 24036 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0605 11:53:40.753751 24036 net.cpp:411] out_x -> out_x
I0605 11:53:40.753768 24036 net.cpp:150] Setting up out_x
I0605 11:53:40.753772 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.753775 24036 net.cpp:165] Memory required for data: 1478513692
I0605 11:53:40.753778 24036 layer_factory.hpp:77] Creating layer query_conv_reshape_ch
I0605 11:53:40.753782 24036 net.cpp:106] Creating Layer query_conv_reshape_ch
I0605 11:53:40.753787 24036 net.cpp:454] query_conv_reshape_ch <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_4
I0605 11:53:40.753790 24036 net.cpp:411] query_conv_reshape_ch -> query_conv_reshape_ch
I0605 11:53:40.753808 24036 net.cpp:150] Setting up query_conv_reshape_ch
I0605 11:53:40.753813 24036 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0605 11:53:40.753814 24036 net.cpp:165] Memory required for data: 1480356892
I0605 11:53:40.753816 24036 layer_factory.hpp:77] Creating layer key_conv_reshape_ch
I0605 11:53:40.753820 24036 net.cpp:106] Creating Layer key_conv_reshape_ch
I0605 11:53:40.753826 24036 net.cpp:454] key_conv_reshape_ch <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_5
I0605 11:53:40.753829 24036 net.cpp:411] key_conv_reshape_ch -> key_conv_reshape_ch
I0605 11:53:40.753844 24036 net.cpp:150] Setting up key_conv_reshape_ch
I0605 11:53:40.753849 24036 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0605 11:53:40.753850 24036 net.cpp:165] Memory required for data: 1482200092
I0605 11:53:40.753854 24036 layer_factory.hpp:77] Creating layer value_conv_reshape_ch
I0605 11:53:40.753857 24036 net.cpp:106] Creating Layer value_conv_reshape_ch
I0605 11:53:40.753861 24036 net.cpp:454] value_conv_reshape_ch <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_6
I0605 11:53:40.753865 24036 net.cpp:411] value_conv_reshape_ch -> value_conv_reshape_ch
I0605 11:53:40.753883 24036 net.cpp:150] Setting up value_conv_reshape_ch
I0605 11:53:40.753887 24036 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0605 11:53:40.753890 24036 net.cpp:165] Memory required for data: 1484043292
I0605 11:53:40.753892 24036 layer_factory.hpp:77] Creating layer query_conv_reshape_perm_ch
I0605 11:53:40.753896 24036 net.cpp:106] Creating Layer query_conv_reshape_perm_ch
I0605 11:53:40.753903 24036 net.cpp:454] query_conv_reshape_perm_ch <- query_conv_reshape_ch
I0605 11:53:40.753907 24036 net.cpp:411] query_conv_reshape_perm_ch -> query_conv_reshape_perm_ch
I0605 11:53:40.753973 24036 net.cpp:150] Setting up query_conv_reshape_perm_ch
I0605 11:53:40.753978 24036 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0605 11:53:40.753980 24036 net.cpp:165] Memory required for data: 1485886492
I0605 11:53:40.753983 24036 layer_factory.hpp:77] Creating layer key_conv_reshape_perm_ch
I0605 11:53:40.753986 24036 net.cpp:106] Creating Layer key_conv_reshape_perm_ch
I0605 11:53:40.753988 24036 net.cpp:454] key_conv_reshape_perm_ch <- key_conv_reshape_ch
I0605 11:53:40.753993 24036 net.cpp:411] key_conv_reshape_perm_ch -> key_conv_reshape_perm_ch
I0605 11:53:40.754053 24036 net.cpp:150] Setting up key_conv_reshape_perm_ch
I0605 11:53:40.754058 24036 net.cpp:157] Top shape: 1 1 900 512 (460800)
I0605 11:53:40.754060 24036 net.cpp:165] Memory required for data: 1487729692
I0605 11:53:40.754063 24036 layer_factory.hpp:77] Creating layer energy_ch
I0605 11:53:40.754067 24036 net.cpp:106] Creating Layer energy_ch
I0605 11:53:40.754071 24036 net.cpp:454] energy_ch <- query_conv_reshape_perm_ch
I0605 11:53:40.754074 24036 net.cpp:454] energy_ch <- key_conv_reshape_perm_ch
I0605 11:53:40.754079 24036 net.cpp:411] energy_ch -> energy_ch
I0605 11:53:40.754096 24036 net.cpp:150] Setting up energy_ch
I0605 11:53:40.754101 24036 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0605 11:53:40.754102 24036 net.cpp:165] Memory required for data: 1488778268
I0605 11:53:40.754106 24036 layer_factory.hpp:77] Creating layer energy_ch_energy_ch_0_split
I0605 11:53:40.754110 24036 net.cpp:106] Creating Layer energy_ch_energy_ch_0_split
I0605 11:53:40.754114 24036 net.cpp:454] energy_ch_energy_ch_0_split <- energy_ch
I0605 11:53:40.754117 24036 net.cpp:411] energy_ch_energy_ch_0_split -> energy_ch_energy_ch_0_split_0
I0605 11:53:40.754123 24036 net.cpp:411] energy_ch_energy_ch_0_split -> energy_ch_energy_ch_0_split_1
I0605 11:53:40.754145 24036 net.cpp:150] Setting up energy_ch_energy_ch_0_split
I0605 11:53:40.754149 24036 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0605 11:53:40.754153 24036 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0605 11:53:40.754155 24036 net.cpp:165] Memory required for data: 1490875420
I0605 11:53:40.754158 24036 layer_factory.hpp:77] Creating layer energy_ch_pool
I0605 11:53:40.754163 24036 net.cpp:106] Creating Layer energy_ch_pool
I0605 11:53:40.754168 24036 net.cpp:454] energy_ch_pool <- energy_ch_energy_ch_0_split_0
I0605 11:53:40.754173 24036 net.cpp:411] energy_ch_pool -> energy_ch_pool
I0605 11:53:40.754199 24036 net.cpp:150] Setting up energy_ch_pool
I0605 11:53:40.754202 24036 net.cpp:157] Top shape: 1 1 512 1 (512)
I0605 11:53:40.754204 24036 net.cpp:165] Memory required for data: 1490877468
I0605 11:53:40.754206 24036 layer_factory.hpp:77] Creating layer energy_ch_max
I0605 11:53:40.754212 24036 net.cpp:106] Creating Layer energy_ch_max
I0605 11:53:40.754216 24036 net.cpp:454] energy_ch_max <- energy_ch_pool
I0605 11:53:40.754220 24036 net.cpp:411] energy_ch_max -> energy_ch_max
I0605 11:53:40.754235 24036 net.cpp:150] Setting up energy_ch_max
I0605 11:53:40.754240 24036 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0605 11:53:40.754242 24036 net.cpp:165] Memory required for data: 1491926044
I0605 11:53:40.754245 24036 layer_factory.hpp:77] Creating layer energy_ch_minus
I0605 11:53:40.754248 24036 net.cpp:106] Creating Layer energy_ch_minus
I0605 11:53:40.754251 24036 net.cpp:454] energy_ch_minus <- energy_ch_energy_ch_0_split_1
I0605 11:53:40.754256 24036 net.cpp:411] energy_ch_minus -> energy_ch_minus
I0605 11:53:40.754276 24036 net.cpp:150] Setting up energy_ch_minus
I0605 11:53:40.754279 24036 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0605 11:53:40.754282 24036 net.cpp:165] Memory required for data: 1492974620
I0605 11:53:40.754284 24036 layer_factory.hpp:77] Creating layer energy_new
I0605 11:53:40.754289 24036 net.cpp:106] Creating Layer energy_new
I0605 11:53:40.754292 24036 net.cpp:454] energy_new <- energy_ch_max
I0605 11:53:40.754295 24036 net.cpp:454] energy_new <- energy_ch_minus
I0605 11:53:40.754300 24036 net.cpp:411] energy_new -> energy_new
I0605 11:53:40.754317 24036 net.cpp:150] Setting up energy_new
I0605 11:53:40.754323 24036 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0605 11:53:40.754324 24036 net.cpp:165] Memory required for data: 1494023196
I0605 11:53:40.754328 24036 layer_factory.hpp:77] Creating layer attention_ch
I0605 11:53:40.754331 24036 net.cpp:106] Creating Layer attention_ch
I0605 11:53:40.754336 24036 net.cpp:454] attention_ch <- energy_new
I0605 11:53:40.754339 24036 net.cpp:411] attention_ch -> attention_ch
I0605 11:53:40.754900 24036 net.cpp:150] Setting up attention_ch
I0605 11:53:40.754909 24036 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0605 11:53:40.754912 24036 net.cpp:165] Memory required for data: 1495071772
I0605 11:53:40.754915 24036 layer_factory.hpp:77] Creating layer value_conv_reshape_ch_perm
I0605 11:53:40.754920 24036 net.cpp:106] Creating Layer value_conv_reshape_ch_perm
I0605 11:53:40.754925 24036 net.cpp:454] value_conv_reshape_ch_perm <- value_conv_reshape_ch
I0605 11:53:40.754930 24036 net.cpp:411] value_conv_reshape_ch_perm -> value_conv_reshape_ch_perm
I0605 11:53:40.754995 24036 net.cpp:150] Setting up value_conv_reshape_ch_perm
I0605 11:53:40.755000 24036 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0605 11:53:40.755002 24036 net.cpp:165] Memory required for data: 1496914972
I0605 11:53:40.755005 24036 layer_factory.hpp:77] Creating layer attention_ch_perm
I0605 11:53:40.755012 24036 net.cpp:106] Creating Layer attention_ch_perm
I0605 11:53:40.755015 24036 net.cpp:454] attention_ch_perm <- attention_ch
I0605 11:53:40.755018 24036 net.cpp:411] attention_ch_perm -> attention_ch_perm
I0605 11:53:40.755082 24036 net.cpp:150] Setting up attention_ch_perm
I0605 11:53:40.755086 24036 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0605 11:53:40.755089 24036 net.cpp:165] Memory required for data: 1497963548
I0605 11:53:40.755091 24036 layer_factory.hpp:77] Creating layer out_ch
I0605 11:53:40.755096 24036 net.cpp:106] Creating Layer out_ch
I0605 11:53:40.755098 24036 net.cpp:454] out_ch <- attention_ch_perm
I0605 11:53:40.755102 24036 net.cpp:454] out_ch <- value_conv_reshape_ch_perm
I0605 11:53:40.755110 24036 net.cpp:411] out_ch -> out_ch
I0605 11:53:40.755127 24036 net.cpp:150] Setting up out_ch
I0605 11:53:40.755131 24036 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0605 11:53:40.755133 24036 net.cpp:165] Memory required for data: 1499806748
I0605 11:53:40.755136 24036 layer_factory.hpp:77] Creating layer out_ch_reshape
I0605 11:53:40.755141 24036 net.cpp:106] Creating Layer out_ch_reshape
I0605 11:53:40.755142 24036 net.cpp:454] out_ch_reshape <- out_ch
I0605 11:53:40.755146 24036 net.cpp:411] out_ch_reshape -> out_ch_reshape
I0605 11:53:40.755162 24036 net.cpp:150] Setting up out_ch_reshape
I0605 11:53:40.755165 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.755168 24036 net.cpp:165] Memory required for data: 1501649948
I0605 11:53:40.755170 24036 layer_factory.hpp:77] Creating layer out_ch_reshape_scale
I0605 11:53:40.755175 24036 net.cpp:106] Creating Layer out_ch_reshape_scale
I0605 11:53:40.755178 24036 net.cpp:454] out_ch_reshape_scale <- out_ch_reshape
I0605 11:53:40.755182 24036 net.cpp:411] out_ch_reshape_scale -> out_ch_reshape_scale
I0605 11:53:40.755236 24036 net.cpp:150] Setting up out_ch_reshape_scale
I0605 11:53:40.755241 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.755244 24036 net.cpp:165] Memory required for data: 1503493148
I0605 11:53:40.755246 24036 net.cpp:514] Sharing parameters 'scale_conv1_1' owned by layer 'out_reshape_scale', param index 0
I0605 11:53:40.755249 24036 layer_factory.hpp:77] Creating layer out_ch_x
I0605 11:53:40.755254 24036 net.cpp:106] Creating Layer out_ch_x
I0605 11:53:40.755255 24036 net.cpp:454] out_ch_x <- out_ch_reshape_scale
I0605 11:53:40.755259 24036 net.cpp:454] out_ch_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_7
I0605 11:53:40.755264 24036 net.cpp:411] out_ch_x -> out_ch_x
I0605 11:53:40.755278 24036 net.cpp:150] Setting up out_ch_x
I0605 11:53:40.755282 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.755285 24036 net.cpp:165] Memory required for data: 1505336348
I0605 11:53:40.755287 24036 layer_factory.hpp:77] Creating layer out_conv_ch_x
I0605 11:53:40.755300 24036 net.cpp:106] Creating Layer out_conv_ch_x
I0605 11:53:40.755302 24036 net.cpp:454] out_conv_ch_x <- out_ch_x
I0605 11:53:40.755307 24036 net.cpp:411] out_conv_ch_x -> out_conv_ch_x
I0605 11:53:40.761812 24036 net.cpp:150] Setting up out_conv_ch_x
I0605 11:53:40.761821 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.761824 24036 net.cpp:165] Memory required for data: 1507179548
I0605 11:53:40.761831 24036 layer_factory.hpp:77] Creating layer out_conv_x
I0605 11:53:40.761842 24036 net.cpp:106] Creating Layer out_conv_x
I0605 11:53:40.761847 24036 net.cpp:454] out_conv_x <- out_x
I0605 11:53:40.761857 24036 net.cpp:411] out_conv_x -> out_conv_x
I0605 11:53:40.768853 24036 net.cpp:150] Setting up out_conv_x
I0605 11:53:40.768862 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.768864 24036 net.cpp:165] Memory required for data: 1509022748
I0605 11:53:40.768870 24036 layer_factory.hpp:77] Creating layer out_x_sum
I0605 11:53:40.768877 24036 net.cpp:106] Creating Layer out_x_sum
I0605 11:53:40.768879 24036 net.cpp:454] out_x_sum <- out_conv_x
I0605 11:53:40.768882 24036 net.cpp:454] out_x_sum <- out_conv_ch_x
I0605 11:53:40.768887 24036 net.cpp:411] out_x_sum -> out_x_sum
I0605 11:53:40.768916 24036 net.cpp:150] Setting up out_x_sum
I0605 11:53:40.768924 24036 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 11:53:40.768929 24036 net.cpp:165] Memory required for data: 1510865948
I0605 11:53:40.768934 24036 layer_factory.hpp:77] Creating layer mask_deconv2
I0605 11:53:40.768941 24036 net.cpp:106] Creating Layer mask_deconv2
I0605 11:53:40.768946 24036 net.cpp:454] mask_deconv2 <- out_x_sum
I0605 11:53:40.768955 24036 net.cpp:411] mask_deconv2 -> mask_deconv2
I0605 11:53:40.769781 24036 net.cpp:150] Setting up mask_deconv2
I0605 11:53:40.769788 24036 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0605 11:53:40.769790 24036 net.cpp:165] Memory required for data: 1526107164
I0605 11:53:40.769794 24036 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0605 11:53:40.769804 24036 net.cpp:106] Creating Layer pool5_2_conv5
I0605 11:53:40.769809 24036 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0605 11:53:40.769816 24036 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0605 11:53:40.796928 24036 net.cpp:150] Setting up pool5_2_conv5
I0605 11:53:40.796947 24036 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 11:53:40.796949 24036 net.cpp:165] Memory required for data: 1556589596
I0605 11:53:40.796967 24036 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0605 11:53:40.796978 24036 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0605 11:53:40.796986 24036 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0605 11:53:40.796993 24036 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0605 11:53:40.797170 24036 net.cpp:150] Setting up pool5_2_conv5_relu
I0605 11:53:40.797178 24036 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 11:53:40.797180 24036 net.cpp:165] Memory required for data: 1587072028
I0605 11:53:40.797194 24036 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0605 11:53:40.797207 24036 net.cpp:106] Creating Layer pool5_2_conv6
I0605 11:53:40.797222 24036 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0605 11:53:40.797230 24036 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0605 11:53:40.848740 24036 net.cpp:150] Setting up pool5_2_conv6
I0605 11:53:40.848759 24036 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 11:53:40.848763 24036 net.cpp:165] Memory required for data: 1617554460
I0605 11:53:40.848770 24036 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0605 11:53:40.848788 24036 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0605 11:53:40.848794 24036 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0605 11:53:40.848803 24036 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0605 11:53:40.849429 24036 net.cpp:150] Setting up pool5_2_conv6_relu
I0605 11:53:40.849445 24036 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 11:53:40.849447 24036 net.cpp:165] Memory required for data: 1648036892
I0605 11:53:40.849460 24036 layer_factory.hpp:77] Creating layer mask_deconv3
I0605 11:53:40.849469 24036 net.cpp:106] Creating Layer mask_deconv3
I0605 11:53:40.849473 24036 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0605 11:53:40.849481 24036 net.cpp:411] mask_deconv3 -> mask_deconv3
I0605 11:53:40.849894 24036 net.cpp:150] Setting up mask_deconv3
I0605 11:53:40.849900 24036 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0605 11:53:40.849902 24036 net.cpp:165] Memory required for data: 1709001756
I0605 11:53:40.849907 24036 layer_factory.hpp:77] Creating layer mask_score
I0605 11:53:40.849915 24036 net.cpp:106] Creating Layer mask_score
I0605 11:53:40.849918 24036 net.cpp:454] mask_score <- mask_deconv3
I0605 11:53:40.849932 24036 net.cpp:411] mask_score -> mask_score
I0605 11:53:40.850978 24036 net.cpp:150] Setting up mask_score
I0605 11:53:40.850987 24036 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0605 11:53:40.850989 24036 net.cpp:165] Memory required for data: 1710906908
I0605 11:53:40.850994 24036 layer_factory.hpp:77] Creating layer loss_mask
I0605 11:53:40.851001 24036 net.cpp:106] Creating Layer loss_mask
I0605 11:53:40.851004 24036 net.cpp:454] loss_mask <- mask_score
I0605 11:53:40.851017 24036 net.cpp:454] loss_mask <- mask_targets
I0605 11:53:40.851022 24036 net.cpp:411] loss_mask -> loss_mask
I0605 11:53:40.851043 24036 layer_factory.hpp:77] Creating layer loss_mask
I0605 11:53:40.852113 24036 net.cpp:150] Setting up loss_mask
I0605 11:53:40.852121 24036 net.cpp:157] Top shape: (1)
I0605 11:53:40.852123 24036 net.cpp:160]     with loss weight 3
I0605 11:53:40.852130 24036 net.cpp:165] Memory required for data: 1710906912
I0605 11:53:40.852133 24036 net.cpp:226] loss_mask needs backward computation.
I0605 11:53:40.852135 24036 net.cpp:226] mask_score needs backward computation.
I0605 11:53:40.852138 24036 net.cpp:226] mask_deconv3 needs backward computation.
I0605 11:53:40.852150 24036 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0605 11:53:40.852154 24036 net.cpp:226] pool5_2_conv6 needs backward computation.
I0605 11:53:40.852157 24036 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0605 11:53:40.852162 24036 net.cpp:226] pool5_2_conv5 needs backward computation.
I0605 11:53:40.852166 24036 net.cpp:226] mask_deconv2 needs backward computation.
I0605 11:53:40.852170 24036 net.cpp:226] out_x_sum needs backward computation.
I0605 11:53:40.852174 24036 net.cpp:226] out_conv_x needs backward computation.
I0605 11:53:40.852190 24036 net.cpp:226] out_conv_ch_x needs backward computation.
I0605 11:53:40.852195 24036 net.cpp:226] out_ch_x needs backward computation.
I0605 11:53:40.852202 24036 net.cpp:226] out_ch_reshape_scale needs backward computation.
I0605 11:53:40.852208 24036 net.cpp:226] out_ch_reshape needs backward computation.
I0605 11:53:40.852222 24036 net.cpp:226] out_ch needs backward computation.
I0605 11:53:40.852227 24036 net.cpp:226] attention_ch_perm needs backward computation.
I0605 11:53:40.852231 24036 net.cpp:226] value_conv_reshape_ch_perm needs backward computation.
I0605 11:53:40.852236 24036 net.cpp:226] attention_ch needs backward computation.
I0605 11:53:40.852241 24036 net.cpp:226] energy_new needs backward computation.
I0605 11:53:40.852246 24036 net.cpp:226] energy_ch_minus needs backward computation.
I0605 11:53:40.852252 24036 net.cpp:226] energy_ch_max needs backward computation.
I0605 11:53:40.852257 24036 net.cpp:226] energy_ch_pool needs backward computation.
I0605 11:53:40.852263 24036 net.cpp:226] energy_ch_energy_ch_0_split needs backward computation.
I0605 11:53:40.852267 24036 net.cpp:226] energy_ch needs backward computation.
I0605 11:53:40.852273 24036 net.cpp:226] key_conv_reshape_perm_ch needs backward computation.
I0605 11:53:40.852278 24036 net.cpp:226] query_conv_reshape_perm_ch needs backward computation.
I0605 11:53:40.852284 24036 net.cpp:226] value_conv_reshape_ch needs backward computation.
I0605 11:53:40.852289 24036 net.cpp:226] key_conv_reshape_ch needs backward computation.
I0605 11:53:40.852293 24036 net.cpp:226] query_conv_reshape_ch needs backward computation.
I0605 11:53:40.852300 24036 net.cpp:226] out_x needs backward computation.
I0605 11:53:40.852310 24036 net.cpp:226] out_reshape_scale needs backward computation.
I0605 11:53:40.852316 24036 net.cpp:226] out_reshape needs backward computation.
I0605 11:53:40.852324 24036 net.cpp:226] out needs backward computation.
I0605 11:53:40.852330 24036 net.cpp:226] attention_perm needs backward computation.
I0605 11:53:40.852334 24036 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0605 11:53:40.852339 24036 net.cpp:226] attention needs backward computation.
I0605 11:53:40.852345 24036 net.cpp:226] energy needs backward computation.
I0605 11:53:40.852360 24036 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0605 11:53:40.852365 24036 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0605 11:53:40.852372 24036 net.cpp:226] value_conv_reshape needs backward computation.
I0605 11:53:40.852376 24036 net.cpp:226] key_conv_reshape needs backward computation.
I0605 11:53:40.852381 24036 net.cpp:226] query_conv_reshape needs backward computation.
I0605 11:53:40.852386 24036 net.cpp:226] value_conv needs backward computation.
I0605 11:53:40.852392 24036 net.cpp:226] key_conv needs backward computation.
I0605 11:53:40.852409 24036 net.cpp:226] query_conv needs backward computation.
I0605 11:53:40.852414 24036 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0605 11:53:40.852430 24036 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0605 11:53:40.852434 24036 net.cpp:226] pool5_2_conv4 needs backward computation.
I0605 11:53:40.852442 24036 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0605 11:53:40.852447 24036 net.cpp:226] pool5_2_conv3 needs backward computation.
I0605 11:53:40.852464 24036 net.cpp:226] mask_deconv1 needs backward computation.
I0605 11:53:40.852469 24036 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0605 11:53:40.852476 24036 net.cpp:226] pool5_2_conv2 needs backward computation.
I0605 11:53:40.852480 24036 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0605 11:53:40.852486 24036 net.cpp:226] pool5_2_conv needs backward computation.
I0605 11:53:40.852491 24036 net.cpp:226] roi_pool5_2 needs backward computation.
I0605 11:53:40.852497 24036 net.cpp:226] loss_bbox needs backward computation.
I0605 11:53:40.852504 24036 net.cpp:226] loss_cls needs backward computation.
I0605 11:53:40.852510 24036 net.cpp:226] bbox_pred needs backward computation.
I0605 11:53:40.852516 24036 net.cpp:226] cls_score needs backward computation.
I0605 11:53:40.852520 24036 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0605 11:53:40.852526 24036 net.cpp:226] relu7 needs backward computation.
I0605 11:53:40.852532 24036 net.cpp:226] fc7 needs backward computation.
I0605 11:53:40.852536 24036 net.cpp:226] relu6 needs backward computation.
I0605 11:53:40.852541 24036 net.cpp:226] fc6 needs backward computation.
I0605 11:53:40.852546 24036 net.cpp:226] roi_pool5 needs backward computation.
I0605 11:53:40.852552 24036 net.cpp:226] roi-data needs backward computation.
I0605 11:53:40.852562 24036 net.cpp:226] proposal needs backward computation.
I0605 11:53:40.852569 24036 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0605 11:53:40.852576 24036 net.cpp:226] rpn_cls_prob needs backward computation.
I0605 11:53:40.852581 24036 net.cpp:226] rpn_loss_bbox needs backward computation.
I0605 11:53:40.852586 24036 net.cpp:226] rpn_loss_cls needs backward computation.
I0605 11:53:40.852596 24036 net.cpp:226] rpn-data needs backward computation.
I0605 11:53:40.852602 24036 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0605 11:53:40.852609 24036 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0605 11:53:40.852613 24036 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0605 11:53:40.852618 24036 net.cpp:226] rpn_bbox_pred needs backward computation.
I0605 11:53:40.852622 24036 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0605 11:53:40.852628 24036 net.cpp:226] rpn_cls_score needs backward computation.
I0605 11:53:40.852635 24036 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0605 11:53:40.852639 24036 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0605 11:53:40.852645 24036 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0605 11:53:40.852661 24036 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0605 11:53:40.852669 24036 net.cpp:226] relu5_3 needs backward computation.
I0605 11:53:40.852672 24036 net.cpp:226] conv5_3 needs backward computation.
I0605 11:53:40.852679 24036 net.cpp:226] relu5_2 needs backward computation.
I0605 11:53:40.852684 24036 net.cpp:226] conv5_2 needs backward computation.
I0605 11:53:40.852689 24036 net.cpp:226] relu5_1 needs backward computation.
I0605 11:53:40.852696 24036 net.cpp:226] conv5_1 needs backward computation.
I0605 11:53:40.852700 24036 net.cpp:226] pool4 needs backward computation.
I0605 11:53:40.852705 24036 net.cpp:226] relu4_3 needs backward computation.
I0605 11:53:40.852712 24036 net.cpp:226] conv4_3 needs backward computation.
I0605 11:53:40.852717 24036 net.cpp:226] relu4_2 needs backward computation.
I0605 11:53:40.852722 24036 net.cpp:226] conv4_2 needs backward computation.
I0605 11:53:40.852726 24036 net.cpp:226] relu4_1 needs backward computation.
I0605 11:53:40.852731 24036 net.cpp:226] conv4_1 needs backward computation.
I0605 11:53:40.852735 24036 net.cpp:226] pool3 needs backward computation.
I0605 11:53:40.852741 24036 net.cpp:226] relu3_3 needs backward computation.
I0605 11:53:40.852746 24036 net.cpp:226] conv3_3 needs backward computation.
I0605 11:53:40.852751 24036 net.cpp:226] relu3_2 needs backward computation.
I0605 11:53:40.852758 24036 net.cpp:226] conv3_2 needs backward computation.
I0605 11:53:40.852764 24036 net.cpp:226] relu3_1 needs backward computation.
I0605 11:53:40.852771 24036 net.cpp:226] conv3_1 needs backward computation.
I0605 11:53:40.852777 24036 net.cpp:228] pool2 does not need backward computation.
I0605 11:53:40.852790 24036 net.cpp:228] relu2_2 does not need backward computation.
I0605 11:53:40.852803 24036 net.cpp:228] conv2_2 does not need backward computation.
I0605 11:53:40.852811 24036 net.cpp:228] relu2_1 does not need backward computation.
I0605 11:53:40.852816 24036 net.cpp:228] conv2_1 does not need backward computation.
I0605 11:53:40.852823 24036 net.cpp:228] pool1 does not need backward computation.
I0605 11:53:40.852829 24036 net.cpp:228] relu1_2 does not need backward computation.
I0605 11:53:40.852835 24036 net.cpp:228] conv1_2 does not need backward computation.
I0605 11:53:40.852843 24036 net.cpp:228] relu1_1 does not need backward computation.
I0605 11:53:40.852846 24036 net.cpp:228] conv1_1 does not need backward computation.
I0605 11:53:40.852854 24036 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0605 11:53:40.852861 24036 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0605 11:53:40.852867 24036 net.cpp:228] data_input-data_0_split does not need backward computation.
I0605 11:53:40.852874 24036 net.cpp:228] input-data does not need backward computation.
I0605 11:53:40.852880 24036 net.cpp:270] This network produces output loss_bbox
I0605 11:53:40.852886 24036 net.cpp:270] This network produces output loss_cls
I0605 11:53:40.852892 24036 net.cpp:270] This network produces output loss_mask
I0605 11:53:40.852896 24036 net.cpp:270] This network produces output rpn_cls_loss
I0605 11:53:40.852902 24036 net.cpp:270] This network produces output rpn_loss_bbox
I0605 11:53:40.852994 24036 net.cpp:283] Network initialization done.
I0605 11:53:40.853230 24036 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0605 11:53:52.313261 24036 net.cpp:816] Ignoring source layer pool5
I0605 11:53:52.386261 24036 net.cpp:816] Ignoring source layer drop6
I0605 11:53:52.397974 24036 net.cpp:816] Ignoring source layer drop7
I0605 11:53:52.397989 24036 net.cpp:816] Ignoring source layer fc8
I0605 11:53:52.397991 24036 net.cpp:816] Ignoring source layer prob
Solving...
15080
15080
15735
15735
I0605 11:53:54.167860 24036 solver.cpp:229] Iteration 0, loss = 9.12671
I0605 11:53:54.167894 24036 solver.cpp:245]     Train net output #0: loss_bbox = 0.244229 (* 2 = 0.488458 loss)
I0605 11:53:54.167902 24036 solver.cpp:245]     Train net output #1: loss_cls = 0.52338 (* 3 = 1.57014 loss)
I0605 11:53:54.167909 24036 solver.cpp:245]     Train net output #2: loss_mask = 2.07894 (* 3 = 6.23681 loss)
I0605 11:53:54.167933 24036 solver.cpp:245]     Train net output #3: rpn_cls_loss = 0.728647 (* 1 = 0.728647 loss)
I0605 11:53:54.167942 24036 solver.cpp:245]     Train net output #4: rpn_loss_bbox = 0.0193384 (* 1 = 0.0193384 loss)
I0605 11:53:54.167963 24036 sgd_solver.cpp:106] Iteration 0, lr = 0.001
20639
20639
6260
6260
925
925
