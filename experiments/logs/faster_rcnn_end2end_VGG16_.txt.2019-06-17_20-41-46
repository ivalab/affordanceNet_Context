+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-17_20-41-46
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-17_20-41-46
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 16,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0617 20:41:53.134577  6875 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0617 20:41:53.134596  6875 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0617 20:41:53.136008  6875 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  top: "attrArray"
  top: "attrArrayInd"
  top: "attrArrayShift"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "attr_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "attr_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "attr_score_pos"
  type: "Eltwise"
  bottom: "attr_score"
  bottom: "attrArrayInd"
  top: "attr_score_pos"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "attr_score_pos_shift"
  type: "Eltwise"
  bottom: "attr_score_pos"
  bottom: "attrArrayShift"
  top: "attr_score_pos_shift"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_attribute"
  type: "SigmoidCrossEntropyLoss"
  bottom: "attr_score_pos_shift"
  bottom: "attrArray"
  top: "loss_attribute"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_mask"
  type: "SoftmaxWithLoss"
  bottom: "mask_score"
  bottom: "mask_targets"
  top: "loss_mask"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "pool5_2_conv5_2"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5_2"
  top: "pool5_2_conv5_2_relu"
}
layer {
  name: "mask_deconv3_2"
  type: "Deconvolution"
  bottom: "pool5_2_conv5_2_relu"
  top: "mask_deconv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score_2"
  type: "Convolution"
  bottom: "mask_deconv3_2"
  top: "mask_score_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_mask_2"
  type: "SoftmaxWithLoss"
  bottom: "mask_score_2"
  bottom: "mask_targets"
  top: "loss_mask_2"
  loss_weight: 0.3
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
I0617 20:41:53.136303  6875 layer_factory.hpp:77] Creating layer input-data
I0617 20:41:53.148056  6875 net.cpp:106] Creating Layer input-data
I0617 20:41:53.148080  6875 net.cpp:411] input-data -> data
I0617 20:41:53.148087  6875 net.cpp:411] input-data -> im_info
I0617 20:41:53.148102  6875 net.cpp:411] input-data -> gt_boxes
I0617 20:41:53.148105  6875 net.cpp:411] input-data -> seg_mask_inds
I0617 20:41:53.148108  6875 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0617 20:41:53.158402  6875 net.cpp:150] Setting up input-data
I0617 20:41:53.158437  6875 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0617 20:41:53.158440  6875 net.cpp:157] Top shape: 1 3 (3)
I0617 20:41:53.158442  6875 net.cpp:157] Top shape: 1 4 (4)
I0617 20:41:53.158444  6875 net.cpp:157] Top shape: 1 2 (2)
I0617 20:41:53.158447  6875 net.cpp:157] Top shape: 1 1 (1)
I0617 20:41:53.158447  6875 net.cpp:165] Memory required for data: 7200040
I0617 20:41:53.158452  6875 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0617 20:41:53.158474  6875 net.cpp:106] Creating Layer data_input-data_0_split
I0617 20:41:53.158478  6875 net.cpp:454] data_input-data_0_split <- data
I0617 20:41:53.158490  6875 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0617 20:41:53.158496  6875 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0617 20:41:53.158525  6875 net.cpp:150] Setting up data_input-data_0_split
I0617 20:41:53.158529  6875 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0617 20:41:53.158531  6875 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0617 20:41:53.158532  6875 net.cpp:165] Memory required for data: 21600040
I0617 20:41:53.158535  6875 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0617 20:41:53.158538  6875 net.cpp:106] Creating Layer im_info_input-data_1_split
I0617 20:41:53.158550  6875 net.cpp:454] im_info_input-data_1_split <- im_info
I0617 20:41:53.158553  6875 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0617 20:41:53.158557  6875 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0617 20:41:53.158571  6875 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0617 20:41:53.158612  6875 net.cpp:150] Setting up im_info_input-data_1_split
I0617 20:41:53.158615  6875 net.cpp:157] Top shape: 1 3 (3)
I0617 20:41:53.158617  6875 net.cpp:157] Top shape: 1 3 (3)
I0617 20:41:53.158619  6875 net.cpp:157] Top shape: 1 3 (3)
I0617 20:41:53.158620  6875 net.cpp:165] Memory required for data: 21600076
I0617 20:41:53.158633  6875 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0617 20:41:53.158637  6875 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0617 20:41:53.158638  6875 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0617 20:41:53.158640  6875 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0617 20:41:53.158643  6875 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0617 20:41:53.158668  6875 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0617 20:41:53.158670  6875 net.cpp:157] Top shape: 1 4 (4)
I0617 20:41:53.158673  6875 net.cpp:157] Top shape: 1 4 (4)
I0617 20:41:53.158674  6875 net.cpp:165] Memory required for data: 21600108
I0617 20:41:53.158675  6875 layer_factory.hpp:77] Creating layer conv1_1
I0617 20:41:53.158682  6875 net.cpp:106] Creating Layer conv1_1
I0617 20:41:53.158684  6875 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0617 20:41:53.158687  6875 net.cpp:411] conv1_1 -> conv1_1
I0617 20:41:53.319227  6875 net.cpp:150] Setting up conv1_1
I0617 20:41:53.319250  6875 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0617 20:41:53.319254  6875 net.cpp:165] Memory required for data: 175200108
I0617 20:41:53.319269  6875 layer_factory.hpp:77] Creating layer relu1_1
I0617 20:41:53.319279  6875 net.cpp:106] Creating Layer relu1_1
I0617 20:41:53.319285  6875 net.cpp:454] relu1_1 <- conv1_1
I0617 20:41:53.319288  6875 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0617 20:41:53.319424  6875 net.cpp:150] Setting up relu1_1
I0617 20:41:53.319430  6875 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0617 20:41:53.319432  6875 net.cpp:165] Memory required for data: 328800108
I0617 20:41:53.319434  6875 layer_factory.hpp:77] Creating layer conv1_2
I0617 20:41:53.319440  6875 net.cpp:106] Creating Layer conv1_2
I0617 20:41:53.319442  6875 net.cpp:454] conv1_2 <- conv1_1
I0617 20:41:53.319447  6875 net.cpp:411] conv1_2 -> conv1_2
I0617 20:41:53.323599  6875 net.cpp:150] Setting up conv1_2
I0617 20:41:53.323626  6875 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0617 20:41:53.323627  6875 net.cpp:165] Memory required for data: 482400108
I0617 20:41:53.323637  6875 layer_factory.hpp:77] Creating layer relu1_2
I0617 20:41:53.323653  6875 net.cpp:106] Creating Layer relu1_2
I0617 20:41:53.323658  6875 net.cpp:454] relu1_2 <- conv1_2
I0617 20:41:53.323662  6875 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0617 20:41:53.323791  6875 net.cpp:150] Setting up relu1_2
I0617 20:41:53.323797  6875 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0617 20:41:53.323809  6875 net.cpp:165] Memory required for data: 636000108
I0617 20:41:53.323812  6875 layer_factory.hpp:77] Creating layer pool1
I0617 20:41:53.323817  6875 net.cpp:106] Creating Layer pool1
I0617 20:41:53.323819  6875 net.cpp:454] pool1 <- conv1_2
I0617 20:41:53.323832  6875 net.cpp:411] pool1 -> pool1
I0617 20:41:53.323882  6875 net.cpp:150] Setting up pool1
I0617 20:41:53.323886  6875 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0617 20:41:53.323887  6875 net.cpp:165] Memory required for data: 674400108
I0617 20:41:53.323899  6875 layer_factory.hpp:77] Creating layer conv2_1
I0617 20:41:53.323905  6875 net.cpp:106] Creating Layer conv2_1
I0617 20:41:53.323907  6875 net.cpp:454] conv2_1 <- pool1
I0617 20:41:53.323909  6875 net.cpp:411] conv2_1 -> conv2_1
I0617 20:41:53.325567  6875 net.cpp:150] Setting up conv2_1
I0617 20:41:53.325574  6875 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0617 20:41:53.325587  6875 net.cpp:165] Memory required for data: 751200108
I0617 20:41:53.325592  6875 layer_factory.hpp:77] Creating layer relu2_1
I0617 20:41:53.325597  6875 net.cpp:106] Creating Layer relu2_1
I0617 20:41:53.325598  6875 net.cpp:454] relu2_1 <- conv2_1
I0617 20:41:53.325601  6875 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0617 20:41:53.326071  6875 net.cpp:150] Setting up relu2_1
I0617 20:41:53.326078  6875 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0617 20:41:53.326090  6875 net.cpp:165] Memory required for data: 828000108
I0617 20:41:53.326092  6875 layer_factory.hpp:77] Creating layer conv2_2
I0617 20:41:53.326098  6875 net.cpp:106] Creating Layer conv2_2
I0617 20:41:53.326099  6875 net.cpp:454] conv2_2 <- conv2_1
I0617 20:41:53.326113  6875 net.cpp:411] conv2_2 -> conv2_2
I0617 20:41:53.327410  6875 net.cpp:150] Setting up conv2_2
I0617 20:41:53.327419  6875 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0617 20:41:53.327420  6875 net.cpp:165] Memory required for data: 904800108
I0617 20:41:53.327425  6875 layer_factory.hpp:77] Creating layer relu2_2
I0617 20:41:53.327427  6875 net.cpp:106] Creating Layer relu2_2
I0617 20:41:53.327430  6875 net.cpp:454] relu2_2 <- conv2_2
I0617 20:41:53.327433  6875 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0617 20:41:53.327579  6875 net.cpp:150] Setting up relu2_2
I0617 20:41:53.327584  6875 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0617 20:41:53.327585  6875 net.cpp:165] Memory required for data: 981600108
I0617 20:41:53.327587  6875 layer_factory.hpp:77] Creating layer pool2
I0617 20:41:53.327591  6875 net.cpp:106] Creating Layer pool2
I0617 20:41:53.327594  6875 net.cpp:454] pool2 <- conv2_2
I0617 20:41:53.327595  6875 net.cpp:411] pool2 -> pool2
I0617 20:41:53.327651  6875 net.cpp:150] Setting up pool2
I0617 20:41:53.327654  6875 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0617 20:41:53.327656  6875 net.cpp:165] Memory required for data: 1000800108
I0617 20:41:53.327657  6875 layer_factory.hpp:77] Creating layer conv3_1
I0617 20:41:53.327672  6875 net.cpp:106] Creating Layer conv3_1
I0617 20:41:53.327674  6875 net.cpp:454] conv3_1 <- pool2
I0617 20:41:53.327677  6875 net.cpp:411] conv3_1 -> conv3_1
I0617 20:41:53.329411  6875 net.cpp:150] Setting up conv3_1
I0617 20:41:53.329419  6875 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0617 20:41:53.329421  6875 net.cpp:165] Memory required for data: 1039200108
I0617 20:41:53.329428  6875 layer_factory.hpp:77] Creating layer relu3_1
I0617 20:41:53.329432  6875 net.cpp:106] Creating Layer relu3_1
I0617 20:41:53.329433  6875 net.cpp:454] relu3_1 <- conv3_1
I0617 20:41:53.329437  6875 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0617 20:41:53.329576  6875 net.cpp:150] Setting up relu3_1
I0617 20:41:53.329582  6875 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0617 20:41:53.329593  6875 net.cpp:165] Memory required for data: 1077600108
I0617 20:41:53.329596  6875 layer_factory.hpp:77] Creating layer conv3_2
I0617 20:41:53.329602  6875 net.cpp:106] Creating Layer conv3_2
I0617 20:41:53.329614  6875 net.cpp:454] conv3_2 <- conv3_1
I0617 20:41:53.329618  6875 net.cpp:411] conv3_2 -> conv3_2
I0617 20:41:53.331755  6875 net.cpp:150] Setting up conv3_2
I0617 20:41:53.331780  6875 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0617 20:41:53.331784  6875 net.cpp:165] Memory required for data: 1116000108
I0617 20:41:53.331789  6875 layer_factory.hpp:77] Creating layer relu3_2
I0617 20:41:53.331795  6875 net.cpp:106] Creating Layer relu3_2
I0617 20:41:53.331799  6875 net.cpp:454] relu3_2 <- conv3_2
I0617 20:41:53.331802  6875 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0617 20:41:53.331938  6875 net.cpp:150] Setting up relu3_2
I0617 20:41:53.331945  6875 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0617 20:41:53.331957  6875 net.cpp:165] Memory required for data: 1154400108
I0617 20:41:53.331959  6875 layer_factory.hpp:77] Creating layer conv3_3
I0617 20:41:53.331964  6875 net.cpp:106] Creating Layer conv3_3
I0617 20:41:53.331979  6875 net.cpp:454] conv3_3 <- conv3_2
I0617 20:41:53.331981  6875 net.cpp:411] conv3_3 -> conv3_3
I0617 20:41:53.334100  6875 net.cpp:150] Setting up conv3_3
I0617 20:41:53.334110  6875 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0617 20:41:53.334111  6875 net.cpp:165] Memory required for data: 1192800108
I0617 20:41:53.334116  6875 layer_factory.hpp:77] Creating layer relu3_3
I0617 20:41:53.334120  6875 net.cpp:106] Creating Layer relu3_3
I0617 20:41:53.334122  6875 net.cpp:454] relu3_3 <- conv3_3
I0617 20:41:53.334125  6875 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0617 20:41:53.334305  6875 net.cpp:150] Setting up relu3_3
I0617 20:41:53.334311  6875 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0617 20:41:53.334313  6875 net.cpp:165] Memory required for data: 1231200108
I0617 20:41:53.334314  6875 layer_factory.hpp:77] Creating layer pool3
I0617 20:41:53.334321  6875 net.cpp:106] Creating Layer pool3
I0617 20:41:53.334321  6875 net.cpp:454] pool3 <- conv3_3
I0617 20:41:53.334326  6875 net.cpp:411] pool3 -> pool3
I0617 20:41:53.334385  6875 net.cpp:150] Setting up pool3
I0617 20:41:53.334389  6875 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0617 20:41:53.334391  6875 net.cpp:165] Memory required for data: 1240800108
I0617 20:41:53.334403  6875 layer_factory.hpp:77] Creating layer conv4_1
I0617 20:41:53.334408  6875 net.cpp:106] Creating Layer conv4_1
I0617 20:41:53.334409  6875 net.cpp:454] conv4_1 <- pool3
I0617 20:41:53.334424  6875 net.cpp:411] conv4_1 -> conv4_1
I0617 20:41:53.338063  6875 net.cpp:150] Setting up conv4_1
I0617 20:41:53.338079  6875 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0617 20:41:53.338083  6875 net.cpp:165] Memory required for data: 1260000108
I0617 20:41:53.338088  6875 layer_factory.hpp:77] Creating layer relu4_1
I0617 20:41:53.338096  6875 net.cpp:106] Creating Layer relu4_1
I0617 20:41:53.338109  6875 net.cpp:454] relu4_1 <- conv4_1
I0617 20:41:53.338115  6875 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0617 20:41:53.338253  6875 net.cpp:150] Setting up relu4_1
I0617 20:41:53.338279  6875 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0617 20:41:53.338281  6875 net.cpp:165] Memory required for data: 1279200108
I0617 20:41:53.338284  6875 layer_factory.hpp:77] Creating layer conv4_2
I0617 20:41:53.338292  6875 net.cpp:106] Creating Layer conv4_2
I0617 20:41:53.338294  6875 net.cpp:454] conv4_2 <- conv4_1
I0617 20:41:53.338299  6875 net.cpp:411] conv4_2 -> conv4_2
I0617 20:41:53.342859  6875 net.cpp:150] Setting up conv4_2
I0617 20:41:53.342877  6875 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0617 20:41:53.342880  6875 net.cpp:165] Memory required for data: 1298400108
I0617 20:41:53.342890  6875 layer_factory.hpp:77] Creating layer relu4_2
I0617 20:41:53.342908  6875 net.cpp:106] Creating Layer relu4_2
I0617 20:41:53.342912  6875 net.cpp:454] relu4_2 <- conv4_2
I0617 20:41:53.342916  6875 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0617 20:41:53.343400  6875 net.cpp:150] Setting up relu4_2
I0617 20:41:53.343406  6875 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0617 20:41:53.343408  6875 net.cpp:165] Memory required for data: 1317600108
I0617 20:41:53.343410  6875 layer_factory.hpp:77] Creating layer conv4_3
I0617 20:41:53.343417  6875 net.cpp:106] Creating Layer conv4_3
I0617 20:41:53.343420  6875 net.cpp:454] conv4_3 <- conv4_2
I0617 20:41:53.343422  6875 net.cpp:411] conv4_3 -> conv4_3
I0617 20:41:53.348755  6875 net.cpp:150] Setting up conv4_3
I0617 20:41:53.348783  6875 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0617 20:41:53.348785  6875 net.cpp:165] Memory required for data: 1336800108
I0617 20:41:53.348791  6875 layer_factory.hpp:77] Creating layer relu4_3
I0617 20:41:53.348809  6875 net.cpp:106] Creating Layer relu4_3
I0617 20:41:53.348814  6875 net.cpp:454] relu4_3 <- conv4_3
I0617 20:41:53.348817  6875 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0617 20:41:53.348944  6875 net.cpp:150] Setting up relu4_3
I0617 20:41:53.348950  6875 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0617 20:41:53.348951  6875 net.cpp:165] Memory required for data: 1356000108
I0617 20:41:53.348963  6875 layer_factory.hpp:77] Creating layer pool4
I0617 20:41:53.348969  6875 net.cpp:106] Creating Layer pool4
I0617 20:41:53.348970  6875 net.cpp:454] pool4 <- conv4_3
I0617 20:41:53.348984  6875 net.cpp:411] pool4 -> pool4
I0617 20:41:53.349021  6875 net.cpp:150] Setting up pool4
I0617 20:41:53.349025  6875 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0617 20:41:53.349027  6875 net.cpp:165] Memory required for data: 1360903020
I0617 20:41:53.349037  6875 layer_factory.hpp:77] Creating layer conv5_1
I0617 20:41:53.349043  6875 net.cpp:106] Creating Layer conv5_1
I0617 20:41:53.349056  6875 net.cpp:454] conv5_1 <- pool4
I0617 20:41:53.349059  6875 net.cpp:411] conv5_1 -> conv5_1
I0617 20:41:53.353477  6875 net.cpp:150] Setting up conv5_1
I0617 20:41:53.353495  6875 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0617 20:41:53.353497  6875 net.cpp:165] Memory required for data: 1365805932
I0617 20:41:53.353503  6875 layer_factory.hpp:77] Creating layer relu5_1
I0617 20:41:53.353511  6875 net.cpp:106] Creating Layer relu5_1
I0617 20:41:53.353514  6875 net.cpp:454] relu5_1 <- conv5_1
I0617 20:41:53.353529  6875 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0617 20:41:53.353649  6875 net.cpp:150] Setting up relu5_1
I0617 20:41:53.353655  6875 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0617 20:41:53.353657  6875 net.cpp:165] Memory required for data: 1370708844
I0617 20:41:53.353658  6875 layer_factory.hpp:77] Creating layer conv5_2
I0617 20:41:53.353664  6875 net.cpp:106] Creating Layer conv5_2
I0617 20:41:53.353667  6875 net.cpp:454] conv5_2 <- conv5_1
I0617 20:41:53.353670  6875 net.cpp:411] conv5_2 -> conv5_2
I0617 20:41:53.357865  6875 net.cpp:150] Setting up conv5_2
I0617 20:41:53.357883  6875 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0617 20:41:53.357887  6875 net.cpp:165] Memory required for data: 1375611756
I0617 20:41:53.357892  6875 layer_factory.hpp:77] Creating layer relu5_2
I0617 20:41:53.357899  6875 net.cpp:106] Creating Layer relu5_2
I0617 20:41:53.357903  6875 net.cpp:454] relu5_2 <- conv5_2
I0617 20:41:53.357909  6875 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0617 20:41:53.358038  6875 net.cpp:150] Setting up relu5_2
I0617 20:41:53.358044  6875 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0617 20:41:53.358047  6875 net.cpp:165] Memory required for data: 1380514668
I0617 20:41:53.358047  6875 layer_factory.hpp:77] Creating layer conv5_3
I0617 20:41:53.358057  6875 net.cpp:106] Creating Layer conv5_3
I0617 20:41:53.358059  6875 net.cpp:454] conv5_3 <- conv5_2
I0617 20:41:53.358073  6875 net.cpp:411] conv5_3 -> conv5_3
I0617 20:41:53.362327  6875 net.cpp:150] Setting up conv5_3
I0617 20:41:53.362346  6875 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0617 20:41:53.362349  6875 net.cpp:165] Memory required for data: 1385417580
I0617 20:41:53.362355  6875 layer_factory.hpp:77] Creating layer relu5_3
I0617 20:41:53.362362  6875 net.cpp:106] Creating Layer relu5_3
I0617 20:41:53.362365  6875 net.cpp:454] relu5_3 <- conv5_3
I0617 20:41:53.362371  6875 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0617 20:41:53.362504  6875 net.cpp:150] Setting up relu5_3
I0617 20:41:53.362509  6875 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0617 20:41:53.362511  6875 net.cpp:165] Memory required for data: 1390320492
I0617 20:41:53.362514  6875 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0617 20:41:53.362516  6875 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0617 20:41:53.362519  6875 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0617 20:41:53.362522  6875 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0617 20:41:53.362526  6875 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0617 20:41:53.362529  6875 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0617 20:41:53.362581  6875 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0617 20:41:53.362584  6875 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0617 20:41:53.362586  6875 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0617 20:41:53.362588  6875 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0617 20:41:53.362591  6875 net.cpp:165] Memory required for data: 1405029228
I0617 20:41:53.362591  6875 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0617 20:41:53.362598  6875 net.cpp:106] Creating Layer rpn_conv/3x3
I0617 20:41:53.362601  6875 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0617 20:41:53.362604  6875 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0617 20:41:53.413511  6875 net.cpp:150] Setting up rpn_conv/3x3
I0617 20:41:53.413529  6875 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0617 20:41:53.413532  6875 net.cpp:165] Memory required for data: 1409932140
I0617 20:41:53.413537  6875 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0617 20:41:53.413543  6875 net.cpp:106] Creating Layer rpn_relu/3x3
I0617 20:41:53.413547  6875 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0617 20:41:53.413550  6875 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0617 20:41:53.413683  6875 net.cpp:150] Setting up rpn_relu/3x3
I0617 20:41:53.413689  6875 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0617 20:41:53.413691  6875 net.cpp:165] Memory required for data: 1414835052
I0617 20:41:53.413692  6875 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0617 20:41:53.413697  6875 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0617 20:41:53.413697  6875 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0617 20:41:53.413702  6875 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0617 20:41:53.413704  6875 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0617 20:41:53.413739  6875 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0617 20:41:53.413753  6875 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0617 20:41:53.413754  6875 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0617 20:41:53.413756  6875 net.cpp:165] Memory required for data: 1424640876
I0617 20:41:53.413758  6875 layer_factory.hpp:77] Creating layer rpn_cls_score
I0617 20:41:53.413776  6875 net.cpp:106] Creating Layer rpn_cls_score
I0617 20:41:53.413779  6875 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0617 20:41:53.413790  6875 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0617 20:41:53.415349  6875 net.cpp:150] Setting up rpn_cls_score
I0617 20:41:53.415356  6875 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0617 20:41:53.415359  6875 net.cpp:165] Memory required for data: 1424928156
I0617 20:41:53.415362  6875 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0617 20:41:53.415365  6875 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0617 20:41:53.415367  6875 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0617 20:41:53.415372  6875 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0617 20:41:53.415386  6875 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0617 20:41:53.415433  6875 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0617 20:41:53.415446  6875 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0617 20:41:53.415448  6875 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0617 20:41:53.415450  6875 net.cpp:165] Memory required for data: 1425502716
I0617 20:41:53.415452  6875 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0617 20:41:53.415468  6875 net.cpp:106] Creating Layer rpn_bbox_pred
I0617 20:41:53.415470  6875 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0617 20:41:53.415473  6875 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0617 20:41:53.416960  6875 net.cpp:150] Setting up rpn_bbox_pred
I0617 20:41:53.416967  6875 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0617 20:41:53.416970  6875 net.cpp:165] Memory required for data: 1426077276
I0617 20:41:53.416972  6875 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0617 20:41:53.416976  6875 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0617 20:41:53.416980  6875 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0617 20:41:53.416982  6875 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0617 20:41:53.416986  6875 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0617 20:41:53.417045  6875 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0617 20:41:53.417049  6875 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0617 20:41:53.417063  6875 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0617 20:41:53.417064  6875 net.cpp:165] Memory required for data: 1427226396
I0617 20:41:53.417066  6875 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0617 20:41:53.417070  6875 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0617 20:41:53.417073  6875 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0617 20:41:53.417075  6875 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0617 20:41:53.417100  6875 net.cpp:150] Setting up rpn_cls_score_reshape
I0617 20:41:53.417117  6875 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0617 20:41:53.417119  6875 net.cpp:165] Memory required for data: 1427513676
I0617 20:41:53.417120  6875 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0617 20:41:53.417124  6875 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0617 20:41:53.417135  6875 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0617 20:41:53.417137  6875 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0617 20:41:53.417141  6875 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0617 20:41:53.417197  6875 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0617 20:41:53.417201  6875 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0617 20:41:53.417202  6875 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0617 20:41:53.417203  6875 net.cpp:165] Memory required for data: 1428088236
I0617 20:41:53.417205  6875 layer_factory.hpp:77] Creating layer rpn-data
I0617 20:41:53.417542  6875 net.cpp:106] Creating Layer rpn-data
I0617 20:41:53.417549  6875 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0617 20:41:53.417552  6875 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0617 20:41:53.417556  6875 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0617 20:41:53.417557  6875 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0617 20:41:53.417560  6875 net.cpp:411] rpn-data -> rpn_labels
I0617 20:41:53.417564  6875 net.cpp:411] rpn-data -> rpn_bbox_targets
I0617 20:41:53.417578  6875 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0617 20:41:53.417582  6875 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0617 20:41:53.418386  6875 net.cpp:150] Setting up rpn-data
I0617 20:41:53.418395  6875 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0617 20:41:53.418396  6875 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0617 20:41:53.418398  6875 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0617 20:41:53.418401  6875 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0617 20:41:53.418401  6875 net.cpp:165] Memory required for data: 1429955556
I0617 20:41:53.418404  6875 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0617 20:41:53.418408  6875 net.cpp:106] Creating Layer rpn_loss_cls
I0617 20:41:53.418411  6875 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0617 20:41:53.418413  6875 net.cpp:454] rpn_loss_cls <- rpn_labels
I0617 20:41:53.418416  6875 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0617 20:41:53.418421  6875 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0617 20:41:53.418998  6875 net.cpp:150] Setting up rpn_loss_cls
I0617 20:41:53.419006  6875 net.cpp:157] Top shape: (1)
I0617 20:41:53.419008  6875 net.cpp:160]     with loss weight 1
I0617 20:41:53.419013  6875 net.cpp:165] Memory required for data: 1429955560
I0617 20:41:53.419014  6875 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0617 20:41:53.419019  6875 net.cpp:106] Creating Layer rpn_loss_bbox
I0617 20:41:53.419021  6875 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0617 20:41:53.419024  6875 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0617 20:41:53.419026  6875 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0617 20:41:53.419028  6875 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0617 20:41:53.419032  6875 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0617 20:41:53.420061  6875 net.cpp:150] Setting up rpn_loss_bbox
I0617 20:41:53.420068  6875 net.cpp:157] Top shape: (1)
I0617 20:41:53.420070  6875 net.cpp:160]     with loss weight 1
I0617 20:41:53.420074  6875 net.cpp:165] Memory required for data: 1429955564
I0617 20:41:53.420076  6875 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0617 20:41:53.420079  6875 net.cpp:106] Creating Layer rpn_cls_prob
I0617 20:41:53.420083  6875 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0617 20:41:53.420086  6875 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0617 20:41:53.420233  6875 net.cpp:150] Setting up rpn_cls_prob
I0617 20:41:53.420238  6875 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0617 20:41:53.420240  6875 net.cpp:165] Memory required for data: 1430242844
I0617 20:41:53.420243  6875 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0617 20:41:53.420245  6875 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0617 20:41:53.420248  6875 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0617 20:41:53.420253  6875 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0617 20:41:53.420269  6875 net.cpp:150] Setting up rpn_cls_prob_reshape
I0617 20:41:53.420272  6875 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0617 20:41:53.420274  6875 net.cpp:165] Memory required for data: 1430530124
I0617 20:41:53.420275  6875 layer_factory.hpp:77] Creating layer proposal
I0617 20:41:53.420681  6875 net.cpp:106] Creating Layer proposal
I0617 20:41:53.420688  6875 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0617 20:41:53.420691  6875 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0617 20:41:53.420696  6875 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0617 20:41:53.420698  6875 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0617 20:41:53.421411  6875 net.cpp:150] Setting up proposal
I0617 20:41:53.421419  6875 net.cpp:157] Top shape: 1 5 (5)
I0617 20:41:53.421422  6875 net.cpp:165] Memory required for data: 1430530144
I0617 20:41:53.421423  6875 layer_factory.hpp:77] Creating layer roi-data
I0617 20:41:53.421619  6875 net.cpp:106] Creating Layer roi-data
I0617 20:41:53.421625  6875 net.cpp:454] roi-data <- rpn_rois
I0617 20:41:53.421628  6875 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0617 20:41:53.421631  6875 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0617 20:41:53.421633  6875 net.cpp:454] roi-data <- seg_mask_inds
I0617 20:41:53.421635  6875 net.cpp:454] roi-data <- flipped
I0617 20:41:53.421638  6875 net.cpp:411] roi-data -> rois
I0617 20:41:53.421644  6875 net.cpp:411] roi-data -> labels
I0617 20:41:53.421649  6875 net.cpp:411] roi-data -> bbox_targets
I0617 20:41:53.421653  6875 net.cpp:411] roi-data -> bbox_inside_weights
I0617 20:41:53.421658  6875 net.cpp:411] roi-data -> bbox_outside_weights
I0617 20:41:53.421661  6875 net.cpp:411] roi-data -> mask_targets
I0617 20:41:53.421665  6875 net.cpp:411] roi-data -> rois_pos
I0617 20:41:53.421669  6875 net.cpp:411] roi-data -> attrArray
I0617 20:41:53.421672  6875 net.cpp:411] roi-data -> attrArrayInd
I0617 20:41:53.421677  6875 net.cpp:411] roi-data -> attrArrayShift
I0617 20:41:53.421939  6875 net.cpp:150] Setting up roi-data
I0617 20:41:53.421948  6875 net.cpp:157] Top shape: 1 5 (5)
I0617 20:41:53.421960  6875 net.cpp:157] Top shape: 1 1 (1)
I0617 20:41:53.421962  6875 net.cpp:157] Top shape: 1 8 (8)
I0617 20:41:53.421964  6875 net.cpp:157] Top shape: 1 8 (8)
I0617 20:41:53.421967  6875 net.cpp:157] Top shape: 1 8 (8)
I0617 20:41:53.421968  6875 net.cpp:157] Top shape: 1 244 244 (59536)
I0617 20:41:53.421970  6875 net.cpp:157] Top shape: 1 5 (5)
I0617 20:41:53.421972  6875 net.cpp:157] Top shape: 1 7 (7)
I0617 20:41:53.421974  6875 net.cpp:157] Top shape: 1 7 (7)
I0617 20:41:53.421975  6875 net.cpp:157] Top shape: 1 7 (7)
I0617 20:41:53.421977  6875 net.cpp:165] Memory required for data: 1430768512
I0617 20:41:53.421979  6875 layer_factory.hpp:77] Creating layer mask_targets_roi-data_5_split
I0617 20:41:53.421983  6875 net.cpp:106] Creating Layer mask_targets_roi-data_5_split
I0617 20:41:53.421986  6875 net.cpp:454] mask_targets_roi-data_5_split <- mask_targets
I0617 20:41:53.421989  6875 net.cpp:411] mask_targets_roi-data_5_split -> mask_targets_roi-data_5_split_0
I0617 20:41:53.421993  6875 net.cpp:411] mask_targets_roi-data_5_split -> mask_targets_roi-data_5_split_1
I0617 20:41:53.422030  6875 net.cpp:150] Setting up mask_targets_roi-data_5_split
I0617 20:41:53.422034  6875 net.cpp:157] Top shape: 1 244 244 (59536)
I0617 20:41:53.422046  6875 net.cpp:157] Top shape: 1 244 244 (59536)
I0617 20:41:53.422049  6875 net.cpp:165] Memory required for data: 1431244800
I0617 20:41:53.422049  6875 layer_factory.hpp:77] Creating layer roi_pool5
I0617 20:41:53.422055  6875 net.cpp:106] Creating Layer roi_pool5
I0617 20:41:53.422056  6875 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0617 20:41:53.422060  6875 net.cpp:454] roi_pool5 <- rois
I0617 20:41:53.422063  6875 net.cpp:411] roi_pool5 -> pool5
I0617 20:41:53.422067  6875 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0617 20:41:53.422129  6875 net.cpp:150] Setting up roi_pool5
I0617 20:41:53.422133  6875 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0617 20:41:53.422137  6875 net.cpp:165] Memory required for data: 1431345152
I0617 20:41:53.422137  6875 layer_factory.hpp:77] Creating layer fc6
I0617 20:41:53.422142  6875 net.cpp:106] Creating Layer fc6
I0617 20:41:53.422144  6875 net.cpp:454] fc6 <- pool5
I0617 20:41:53.422147  6875 net.cpp:411] fc6 -> fc6
I0617 20:41:53.563416  6875 net.cpp:150] Setting up fc6
I0617 20:41:53.563439  6875 net.cpp:157] Top shape: 1 4096 (4096)
I0617 20:41:53.563441  6875 net.cpp:165] Memory required for data: 1431361536
I0617 20:41:53.563454  6875 layer_factory.hpp:77] Creating layer relu6
I0617 20:41:53.563472  6875 net.cpp:106] Creating Layer relu6
I0617 20:41:53.563477  6875 net.cpp:454] relu6 <- fc6
I0617 20:41:53.563480  6875 net.cpp:397] relu6 -> fc6 (in-place)
I0617 20:41:53.563699  6875 net.cpp:150] Setting up relu6
I0617 20:41:53.563704  6875 net.cpp:157] Top shape: 1 4096 (4096)
I0617 20:41:53.563706  6875 net.cpp:165] Memory required for data: 1431377920
I0617 20:41:53.563707  6875 layer_factory.hpp:77] Creating layer fc7
I0617 20:41:53.563712  6875 net.cpp:106] Creating Layer fc7
I0617 20:41:53.563714  6875 net.cpp:454] fc7 <- fc6
I0617 20:41:53.563719  6875 net.cpp:411] fc7 -> fc7
I0617 20:41:53.586921  6875 net.cpp:150] Setting up fc7
I0617 20:41:53.586942  6875 net.cpp:157] Top shape: 1 4096 (4096)
I0617 20:41:53.586944  6875 net.cpp:165] Memory required for data: 1431394304
I0617 20:41:53.586952  6875 layer_factory.hpp:77] Creating layer relu7
I0617 20:41:53.586959  6875 net.cpp:106] Creating Layer relu7
I0617 20:41:53.586973  6875 net.cpp:454] relu7 <- fc7
I0617 20:41:53.586978  6875 net.cpp:397] relu7 -> fc7 (in-place)
I0617 20:41:53.587167  6875 net.cpp:150] Setting up relu7
I0617 20:41:53.587172  6875 net.cpp:157] Top shape: 1 4096 (4096)
I0617 20:41:53.587174  6875 net.cpp:165] Memory required for data: 1431410688
I0617 20:41:53.587177  6875 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0617 20:41:53.587180  6875 net.cpp:106] Creating Layer fc7_relu7_0_split
I0617 20:41:53.587182  6875 net.cpp:454] fc7_relu7_0_split <- fc7
I0617 20:41:53.587185  6875 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0617 20:41:53.587188  6875 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0617 20:41:53.587191  6875 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0617 20:41:53.587244  6875 net.cpp:150] Setting up fc7_relu7_0_split
I0617 20:41:53.587247  6875 net.cpp:157] Top shape: 1 4096 (4096)
I0617 20:41:53.587249  6875 net.cpp:157] Top shape: 1 4096 (4096)
I0617 20:41:53.587251  6875 net.cpp:157] Top shape: 1 4096 (4096)
I0617 20:41:53.587254  6875 net.cpp:165] Memory required for data: 1431459840
I0617 20:41:53.587255  6875 layer_factory.hpp:77] Creating layer attr_score
I0617 20:41:53.587258  6875 net.cpp:106] Creating Layer attr_score
I0617 20:41:53.587260  6875 net.cpp:454] attr_score <- fc7_relu7_0_split_0
I0617 20:41:53.587270  6875 net.cpp:411] attr_score -> attr_score
I0617 20:41:53.587920  6875 net.cpp:150] Setting up attr_score
I0617 20:41:53.587924  6875 net.cpp:157] Top shape: 1 7 (7)
I0617 20:41:53.587926  6875 net.cpp:165] Memory required for data: 1431459868
I0617 20:41:53.587929  6875 layer_factory.hpp:77] Creating layer attr_score_pos
I0617 20:41:53.587934  6875 net.cpp:106] Creating Layer attr_score_pos
I0617 20:41:53.587935  6875 net.cpp:454] attr_score_pos <- attr_score
I0617 20:41:53.587939  6875 net.cpp:454] attr_score_pos <- attrArrayInd
I0617 20:41:53.587941  6875 net.cpp:411] attr_score_pos -> attr_score_pos
I0617 20:41:53.587965  6875 net.cpp:150] Setting up attr_score_pos
I0617 20:41:53.587968  6875 net.cpp:157] Top shape: 1 7 (7)
I0617 20:41:53.587970  6875 net.cpp:165] Memory required for data: 1431459896
I0617 20:41:53.587971  6875 layer_factory.hpp:77] Creating layer attr_score_pos_shift
I0617 20:41:53.587975  6875 net.cpp:106] Creating Layer attr_score_pos_shift
I0617 20:41:53.587977  6875 net.cpp:454] attr_score_pos_shift <- attr_score_pos
I0617 20:41:53.587980  6875 net.cpp:454] attr_score_pos_shift <- attrArrayShift
I0617 20:41:53.587981  6875 net.cpp:411] attr_score_pos_shift -> attr_score_pos_shift
I0617 20:41:53.588004  6875 net.cpp:150] Setting up attr_score_pos_shift
I0617 20:41:53.588007  6875 net.cpp:157] Top shape: 1 7 (7)
I0617 20:41:53.588009  6875 net.cpp:165] Memory required for data: 1431459924
I0617 20:41:53.588011  6875 layer_factory.hpp:77] Creating layer cls_score
I0617 20:41:53.588024  6875 net.cpp:106] Creating Layer cls_score
I0617 20:41:53.588027  6875 net.cpp:454] cls_score <- fc7_relu7_0_split_1
I0617 20:41:53.588030  6875 net.cpp:411] cls_score -> cls_score
I0617 20:41:53.588284  6875 net.cpp:150] Setting up cls_score
I0617 20:41:53.588287  6875 net.cpp:157] Top shape: 1 2 (2)
I0617 20:41:53.588289  6875 net.cpp:165] Memory required for data: 1431459932
I0617 20:41:53.588302  6875 layer_factory.hpp:77] Creating layer bbox_pred
I0617 20:41:53.588307  6875 net.cpp:106] Creating Layer bbox_pred
I0617 20:41:53.588310  6875 net.cpp:454] bbox_pred <- fc7_relu7_0_split_2
I0617 20:41:53.588328  6875 net.cpp:411] bbox_pred -> bbox_pred
I0617 20:41:53.589051  6875 net.cpp:150] Setting up bbox_pred
I0617 20:41:53.589056  6875 net.cpp:157] Top shape: 1 8 (8)
I0617 20:41:53.589057  6875 net.cpp:165] Memory required for data: 1431459964
I0617 20:41:53.589061  6875 layer_factory.hpp:77] Creating layer loss_attribute
I0617 20:41:53.589076  6875 net.cpp:106] Creating Layer loss_attribute
I0617 20:41:53.589078  6875 net.cpp:454] loss_attribute <- attr_score_pos_shift
I0617 20:41:53.589080  6875 net.cpp:454] loss_attribute <- attrArray
I0617 20:41:53.589083  6875 net.cpp:411] loss_attribute -> loss_attribute
I0617 20:41:53.589143  6875 net.cpp:150] Setting up loss_attribute
I0617 20:41:53.589146  6875 net.cpp:157] Top shape: (1)
I0617 20:41:53.589148  6875 net.cpp:160]     with loss weight 1
I0617 20:41:53.589167  6875 net.cpp:165] Memory required for data: 1431459968
I0617 20:41:53.589169  6875 layer_factory.hpp:77] Creating layer loss_cls
I0617 20:41:53.589187  6875 net.cpp:106] Creating Layer loss_cls
I0617 20:41:53.589190  6875 net.cpp:454] loss_cls <- cls_score
I0617 20:41:53.589192  6875 net.cpp:454] loss_cls <- labels
I0617 20:41:53.589206  6875 net.cpp:411] loss_cls -> loss_cls
I0617 20:41:53.589210  6875 layer_factory.hpp:77] Creating layer loss_cls
I0617 20:41:53.589861  6875 net.cpp:150] Setting up loss_cls
I0617 20:41:53.589869  6875 net.cpp:157] Top shape: (1)
I0617 20:41:53.589870  6875 net.cpp:160]     with loss weight 3
I0617 20:41:53.589885  6875 net.cpp:165] Memory required for data: 1431459972
I0617 20:41:53.589887  6875 layer_factory.hpp:77] Creating layer loss_bbox
I0617 20:41:53.589901  6875 net.cpp:106] Creating Layer loss_bbox
I0617 20:41:53.589905  6875 net.cpp:454] loss_bbox <- bbox_pred
I0617 20:41:53.589907  6875 net.cpp:454] loss_bbox <- bbox_targets
I0617 20:41:53.589910  6875 net.cpp:454] loss_bbox <- bbox_inside_weights
I0617 20:41:53.589912  6875 net.cpp:454] loss_bbox <- bbox_outside_weights
I0617 20:41:53.589915  6875 net.cpp:411] loss_bbox -> loss_bbox
I0617 20:41:53.589982  6875 net.cpp:150] Setting up loss_bbox
I0617 20:41:53.589985  6875 net.cpp:157] Top shape: (1)
I0617 20:41:53.589988  6875 net.cpp:160]     with loss weight 2
I0617 20:41:53.590000  6875 net.cpp:165] Memory required for data: 1431459976
I0617 20:41:53.590003  6875 layer_factory.hpp:77] Creating layer roi_pool5_2
I0617 20:41:53.590008  6875 net.cpp:106] Creating Layer roi_pool5_2
I0617 20:41:53.590010  6875 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0617 20:41:53.590013  6875 net.cpp:454] roi_pool5_2 <- rois_pos
I0617 20:41:53.590019  6875 net.cpp:411] roi_pool5_2 -> pool5_2
I0617 20:41:53.590024  6875 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0617 20:41:53.590097  6875 net.cpp:150] Setting up roi_pool5_2
I0617 20:41:53.590101  6875 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0617 20:41:53.590103  6875 net.cpp:165] Memory required for data: 1431560328
I0617 20:41:53.590106  6875 layer_factory.hpp:77] Creating layer pool5_2_conv
I0617 20:41:53.590122  6875 net.cpp:106] Creating Layer pool5_2_conv
I0617 20:41:53.590126  6875 net.cpp:454] pool5_2_conv <- pool5_2
I0617 20:41:53.590128  6875 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0617 20:41:53.596738  6875 net.cpp:150] Setting up pool5_2_conv
I0617 20:41:53.596747  6875 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0617 20:41:53.596750  6875 net.cpp:165] Memory required for data: 1431660680
I0617 20:41:53.596753  6875 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0617 20:41:53.596767  6875 net.cpp:106] Creating Layer pool5_2_conv_relu
I0617 20:41:53.596771  6875 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0617 20:41:53.596773  6875 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0617 20:41:53.596910  6875 net.cpp:150] Setting up pool5_2_conv_relu
I0617 20:41:53.596916  6875 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0617 20:41:53.596918  6875 net.cpp:165] Memory required for data: 1431761032
I0617 20:41:53.596920  6875 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0617 20:41:53.596936  6875 net.cpp:106] Creating Layer pool5_2_conv2
I0617 20:41:53.596940  6875 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0617 20:41:53.596942  6875 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0617 20:41:53.649193  6875 net.cpp:150] Setting up pool5_2_conv2
I0617 20:41:53.649209  6875 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0617 20:41:53.649212  6875 net.cpp:165] Memory required for data: 1431861384
I0617 20:41:53.649230  6875 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0617 20:41:53.649237  6875 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0617 20:41:53.649250  6875 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0617 20:41:53.649255  6875 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0617 20:41:53.649408  6875 net.cpp:150] Setting up pool5_2_conv2_relu
I0617 20:41:53.649415  6875 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0617 20:41:53.649416  6875 net.cpp:165] Memory required for data: 1431961736
I0617 20:41:53.649417  6875 layer_factory.hpp:77] Creating layer mask_deconv1
I0617 20:41:53.649435  6875 net.cpp:106] Creating Layer mask_deconv1
I0617 20:41:53.649436  6875 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0617 20:41:53.649454  6875 net.cpp:411] mask_deconv1 -> mask_deconv1
I0617 20:41:53.650425  6875 net.cpp:150] Setting up mask_deconv1
I0617 20:41:53.650432  6875 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0617 20:41:53.650434  6875 net.cpp:165] Memory required for data: 1432883336
I0617 20:41:53.650437  6875 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0617 20:41:53.650445  6875 net.cpp:106] Creating Layer pool5_2_conv3
I0617 20:41:53.650449  6875 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0617 20:41:53.650454  6875 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0617 20:41:53.677839  6875 net.cpp:150] Setting up pool5_2_conv3
I0617 20:41:53.677867  6875 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0617 20:41:53.677870  6875 net.cpp:165] Memory required for data: 1434726536
I0617 20:41:53.677876  6875 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0617 20:41:53.677894  6875 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0617 20:41:53.677898  6875 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0617 20:41:53.677903  6875 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0617 20:41:53.678043  6875 net.cpp:150] Setting up pool5_2_conv3_relu
I0617 20:41:53.678050  6875 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0617 20:41:53.678061  6875 net.cpp:165] Memory required for data: 1436569736
I0617 20:41:53.678063  6875 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0617 20:41:53.678071  6875 net.cpp:106] Creating Layer pool5_2_conv4
I0617 20:41:53.678073  6875 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0617 20:41:53.678077  6875 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0617 20:41:53.727457  6875 net.cpp:150] Setting up pool5_2_conv4
I0617 20:41:53.727474  6875 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0617 20:41:53.727476  6875 net.cpp:165] Memory required for data: 1438412936
I0617 20:41:53.727483  6875 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0617 20:41:53.727489  6875 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0617 20:41:53.727504  6875 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0617 20:41:53.727509  6875 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0617 20:41:53.727658  6875 net.cpp:150] Setting up pool5_2_conv4_relu
I0617 20:41:53.727663  6875 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0617 20:41:53.727665  6875 net.cpp:165] Memory required for data: 1440256136
I0617 20:41:53.727666  6875 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0617 20:41:53.727671  6875 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0617 20:41:53.727674  6875 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0617 20:41:53.727676  6875 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0617 20:41:53.727679  6875 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0617 20:41:53.727694  6875 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0617 20:41:53.727696  6875 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0617 20:41:53.727767  6875 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0617 20:41:53.727771  6875 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0617 20:41:53.727772  6875 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0617 20:41:53.727774  6875 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0617 20:41:53.727777  6875 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0617 20:41:53.727777  6875 net.cpp:165] Memory required for data: 1447628936
I0617 20:41:53.727779  6875 layer_factory.hpp:77] Creating layer query_conv
I0617 20:41:53.727785  6875 net.cpp:106] Creating Layer query_conv
I0617 20:41:53.727787  6875 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0617 20:41:53.727802  6875 net.cpp:411] query_conv -> query_conv
I0617 20:41:53.729319  6875 net.cpp:150] Setting up query_conv
I0617 20:41:53.729327  6875 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0617 20:41:53.729329  6875 net.cpp:165] Memory required for data: 1447859336
I0617 20:41:53.729333  6875 layer_factory.hpp:77] Creating layer key_conv
I0617 20:41:53.729341  6875 net.cpp:106] Creating Layer key_conv
I0617 20:41:53.729342  6875 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0617 20:41:53.729357  6875 net.cpp:411] key_conv -> key_conv
I0617 20:41:53.731075  6875 net.cpp:150] Setting up key_conv
I0617 20:41:53.731091  6875 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0617 20:41:53.731094  6875 net.cpp:165] Memory required for data: 1448089736
I0617 20:41:53.731102  6875 layer_factory.hpp:77] Creating layer value_conv
I0617 20:41:53.731117  6875 net.cpp:106] Creating Layer value_conv
I0617 20:41:53.731137  6875 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0617 20:41:53.731145  6875 net.cpp:411] value_conv -> value_conv
I0617 20:41:53.740046  6875 net.cpp:150] Setting up value_conv
I0617 20:41:53.740073  6875 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0617 20:41:53.740077  6875 net.cpp:165] Memory required for data: 1449932936
I0617 20:41:53.740082  6875 layer_factory.hpp:77] Creating layer query_conv_reshape
I0617 20:41:53.740094  6875 net.cpp:106] Creating Layer query_conv_reshape
I0617 20:41:53.740100  6875 net.cpp:454] query_conv_reshape <- query_conv
I0617 20:41:53.740108  6875 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0617 20:41:53.740141  6875 net.cpp:150] Setting up query_conv_reshape
I0617 20:41:53.740147  6875 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0617 20:41:53.740159  6875 net.cpp:165] Memory required for data: 1450163336
I0617 20:41:53.740160  6875 layer_factory.hpp:77] Creating layer key_conv_reshape
I0617 20:41:53.740164  6875 net.cpp:106] Creating Layer key_conv_reshape
I0617 20:41:53.740166  6875 net.cpp:454] key_conv_reshape <- key_conv
I0617 20:41:53.740170  6875 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0617 20:41:53.740200  6875 net.cpp:150] Setting up key_conv_reshape
I0617 20:41:53.740203  6875 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0617 20:41:53.740204  6875 net.cpp:165] Memory required for data: 1450393736
I0617 20:41:53.740216  6875 layer_factory.hpp:77] Creating layer value_conv_reshape
I0617 20:41:53.740219  6875 net.cpp:106] Creating Layer value_conv_reshape
I0617 20:41:53.740221  6875 net.cpp:454] value_conv_reshape <- value_conv
I0617 20:41:53.740226  6875 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0617 20:41:53.740252  6875 net.cpp:150] Setting up value_conv_reshape
I0617 20:41:53.740257  6875 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0617 20:41:53.740257  6875 net.cpp:165] Memory required for data: 1452236936
I0617 20:41:53.740259  6875 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0617 20:41:53.740278  6875 net.cpp:106] Creating Layer query_conv_reshape_perm
I0617 20:41:53.740280  6875 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0617 20:41:53.740285  6875 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0617 20:41:53.740351  6875 net.cpp:150] Setting up query_conv_reshape_perm
I0617 20:41:53.740356  6875 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0617 20:41:53.740360  6875 net.cpp:165] Memory required for data: 1452467336
I0617 20:41:53.740362  6875 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0617 20:41:53.740368  6875 net.cpp:106] Creating Layer key_conv_reshape_perm
I0617 20:41:53.740371  6875 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0617 20:41:53.740375  6875 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0617 20:41:53.740435  6875 net.cpp:150] Setting up key_conv_reshape_perm
I0617 20:41:53.740439  6875 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0617 20:41:53.740443  6875 net.cpp:165] Memory required for data: 1452697736
I0617 20:41:53.740445  6875 layer_factory.hpp:77] Creating layer energy
I0617 20:41:53.740451  6875 net.cpp:106] Creating Layer energy
I0617 20:41:53.740454  6875 net.cpp:454] energy <- query_conv_reshape_perm
I0617 20:41:53.740458  6875 net.cpp:454] energy <- key_conv_reshape_perm
I0617 20:41:53.740464  6875 net.cpp:411] energy -> energy
I0617 20:41:53.740479  6875 net.cpp:150] Setting up energy
I0617 20:41:53.740483  6875 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0617 20:41:53.740484  6875 net.cpp:165] Memory required for data: 1455937736
I0617 20:41:53.740486  6875 layer_factory.hpp:77] Creating layer attention
I0617 20:41:53.740491  6875 net.cpp:106] Creating Layer attention
I0617 20:41:53.740495  6875 net.cpp:454] attention <- energy
I0617 20:41:53.740499  6875 net.cpp:411] attention -> attention
I0617 20:41:53.740659  6875 net.cpp:150] Setting up attention
I0617 20:41:53.740665  6875 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0617 20:41:53.740667  6875 net.cpp:165] Memory required for data: 1459177736
I0617 20:41:53.740669  6875 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0617 20:41:53.740672  6875 net.cpp:106] Creating Layer value_conv_reshape_perm
I0617 20:41:53.740674  6875 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0617 20:41:53.740677  6875 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0617 20:41:53.740743  6875 net.cpp:150] Setting up value_conv_reshape_perm
I0617 20:41:53.740748  6875 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0617 20:41:53.740752  6875 net.cpp:165] Memory required for data: 1461020936
I0617 20:41:53.740754  6875 layer_factory.hpp:77] Creating layer attention_perm
I0617 20:41:53.740759  6875 net.cpp:106] Creating Layer attention_perm
I0617 20:41:53.740762  6875 net.cpp:454] attention_perm <- attention
I0617 20:41:53.740767  6875 net.cpp:411] attention_perm -> attention_perm
I0617 20:41:53.740829  6875 net.cpp:150] Setting up attention_perm
I0617 20:41:53.740833  6875 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0617 20:41:53.740837  6875 net.cpp:165] Memory required for data: 1464260936
I0617 20:41:53.740839  6875 layer_factory.hpp:77] Creating layer out
I0617 20:41:53.740844  6875 net.cpp:106] Creating Layer out
I0617 20:41:53.740847  6875 net.cpp:454] out <- value_conv_reshape_perm
I0617 20:41:53.740851  6875 net.cpp:454] out <- attention_perm
I0617 20:41:53.740855  6875 net.cpp:411] out -> out
I0617 20:41:53.740871  6875 net.cpp:150] Setting up out
I0617 20:41:53.740875  6875 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0617 20:41:53.740878  6875 net.cpp:165] Memory required for data: 1466104136
I0617 20:41:53.740881  6875 layer_factory.hpp:77] Creating layer out_reshape
I0617 20:41:53.740890  6875 net.cpp:106] Creating Layer out_reshape
I0617 20:41:53.740891  6875 net.cpp:454] out_reshape <- out
I0617 20:41:53.740896  6875 net.cpp:411] out_reshape -> out_reshape
I0617 20:41:53.740912  6875 net.cpp:150] Setting up out_reshape
I0617 20:41:53.740916  6875 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0617 20:41:53.740919  6875 net.cpp:165] Memory required for data: 1467947336
I0617 20:41:53.740922  6875 layer_factory.hpp:77] Creating layer out_reshape_scale
I0617 20:41:53.740931  6875 net.cpp:106] Creating Layer out_reshape_scale
I0617 20:41:53.740934  6875 net.cpp:454] out_reshape_scale <- out_reshape
I0617 20:41:53.740938  6875 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0617 20:41:53.740998  6875 net.cpp:150] Setting up out_reshape_scale
I0617 20:41:53.741003  6875 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0617 20:41:53.741006  6875 net.cpp:165] Memory required for data: 1469790536
I0617 20:41:53.741009  6875 layer_factory.hpp:77] Creating layer out_x
I0617 20:41:53.741019  6875 net.cpp:106] Creating Layer out_x
I0617 20:41:53.741021  6875 net.cpp:454] out_x <- out_reshape_scale
I0617 20:41:53.741025  6875 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0617 20:41:53.741029  6875 net.cpp:411] out_x -> out_x
I0617 20:41:53.741050  6875 net.cpp:150] Setting up out_x
I0617 20:41:53.741052  6875 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0617 20:41:53.741056  6875 net.cpp:165] Memory required for data: 1471633736
I0617 20:41:53.741058  6875 layer_factory.hpp:77] Creating layer mask_deconv2
I0617 20:41:53.741066  6875 net.cpp:106] Creating Layer mask_deconv2
I0617 20:41:53.741070  6875 net.cpp:454] mask_deconv2 <- out_x
I0617 20:41:53.741075  6875 net.cpp:411] mask_deconv2 -> mask_deconv2
I0617 20:41:53.741866  6875 net.cpp:150] Setting up mask_deconv2
I0617 20:41:53.741873  6875 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0617 20:41:53.741875  6875 net.cpp:165] Memory required for data: 1486874952
I0617 20:41:53.741881  6875 layer_factory.hpp:77] Creating layer mask_deconv2_mask_deconv2_0_split
I0617 20:41:53.741886  6875 net.cpp:106] Creating Layer mask_deconv2_mask_deconv2_0_split
I0617 20:41:53.741889  6875 net.cpp:454] mask_deconv2_mask_deconv2_0_split <- mask_deconv2
I0617 20:41:53.741894  6875 net.cpp:411] mask_deconv2_mask_deconv2_0_split -> mask_deconv2_mask_deconv2_0_split_0
I0617 20:41:53.741899  6875 net.cpp:411] mask_deconv2_mask_deconv2_0_split -> mask_deconv2_mask_deconv2_0_split_1
I0617 20:41:53.741927  6875 net.cpp:150] Setting up mask_deconv2_mask_deconv2_0_split
I0617 20:41:53.741931  6875 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0617 20:41:53.741935  6875 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0617 20:41:53.741938  6875 net.cpp:165] Memory required for data: 1517357384
I0617 20:41:53.741941  6875 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0617 20:41:53.741950  6875 net.cpp:106] Creating Layer pool5_2_conv5
I0617 20:41:53.741953  6875 net.cpp:454] pool5_2_conv5 <- mask_deconv2_mask_deconv2_0_split_0
I0617 20:41:53.741958  6875 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0617 20:41:53.768363  6875 net.cpp:150] Setting up pool5_2_conv5
I0617 20:41:53.768380  6875 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0617 20:41:53.768383  6875 net.cpp:165] Memory required for data: 1547839816
I0617 20:41:53.768388  6875 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0617 20:41:53.768395  6875 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0617 20:41:53.768410  6875 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0617 20:41:53.768414  6875 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0617 20:41:53.768554  6875 net.cpp:150] Setting up pool5_2_conv5_relu
I0617 20:41:53.768560  6875 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0617 20:41:53.768561  6875 net.cpp:165] Memory required for data: 1578322248
I0617 20:41:53.768563  6875 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0617 20:41:53.768571  6875 net.cpp:106] Creating Layer pool5_2_conv6
I0617 20:41:53.768574  6875 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0617 20:41:53.768577  6875 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0617 20:41:53.818490  6875 net.cpp:150] Setting up pool5_2_conv6
I0617 20:41:53.818506  6875 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0617 20:41:53.818509  6875 net.cpp:165] Memory required for data: 1608804680
I0617 20:41:53.818522  6875 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0617 20:41:53.818540  6875 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0617 20:41:53.818544  6875 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0617 20:41:53.818558  6875 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0617 20:41:53.819073  6875 net.cpp:150] Setting up pool5_2_conv6_relu
I0617 20:41:53.819082  6875 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0617 20:41:53.819083  6875 net.cpp:165] Memory required for data: 1639287112
I0617 20:41:53.819085  6875 layer_factory.hpp:77] Creating layer mask_deconv3
I0617 20:41:53.819092  6875 net.cpp:106] Creating Layer mask_deconv3
I0617 20:41:53.819093  6875 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0617 20:41:53.819097  6875 net.cpp:411] mask_deconv3 -> mask_deconv3
I0617 20:41:53.819465  6875 net.cpp:150] Setting up mask_deconv3
I0617 20:41:53.819470  6875 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0617 20:41:53.819471  6875 net.cpp:165] Memory required for data: 1700251976
I0617 20:41:53.819475  6875 layer_factory.hpp:77] Creating layer mask_score
I0617 20:41:53.819480  6875 net.cpp:106] Creating Layer mask_score
I0617 20:41:53.819483  6875 net.cpp:454] mask_score <- mask_deconv3
I0617 20:41:53.819486  6875 net.cpp:411] mask_score -> mask_score
I0617 20:41:53.820067  6875 net.cpp:150] Setting up mask_score
I0617 20:41:53.820075  6875 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0617 20:41:53.820076  6875 net.cpp:165] Memory required for data: 1702157128
I0617 20:41:53.820080  6875 layer_factory.hpp:77] Creating layer loss_mask
I0617 20:41:53.820086  6875 net.cpp:106] Creating Layer loss_mask
I0617 20:41:53.820087  6875 net.cpp:454] loss_mask <- mask_score
I0617 20:41:53.820091  6875 net.cpp:454] loss_mask <- mask_targets_roi-data_5_split_0
I0617 20:41:53.820093  6875 net.cpp:411] loss_mask -> loss_mask
I0617 20:41:53.820108  6875 layer_factory.hpp:77] Creating layer loss_mask
I0617 20:41:53.821346  6875 net.cpp:150] Setting up loss_mask
I0617 20:41:53.821353  6875 net.cpp:157] Top shape: (1)
I0617 20:41:53.821354  6875 net.cpp:160]     with loss weight 3
I0617 20:41:53.821360  6875 net.cpp:165] Memory required for data: 1702157132
I0617 20:41:53.821372  6875 layer_factory.hpp:77] Creating layer pool5_2_conv5_2
I0617 20:41:53.821382  6875 net.cpp:106] Creating Layer pool5_2_conv5_2
I0617 20:41:53.821384  6875 net.cpp:454] pool5_2_conv5_2 <- mask_deconv2_mask_deconv2_0_split_1
I0617 20:41:53.821388  6875 net.cpp:411] pool5_2_conv5_2 -> pool5_2_conv5_2
I0617 20:41:53.847645  6875 net.cpp:150] Setting up pool5_2_conv5_2
I0617 20:41:53.847661  6875 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0617 20:41:53.847664  6875 net.cpp:165] Memory required for data: 1732639564
I0617 20:41:53.847671  6875 layer_factory.hpp:77] Creating layer pool5_2_conv5_2_relu
I0617 20:41:53.847678  6875 net.cpp:106] Creating Layer pool5_2_conv5_2_relu
I0617 20:41:53.847682  6875 net.cpp:454] pool5_2_conv5_2_relu <- pool5_2_conv5_2
I0617 20:41:53.847697  6875 net.cpp:411] pool5_2_conv5_2_relu -> pool5_2_conv5_2_relu
I0617 20:41:53.847857  6875 net.cpp:150] Setting up pool5_2_conv5_2_relu
I0617 20:41:53.847873  6875 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0617 20:41:53.847875  6875 net.cpp:165] Memory required for data: 1763121996
I0617 20:41:53.847887  6875 layer_factory.hpp:77] Creating layer mask_deconv3_2
I0617 20:41:53.847893  6875 net.cpp:106] Creating Layer mask_deconv3_2
I0617 20:41:53.847895  6875 net.cpp:454] mask_deconv3_2 <- pool5_2_conv5_2_relu
I0617 20:41:53.847900  6875 net.cpp:411] mask_deconv3_2 -> mask_deconv3_2
I0617 20:41:53.848897  6875 net.cpp:150] Setting up mask_deconv3_2
I0617 20:41:53.848906  6875 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0617 20:41:53.848917  6875 net.cpp:165] Memory required for data: 1824086860
I0617 20:41:53.848922  6875 layer_factory.hpp:77] Creating layer mask_score_2
I0617 20:41:53.848930  6875 net.cpp:106] Creating Layer mask_score_2
I0617 20:41:53.848942  6875 net.cpp:454] mask_score_2 <- mask_deconv3_2
I0617 20:41:53.848948  6875 net.cpp:411] mask_score_2 -> mask_score_2
I0617 20:41:53.850302  6875 net.cpp:150] Setting up mask_score_2
I0617 20:41:53.850311  6875 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0617 20:41:53.850312  6875 net.cpp:165] Memory required for data: 1825992012
I0617 20:41:53.850317  6875 layer_factory.hpp:77] Creating layer loss_mask_2
I0617 20:41:53.850322  6875 net.cpp:106] Creating Layer loss_mask_2
I0617 20:41:53.850324  6875 net.cpp:454] loss_mask_2 <- mask_score_2
I0617 20:41:53.850327  6875 net.cpp:454] loss_mask_2 <- mask_targets_roi-data_5_split_1
I0617 20:41:53.850330  6875 net.cpp:411] loss_mask_2 -> loss_mask_2
I0617 20:41:53.850347  6875 layer_factory.hpp:77] Creating layer loss_mask_2
I0617 20:41:53.851238  6875 net.cpp:150] Setting up loss_mask_2
I0617 20:41:53.851245  6875 net.cpp:157] Top shape: (1)
I0617 20:41:53.851258  6875 net.cpp:160]     with loss weight 0.3
I0617 20:41:53.851266  6875 net.cpp:165] Memory required for data: 1825992016
I0617 20:41:53.851279  6875 net.cpp:226] loss_mask_2 needs backward computation.
I0617 20:41:53.851281  6875 net.cpp:226] mask_score_2 needs backward computation.
I0617 20:41:53.851282  6875 net.cpp:226] mask_deconv3_2 needs backward computation.
I0617 20:41:53.851284  6875 net.cpp:226] pool5_2_conv5_2_relu needs backward computation.
I0617 20:41:53.851286  6875 net.cpp:226] pool5_2_conv5_2 needs backward computation.
I0617 20:41:53.851289  6875 net.cpp:226] loss_mask needs backward computation.
I0617 20:41:53.851290  6875 net.cpp:226] mask_score needs backward computation.
I0617 20:41:53.851292  6875 net.cpp:226] mask_deconv3 needs backward computation.
I0617 20:41:53.851294  6875 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0617 20:41:53.851296  6875 net.cpp:226] pool5_2_conv6 needs backward computation.
I0617 20:41:53.851299  6875 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0617 20:41:53.851300  6875 net.cpp:226] pool5_2_conv5 needs backward computation.
I0617 20:41:53.851302  6875 net.cpp:226] mask_deconv2_mask_deconv2_0_split needs backward computation.
I0617 20:41:53.851305  6875 net.cpp:226] mask_deconv2 needs backward computation.
I0617 20:41:53.851306  6875 net.cpp:226] out_x needs backward computation.
I0617 20:41:53.851310  6875 net.cpp:226] out_reshape_scale needs backward computation.
I0617 20:41:53.851311  6875 net.cpp:226] out_reshape needs backward computation.
I0617 20:41:53.851313  6875 net.cpp:226] out needs backward computation.
I0617 20:41:53.851315  6875 net.cpp:226] attention_perm needs backward computation.
I0617 20:41:53.851317  6875 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0617 20:41:53.851320  6875 net.cpp:226] attention needs backward computation.
I0617 20:41:53.851321  6875 net.cpp:226] energy needs backward computation.
I0617 20:41:53.851323  6875 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0617 20:41:53.851325  6875 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0617 20:41:53.851327  6875 net.cpp:226] value_conv_reshape needs backward computation.
I0617 20:41:53.851330  6875 net.cpp:226] key_conv_reshape needs backward computation.
I0617 20:41:53.851332  6875 net.cpp:226] query_conv_reshape needs backward computation.
I0617 20:41:53.851333  6875 net.cpp:226] value_conv needs backward computation.
I0617 20:41:53.851336  6875 net.cpp:226] key_conv needs backward computation.
I0617 20:41:53.851338  6875 net.cpp:226] query_conv needs backward computation.
I0617 20:41:53.851351  6875 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0617 20:41:53.851352  6875 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0617 20:41:53.851354  6875 net.cpp:226] pool5_2_conv4 needs backward computation.
I0617 20:41:53.851356  6875 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0617 20:41:53.851358  6875 net.cpp:226] pool5_2_conv3 needs backward computation.
I0617 20:41:53.851361  6875 net.cpp:226] mask_deconv1 needs backward computation.
I0617 20:41:53.851363  6875 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0617 20:41:53.851366  6875 net.cpp:226] pool5_2_conv2 needs backward computation.
I0617 20:41:53.851367  6875 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0617 20:41:53.851369  6875 net.cpp:226] pool5_2_conv needs backward computation.
I0617 20:41:53.851372  6875 net.cpp:226] roi_pool5_2 needs backward computation.
I0617 20:41:53.851373  6875 net.cpp:226] loss_bbox needs backward computation.
I0617 20:41:53.851377  6875 net.cpp:226] loss_cls needs backward computation.
I0617 20:41:53.851380  6875 net.cpp:226] loss_attribute needs backward computation.
I0617 20:41:53.851383  6875 net.cpp:226] bbox_pred needs backward computation.
I0617 20:41:53.851385  6875 net.cpp:226] cls_score needs backward computation.
I0617 20:41:53.851387  6875 net.cpp:226] attr_score_pos_shift needs backward computation.
I0617 20:41:53.851390  6875 net.cpp:226] attr_score_pos needs backward computation.
I0617 20:41:53.851393  6875 net.cpp:226] attr_score needs backward computation.
I0617 20:41:53.851395  6875 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0617 20:41:53.851397  6875 net.cpp:226] relu7 needs backward computation.
I0617 20:41:53.851399  6875 net.cpp:226] fc7 needs backward computation.
I0617 20:41:53.851402  6875 net.cpp:226] relu6 needs backward computation.
I0617 20:41:53.851403  6875 net.cpp:226] fc6 needs backward computation.
I0617 20:41:53.851405  6875 net.cpp:226] roi_pool5 needs backward computation.
I0617 20:41:53.851408  6875 net.cpp:228] mask_targets_roi-data_5_split does not need backward computation.
I0617 20:41:53.851411  6875 net.cpp:226] roi-data needs backward computation.
I0617 20:41:53.851414  6875 net.cpp:226] proposal needs backward computation.
I0617 20:41:53.851418  6875 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0617 20:41:53.851421  6875 net.cpp:226] rpn_cls_prob needs backward computation.
I0617 20:41:53.851423  6875 net.cpp:226] rpn_loss_bbox needs backward computation.
I0617 20:41:53.851426  6875 net.cpp:226] rpn_loss_cls needs backward computation.
I0617 20:41:53.851430  6875 net.cpp:226] rpn-data needs backward computation.
I0617 20:41:53.851434  6875 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0617 20:41:53.851438  6875 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0617 20:41:53.851439  6875 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0617 20:41:53.851441  6875 net.cpp:226] rpn_bbox_pred needs backward computation.
I0617 20:41:53.851444  6875 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0617 20:41:53.851446  6875 net.cpp:226] rpn_cls_score needs backward computation.
I0617 20:41:53.851449  6875 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0617 20:41:53.851450  6875 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0617 20:41:53.851452  6875 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0617 20:41:53.851454  6875 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0617 20:41:53.851456  6875 net.cpp:226] relu5_3 needs backward computation.
I0617 20:41:53.851459  6875 net.cpp:226] conv5_3 needs backward computation.
I0617 20:41:53.851459  6875 net.cpp:226] relu5_2 needs backward computation.
I0617 20:41:53.851461  6875 net.cpp:226] conv5_2 needs backward computation.
I0617 20:41:53.851464  6875 net.cpp:226] relu5_1 needs backward computation.
I0617 20:41:53.851465  6875 net.cpp:226] conv5_1 needs backward computation.
I0617 20:41:53.851467  6875 net.cpp:226] pool4 needs backward computation.
I0617 20:41:53.851469  6875 net.cpp:226] relu4_3 needs backward computation.
I0617 20:41:53.851471  6875 net.cpp:226] conv4_3 needs backward computation.
I0617 20:41:53.851474  6875 net.cpp:226] relu4_2 needs backward computation.
I0617 20:41:53.851475  6875 net.cpp:226] conv4_2 needs backward computation.
I0617 20:41:53.851477  6875 net.cpp:226] relu4_1 needs backward computation.
I0617 20:41:53.851478  6875 net.cpp:226] conv4_1 needs backward computation.
I0617 20:41:53.851480  6875 net.cpp:226] pool3 needs backward computation.
I0617 20:41:53.851482  6875 net.cpp:226] relu3_3 needs backward computation.
I0617 20:41:53.851485  6875 net.cpp:226] conv3_3 needs backward computation.
I0617 20:41:53.851486  6875 net.cpp:226] relu3_2 needs backward computation.
I0617 20:41:53.851487  6875 net.cpp:226] conv3_2 needs backward computation.
I0617 20:41:53.851490  6875 net.cpp:226] relu3_1 needs backward computation.
I0617 20:41:53.851491  6875 net.cpp:226] conv3_1 needs backward computation.
I0617 20:41:53.851493  6875 net.cpp:228] pool2 does not need backward computation.
I0617 20:41:53.851495  6875 net.cpp:228] relu2_2 does not need backward computation.
I0617 20:41:53.851496  6875 net.cpp:228] conv2_2 does not need backward computation.
I0617 20:41:53.851498  6875 net.cpp:228] relu2_1 does not need backward computation.
I0617 20:41:53.851500  6875 net.cpp:228] conv2_1 does not need backward computation.
I0617 20:41:53.851502  6875 net.cpp:228] pool1 does not need backward computation.
I0617 20:41:53.851505  6875 net.cpp:228] relu1_2 does not need backward computation.
I0617 20:41:53.851506  6875 net.cpp:228] conv1_2 does not need backward computation.
I0617 20:41:53.851508  6875 net.cpp:228] relu1_1 does not need backward computation.
I0617 20:41:53.851511  6875 net.cpp:228] conv1_1 does not need backward computation.
I0617 20:41:53.851514  6875 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0617 20:41:53.851516  6875 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0617 20:41:53.851519  6875 net.cpp:228] data_input-data_0_split does not need backward computation.
I0617 20:41:53.851522  6875 net.cpp:228] input-data does not need backward computation.
I0617 20:41:53.851524  6875 net.cpp:270] This network produces output loss_attribute
I0617 20:41:53.851526  6875 net.cpp:270] This network produces output loss_bbox
I0617 20:41:53.851529  6875 net.cpp:270] This network produces output loss_cls
I0617 20:41:53.851531  6875 net.cpp:270] This network produces output loss_mask
I0617 20:41:53.851532  6875 net.cpp:270] This network produces output loss_mask_2
I0617 20:41:53.851534  6875 net.cpp:270] This network produces output rpn_cls_loss
I0617 20:41:53.851536  6875 net.cpp:270] This network produces output rpn_loss_bbox
I0617 20:41:53.851590  6875 net.cpp:283] Network initialization done.
I0617 20:41:53.851771  6875 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0617 20:41:54.382038  6875 net.cpp:816] Ignoring source layer pool5
I0617 20:41:54.444669  6875 net.cpp:816] Ignoring source layer drop6
I0617 20:41:54.455168  6875 net.cpp:816] Ignoring source layer drop7
I0617 20:41:54.455183  6875 net.cpp:816] Ignoring source layer fc8
I0617 20:41:54.455184  6875 net.cpp:816] Ignoring source layer prob
Solving...
I0617 20:41:55.824573  6875 solver.cpp:229] Iteration 0, loss = 11.8755
I0617 20:41:55.824607  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.914377 (* 1 = 0.914377 loss)
I0617 20:41:55.824612  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.27497 (* 2 = 0.54994 loss)
I0617 20:41:55.824616  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.89034 (* 3 = 2.67102 loss)
I0617 20:41:55.824620  6875 solver.cpp:245]     Train net output #3: loss_mask = 2.08166 (* 3 = 6.24497 loss)
I0617 20:41:55.824622  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 2.07725 (* 0.3 = 0.623176 loss)
I0617 20:41:55.824636  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.73882 (* 1 = 0.73882 loss)
I0617 20:41:55.824640  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.0189577 (* 1 = 0.0189577 loss)
I0617 20:41:55.824643  6875 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0617 20:42:15.576519  6875 solver.cpp:229] Iteration 20, loss = 7.17234
I0617 20:42:15.576545  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.186026 (* 1 = 0.186026 loss)
I0617 20:42:15.576550  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.00233912 (* 2 = 0.00467825 loss)
I0617 20:42:15.576555  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.19588 (* 3 = 0.587639 loss)
I0617 20:42:15.576557  6875 solver.cpp:245]     Train net output #3: loss_mask = 1.84469 (* 3 = 5.53407 loss)
I0617 20:42:15.576561  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 2.0207 (* 0.3 = 0.606209 loss)
I0617 20:42:15.576565  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.347931 (* 1 = 0.347931 loss)
I0617 20:42:15.576567  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.0370428 (* 1 = 0.0370428 loss)
I0617 20:42:15.576571  6875 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0617 20:42:33.763970  6875 solver.cpp:229] Iteration 40, loss = 8.21966
I0617 20:42:33.763996  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.273692 (* 1 = 0.273692 loss)
I0617 20:42:33.764003  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.000537674 (* 2 = 0.00107535 loss)
I0617 20:42:33.764009  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.237246 (* 3 = 0.711737 loss)
I0617 20:42:33.764014  6875 solver.cpp:245]     Train net output #3: loss_mask = 1.71307 (* 3 = 5.1392 loss)
I0617 20:42:33.764030  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 1.97145 (* 0.3 = 0.591435 loss)
I0617 20:42:33.764047  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.123528 (* 1 = 0.123528 loss)
I0617 20:42:33.764055  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.00427758 (* 1 = 0.00427758 loss)
I0617 20:42:33.764075  6875 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0617 20:42:53.544704  6875 solver.cpp:229] Iteration 60, loss = 12.0847
I0617 20:42:53.544729  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.192646 (* 1 = 0.192646 loss)
I0617 20:42:53.544734  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.0188633 (* 2 = 0.0377265 loss)
I0617 20:42:53.544737  6875 solver.cpp:245]     Train net output #2: loss_cls = 2.32701 (* 3 = 6.98103 loss)
I0617 20:42:53.544741  6875 solver.cpp:245]     Train net output #3: loss_mask = 1.52333 (* 3 = 4.56999 loss)
I0617 20:42:53.544744  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 1.64899 (* 0.3 = 0.494698 loss)
I0617 20:42:53.544759  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.262224 (* 1 = 0.262224 loss)
I0617 20:42:53.544761  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.0241043 (* 1 = 0.0241043 loss)
I0617 20:42:53.544780  6875 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0617 20:43:10.777417  6875 solver.cpp:229] Iteration 80, loss = 4.98576
I0617 20:43:10.777442  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.200265 (* 1 = 0.200265 loss)
I0617 20:43:10.777448  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.0153918 (* 2 = 0.0307837 loss)
I0617 20:43:10.777451  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.207045 (* 3 = 0.621134 loss)
I0617 20:43:10.777454  6875 solver.cpp:245]     Train net output #3: loss_mask = 1.37415 (* 3 = 4.12245 loss)
I0617 20:43:10.777460  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 1.49 (* 0.3 = 0.447001 loss)
I0617 20:43:10.777475  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.291767 (* 1 = 0.291767 loss)
I0617 20:43:10.777480  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.254628 (* 1 = 0.254628 loss)
I0617 20:43:10.777487  6875 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0617 20:43:32.673672  6875 solver.cpp:229] Iteration 100, loss = 26.5855
I0617 20:43:32.673697  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.372318 (* 1 = 0.372318 loss)
I0617 20:43:32.673702  6875 solver.cpp:245]     Train net output #1: loss_bbox = 1.98215 (* 2 = 3.96429 loss)
I0617 20:43:32.673705  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.0345144 (* 3 = 0.103543 loss)
I0617 20:43:32.673709  6875 solver.cpp:245]     Train net output #3: loss_mask = 5.10367 (* 3 = 15.311 loss)
I0617 20:43:32.673723  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 12.9838 (* 0.3 = 3.89515 loss)
I0617 20:43:32.673727  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 5.18447 (* 1 = 5.18447 loss)
I0617 20:43:32.673730  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 1.55301 (* 1 = 1.55301 loss)
I0617 20:43:32.673744  6875 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0617 20:43:49.195591  6875 solver.cpp:229] Iteration 120, loss = 6.48555
I0617 20:43:49.195617  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.212251 (* 1 = 0.212251 loss)
I0617 20:43:49.195623  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.078563 (* 2 = 0.157126 loss)
I0617 20:43:49.195627  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.117242 (* 3 = 0.351725 loss)
I0617 20:43:49.195631  6875 solver.cpp:245]     Train net output #3: loss_mask = 1.80988 (* 3 = 5.42964 loss)
I0617 20:43:49.195636  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 1.98799 (* 0.3 = 0.596396 loss)
I0617 20:43:49.195638  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.233799 (* 1 = 0.233799 loss)
I0617 20:43:49.195642  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.00610633 (* 1 = 0.00610633 loss)
I0617 20:43:49.195647  6875 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0617 20:44:10.976572  6875 solver.cpp:229] Iteration 140, loss = 7.03914
I0617 20:44:10.976598  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.197918 (* 1 = 0.197918 loss)
I0617 20:44:10.976603  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.00573513 (* 2 = 0.0114703 loss)
I0617 20:44:10.976606  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.824985 (* 3 = 2.47495 loss)
I0617 20:44:10.976610  6875 solver.cpp:245]     Train net output #3: loss_mask = 1.15285 (* 3 = 3.45854 loss)
I0617 20:44:10.976624  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 1.92422 (* 0.3 = 0.577265 loss)
I0617 20:44:10.976627  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.159887 (* 1 = 0.159887 loss)
I0617 20:44:10.976631  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.271527 (* 1 = 0.271527 loss)
I0617 20:44:10.976645  6875 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0617 20:44:30.016786  6875 solver.cpp:229] Iteration 160, loss = 7.29503
I0617 20:44:30.016813  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.234349 (* 1 = 0.234349 loss)
I0617 20:44:30.016818  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.0160758 (* 2 = 0.0321515 loss)
I0617 20:44:30.016821  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.19555 (* 3 = 0.58665 loss)
I0617 20:44:30.016824  6875 solver.cpp:245]     Train net output #3: loss_mask = 1.76871 (* 3 = 5.30614 loss)
I0617 20:44:30.016829  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 1.92851 (* 0.3 = 0.578553 loss)
I0617 20:44:30.016842  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.179996 (* 1 = 0.179996 loss)
I0617 20:44:30.016845  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.00509947 (* 1 = 0.00509947 loss)
I0617 20:44:30.016850  6875 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0617 20:44:52.572489  6875 solver.cpp:229] Iteration 180, loss = 6.37639
I0617 20:44:52.572520  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.568583 (* 1 = 0.568583 loss)
I0617 20:44:52.572525  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.355771 (* 2 = 0.711541 loss)
I0617 20:44:52.572530  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.102051 (* 3 = 0.306154 loss)
I0617 20:44:52.572535  6875 solver.cpp:245]     Train net output #3: loss_mask = 1.49092 (* 3 = 4.47275 loss)
I0617 20:44:52.572540  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 1.87149 (* 0.3 = 0.561447 loss)
I0617 20:44:52.572543  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.121687 (* 1 = 0.121687 loss)
I0617 20:44:52.572547  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.00724699 (* 1 = 0.00724699 loss)
I0617 20:44:52.572553  6875 sgd_solver.cpp:106] Iteration 180, lr = 0.001
speed: 1.009s / iter
I0617 20:45:17.375810  6875 solver.cpp:229] Iteration 200, loss = 7.12732
I0617 20:45:17.375835  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.923698 (* 1 = 0.923698 loss)
I0617 20:45:17.375840  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.501482 (* 2 = 1.00296 loss)
I0617 20:45:17.375845  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.456913 (* 3 = 1.37074 loss)
I0617 20:45:17.375849  6875 solver.cpp:245]     Train net output #3: loss_mask = 1.07516 (* 3 = 3.22548 loss)
I0617 20:45:17.375852  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 1.75732 (* 0.3 = 0.527195 loss)
I0617 20:45:17.375856  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.175421 (* 1 = 0.175421 loss)
I0617 20:45:17.375860  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.0302105 (* 1 = 0.0302105 loss)
I0617 20:45:17.375864  6875 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0617 20:45:44.897240  6875 solver.cpp:229] Iteration 220, loss = 7.76307
I0617 20:45:44.897266  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.879595 (* 1 = 0.879595 loss)
I0617 20:45:44.897271  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.404415 (* 2 = 0.808831 loss)
I0617 20:45:44.897274  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.107394 (* 3 = 0.322182 loss)
I0617 20:45:44.897279  6875 solver.cpp:245]     Train net output #3: loss_mask = 1.36884 (* 3 = 4.10651 loss)
I0617 20:45:44.897281  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 1.80126 (* 0.3 = 0.540377 loss)
I0617 20:45:44.897295  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.0683403 (* 1 = 0.0683403 loss)
I0617 20:45:44.897298  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.00215891 (* 1 = 0.00215891 loss)
I0617 20:45:44.897302  6875 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0617 20:46:10.684291  6875 solver.cpp:229] Iteration 240, loss = 5.85653
I0617 20:46:10.684319  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.858539 (* 1 = 0.858539 loss)
I0617 20:46:10.684324  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.908599 (* 2 = 1.8172 loss)
I0617 20:46:10.684327  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.0574798 (* 3 = 0.172439 loss)
I0617 20:46:10.684331  6875 solver.cpp:245]     Train net output #3: loss_mask = 0.836015 (* 3 = 2.50804 loss)
I0617 20:46:10.684335  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 1.49529 (* 0.3 = 0.448586 loss)
I0617 20:46:10.684339  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.294275 (* 1 = 0.294275 loss)
I0617 20:46:10.684343  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.100272 (* 1 = 0.100272 loss)
I0617 20:46:10.684350  6875 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0617 20:46:37.360702  6875 solver.cpp:229] Iteration 260, loss = 4.86126
I0617 20:46:37.360730  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.557718 (* 1 = 0.557718 loss)
I0617 20:46:37.360735  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.451371 (* 2 = 0.902743 loss)
I0617 20:46:37.360738  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.050533 (* 3 = 0.151599 loss)
I0617 20:46:37.360743  6875 solver.cpp:245]     Train net output #3: loss_mask = 0.746988 (* 3 = 2.24096 loss)
I0617 20:46:37.360746  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 1.31435 (* 0.3 = 0.394305 loss)
I0617 20:46:37.360749  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.0460687 (* 1 = 0.0460687 loss)
I0617 20:46:37.360754  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.00784161 (* 1 = 0.00784161 loss)
I0617 20:46:37.360757  6875 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0617 20:47:03.981588  6875 solver.cpp:229] Iteration 280, loss = 5.10768
I0617 20:47:03.981616  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.434153 (* 1 = 0.434153 loss)
I0617 20:47:03.981621  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.613492 (* 2 = 1.22698 loss)
I0617 20:47:03.981624  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.0127709 (* 3 = 0.0383126 loss)
I0617 20:47:03.981628  6875 solver.cpp:245]     Train net output #3: loss_mask = 0.64812 (* 3 = 1.94436 loss)
I0617 20:47:03.981632  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 0.471446 (* 0.3 = 0.141434 loss)
I0617 20:47:03.981637  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.0861433 (* 1 = 0.0861433 loss)
I0617 20:47:03.981639  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.0397252 (* 1 = 0.0397252 loss)
I0617 20:47:03.981644  6875 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0617 20:47:30.889678  6875 solver.cpp:229] Iteration 300, loss = 5.41457
I0617 20:47:30.889704  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.487993 (* 1 = 0.487993 loss)
I0617 20:47:30.889709  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.659102 (* 2 = 1.3182 loss)
I0617 20:47:30.889714  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.0261386 (* 3 = 0.0784158 loss)
I0617 20:47:30.889717  6875 solver.cpp:245]     Train net output #3: loss_mask = 0.820518 (* 3 = 2.46155 loss)
I0617 20:47:30.889730  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 1.42473 (* 0.3 = 0.427419 loss)
I0617 20:47:30.889734  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.0491547 (* 1 = 0.0491547 loss)
I0617 20:47:30.889739  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.0331779 (* 1 = 0.0331779 loss)
I0617 20:47:30.889755  6875 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0617 20:47:58.893095  6875 solver.cpp:229] Iteration 320, loss = 3.68907
I0617 20:47:58.893131  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.393638 (* 1 = 0.393638 loss)
I0617 20:47:58.893136  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.366749 (* 2 = 0.733497 loss)
I0617 20:47:58.893138  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.252765 (* 3 = 0.758295 loss)
I0617 20:47:58.893152  6875 solver.cpp:245]     Train net output #3: loss_mask = 0.774287 (* 3 = 2.32286 loss)
I0617 20:47:58.893157  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 0.725094 (* 0.3 = 0.217528 loss)
I0617 20:47:58.893159  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.0292523 (* 1 = 0.0292523 loss)
I0617 20:47:58.893163  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.00257511 (* 1 = 0.00257511 loss)
I0617 20:47:58.893168  6875 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0617 20:48:27.259779  6875 solver.cpp:229] Iteration 340, loss = 5.84722
I0617 20:48:27.259809  6875 solver.cpp:245]     Train net output #0: loss_attribute = 0.0701492 (* 1 = 0.0701492 loss)
I0617 20:48:27.259817  6875 solver.cpp:245]     Train net output #1: loss_bbox = 0.0629898 (* 2 = 0.12598 loss)
I0617 20:48:27.259824  6875 solver.cpp:245]     Train net output #2: loss_cls = 0.0168237 (* 3 = 0.0504711 loss)
I0617 20:48:27.259832  6875 solver.cpp:245]     Train net output #3: loss_mask = 1.30768 (* 3 = 3.92305 loss)
I0617 20:48:27.259848  6875 solver.cpp:245]     Train net output #4: loss_mask_2 = 1.53166 (* 0.3 = 0.459497 loss)
I0617 20:48:27.259862  6875 solver.cpp:245]     Train net output #5: rpn_cls_loss = 0.10909 (* 1 = 0.10909 loss)
I0617 20:48:27.259867  6875 solver.cpp:245]     Train net output #6: rpn_loss_bbox = 0.0126789 (* 1 = 0.0126789 loss)
I0617 20:48:27.259887  6875 sgd_solver.cpp:106] Iteration 340, lr = 0.001
