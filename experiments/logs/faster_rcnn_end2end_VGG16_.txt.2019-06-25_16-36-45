+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-25_16-36-45
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-25_16-36-45
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0625 16:36:58.277343 14909 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0625 16:36:58.277360 14909 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0625 16:36:58.278826 14909 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  top: "attrArray"
  top: "attrArrayInd"
  top: "attrArrayShift"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "attr_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "attr_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "attr_score_pos"
  type: "Eltwise"
  bottom: "attr_score"
  bottom: "attrArrayInd"
  top: "attr_score_pos"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "attr_score_pos_shift"
  type: "Eltwise"
  bottom: "attr_score_pos"
  bottom: "attrArrayShift"
  top: "attr_score_pos_shift"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_attribute"
  type: "SigmoidCrossEntropyLoss"
  bottom: "attr_score_pos_shift"
  bottom: "attrArray"
  top: "loss_attribute"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "mask_score"
  top: "mask_score_softmax"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "log"
  type: "Log"
  bottom: "mask_score_softmax"
  top: "log"
}
layer {
  name: "mult1"
  type: "Eltwise"
  bottom: "log"
  bottom: "mask_targets"
  top: "mult1"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "cross_entropy"
  type: "Power"
  bottom: "mult1"
  top: "cross_entropy"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "ce_sum"
  type: "Convolution"
  bottom: "cross_entropy"
  top: "cross_entropy_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "ce_mean"
  type: "Reduction"
  bottom: "cross_entropy_sum"
  top: "cross_entropy_mean"
  loss_weight: 1
  reduction_param {
    operation: MEAN
    axis: 0
  }
}
I0625 16:36:58.279148 14909 layer_factory.hpp:77] Creating layer input-data
I0625 16:36:58.328336 14909 net.cpp:106] Creating Layer input-data
I0625 16:36:58.328352 14909 net.cpp:411] input-data -> data
I0625 16:36:58.328359 14909 net.cpp:411] input-data -> im_info
I0625 16:36:58.328364 14909 net.cpp:411] input-data -> gt_boxes
I0625 16:36:58.328368 14909 net.cpp:411] input-data -> seg_mask_inds
I0625 16:36:58.328373 14909 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0625 16:36:58.404500 14909 net.cpp:150] Setting up input-data
I0625 16:36:58.404515 14909 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 16:36:58.404518 14909 net.cpp:157] Top shape: 1 3 (3)
I0625 16:36:58.404520 14909 net.cpp:157] Top shape: 1 4 (4)
I0625 16:36:58.404522 14909 net.cpp:157] Top shape: 1 2 (2)
I0625 16:36:58.404525 14909 net.cpp:157] Top shape: 1 1 (1)
I0625 16:36:58.404528 14909 net.cpp:165] Memory required for data: 7200040
I0625 16:36:58.404534 14909 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0625 16:36:58.404551 14909 net.cpp:106] Creating Layer data_input-data_0_split
I0625 16:36:58.404553 14909 net.cpp:454] data_input-data_0_split <- data
I0625 16:36:58.404558 14909 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0625 16:36:58.404563 14909 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0625 16:36:58.404585 14909 net.cpp:150] Setting up data_input-data_0_split
I0625 16:36:58.404589 14909 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 16:36:58.404592 14909 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 16:36:58.404593 14909 net.cpp:165] Memory required for data: 21600040
I0625 16:36:58.404595 14909 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0625 16:36:58.404599 14909 net.cpp:106] Creating Layer im_info_input-data_1_split
I0625 16:36:58.404600 14909 net.cpp:454] im_info_input-data_1_split <- im_info
I0625 16:36:58.404603 14909 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0625 16:36:58.404606 14909 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0625 16:36:58.404610 14909 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0625 16:36:58.404633 14909 net.cpp:150] Setting up im_info_input-data_1_split
I0625 16:36:58.404636 14909 net.cpp:157] Top shape: 1 3 (3)
I0625 16:36:58.404639 14909 net.cpp:157] Top shape: 1 3 (3)
I0625 16:36:58.404640 14909 net.cpp:157] Top shape: 1 3 (3)
I0625 16:36:58.404642 14909 net.cpp:165] Memory required for data: 21600076
I0625 16:36:58.404644 14909 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0625 16:36:58.404646 14909 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0625 16:36:58.404649 14909 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0625 16:36:58.404651 14909 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0625 16:36:58.404654 14909 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0625 16:36:58.404670 14909 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0625 16:36:58.404673 14909 net.cpp:157] Top shape: 1 4 (4)
I0625 16:36:58.404675 14909 net.cpp:157] Top shape: 1 4 (4)
I0625 16:36:58.404677 14909 net.cpp:165] Memory required for data: 21600108
I0625 16:36:58.404680 14909 layer_factory.hpp:77] Creating layer conv1_1
I0625 16:36:58.404690 14909 net.cpp:106] Creating Layer conv1_1
I0625 16:36:58.404691 14909 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0625 16:36:58.404695 14909 net.cpp:411] conv1_1 -> conv1_1
I0625 16:36:58.619647 14909 net.cpp:150] Setting up conv1_1
I0625 16:36:58.619678 14909 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 16:36:58.619683 14909 net.cpp:165] Memory required for data: 175200108
I0625 16:36:58.619696 14909 layer_factory.hpp:77] Creating layer relu1_1
I0625 16:36:58.619706 14909 net.cpp:106] Creating Layer relu1_1
I0625 16:36:58.619710 14909 net.cpp:454] relu1_1 <- conv1_1
I0625 16:36:58.619714 14909 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0625 16:36:58.619866 14909 net.cpp:150] Setting up relu1_1
I0625 16:36:58.619877 14909 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 16:36:58.619879 14909 net.cpp:165] Memory required for data: 328800108
I0625 16:36:58.619882 14909 layer_factory.hpp:77] Creating layer conv1_2
I0625 16:36:58.619890 14909 net.cpp:106] Creating Layer conv1_2
I0625 16:36:58.619894 14909 net.cpp:454] conv1_2 <- conv1_1
I0625 16:36:58.619897 14909 net.cpp:411] conv1_2 -> conv1_2
I0625 16:36:58.622382 14909 net.cpp:150] Setting up conv1_2
I0625 16:36:58.622404 14909 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 16:36:58.622406 14909 net.cpp:165] Memory required for data: 482400108
I0625 16:36:58.622413 14909 layer_factory.hpp:77] Creating layer relu1_2
I0625 16:36:58.622428 14909 net.cpp:106] Creating Layer relu1_2
I0625 16:36:58.622432 14909 net.cpp:454] relu1_2 <- conv1_2
I0625 16:36:58.622437 14909 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0625 16:36:58.622565 14909 net.cpp:150] Setting up relu1_2
I0625 16:36:58.622571 14909 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 16:36:58.622583 14909 net.cpp:165] Memory required for data: 636000108
I0625 16:36:58.622586 14909 layer_factory.hpp:77] Creating layer pool1
I0625 16:36:58.622592 14909 net.cpp:106] Creating Layer pool1
I0625 16:36:58.622596 14909 net.cpp:454] pool1 <- conv1_2
I0625 16:36:58.622601 14909 net.cpp:411] pool1 -> pool1
I0625 16:36:58.622656 14909 net.cpp:150] Setting up pool1
I0625 16:36:58.622661 14909 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0625 16:36:58.622673 14909 net.cpp:165] Memory required for data: 674400108
I0625 16:36:58.622675 14909 layer_factory.hpp:77] Creating layer conv2_1
I0625 16:36:58.622680 14909 net.cpp:106] Creating Layer conv2_1
I0625 16:36:58.622683 14909 net.cpp:454] conv2_1 <- pool1
I0625 16:36:58.622685 14909 net.cpp:411] conv2_1 -> conv2_1
I0625 16:36:58.624493 14909 net.cpp:150] Setting up conv2_1
I0625 16:36:58.624502 14909 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 16:36:58.624514 14909 net.cpp:165] Memory required for data: 751200108
I0625 16:36:58.624521 14909 layer_factory.hpp:77] Creating layer relu2_1
I0625 16:36:58.624536 14909 net.cpp:106] Creating Layer relu2_1
I0625 16:36:58.624539 14909 net.cpp:454] relu2_1 <- conv2_1
I0625 16:36:58.624542 14909 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0625 16:36:58.624999 14909 net.cpp:150] Setting up relu2_1
I0625 16:36:58.625006 14909 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 16:36:58.625018 14909 net.cpp:165] Memory required for data: 828000108
I0625 16:36:58.625020 14909 layer_factory.hpp:77] Creating layer conv2_2
I0625 16:36:58.625036 14909 net.cpp:106] Creating Layer conv2_2
I0625 16:36:58.625038 14909 net.cpp:454] conv2_2 <- conv2_1
I0625 16:36:58.625041 14909 net.cpp:411] conv2_2 -> conv2_2
I0625 16:36:58.626405 14909 net.cpp:150] Setting up conv2_2
I0625 16:36:58.626412 14909 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 16:36:58.626415 14909 net.cpp:165] Memory required for data: 904800108
I0625 16:36:58.626420 14909 layer_factory.hpp:77] Creating layer relu2_2
I0625 16:36:58.626423 14909 net.cpp:106] Creating Layer relu2_2
I0625 16:36:58.626426 14909 net.cpp:454] relu2_2 <- conv2_2
I0625 16:36:58.626440 14909 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0625 16:36:58.626574 14909 net.cpp:150] Setting up relu2_2
I0625 16:36:58.626579 14909 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 16:36:58.626581 14909 net.cpp:165] Memory required for data: 981600108
I0625 16:36:58.626593 14909 layer_factory.hpp:77] Creating layer pool2
I0625 16:36:58.626598 14909 net.cpp:106] Creating Layer pool2
I0625 16:36:58.626615 14909 net.cpp:454] pool2 <- conv2_2
I0625 16:36:58.626621 14909 net.cpp:411] pool2 -> pool2
I0625 16:36:58.626657 14909 net.cpp:150] Setting up pool2
I0625 16:36:58.626670 14909 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0625 16:36:58.626674 14909 net.cpp:165] Memory required for data: 1000800108
I0625 16:36:58.626686 14909 layer_factory.hpp:77] Creating layer conv3_1
I0625 16:36:58.626693 14909 net.cpp:106] Creating Layer conv3_1
I0625 16:36:58.626695 14909 net.cpp:454] conv3_1 <- pool2
I0625 16:36:58.626700 14909 net.cpp:411] conv3_1 -> conv3_1
I0625 16:36:58.628545 14909 net.cpp:150] Setting up conv3_1
I0625 16:36:58.628553 14909 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 16:36:58.628556 14909 net.cpp:165] Memory required for data: 1039200108
I0625 16:36:58.628562 14909 layer_factory.hpp:77] Creating layer relu3_1
I0625 16:36:58.628566 14909 net.cpp:106] Creating Layer relu3_1
I0625 16:36:58.628568 14909 net.cpp:454] relu3_1 <- conv3_1
I0625 16:36:58.628582 14909 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0625 16:36:58.628715 14909 net.cpp:150] Setting up relu3_1
I0625 16:36:58.628721 14909 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 16:36:58.628723 14909 net.cpp:165] Memory required for data: 1077600108
I0625 16:36:58.628726 14909 layer_factory.hpp:77] Creating layer conv3_2
I0625 16:36:58.628731 14909 net.cpp:106] Creating Layer conv3_2
I0625 16:36:58.628733 14909 net.cpp:454] conv3_2 <- conv3_1
I0625 16:36:58.628736 14909 net.cpp:411] conv3_2 -> conv3_2
I0625 16:36:58.630659 14909 net.cpp:150] Setting up conv3_2
I0625 16:36:58.630668 14909 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 16:36:58.630671 14909 net.cpp:165] Memory required for data: 1116000108
I0625 16:36:58.630676 14909 layer_factory.hpp:77] Creating layer relu3_2
I0625 16:36:58.630679 14909 net.cpp:106] Creating Layer relu3_2
I0625 16:36:58.630681 14909 net.cpp:454] relu3_2 <- conv3_2
I0625 16:36:58.630686 14909 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0625 16:36:58.630810 14909 net.cpp:150] Setting up relu3_2
I0625 16:36:58.630815 14909 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 16:36:58.630817 14909 net.cpp:165] Memory required for data: 1154400108
I0625 16:36:58.630820 14909 layer_factory.hpp:77] Creating layer conv3_3
I0625 16:36:58.630825 14909 net.cpp:106] Creating Layer conv3_3
I0625 16:36:58.630826 14909 net.cpp:454] conv3_3 <- conv3_2
I0625 16:36:58.630829 14909 net.cpp:411] conv3_3 -> conv3_3
I0625 16:36:58.632815 14909 net.cpp:150] Setting up conv3_3
I0625 16:36:58.632825 14909 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 16:36:58.632827 14909 net.cpp:165] Memory required for data: 1192800108
I0625 16:36:58.632833 14909 layer_factory.hpp:77] Creating layer relu3_3
I0625 16:36:58.632836 14909 net.cpp:106] Creating Layer relu3_3
I0625 16:36:58.632839 14909 net.cpp:454] relu3_3 <- conv3_3
I0625 16:36:58.632843 14909 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0625 16:36:58.632964 14909 net.cpp:150] Setting up relu3_3
I0625 16:36:58.632971 14909 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 16:36:58.632972 14909 net.cpp:165] Memory required for data: 1231200108
I0625 16:36:58.632974 14909 layer_factory.hpp:77] Creating layer pool3
I0625 16:36:58.632978 14909 net.cpp:106] Creating Layer pool3
I0625 16:36:58.632980 14909 net.cpp:454] pool3 <- conv3_3
I0625 16:36:58.632983 14909 net.cpp:411] pool3 -> pool3
I0625 16:36:58.633030 14909 net.cpp:150] Setting up pool3
I0625 16:36:58.633034 14909 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0625 16:36:58.633046 14909 net.cpp:165] Memory required for data: 1240800108
I0625 16:36:58.633049 14909 layer_factory.hpp:77] Creating layer conv4_1
I0625 16:36:58.633052 14909 net.cpp:106] Creating Layer conv4_1
I0625 16:36:58.633055 14909 net.cpp:454] conv4_1 <- pool3
I0625 16:36:58.633069 14909 net.cpp:411] conv4_1 -> conv4_1
I0625 16:36:58.637123 14909 net.cpp:150] Setting up conv4_1
I0625 16:36:58.637151 14909 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 16:36:58.637153 14909 net.cpp:165] Memory required for data: 1260000108
I0625 16:36:58.637169 14909 layer_factory.hpp:77] Creating layer relu4_1
I0625 16:36:58.637187 14909 net.cpp:106] Creating Layer relu4_1
I0625 16:36:58.637192 14909 net.cpp:454] relu4_1 <- conv4_1
I0625 16:36:58.637195 14909 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0625 16:36:58.637323 14909 net.cpp:150] Setting up relu4_1
I0625 16:36:58.637329 14909 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 16:36:58.637341 14909 net.cpp:165] Memory required for data: 1279200108
I0625 16:36:58.637343 14909 layer_factory.hpp:77] Creating layer conv4_2
I0625 16:36:58.637349 14909 net.cpp:106] Creating Layer conv4_2
I0625 16:36:58.637367 14909 net.cpp:454] conv4_2 <- conv4_1
I0625 16:36:58.637372 14909 net.cpp:411] conv4_2 -> conv4_2
I0625 16:36:58.641952 14909 net.cpp:150] Setting up conv4_2
I0625 16:36:58.641983 14909 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 16:36:58.641985 14909 net.cpp:165] Memory required for data: 1298400108
I0625 16:36:58.642006 14909 layer_factory.hpp:77] Creating layer relu4_2
I0625 16:36:58.642014 14909 net.cpp:106] Creating Layer relu4_2
I0625 16:36:58.642019 14909 net.cpp:454] relu4_2 <- conv4_2
I0625 16:36:58.642025 14909 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0625 16:36:58.642534 14909 net.cpp:150] Setting up relu4_2
I0625 16:36:58.642541 14909 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 16:36:58.642544 14909 net.cpp:165] Memory required for data: 1317600108
I0625 16:36:58.642545 14909 layer_factory.hpp:77] Creating layer conv4_3
I0625 16:36:58.642551 14909 net.cpp:106] Creating Layer conv4_3
I0625 16:36:58.642554 14909 net.cpp:454] conv4_3 <- conv4_2
I0625 16:36:58.642557 14909 net.cpp:411] conv4_3 -> conv4_3
I0625 16:36:58.646754 14909 net.cpp:150] Setting up conv4_3
I0625 16:36:58.646772 14909 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 16:36:58.646775 14909 net.cpp:165] Memory required for data: 1336800108
I0625 16:36:58.646781 14909 layer_factory.hpp:77] Creating layer relu4_3
I0625 16:36:58.646788 14909 net.cpp:106] Creating Layer relu4_3
I0625 16:36:58.646792 14909 net.cpp:454] relu4_3 <- conv4_3
I0625 16:36:58.646798 14909 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0625 16:36:58.646919 14909 net.cpp:150] Setting up relu4_3
I0625 16:36:58.646925 14909 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 16:36:58.646927 14909 net.cpp:165] Memory required for data: 1356000108
I0625 16:36:58.646929 14909 layer_factory.hpp:77] Creating layer pool4
I0625 16:36:58.646934 14909 net.cpp:106] Creating Layer pool4
I0625 16:36:58.646935 14909 net.cpp:454] pool4 <- conv4_3
I0625 16:36:58.646939 14909 net.cpp:411] pool4 -> pool4
I0625 16:36:58.646986 14909 net.cpp:150] Setting up pool4
I0625 16:36:58.646991 14909 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:36:58.647002 14909 net.cpp:165] Memory required for data: 1360903020
I0625 16:36:58.647004 14909 layer_factory.hpp:77] Creating layer conv5_1
I0625 16:36:58.647011 14909 net.cpp:106] Creating Layer conv5_1
I0625 16:36:58.647012 14909 net.cpp:454] conv5_1 <- pool4
I0625 16:36:58.647017 14909 net.cpp:411] conv5_1 -> conv5_1
I0625 16:36:58.651638 14909 net.cpp:150] Setting up conv5_1
I0625 16:36:58.651655 14909 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:36:58.651657 14909 net.cpp:165] Memory required for data: 1365805932
I0625 16:36:58.651664 14909 layer_factory.hpp:77] Creating layer relu5_1
I0625 16:36:58.651671 14909 net.cpp:106] Creating Layer relu5_1
I0625 16:36:58.651675 14909 net.cpp:454] relu5_1 <- conv5_1
I0625 16:36:58.651681 14909 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0625 16:36:58.651806 14909 net.cpp:150] Setting up relu5_1
I0625 16:36:58.651811 14909 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:36:58.651813 14909 net.cpp:165] Memory required for data: 1370708844
I0625 16:36:58.651815 14909 layer_factory.hpp:77] Creating layer conv5_2
I0625 16:36:58.651821 14909 net.cpp:106] Creating Layer conv5_2
I0625 16:36:58.651823 14909 net.cpp:454] conv5_2 <- conv5_1
I0625 16:36:58.651826 14909 net.cpp:411] conv5_2 -> conv5_2
I0625 16:36:58.656183 14909 net.cpp:150] Setting up conv5_2
I0625 16:36:58.656203 14909 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:36:58.656205 14909 net.cpp:165] Memory required for data: 1375611756
I0625 16:36:58.656211 14909 layer_factory.hpp:77] Creating layer relu5_2
I0625 16:36:58.656220 14909 net.cpp:106] Creating Layer relu5_2
I0625 16:36:58.656224 14909 net.cpp:454] relu5_2 <- conv5_2
I0625 16:36:58.656229 14909 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0625 16:36:58.656340 14909 net.cpp:150] Setting up relu5_2
I0625 16:36:58.656347 14909 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:36:58.656348 14909 net.cpp:165] Memory required for data: 1380514668
I0625 16:36:58.656350 14909 layer_factory.hpp:77] Creating layer conv5_3
I0625 16:36:58.656358 14909 net.cpp:106] Creating Layer conv5_3
I0625 16:36:58.656361 14909 net.cpp:454] conv5_3 <- conv5_2
I0625 16:36:58.656366 14909 net.cpp:411] conv5_3 -> conv5_3
I0625 16:36:58.661360 14909 net.cpp:150] Setting up conv5_3
I0625 16:36:58.661389 14909 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:36:58.661392 14909 net.cpp:165] Memory required for data: 1385417580
I0625 16:36:58.661399 14909 layer_factory.hpp:77] Creating layer relu5_3
I0625 16:36:58.661418 14909 net.cpp:106] Creating Layer relu5_3
I0625 16:36:58.661423 14909 net.cpp:454] relu5_3 <- conv5_3
I0625 16:36:58.661429 14909 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0625 16:36:58.661584 14909 net.cpp:150] Setting up relu5_3
I0625 16:36:58.661602 14909 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:36:58.661602 14909 net.cpp:165] Memory required for data: 1390320492
I0625 16:36:58.661604 14909 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0625 16:36:58.661619 14909 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0625 16:36:58.661622 14909 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0625 16:36:58.661625 14909 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0625 16:36:58.661630 14909 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0625 16:36:58.661634 14909 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0625 16:36:58.661675 14909 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0625 16:36:58.661679 14909 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:36:58.661691 14909 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:36:58.661693 14909 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:36:58.661695 14909 net.cpp:165] Memory required for data: 1405029228
I0625 16:36:58.661698 14909 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0625 16:36:58.661707 14909 net.cpp:106] Creating Layer rpn_conv/3x3
I0625 16:36:58.661710 14909 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0625 16:36:58.661715 14909 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0625 16:36:58.713416 14909 net.cpp:150] Setting up rpn_conv/3x3
I0625 16:36:58.713435 14909 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:36:58.713438 14909 net.cpp:165] Memory required for data: 1409932140
I0625 16:36:58.713444 14909 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0625 16:36:58.713452 14909 net.cpp:106] Creating Layer rpn_relu/3x3
I0625 16:36:58.713465 14909 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0625 16:36:58.713469 14909 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0625 16:36:58.713584 14909 net.cpp:150] Setting up rpn_relu/3x3
I0625 16:36:58.713590 14909 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:36:58.713593 14909 net.cpp:165] Memory required for data: 1414835052
I0625 16:36:58.713594 14909 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0625 16:36:58.713598 14909 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0625 16:36:58.713600 14909 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0625 16:36:58.713603 14909 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0625 16:36:58.713608 14909 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0625 16:36:58.713652 14909 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0625 16:36:58.713656 14909 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:36:58.713668 14909 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:36:58.713670 14909 net.cpp:165] Memory required for data: 1424640876
I0625 16:36:58.713671 14909 layer_factory.hpp:77] Creating layer rpn_cls_score
I0625 16:36:58.713688 14909 net.cpp:106] Creating Layer rpn_cls_score
I0625 16:36:58.713690 14909 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0625 16:36:58.713693 14909 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0625 16:36:58.715409 14909 net.cpp:150] Setting up rpn_cls_score
I0625 16:36:58.715417 14909 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 16:36:58.715420 14909 net.cpp:165] Memory required for data: 1424928156
I0625 16:36:58.715425 14909 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0625 16:36:58.715428 14909 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0625 16:36:58.715431 14909 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0625 16:36:58.715445 14909 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0625 16:36:58.715451 14909 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0625 16:36:58.715483 14909 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0625 16:36:58.715487 14909 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 16:36:58.715488 14909 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 16:36:58.715502 14909 net.cpp:165] Memory required for data: 1425502716
I0625 16:36:58.715503 14909 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0625 16:36:58.715509 14909 net.cpp:106] Creating Layer rpn_bbox_pred
I0625 16:36:58.715524 14909 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0625 16:36:58.715528 14909 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0625 16:36:58.717201 14909 net.cpp:150] Setting up rpn_bbox_pred
I0625 16:36:58.717223 14909 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 16:36:58.717236 14909 net.cpp:165] Memory required for data: 1426077276
I0625 16:36:58.717253 14909 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 16:36:58.717260 14909 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 16:36:58.717276 14909 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0625 16:36:58.717280 14909 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0625 16:36:58.717294 14909 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0625 16:36:58.717339 14909 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 16:36:58.717353 14909 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 16:36:58.717355 14909 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 16:36:58.717357 14909 net.cpp:165] Memory required for data: 1427226396
I0625 16:36:58.717360 14909 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0625 16:36:58.717365 14909 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0625 16:36:58.717366 14909 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0625 16:36:58.717370 14909 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0625 16:36:58.717383 14909 net.cpp:150] Setting up rpn_cls_score_reshape
I0625 16:36:58.717387 14909 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 16:36:58.717388 14909 net.cpp:165] Memory required for data: 1427513676
I0625 16:36:58.717391 14909 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 16:36:58.717393 14909 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 16:36:58.717396 14909 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0625 16:36:58.717399 14909 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0625 16:36:58.717402 14909 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0625 16:36:58.717422 14909 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 16:36:58.717425 14909 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 16:36:58.717427 14909 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 16:36:58.717428 14909 net.cpp:165] Memory required for data: 1428088236
I0625 16:36:58.717430 14909 layer_factory.hpp:77] Creating layer rpn-data
I0625 16:36:58.718437 14909 net.cpp:106] Creating Layer rpn-data
I0625 16:36:58.718446 14909 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0625 16:36:58.718449 14909 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0625 16:36:58.718452 14909 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0625 16:36:58.718456 14909 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0625 16:36:58.718459 14909 net.cpp:411] rpn-data -> rpn_labels
I0625 16:36:58.718464 14909 net.cpp:411] rpn-data -> rpn_bbox_targets
I0625 16:36:58.718469 14909 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0625 16:36:58.718474 14909 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0625 16:36:58.719408 14909 net.cpp:150] Setting up rpn-data
I0625 16:36:58.719416 14909 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0625 16:36:58.719419 14909 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 16:36:58.719431 14909 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 16:36:58.719434 14909 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 16:36:58.719435 14909 net.cpp:165] Memory required for data: 1429955556
I0625 16:36:58.719437 14909 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0625 16:36:58.719442 14909 net.cpp:106] Creating Layer rpn_loss_cls
I0625 16:36:58.719445 14909 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0625 16:36:58.719449 14909 net.cpp:454] rpn_loss_cls <- rpn_labels
I0625 16:36:58.719453 14909 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0625 16:36:58.719465 14909 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0625 16:36:58.720094 14909 net.cpp:150] Setting up rpn_loss_cls
I0625 16:36:58.720103 14909 net.cpp:157] Top shape: (1)
I0625 16:36:58.720108 14909 net.cpp:160]     with loss weight 1
I0625 16:36:58.720115 14909 net.cpp:165] Memory required for data: 1429955560
I0625 16:36:58.720118 14909 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0625 16:36:58.720126 14909 net.cpp:106] Creating Layer rpn_loss_bbox
I0625 16:36:58.720129 14909 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0625 16:36:58.720132 14909 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0625 16:36:58.720134 14909 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0625 16:36:58.720137 14909 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0625 16:36:58.720139 14909 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0625 16:36:58.721287 14909 net.cpp:150] Setting up rpn_loss_bbox
I0625 16:36:58.721294 14909 net.cpp:157] Top shape: (1)
I0625 16:36:58.721297 14909 net.cpp:160]     with loss weight 1
I0625 16:36:58.721302 14909 net.cpp:165] Memory required for data: 1429955564
I0625 16:36:58.721303 14909 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0625 16:36:58.721308 14909 net.cpp:106] Creating Layer rpn_cls_prob
I0625 16:36:58.721310 14909 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0625 16:36:58.721313 14909 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0625 16:36:58.721468 14909 net.cpp:150] Setting up rpn_cls_prob
I0625 16:36:58.721474 14909 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 16:36:58.721477 14909 net.cpp:165] Memory required for data: 1430242844
I0625 16:36:58.721478 14909 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0625 16:36:58.721484 14909 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0625 16:36:58.721487 14909 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0625 16:36:58.721490 14909 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0625 16:36:58.721508 14909 net.cpp:150] Setting up rpn_cls_prob_reshape
I0625 16:36:58.721511 14909 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 16:36:58.721513 14909 net.cpp:165] Memory required for data: 1430530124
I0625 16:36:58.721514 14909 layer_factory.hpp:77] Creating layer proposal
I0625 16:36:58.722641 14909 net.cpp:106] Creating Layer proposal
I0625 16:36:58.722651 14909 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0625 16:36:58.722653 14909 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0625 16:36:58.722657 14909 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0625 16:36:58.722661 14909 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0625 16:36:58.723892 14909 net.cpp:150] Setting up proposal
I0625 16:36:58.723901 14909 net.cpp:157] Top shape: 1 5 (5)
I0625 16:36:58.723904 14909 net.cpp:165] Memory required for data: 1430530144
I0625 16:36:58.723906 14909 layer_factory.hpp:77] Creating layer roi-data
I0625 16:36:58.726848 14909 net.cpp:106] Creating Layer roi-data
I0625 16:36:58.726856 14909 net.cpp:454] roi-data <- rpn_rois
I0625 16:36:58.726860 14909 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0625 16:36:58.726862 14909 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0625 16:36:58.726864 14909 net.cpp:454] roi-data <- seg_mask_inds
I0625 16:36:58.726866 14909 net.cpp:454] roi-data <- flipped
I0625 16:36:58.726871 14909 net.cpp:411] roi-data -> rois
I0625 16:36:58.726876 14909 net.cpp:411] roi-data -> labels
I0625 16:36:58.726889 14909 net.cpp:411] roi-data -> bbox_targets
I0625 16:36:58.726892 14909 net.cpp:411] roi-data -> bbox_inside_weights
I0625 16:36:58.726897 14909 net.cpp:411] roi-data -> bbox_outside_weights
I0625 16:36:58.726912 14909 net.cpp:411] roi-data -> mask_targets
I0625 16:36:58.726917 14909 net.cpp:411] roi-data -> rois_pos
I0625 16:36:58.726920 14909 net.cpp:411] roi-data -> attrArray
I0625 16:36:58.726924 14909 net.cpp:411] roi-data -> attrArrayInd
I0625 16:36:58.726928 14909 net.cpp:411] roi-data -> attrArrayShift
I0625 16:36:58.727403 14909 net.cpp:150] Setting up roi-data
I0625 16:36:58.727412 14909 net.cpp:157] Top shape: 1 5 (5)
I0625 16:36:58.727414 14909 net.cpp:157] Top shape: 1 1 (1)
I0625 16:36:58.727416 14909 net.cpp:157] Top shape: 1 8 (8)
I0625 16:36:58.727427 14909 net.cpp:157] Top shape: 1 8 (8)
I0625 16:36:58.727429 14909 net.cpp:157] Top shape: 1 8 (8)
I0625 16:36:58.727432 14909 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 16:36:58.727433 14909 net.cpp:157] Top shape: 1 5 (5)
I0625 16:36:58.727435 14909 net.cpp:157] Top shape: 1 7 (7)
I0625 16:36:58.727437 14909 net.cpp:157] Top shape: 1 7 (7)
I0625 16:36:58.727439 14909 net.cpp:157] Top shape: 1 7 (7)
I0625 16:36:58.727440 14909 net.cpp:165] Memory required for data: 1432435520
I0625 16:36:58.727443 14909 layer_factory.hpp:77] Creating layer roi_pool5
I0625 16:36:58.727448 14909 net.cpp:106] Creating Layer roi_pool5
I0625 16:36:58.727452 14909 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0625 16:36:58.727455 14909 net.cpp:454] roi_pool5 <- rois
I0625 16:36:58.727458 14909 net.cpp:411] roi_pool5 -> pool5
I0625 16:36:58.727463 14909 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0625 16:36:58.727537 14909 net.cpp:150] Setting up roi_pool5
I0625 16:36:58.727545 14909 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 16:36:58.727548 14909 net.cpp:165] Memory required for data: 1432535872
I0625 16:36:58.727551 14909 layer_factory.hpp:77] Creating layer fc6
I0625 16:36:58.727558 14909 net.cpp:106] Creating Layer fc6
I0625 16:36:58.727561 14909 net.cpp:454] fc6 <- pool5
I0625 16:36:58.727564 14909 net.cpp:411] fc6 -> fc6
I0625 16:36:58.882089 14909 net.cpp:150] Setting up fc6
I0625 16:36:58.882115 14909 net.cpp:157] Top shape: 1 4096 (4096)
I0625 16:36:58.882118 14909 net.cpp:165] Memory required for data: 1432552256
I0625 16:36:58.882133 14909 layer_factory.hpp:77] Creating layer relu6
I0625 16:36:58.882140 14909 net.cpp:106] Creating Layer relu6
I0625 16:36:58.882144 14909 net.cpp:454] relu6 <- fc6
I0625 16:36:58.882149 14909 net.cpp:397] relu6 -> fc6 (in-place)
I0625 16:36:58.882361 14909 net.cpp:150] Setting up relu6
I0625 16:36:58.882369 14909 net.cpp:157] Top shape: 1 4096 (4096)
I0625 16:36:58.882371 14909 net.cpp:165] Memory required for data: 1432568640
I0625 16:36:58.882374 14909 layer_factory.hpp:77] Creating layer fc7
I0625 16:36:58.882378 14909 net.cpp:106] Creating Layer fc7
I0625 16:36:58.882381 14909 net.cpp:454] fc7 <- fc6
I0625 16:36:58.882385 14909 net.cpp:411] fc7 -> fc7
I0625 16:36:58.906060 14909 net.cpp:150] Setting up fc7
I0625 16:36:58.906095 14909 net.cpp:157] Top shape: 1 4096 (4096)
I0625 16:36:58.906097 14909 net.cpp:165] Memory required for data: 1432585024
I0625 16:36:58.906105 14909 layer_factory.hpp:77] Creating layer relu7
I0625 16:36:58.906114 14909 net.cpp:106] Creating Layer relu7
I0625 16:36:58.906119 14909 net.cpp:454] relu7 <- fc7
I0625 16:36:58.906124 14909 net.cpp:397] relu7 -> fc7 (in-place)
I0625 16:36:58.906347 14909 net.cpp:150] Setting up relu7
I0625 16:36:58.906364 14909 net.cpp:157] Top shape: 1 4096 (4096)
I0625 16:36:58.906366 14909 net.cpp:165] Memory required for data: 1432601408
I0625 16:36:58.906368 14909 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0625 16:36:58.906373 14909 net.cpp:106] Creating Layer fc7_relu7_0_split
I0625 16:36:58.906376 14909 net.cpp:454] fc7_relu7_0_split <- fc7
I0625 16:36:58.906379 14909 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0625 16:36:58.906386 14909 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0625 16:36:58.906390 14909 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0625 16:36:58.906430 14909 net.cpp:150] Setting up fc7_relu7_0_split
I0625 16:36:58.906435 14909 net.cpp:157] Top shape: 1 4096 (4096)
I0625 16:36:58.906436 14909 net.cpp:157] Top shape: 1 4096 (4096)
I0625 16:36:58.906438 14909 net.cpp:157] Top shape: 1 4096 (4096)
I0625 16:36:58.906440 14909 net.cpp:165] Memory required for data: 1432650560
I0625 16:36:58.906441 14909 layer_factory.hpp:77] Creating layer attr_score
I0625 16:36:58.906446 14909 net.cpp:106] Creating Layer attr_score
I0625 16:36:58.906450 14909 net.cpp:454] attr_score <- fc7_relu7_0_split_0
I0625 16:36:58.906452 14909 net.cpp:411] attr_score -> attr_score
I0625 16:36:58.907106 14909 net.cpp:150] Setting up attr_score
I0625 16:36:58.907110 14909 net.cpp:157] Top shape: 1 7 (7)
I0625 16:36:58.907114 14909 net.cpp:165] Memory required for data: 1432650588
I0625 16:36:58.907127 14909 layer_factory.hpp:77] Creating layer attr_score_pos
I0625 16:36:58.907132 14909 net.cpp:106] Creating Layer attr_score_pos
I0625 16:36:58.907135 14909 net.cpp:454] attr_score_pos <- attr_score
I0625 16:36:58.907138 14909 net.cpp:454] attr_score_pos <- attrArrayInd
I0625 16:36:58.907141 14909 net.cpp:411] attr_score_pos -> attr_score_pos
I0625 16:36:58.907156 14909 net.cpp:150] Setting up attr_score_pos
I0625 16:36:58.907160 14909 net.cpp:157] Top shape: 1 7 (7)
I0625 16:36:58.907161 14909 net.cpp:165] Memory required for data: 1432650616
I0625 16:36:58.907163 14909 layer_factory.hpp:77] Creating layer attr_score_pos_shift
I0625 16:36:58.907166 14909 net.cpp:106] Creating Layer attr_score_pos_shift
I0625 16:36:58.907168 14909 net.cpp:454] attr_score_pos_shift <- attr_score_pos
I0625 16:36:58.907171 14909 net.cpp:454] attr_score_pos_shift <- attrArrayShift
I0625 16:36:58.907173 14909 net.cpp:411] attr_score_pos_shift -> attr_score_pos_shift
I0625 16:36:58.907186 14909 net.cpp:150] Setting up attr_score_pos_shift
I0625 16:36:58.907189 14909 net.cpp:157] Top shape: 1 7 (7)
I0625 16:36:58.907191 14909 net.cpp:165] Memory required for data: 1432650644
I0625 16:36:58.907192 14909 layer_factory.hpp:77] Creating layer cls_score
I0625 16:36:58.907196 14909 net.cpp:106] Creating Layer cls_score
I0625 16:36:58.907197 14909 net.cpp:454] cls_score <- fc7_relu7_0_split_1
I0625 16:36:58.907200 14909 net.cpp:411] cls_score -> cls_score
I0625 16:36:58.907428 14909 net.cpp:150] Setting up cls_score
I0625 16:36:58.907431 14909 net.cpp:157] Top shape: 1 2 (2)
I0625 16:36:58.907433 14909 net.cpp:165] Memory required for data: 1432650652
I0625 16:36:58.907446 14909 layer_factory.hpp:77] Creating layer bbox_pred
I0625 16:36:58.907450 14909 net.cpp:106] Creating Layer bbox_pred
I0625 16:36:58.907454 14909 net.cpp:454] bbox_pred <- fc7_relu7_0_split_2
I0625 16:36:58.907456 14909 net.cpp:411] bbox_pred -> bbox_pred
I0625 16:36:58.908179 14909 net.cpp:150] Setting up bbox_pred
I0625 16:36:58.908185 14909 net.cpp:157] Top shape: 1 8 (8)
I0625 16:36:58.908185 14909 net.cpp:165] Memory required for data: 1432650684
I0625 16:36:58.908190 14909 layer_factory.hpp:77] Creating layer loss_attribute
I0625 16:36:58.908203 14909 net.cpp:106] Creating Layer loss_attribute
I0625 16:36:58.908206 14909 net.cpp:454] loss_attribute <- attr_score_pos_shift
I0625 16:36:58.908210 14909 net.cpp:454] loss_attribute <- attrArray
I0625 16:36:58.908212 14909 net.cpp:411] loss_attribute -> loss_attribute
I0625 16:36:58.908243 14909 net.cpp:150] Setting up loss_attribute
I0625 16:36:58.908247 14909 net.cpp:157] Top shape: (1)
I0625 16:36:58.908249 14909 net.cpp:160]     with loss weight 1
I0625 16:36:58.908259 14909 net.cpp:165] Memory required for data: 1432650688
I0625 16:36:58.908262 14909 layer_factory.hpp:77] Creating layer loss_cls
I0625 16:36:58.908265 14909 net.cpp:106] Creating Layer loss_cls
I0625 16:36:58.908267 14909 net.cpp:454] loss_cls <- cls_score
I0625 16:36:58.908270 14909 net.cpp:454] loss_cls <- labels
I0625 16:36:58.908272 14909 net.cpp:411] loss_cls -> loss_cls
I0625 16:36:58.908277 14909 layer_factory.hpp:77] Creating layer loss_cls
I0625 16:36:58.908936 14909 net.cpp:150] Setting up loss_cls
I0625 16:36:58.908946 14909 net.cpp:157] Top shape: (1)
I0625 16:36:58.908958 14909 net.cpp:160]     with loss weight 3
I0625 16:36:58.908962 14909 net.cpp:165] Memory required for data: 1432650692
I0625 16:36:58.908964 14909 layer_factory.hpp:77] Creating layer loss_bbox
I0625 16:36:58.908984 14909 net.cpp:106] Creating Layer loss_bbox
I0625 16:36:58.908987 14909 net.cpp:454] loss_bbox <- bbox_pred
I0625 16:36:58.908989 14909 net.cpp:454] loss_bbox <- bbox_targets
I0625 16:36:58.908993 14909 net.cpp:454] loss_bbox <- bbox_inside_weights
I0625 16:36:58.908994 14909 net.cpp:454] loss_bbox <- bbox_outside_weights
I0625 16:36:58.908998 14909 net.cpp:411] loss_bbox -> loss_bbox
I0625 16:36:58.909065 14909 net.cpp:150] Setting up loss_bbox
I0625 16:36:58.909070 14909 net.cpp:157] Top shape: (1)
I0625 16:36:58.909070 14909 net.cpp:160]     with loss weight 2
I0625 16:36:58.909083 14909 net.cpp:165] Memory required for data: 1432650696
I0625 16:36:58.909086 14909 layer_factory.hpp:77] Creating layer roi_pool5_2
I0625 16:36:58.909090 14909 net.cpp:106] Creating Layer roi_pool5_2
I0625 16:36:58.909093 14909 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0625 16:36:58.909096 14909 net.cpp:454] roi_pool5_2 <- rois_pos
I0625 16:36:58.909099 14909 net.cpp:411] roi_pool5_2 -> pool5_2
I0625 16:36:58.909103 14909 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0625 16:36:58.909183 14909 net.cpp:150] Setting up roi_pool5_2
I0625 16:36:58.909188 14909 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 16:36:58.909188 14909 net.cpp:165] Memory required for data: 1432751048
I0625 16:36:58.909200 14909 layer_factory.hpp:77] Creating layer pool5_2_conv
I0625 16:36:58.909206 14909 net.cpp:106] Creating Layer pool5_2_conv
I0625 16:36:58.909219 14909 net.cpp:454] pool5_2_conv <- pool5_2
I0625 16:36:58.909222 14909 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0625 16:36:58.915977 14909 net.cpp:150] Setting up pool5_2_conv
I0625 16:36:58.915987 14909 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 16:36:58.915989 14909 net.cpp:165] Memory required for data: 1432851400
I0625 16:36:58.915993 14909 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0625 16:36:58.915998 14909 net.cpp:106] Creating Layer pool5_2_conv_relu
I0625 16:36:58.916000 14909 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0625 16:36:58.916003 14909 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0625 16:36:58.916153 14909 net.cpp:150] Setting up pool5_2_conv_relu
I0625 16:36:58.916159 14909 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 16:36:58.916162 14909 net.cpp:165] Memory required for data: 1432951752
I0625 16:36:58.916163 14909 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0625 16:36:58.916169 14909 net.cpp:106] Creating Layer pool5_2_conv2
I0625 16:36:58.916172 14909 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0625 16:36:58.916175 14909 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0625 16:36:58.967286 14909 net.cpp:150] Setting up pool5_2_conv2
I0625 16:36:58.967314 14909 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 16:36:58.967315 14909 net.cpp:165] Memory required for data: 1433052104
I0625 16:36:58.967322 14909 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0625 16:36:58.967331 14909 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0625 16:36:58.967335 14909 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0625 16:36:58.967339 14909 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0625 16:36:58.967483 14909 net.cpp:150] Setting up pool5_2_conv2_relu
I0625 16:36:58.967489 14909 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 16:36:58.967501 14909 net.cpp:165] Memory required for data: 1433152456
I0625 16:36:58.967504 14909 layer_factory.hpp:77] Creating layer mask_deconv1
I0625 16:36:58.967510 14909 net.cpp:106] Creating Layer mask_deconv1
I0625 16:36:58.967514 14909 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0625 16:36:58.967516 14909 net.cpp:411] mask_deconv1 -> mask_deconv1
I0625 16:36:58.968325 14909 net.cpp:150] Setting up mask_deconv1
I0625 16:36:58.968331 14909 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0625 16:36:58.968343 14909 net.cpp:165] Memory required for data: 1434074056
I0625 16:36:58.968348 14909 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0625 16:36:58.968353 14909 net.cpp:106] Creating Layer pool5_2_conv3
I0625 16:36:58.968365 14909 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0625 16:36:58.968369 14909 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0625 16:36:58.994779 14909 net.cpp:150] Setting up pool5_2_conv3
I0625 16:36:58.994797 14909 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 16:36:58.994801 14909 net.cpp:165] Memory required for data: 1435917256
I0625 16:36:58.994807 14909 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0625 16:36:58.994815 14909 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0625 16:36:58.994829 14909 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0625 16:36:58.994834 14909 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0625 16:36:58.994999 14909 net.cpp:150] Setting up pool5_2_conv3_relu
I0625 16:36:58.995007 14909 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 16:36:58.995008 14909 net.cpp:165] Memory required for data: 1437760456
I0625 16:36:58.995010 14909 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0625 16:36:58.995018 14909 net.cpp:106] Creating Layer pool5_2_conv4
I0625 16:36:58.995020 14909 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0625 16:36:58.995024 14909 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0625 16:36:59.045755 14909 net.cpp:150] Setting up pool5_2_conv4
I0625 16:36:59.045773 14909 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 16:36:59.045774 14909 net.cpp:165] Memory required for data: 1439603656
I0625 16:36:59.045781 14909 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0625 16:36:59.045789 14909 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0625 16:36:59.045792 14909 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0625 16:36:59.045807 14909 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0625 16:36:59.045964 14909 net.cpp:150] Setting up pool5_2_conv4_relu
I0625 16:36:59.045969 14909 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 16:36:59.045971 14909 net.cpp:165] Memory required for data: 1441446856
I0625 16:36:59.045974 14909 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0625 16:36:59.045977 14909 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0625 16:36:59.045979 14909 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0625 16:36:59.045994 14909 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0625 16:36:59.046000 14909 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0625 16:36:59.046002 14909 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0625 16:36:59.046016 14909 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0625 16:36:59.046094 14909 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0625 16:36:59.046098 14909 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 16:36:59.046110 14909 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 16:36:59.046113 14909 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 16:36:59.046114 14909 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 16:36:59.046115 14909 net.cpp:165] Memory required for data: 1448819656
I0625 16:36:59.046118 14909 layer_factory.hpp:77] Creating layer query_conv
I0625 16:36:59.046125 14909 net.cpp:106] Creating Layer query_conv
I0625 16:36:59.046128 14909 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0625 16:36:59.046131 14909 net.cpp:411] query_conv -> query_conv
I0625 16:36:59.047716 14909 net.cpp:150] Setting up query_conv
I0625 16:36:59.047725 14909 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0625 16:36:59.047737 14909 net.cpp:165] Memory required for data: 1449050056
I0625 16:36:59.047742 14909 layer_factory.hpp:77] Creating layer key_conv
I0625 16:36:59.047763 14909 net.cpp:106] Creating Layer key_conv
I0625 16:36:59.047766 14909 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0625 16:36:59.047770 14909 net.cpp:411] key_conv -> key_conv
I0625 16:36:59.049286 14909 net.cpp:150] Setting up key_conv
I0625 16:36:59.049294 14909 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0625 16:36:59.049296 14909 net.cpp:165] Memory required for data: 1449280456
I0625 16:36:59.049300 14909 layer_factory.hpp:77] Creating layer value_conv
I0625 16:36:59.049306 14909 net.cpp:106] Creating Layer value_conv
I0625 16:36:59.049309 14909 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0625 16:36:59.049324 14909 net.cpp:411] value_conv -> value_conv
I0625 16:36:59.055914 14909 net.cpp:150] Setting up value_conv
I0625 16:36:59.055923 14909 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 16:36:59.055925 14909 net.cpp:165] Memory required for data: 1451123656
I0625 16:36:59.055929 14909 layer_factory.hpp:77] Creating layer query_conv_reshape
I0625 16:36:59.055935 14909 net.cpp:106] Creating Layer query_conv_reshape
I0625 16:36:59.055938 14909 net.cpp:454] query_conv_reshape <- query_conv
I0625 16:36:59.055940 14909 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0625 16:36:59.055980 14909 net.cpp:150] Setting up query_conv_reshape
I0625 16:36:59.055996 14909 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0625 16:36:59.055999 14909 net.cpp:165] Memory required for data: 1451354056
I0625 16:36:59.055999 14909 layer_factory.hpp:77] Creating layer key_conv_reshape
I0625 16:36:59.056002 14909 net.cpp:106] Creating Layer key_conv_reshape
I0625 16:36:59.056005 14909 net.cpp:454] key_conv_reshape <- key_conv
I0625 16:36:59.056008 14909 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0625 16:36:59.056030 14909 net.cpp:150] Setting up key_conv_reshape
I0625 16:36:59.056033 14909 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0625 16:36:59.056047 14909 net.cpp:165] Memory required for data: 1451584456
I0625 16:36:59.056048 14909 layer_factory.hpp:77] Creating layer value_conv_reshape
I0625 16:36:59.056051 14909 net.cpp:106] Creating Layer value_conv_reshape
I0625 16:36:59.056053 14909 net.cpp:454] value_conv_reshape <- value_conv
I0625 16:36:59.056071 14909 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0625 16:36:59.056097 14909 net.cpp:150] Setting up value_conv_reshape
I0625 16:36:59.056100 14909 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0625 16:36:59.056110 14909 net.cpp:165] Memory required for data: 1453427656
I0625 16:36:59.056113 14909 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0625 16:36:59.056663 14909 net.cpp:106] Creating Layer query_conv_reshape_perm
I0625 16:36:59.056666 14909 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0625 16:36:59.056669 14909 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0625 16:36:59.056754 14909 net.cpp:150] Setting up query_conv_reshape_perm
I0625 16:36:59.056758 14909 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0625 16:36:59.056761 14909 net.cpp:165] Memory required for data: 1453658056
I0625 16:36:59.056762 14909 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0625 16:36:59.056764 14909 net.cpp:106] Creating Layer key_conv_reshape_perm
I0625 16:36:59.056766 14909 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0625 16:36:59.056769 14909 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0625 16:36:59.056844 14909 net.cpp:150] Setting up key_conv_reshape_perm
I0625 16:36:59.056847 14909 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0625 16:36:59.056849 14909 net.cpp:165] Memory required for data: 1453888456
I0625 16:36:59.056850 14909 layer_factory.hpp:77] Creating layer energy
I0625 16:36:59.056854 14909 net.cpp:106] Creating Layer energy
I0625 16:36:59.056855 14909 net.cpp:454] energy <- query_conv_reshape_perm
I0625 16:36:59.056857 14909 net.cpp:454] energy <- key_conv_reshape_perm
I0625 16:36:59.056860 14909 net.cpp:411] energy -> energy
I0625 16:36:59.056892 14909 net.cpp:150] Setting up energy
I0625 16:36:59.056895 14909 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0625 16:36:59.056897 14909 net.cpp:165] Memory required for data: 1457128456
I0625 16:36:59.056900 14909 layer_factory.hpp:77] Creating layer attention
I0625 16:36:59.056903 14909 net.cpp:106] Creating Layer attention
I0625 16:36:59.056905 14909 net.cpp:454] attention <- energy
I0625 16:36:59.056907 14909 net.cpp:411] attention -> attention
I0625 16:36:59.057062 14909 net.cpp:150] Setting up attention
I0625 16:36:59.057068 14909 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0625 16:36:59.057071 14909 net.cpp:165] Memory required for data: 1460368456
I0625 16:36:59.057073 14909 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0625 16:36:59.057077 14909 net.cpp:106] Creating Layer value_conv_reshape_perm
I0625 16:36:59.057080 14909 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0625 16:36:59.057083 14909 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0625 16:36:59.057143 14909 net.cpp:150] Setting up value_conv_reshape_perm
I0625 16:36:59.057147 14909 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0625 16:36:59.057149 14909 net.cpp:165] Memory required for data: 1462211656
I0625 16:36:59.057152 14909 layer_factory.hpp:77] Creating layer attention_perm
I0625 16:36:59.057154 14909 net.cpp:106] Creating Layer attention_perm
I0625 16:36:59.057157 14909 net.cpp:454] attention_perm <- attention
I0625 16:36:59.057159 14909 net.cpp:411] attention_perm -> attention_perm
I0625 16:36:59.057219 14909 net.cpp:150] Setting up attention_perm
I0625 16:36:59.057222 14909 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0625 16:36:59.057224 14909 net.cpp:165] Memory required for data: 1465451656
I0625 16:36:59.057226 14909 layer_factory.hpp:77] Creating layer out
I0625 16:36:59.057229 14909 net.cpp:106] Creating Layer out
I0625 16:36:59.057231 14909 net.cpp:454] out <- value_conv_reshape_perm
I0625 16:36:59.057235 14909 net.cpp:454] out <- attention_perm
I0625 16:36:59.057237 14909 net.cpp:411] out -> out
I0625 16:36:59.057250 14909 net.cpp:150] Setting up out
I0625 16:36:59.057255 14909 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0625 16:36:59.057256 14909 net.cpp:165] Memory required for data: 1467294856
I0625 16:36:59.057258 14909 layer_factory.hpp:77] Creating layer out_reshape
I0625 16:36:59.057262 14909 net.cpp:106] Creating Layer out_reshape
I0625 16:36:59.057265 14909 net.cpp:454] out_reshape <- out
I0625 16:36:59.057266 14909 net.cpp:411] out_reshape -> out_reshape
I0625 16:36:59.057281 14909 net.cpp:150] Setting up out_reshape
I0625 16:36:59.057286 14909 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 16:36:59.057286 14909 net.cpp:165] Memory required for data: 1469138056
I0625 16:36:59.057288 14909 layer_factory.hpp:77] Creating layer out_reshape_scale
I0625 16:36:59.057296 14909 net.cpp:106] Creating Layer out_reshape_scale
I0625 16:36:59.057299 14909 net.cpp:454] out_reshape_scale <- out_reshape
I0625 16:36:59.057302 14909 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0625 16:36:59.057360 14909 net.cpp:150] Setting up out_reshape_scale
I0625 16:36:59.057364 14909 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 16:36:59.057365 14909 net.cpp:165] Memory required for data: 1470981256
I0625 16:36:59.057368 14909 layer_factory.hpp:77] Creating layer out_x
I0625 16:36:59.057373 14909 net.cpp:106] Creating Layer out_x
I0625 16:36:59.057374 14909 net.cpp:454] out_x <- out_reshape_scale
I0625 16:36:59.057377 14909 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0625 16:36:59.057380 14909 net.cpp:411] out_x -> out_x
I0625 16:36:59.057394 14909 net.cpp:150] Setting up out_x
I0625 16:36:59.057397 14909 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 16:36:59.057399 14909 net.cpp:165] Memory required for data: 1472824456
I0625 16:36:59.057401 14909 layer_factory.hpp:77] Creating layer mask_deconv2
I0625 16:36:59.057405 14909 net.cpp:106] Creating Layer mask_deconv2
I0625 16:36:59.057407 14909 net.cpp:454] mask_deconv2 <- out_x
I0625 16:36:59.057411 14909 net.cpp:411] mask_deconv2 -> mask_deconv2
I0625 16:36:59.058214 14909 net.cpp:150] Setting up mask_deconv2
I0625 16:36:59.058218 14909 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0625 16:36:59.058220 14909 net.cpp:165] Memory required for data: 1488065672
I0625 16:36:59.058234 14909 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0625 16:36:59.058240 14909 net.cpp:106] Creating Layer pool5_2_conv5
I0625 16:36:59.058243 14909 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0625 16:36:59.058248 14909 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0625 16:36:59.084633 14909 net.cpp:150] Setting up pool5_2_conv5
I0625 16:36:59.084651 14909 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 16:36:59.084653 14909 net.cpp:165] Memory required for data: 1518548104
I0625 16:36:59.084661 14909 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0625 16:36:59.084667 14909 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0625 16:36:59.084681 14909 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0625 16:36:59.084686 14909 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0625 16:36:59.084863 14909 net.cpp:150] Setting up pool5_2_conv5_relu
I0625 16:36:59.084870 14909 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 16:36:59.084872 14909 net.cpp:165] Memory required for data: 1549030536
I0625 16:36:59.084874 14909 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0625 16:36:59.084883 14909 net.cpp:106] Creating Layer pool5_2_conv6
I0625 16:36:59.084887 14909 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0625 16:36:59.084889 14909 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0625 16:36:59.135438 14909 net.cpp:150] Setting up pool5_2_conv6
I0625 16:36:59.135455 14909 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 16:36:59.135458 14909 net.cpp:165] Memory required for data: 1579512968
I0625 16:36:59.135473 14909 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0625 16:36:59.135493 14909 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0625 16:36:59.135496 14909 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0625 16:36:59.135501 14909 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0625 16:36:59.136039 14909 net.cpp:150] Setting up pool5_2_conv6_relu
I0625 16:36:59.136049 14909 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 16:36:59.136050 14909 net.cpp:165] Memory required for data: 1609995400
I0625 16:36:59.136052 14909 layer_factory.hpp:77] Creating layer mask_deconv3
I0625 16:36:59.136059 14909 net.cpp:106] Creating Layer mask_deconv3
I0625 16:36:59.136062 14909 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0625 16:36:59.136067 14909 net.cpp:411] mask_deconv3 -> mask_deconv3
I0625 16:36:59.136446 14909 net.cpp:150] Setting up mask_deconv3
I0625 16:36:59.136452 14909 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0625 16:36:59.136454 14909 net.cpp:165] Memory required for data: 1670960264
I0625 16:36:59.136457 14909 layer_factory.hpp:77] Creating layer mask_score
I0625 16:36:59.136463 14909 net.cpp:106] Creating Layer mask_score
I0625 16:36:59.136466 14909 net.cpp:454] mask_score <- mask_deconv3
I0625 16:36:59.136471 14909 net.cpp:411] mask_score -> mask_score
I0625 16:36:59.137063 14909 net.cpp:150] Setting up mask_score
I0625 16:36:59.137070 14909 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 16:36:59.137073 14909 net.cpp:165] Memory required for data: 1672865416
I0625 16:36:59.137075 14909 layer_factory.hpp:77] Creating layer prob
I0625 16:36:59.137080 14909 net.cpp:106] Creating Layer prob
I0625 16:36:59.137084 14909 net.cpp:454] prob <- mask_score
I0625 16:36:59.137087 14909 net.cpp:411] prob -> mask_score_softmax
I0625 16:36:59.137666 14909 net.cpp:150] Setting up prob
I0625 16:36:59.137675 14909 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 16:36:59.137676 14909 net.cpp:165] Memory required for data: 1674770568
I0625 16:36:59.137678 14909 layer_factory.hpp:77] Creating layer log
I0625 16:36:59.137682 14909 net.cpp:106] Creating Layer log
I0625 16:36:59.137684 14909 net.cpp:454] log <- mask_score_softmax
I0625 16:36:59.137687 14909 net.cpp:411] log -> log
I0625 16:36:59.137727 14909 net.cpp:150] Setting up log
I0625 16:36:59.137730 14909 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 16:36:59.137732 14909 net.cpp:165] Memory required for data: 1676675720
I0625 16:36:59.137743 14909 layer_factory.hpp:77] Creating layer mult1
I0625 16:36:59.137748 14909 net.cpp:106] Creating Layer mult1
I0625 16:36:59.137749 14909 net.cpp:454] mult1 <- log
I0625 16:36:59.137761 14909 net.cpp:454] mult1 <- mask_targets
I0625 16:36:59.137764 14909 net.cpp:411] mult1 -> mult1
I0625 16:36:59.137801 14909 net.cpp:150] Setting up mult1
I0625 16:36:59.137804 14909 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 16:36:59.137806 14909 net.cpp:165] Memory required for data: 1678580872
I0625 16:36:59.137807 14909 layer_factory.hpp:77] Creating layer cross_entropy
I0625 16:36:59.137822 14909 net.cpp:106] Creating Layer cross_entropy
I0625 16:36:59.137825 14909 net.cpp:454] cross_entropy <- mult1
I0625 16:36:59.137828 14909 net.cpp:411] cross_entropy -> cross_entropy
I0625 16:36:59.137862 14909 net.cpp:150] Setting up cross_entropy
I0625 16:36:59.137866 14909 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 16:36:59.137866 14909 net.cpp:165] Memory required for data: 1680486024
I0625 16:36:59.137868 14909 layer_factory.hpp:77] Creating layer ce_sum
I0625 16:36:59.137884 14909 net.cpp:106] Creating Layer ce_sum
I0625 16:36:59.137887 14909 net.cpp:454] ce_sum <- cross_entropy
I0625 16:36:59.137902 14909 net.cpp:411] ce_sum -> cross_entropy_sum
I0625 16:36:59.139160 14909 net.cpp:150] Setting up ce_sum
I0625 16:36:59.139168 14909 net.cpp:157] Top shape: 1 1 244 244 (59536)
I0625 16:36:59.139180 14909 net.cpp:165] Memory required for data: 1680724168
I0625 16:36:59.139184 14909 layer_factory.hpp:77] Creating layer ce_mean
I0625 16:36:59.139202 14909 net.cpp:106] Creating Layer ce_mean
I0625 16:36:59.139206 14909 net.cpp:454] ce_mean <- cross_entropy_sum
I0625 16:36:59.139210 14909 net.cpp:411] ce_mean -> cross_entropy_mean
I0625 16:36:59.139853 14909 net.cpp:150] Setting up ce_mean
I0625 16:36:59.139860 14909 net.cpp:157] Top shape: (1)
I0625 16:36:59.139863 14909 net.cpp:160]     with loss weight 1
I0625 16:36:59.139883 14909 net.cpp:165] Memory required for data: 1680724172
I0625 16:36:59.139885 14909 net.cpp:226] ce_mean needs backward computation.
I0625 16:36:59.139888 14909 net.cpp:226] ce_sum needs backward computation.
I0625 16:36:59.139889 14909 net.cpp:226] cross_entropy needs backward computation.
I0625 16:36:59.139891 14909 net.cpp:226] mult1 needs backward computation.
I0625 16:36:59.139894 14909 net.cpp:226] log needs backward computation.
I0625 16:36:59.139894 14909 net.cpp:226] prob needs backward computation.
I0625 16:36:59.139896 14909 net.cpp:226] mask_score needs backward computation.
I0625 16:36:59.139899 14909 net.cpp:226] mask_deconv3 needs backward computation.
I0625 16:36:59.139900 14909 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0625 16:36:59.139902 14909 net.cpp:226] pool5_2_conv6 needs backward computation.
I0625 16:36:59.139904 14909 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0625 16:36:59.139906 14909 net.cpp:226] pool5_2_conv5 needs backward computation.
I0625 16:36:59.139907 14909 net.cpp:226] mask_deconv2 needs backward computation.
I0625 16:36:59.139909 14909 net.cpp:226] out_x needs backward computation.
I0625 16:36:59.139912 14909 net.cpp:226] out_reshape_scale needs backward computation.
I0625 16:36:59.139914 14909 net.cpp:226] out_reshape needs backward computation.
I0625 16:36:59.139915 14909 net.cpp:226] out needs backward computation.
I0625 16:36:59.139919 14909 net.cpp:226] attention_perm needs backward computation.
I0625 16:36:59.139920 14909 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0625 16:36:59.139922 14909 net.cpp:226] attention needs backward computation.
I0625 16:36:59.139925 14909 net.cpp:226] energy needs backward computation.
I0625 16:36:59.139926 14909 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0625 16:36:59.139928 14909 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0625 16:36:59.139931 14909 net.cpp:226] value_conv_reshape needs backward computation.
I0625 16:36:59.139933 14909 net.cpp:226] key_conv_reshape needs backward computation.
I0625 16:36:59.139935 14909 net.cpp:226] query_conv_reshape needs backward computation.
I0625 16:36:59.139937 14909 net.cpp:226] value_conv needs backward computation.
I0625 16:36:59.139940 14909 net.cpp:226] key_conv needs backward computation.
I0625 16:36:59.139941 14909 net.cpp:226] query_conv needs backward computation.
I0625 16:36:59.139943 14909 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0625 16:36:59.139945 14909 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0625 16:36:59.139947 14909 net.cpp:226] pool5_2_conv4 needs backward computation.
I0625 16:36:59.139950 14909 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0625 16:36:59.139951 14909 net.cpp:226] pool5_2_conv3 needs backward computation.
I0625 16:36:59.139955 14909 net.cpp:226] mask_deconv1 needs backward computation.
I0625 16:36:59.139956 14909 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0625 16:36:59.139958 14909 net.cpp:226] pool5_2_conv2 needs backward computation.
I0625 16:36:59.139961 14909 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0625 16:36:59.139962 14909 net.cpp:226] pool5_2_conv needs backward computation.
I0625 16:36:59.139964 14909 net.cpp:226] roi_pool5_2 needs backward computation.
I0625 16:36:59.139966 14909 net.cpp:226] loss_bbox needs backward computation.
I0625 16:36:59.139969 14909 net.cpp:226] loss_cls needs backward computation.
I0625 16:36:59.139972 14909 net.cpp:226] loss_attribute needs backward computation.
I0625 16:36:59.139974 14909 net.cpp:226] bbox_pred needs backward computation.
I0625 16:36:59.139976 14909 net.cpp:226] cls_score needs backward computation.
I0625 16:36:59.139978 14909 net.cpp:226] attr_score_pos_shift needs backward computation.
I0625 16:36:59.139981 14909 net.cpp:226] attr_score_pos needs backward computation.
I0625 16:36:59.139983 14909 net.cpp:226] attr_score needs backward computation.
I0625 16:36:59.139986 14909 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0625 16:36:59.139987 14909 net.cpp:226] relu7 needs backward computation.
I0625 16:36:59.139989 14909 net.cpp:226] fc7 needs backward computation.
I0625 16:36:59.139991 14909 net.cpp:226] relu6 needs backward computation.
I0625 16:36:59.139992 14909 net.cpp:226] fc6 needs backward computation.
I0625 16:36:59.139994 14909 net.cpp:226] roi_pool5 needs backward computation.
I0625 16:36:59.139997 14909 net.cpp:226] roi-data needs backward computation.
I0625 16:36:59.140002 14909 net.cpp:226] proposal needs backward computation.
I0625 16:36:59.140005 14909 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0625 16:36:59.140007 14909 net.cpp:226] rpn_cls_prob needs backward computation.
I0625 16:36:59.140009 14909 net.cpp:226] rpn_loss_bbox needs backward computation.
I0625 16:36:59.140012 14909 net.cpp:226] rpn_loss_cls needs backward computation.
I0625 16:36:59.140015 14909 net.cpp:226] rpn-data needs backward computation.
I0625 16:36:59.140018 14909 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0625 16:36:59.140022 14909 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0625 16:36:59.140024 14909 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0625 16:36:59.140027 14909 net.cpp:226] rpn_bbox_pred needs backward computation.
I0625 16:36:59.140028 14909 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0625 16:36:59.140030 14909 net.cpp:226] rpn_cls_score needs backward computation.
I0625 16:36:59.140033 14909 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0625 16:36:59.140035 14909 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0625 16:36:59.140038 14909 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0625 16:36:59.140039 14909 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0625 16:36:59.140041 14909 net.cpp:226] relu5_3 needs backward computation.
I0625 16:36:59.140043 14909 net.cpp:226] conv5_3 needs backward computation.
I0625 16:36:59.140045 14909 net.cpp:226] relu5_2 needs backward computation.
I0625 16:36:59.140048 14909 net.cpp:226] conv5_2 needs backward computation.
I0625 16:36:59.140049 14909 net.cpp:226] relu5_1 needs backward computation.
I0625 16:36:59.140051 14909 net.cpp:226] conv5_1 needs backward computation.
I0625 16:36:59.140053 14909 net.cpp:226] pool4 needs backward computation.
I0625 16:36:59.140055 14909 net.cpp:226] relu4_3 needs backward computation.
I0625 16:36:59.140058 14909 net.cpp:226] conv4_3 needs backward computation.
I0625 16:36:59.140059 14909 net.cpp:226] relu4_2 needs backward computation.
I0625 16:36:59.140060 14909 net.cpp:226] conv4_2 needs backward computation.
I0625 16:36:59.140063 14909 net.cpp:226] relu4_1 needs backward computation.
I0625 16:36:59.140064 14909 net.cpp:226] conv4_1 needs backward computation.
I0625 16:36:59.140066 14909 net.cpp:226] pool3 needs backward computation.
I0625 16:36:59.140069 14909 net.cpp:226] relu3_3 needs backward computation.
I0625 16:36:59.140070 14909 net.cpp:226] conv3_3 needs backward computation.
I0625 16:36:59.140072 14909 net.cpp:226] relu3_2 needs backward computation.
I0625 16:36:59.140074 14909 net.cpp:226] conv3_2 needs backward computation.
I0625 16:36:59.140076 14909 net.cpp:226] relu3_1 needs backward computation.
I0625 16:36:59.140079 14909 net.cpp:226] conv3_1 needs backward computation.
I0625 16:36:59.140080 14909 net.cpp:228] pool2 does not need backward computation.
I0625 16:36:59.140082 14909 net.cpp:228] relu2_2 does not need backward computation.
I0625 16:36:59.140084 14909 net.cpp:228] conv2_2 does not need backward computation.
I0625 16:36:59.140086 14909 net.cpp:228] relu2_1 does not need backward computation.
I0625 16:36:59.140089 14909 net.cpp:228] conv2_1 does not need backward computation.
I0625 16:36:59.140090 14909 net.cpp:228] pool1 does not need backward computation.
I0625 16:36:59.140092 14909 net.cpp:228] relu1_2 does not need backward computation.
I0625 16:36:59.140094 14909 net.cpp:228] conv1_2 does not need backward computation.
I0625 16:36:59.140096 14909 net.cpp:228] relu1_1 does not need backward computation.
I0625 16:36:59.140098 14909 net.cpp:228] conv1_1 does not need backward computation.
I0625 16:36:59.140101 14909 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0625 16:36:59.140103 14909 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0625 16:36:59.140106 14909 net.cpp:228] data_input-data_0_split does not need backward computation.
I0625 16:36:59.140110 14909 net.cpp:228] input-data does not need backward computation.
I0625 16:36:59.140111 14909 net.cpp:270] This network produces output cross_entropy_mean
I0625 16:36:59.140113 14909 net.cpp:270] This network produces output loss_attribute
I0625 16:36:59.140115 14909 net.cpp:270] This network produces output loss_bbox
I0625 16:36:59.140117 14909 net.cpp:270] This network produces output loss_cls
I0625 16:36:59.140120 14909 net.cpp:270] This network produces output rpn_cls_loss
I0625 16:36:59.140121 14909 net.cpp:270] This network produces output rpn_loss_bbox
I0625 16:36:59.140175 14909 net.cpp:283] Network initialization done.
I0625 16:36:59.140377 14909 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0625 16:37:28.772579 14909 net.cpp:816] Ignoring source layer pool5
I0625 16:37:28.883767 14909 net.cpp:816] Ignoring source layer drop6
I0625 16:37:28.896340 14909 net.cpp:816] Ignoring source layer drop7
I0625 16:37:28.896374 14909 net.cpp:816] Ignoring source layer fc8
Solving...
I0625 16:37:30.131294 14909 solver.cpp:229] Iteration 0, loss = 1.3868
I0625 16:37:30.188808 14909 solver.cpp:245]     Train net output #0: cross_entropy_mean = -2.75731 (* 1 = -2.75731 loss)
I0625 16:37:30.188824 14909 solver.cpp:245]     Train net output #1: loss_attribute = 0.304792 (* 1 = 0.304792 loss)
I0625 16:37:30.188828 14909 solver.cpp:245]     Train net output #2: loss_bbox = 0.0916567 (* 2 = 0.183313 loss)
I0625 16:37:30.188849 14909 solver.cpp:245]     Train net output #3: loss_cls = 0.947394 (* 3 = 2.84218 loss)
I0625 16:37:30.188854 14909 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.73882 (* 1 = 0.73882 loss)
I0625 16:37:30.188868 14909 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0189577 (* 1 = 0.0189577 loss)
I0625 16:37:30.188874 14909 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0625 16:37:48.718104 14909 solver.cpp:229] Iteration 20, loss = 0.422765
I0625 16:37:48.771661 14909 solver.cpp:245]     Train net output #0: cross_entropy_mean = -1.88785 (* 1 = -1.88785 loss)
I0625 16:37:48.771693 14909 solver.cpp:245]     Train net output #1: loss_attribute = 0.227319 (* 1 = 0.227319 loss)
I0625 16:37:48.771704 14909 solver.cpp:245]     Train net output #2: loss_bbox = 0.148108 (* 2 = 0.296216 loss)
I0625 16:37:48.771714 14909 solver.cpp:245]     Train net output #3: loss_cls = 0.0553396 (* 3 = 0.166019 loss)
I0625 16:37:48.771724 14909 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.326015 (* 1 = 0.326015 loss)
I0625 16:37:48.771735 14909 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0182483 (* 1 = 0.0182483 loss)
I0625 16:37:48.771744 14909 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0625 16:38:07.791236 14909 solver.cpp:229] Iteration 40, loss = -2.53
I0625 16:38:07.851307 14909 solver.cpp:245]     Train net output #0: cross_entropy_mean = -3.93974 (* 1 = -3.93974 loss)
I0625 16:38:07.851325 14909 solver.cpp:245]     Train net output #1: loss_attribute = 0.334425 (* 1 = 0.334425 loss)
I0625 16:38:07.851328 14909 solver.cpp:245]     Train net output #2: loss_bbox = 0.213302 (* 2 = 0.426605 loss)
I0625 16:38:07.851332 14909 solver.cpp:245]     Train net output #3: loss_cls = 0.131028 (* 3 = 0.393083 loss)
I0625 16:38:07.851336 14909 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0754039 (* 1 = 0.0754039 loss)
I0625 16:38:07.851342 14909 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0189168 (* 1 = 0.0189168 loss)
I0625 16:38:07.851358 14909 sgd_solver.cpp:106] Iteration 40, lr = 0.001
