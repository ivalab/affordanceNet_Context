+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-11_14-10-51
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-11_14-10-51
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0611 14:10:59.538048 20393 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0611 14:10:59.538084 20393 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0611 14:10:59.539525 20393 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_mask"
  type: "SoftmaxWithLoss"
  bottom: "mask_score"
  bottom: "mask_targets"
  top: "loss_mask"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
I0611 14:10:59.539839 20393 layer_factory.hpp:77] Creating layer input-data
I0611 14:10:59.663642 20393 net.cpp:106] Creating Layer input-data
I0611 14:10:59.663671 20393 net.cpp:411] input-data -> data
I0611 14:10:59.663686 20393 net.cpp:411] input-data -> im_info
I0611 14:10:59.663695 20393 net.cpp:411] input-data -> gt_boxes
I0611 14:10:59.663704 20393 net.cpp:411] input-data -> seg_mask_inds
I0611 14:10:59.663712 20393 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0611 14:10:59.719939 20393 net.cpp:150] Setting up input-data
I0611 14:10:59.719956 20393 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 14:10:59.719960 20393 net.cpp:157] Top shape: 1 3 (3)
I0611 14:10:59.719964 20393 net.cpp:157] Top shape: 1 4 (4)
I0611 14:10:59.719967 20393 net.cpp:157] Top shape: 1 2 (2)
I0611 14:10:59.719971 20393 net.cpp:157] Top shape: 1 1 (1)
I0611 14:10:59.719974 20393 net.cpp:165] Memory required for data: 7200040
I0611 14:10:59.719980 20393 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0611 14:10:59.720554 20393 net.cpp:106] Creating Layer data_input-data_0_split
I0611 14:10:59.720559 20393 net.cpp:454] data_input-data_0_split <- data
I0611 14:10:59.720564 20393 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0611 14:10:59.720571 20393 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0611 14:10:59.720592 20393 net.cpp:150] Setting up data_input-data_0_split
I0611 14:10:59.720597 20393 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 14:10:59.720600 20393 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 14:10:59.720602 20393 net.cpp:165] Memory required for data: 21600040
I0611 14:10:59.720604 20393 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0611 14:10:59.720608 20393 net.cpp:106] Creating Layer im_info_input-data_1_split
I0611 14:10:59.720611 20393 net.cpp:454] im_info_input-data_1_split <- im_info
I0611 14:10:59.720614 20393 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0611 14:10:59.720618 20393 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0611 14:10:59.720623 20393 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0611 14:10:59.720649 20393 net.cpp:150] Setting up im_info_input-data_1_split
I0611 14:10:59.720654 20393 net.cpp:157] Top shape: 1 3 (3)
I0611 14:10:59.720656 20393 net.cpp:157] Top shape: 1 3 (3)
I0611 14:10:59.720659 20393 net.cpp:157] Top shape: 1 3 (3)
I0611 14:10:59.720661 20393 net.cpp:165] Memory required for data: 21600076
I0611 14:10:59.720664 20393 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0611 14:10:59.720667 20393 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0611 14:10:59.720669 20393 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0611 14:10:59.720675 20393 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0611 14:10:59.720679 20393 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0611 14:10:59.720697 20393 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0611 14:10:59.720701 20393 net.cpp:157] Top shape: 1 4 (4)
I0611 14:10:59.720705 20393 net.cpp:157] Top shape: 1 4 (4)
I0611 14:10:59.720706 20393 net.cpp:165] Memory required for data: 21600108
I0611 14:10:59.720710 20393 layer_factory.hpp:77] Creating layer conv1_1
I0611 14:10:59.720718 20393 net.cpp:106] Creating Layer conv1_1
I0611 14:10:59.720721 20393 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0611 14:10:59.720724 20393 net.cpp:411] conv1_1 -> conv1_1
I0611 14:11:00.196135 20393 net.cpp:150] Setting up conv1_1
I0611 14:11:00.196163 20393 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 14:11:00.196166 20393 net.cpp:165] Memory required for data: 175200108
I0611 14:11:00.196194 20393 layer_factory.hpp:77] Creating layer relu1_1
I0611 14:11:00.196208 20393 net.cpp:106] Creating Layer relu1_1
I0611 14:11:00.196215 20393 net.cpp:454] relu1_1 <- conv1_1
I0611 14:11:00.196221 20393 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0611 14:11:00.196406 20393 net.cpp:150] Setting up relu1_1
I0611 14:11:00.196414 20393 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 14:11:00.196416 20393 net.cpp:165] Memory required for data: 328800108
I0611 14:11:00.196419 20393 layer_factory.hpp:77] Creating layer conv1_2
I0611 14:11:00.196431 20393 net.cpp:106] Creating Layer conv1_2
I0611 14:11:00.196436 20393 net.cpp:454] conv1_2 <- conv1_1
I0611 14:11:00.196444 20393 net.cpp:411] conv1_2 -> conv1_2
I0611 14:11:00.198642 20393 net.cpp:150] Setting up conv1_2
I0611 14:11:00.198662 20393 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 14:11:00.198665 20393 net.cpp:165] Memory required for data: 482400108
I0611 14:11:00.198683 20393 layer_factory.hpp:77] Creating layer relu1_2
I0611 14:11:00.198690 20393 net.cpp:106] Creating Layer relu1_2
I0611 14:11:00.198693 20393 net.cpp:454] relu1_2 <- conv1_2
I0611 14:11:00.198698 20393 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0611 14:11:00.198844 20393 net.cpp:150] Setting up relu1_2
I0611 14:11:00.198851 20393 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 14:11:00.198863 20393 net.cpp:165] Memory required for data: 636000108
I0611 14:11:00.198866 20393 layer_factory.hpp:77] Creating layer pool1
I0611 14:11:00.198877 20393 net.cpp:106] Creating Layer pool1
I0611 14:11:00.198881 20393 net.cpp:454] pool1 <- conv1_2
I0611 14:11:00.198886 20393 net.cpp:411] pool1 -> pool1
I0611 14:11:00.199638 20393 net.cpp:150] Setting up pool1
I0611 14:11:00.199645 20393 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0611 14:11:00.199647 20393 net.cpp:165] Memory required for data: 674400108
I0611 14:11:00.199649 20393 layer_factory.hpp:77] Creating layer conv2_1
I0611 14:11:00.199656 20393 net.cpp:106] Creating Layer conv2_1
I0611 14:11:00.199658 20393 net.cpp:454] conv2_1 <- pool1
I0611 14:11:00.199662 20393 net.cpp:411] conv2_1 -> conv2_1
I0611 14:11:00.203317 20393 net.cpp:150] Setting up conv2_1
I0611 14:11:00.203328 20393 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 14:11:00.203331 20393 net.cpp:165] Memory required for data: 751200108
I0611 14:11:00.203339 20393 layer_factory.hpp:77] Creating layer relu2_1
I0611 14:11:00.203346 20393 net.cpp:106] Creating Layer relu2_1
I0611 14:11:00.203348 20393 net.cpp:454] relu2_1 <- conv2_1
I0611 14:11:00.203353 20393 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0611 14:11:00.203966 20393 net.cpp:150] Setting up relu2_1
I0611 14:11:00.203974 20393 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 14:11:00.203977 20393 net.cpp:165] Memory required for data: 828000108
I0611 14:11:00.203979 20393 layer_factory.hpp:77] Creating layer conv2_2
I0611 14:11:00.203987 20393 net.cpp:106] Creating Layer conv2_2
I0611 14:11:00.203991 20393 net.cpp:454] conv2_2 <- conv2_1
I0611 14:11:00.203995 20393 net.cpp:411] conv2_2 -> conv2_2
I0611 14:11:00.208765 20393 net.cpp:150] Setting up conv2_2
I0611 14:11:00.208788 20393 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 14:11:00.208793 20393 net.cpp:165] Memory required for data: 904800108
I0611 14:11:00.208804 20393 layer_factory.hpp:77] Creating layer relu2_2
I0611 14:11:00.208814 20393 net.cpp:106] Creating Layer relu2_2
I0611 14:11:00.208827 20393 net.cpp:454] relu2_2 <- conv2_2
I0611 14:11:00.208835 20393 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0611 14:11:00.209009 20393 net.cpp:150] Setting up relu2_2
I0611 14:11:00.209018 20393 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 14:11:00.209022 20393 net.cpp:165] Memory required for data: 981600108
I0611 14:11:00.209026 20393 layer_factory.hpp:77] Creating layer pool2
I0611 14:11:00.209034 20393 net.cpp:106] Creating Layer pool2
I0611 14:11:00.209040 20393 net.cpp:454] pool2 <- conv2_2
I0611 14:11:00.209048 20393 net.cpp:411] pool2 -> pool2
I0611 14:11:00.209091 20393 net.cpp:150] Setting up pool2
I0611 14:11:00.209098 20393 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0611 14:11:00.209103 20393 net.cpp:165] Memory required for data: 1000800108
I0611 14:11:00.209106 20393 layer_factory.hpp:77] Creating layer conv3_1
I0611 14:11:00.209117 20393 net.cpp:106] Creating Layer conv3_1
I0611 14:11:00.209122 20393 net.cpp:454] conv3_1 <- pool2
I0611 14:11:00.209129 20393 net.cpp:411] conv3_1 -> conv3_1
I0611 14:11:00.211690 20393 net.cpp:150] Setting up conv3_1
I0611 14:11:00.211702 20393 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:11:00.211705 20393 net.cpp:165] Memory required for data: 1039200108
I0611 14:11:00.211714 20393 layer_factory.hpp:77] Creating layer relu3_1
I0611 14:11:00.211724 20393 net.cpp:106] Creating Layer relu3_1
I0611 14:11:00.211730 20393 net.cpp:454] relu3_1 <- conv3_1
I0611 14:11:00.211737 20393 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0611 14:11:00.211903 20393 net.cpp:150] Setting up relu3_1
I0611 14:11:00.211915 20393 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:11:00.211918 20393 net.cpp:165] Memory required for data: 1077600108
I0611 14:11:00.211922 20393 layer_factory.hpp:77] Creating layer conv3_2
I0611 14:11:00.211935 20393 net.cpp:106] Creating Layer conv3_2
I0611 14:11:00.211939 20393 net.cpp:454] conv3_2 <- conv3_1
I0611 14:11:00.211946 20393 net.cpp:411] conv3_2 -> conv3_2
I0611 14:11:00.214620 20393 net.cpp:150] Setting up conv3_2
I0611 14:11:00.214634 20393 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:11:00.214637 20393 net.cpp:165] Memory required for data: 1116000108
I0611 14:11:00.214643 20393 layer_factory.hpp:77] Creating layer relu3_2
I0611 14:11:00.214650 20393 net.cpp:106] Creating Layer relu3_2
I0611 14:11:00.214663 20393 net.cpp:454] relu3_2 <- conv3_2
I0611 14:11:00.214668 20393 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0611 14:11:00.214797 20393 net.cpp:150] Setting up relu3_2
I0611 14:11:00.214803 20393 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:11:00.214805 20393 net.cpp:165] Memory required for data: 1154400108
I0611 14:11:00.214808 20393 layer_factory.hpp:77] Creating layer conv3_3
I0611 14:11:00.214815 20393 net.cpp:106] Creating Layer conv3_3
I0611 14:11:00.214819 20393 net.cpp:454] conv3_3 <- conv3_2
I0611 14:11:00.214825 20393 net.cpp:411] conv3_3 -> conv3_3
I0611 14:11:00.217069 20393 net.cpp:150] Setting up conv3_3
I0611 14:11:00.217079 20393 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:11:00.217082 20393 net.cpp:165] Memory required for data: 1192800108
I0611 14:11:00.217088 20393 layer_factory.hpp:77] Creating layer relu3_3
I0611 14:11:00.217093 20393 net.cpp:106] Creating Layer relu3_3
I0611 14:11:00.217097 20393 net.cpp:454] relu3_3 <- conv3_3
I0611 14:11:00.217101 20393 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0611 14:11:00.217213 20393 net.cpp:150] Setting up relu3_3
I0611 14:11:00.217219 20393 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:11:00.217222 20393 net.cpp:165] Memory required for data: 1231200108
I0611 14:11:00.217226 20393 layer_factory.hpp:77] Creating layer pool3
I0611 14:11:00.217231 20393 net.cpp:106] Creating Layer pool3
I0611 14:11:00.217236 20393 net.cpp:454] pool3 <- conv3_3
I0611 14:11:00.217239 20393 net.cpp:411] pool3 -> pool3
I0611 14:11:00.217269 20393 net.cpp:150] Setting up pool3
I0611 14:11:00.217274 20393 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0611 14:11:00.217276 20393 net.cpp:165] Memory required for data: 1240800108
I0611 14:11:00.217281 20393 layer_factory.hpp:77] Creating layer conv4_1
I0611 14:11:00.217288 20393 net.cpp:106] Creating Layer conv4_1
I0611 14:11:00.217291 20393 net.cpp:454] conv4_1 <- pool3
I0611 14:11:00.217295 20393 net.cpp:411] conv4_1 -> conv4_1
I0611 14:11:00.221591 20393 net.cpp:150] Setting up conv4_1
I0611 14:11:00.221604 20393 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:11:00.221606 20393 net.cpp:165] Memory required for data: 1260000108
I0611 14:11:00.221613 20393 layer_factory.hpp:77] Creating layer relu4_1
I0611 14:11:00.221619 20393 net.cpp:106] Creating Layer relu4_1
I0611 14:11:00.221622 20393 net.cpp:454] relu4_1 <- conv4_1
I0611 14:11:00.221628 20393 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0611 14:11:00.221757 20393 net.cpp:150] Setting up relu4_1
I0611 14:11:00.221765 20393 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:11:00.221767 20393 net.cpp:165] Memory required for data: 1279200108
I0611 14:11:00.221770 20393 layer_factory.hpp:77] Creating layer conv4_2
I0611 14:11:00.221776 20393 net.cpp:106] Creating Layer conv4_2
I0611 14:11:00.221779 20393 net.cpp:454] conv4_2 <- conv4_1
I0611 14:11:00.221783 20393 net.cpp:411] conv4_2 -> conv4_2
I0611 14:11:00.228613 20393 net.cpp:150] Setting up conv4_2
I0611 14:11:00.228654 20393 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:11:00.228663 20393 net.cpp:165] Memory required for data: 1298400108
I0611 14:11:00.228698 20393 layer_factory.hpp:77] Creating layer relu4_2
I0611 14:11:00.228750 20393 net.cpp:106] Creating Layer relu4_2
I0611 14:11:00.228780 20393 net.cpp:454] relu4_2 <- conv4_2
I0611 14:11:00.228804 20393 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0611 14:11:00.229650 20393 net.cpp:150] Setting up relu4_2
I0611 14:11:00.229665 20393 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:11:00.229668 20393 net.cpp:165] Memory required for data: 1317600108
I0611 14:11:00.229673 20393 layer_factory.hpp:77] Creating layer conv4_3
I0611 14:11:00.229688 20393 net.cpp:106] Creating Layer conv4_3
I0611 14:11:00.229709 20393 net.cpp:454] conv4_3 <- conv4_2
I0611 14:11:00.229737 20393 net.cpp:411] conv4_3 -> conv4_3
I0611 14:11:00.236707 20393 net.cpp:150] Setting up conv4_3
I0611 14:11:00.236747 20393 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:11:00.236752 20393 net.cpp:165] Memory required for data: 1336800108
I0611 14:11:00.236774 20393 layer_factory.hpp:77] Creating layer relu4_3
I0611 14:11:00.236789 20393 net.cpp:106] Creating Layer relu4_3
I0611 14:11:00.236800 20393 net.cpp:454] relu4_3 <- conv4_3
I0611 14:11:00.236809 20393 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0611 14:11:00.237040 20393 net.cpp:150] Setting up relu4_3
I0611 14:11:00.237062 20393 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:11:00.237064 20393 net.cpp:165] Memory required for data: 1356000108
I0611 14:11:00.237080 20393 layer_factory.hpp:77] Creating layer pool4
I0611 14:11:00.237092 20393 net.cpp:106] Creating Layer pool4
I0611 14:11:00.237095 20393 net.cpp:454] pool4 <- conv4_3
I0611 14:11:00.237102 20393 net.cpp:411] pool4 -> pool4
I0611 14:11:00.237146 20393 net.cpp:150] Setting up pool4
I0611 14:11:00.237152 20393 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:00.237156 20393 net.cpp:165] Memory required for data: 1360903020
I0611 14:11:00.237159 20393 layer_factory.hpp:77] Creating layer conv5_1
I0611 14:11:00.237167 20393 net.cpp:106] Creating Layer conv5_1
I0611 14:11:00.237174 20393 net.cpp:454] conv5_1 <- pool4
I0611 14:11:00.237181 20393 net.cpp:411] conv5_1 -> conv5_1
I0611 14:11:00.243281 20393 net.cpp:150] Setting up conv5_1
I0611 14:11:00.243306 20393 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:00.243311 20393 net.cpp:165] Memory required for data: 1365805932
I0611 14:11:00.243324 20393 layer_factory.hpp:77] Creating layer relu5_1
I0611 14:11:00.243338 20393 net.cpp:106] Creating Layer relu5_1
I0611 14:11:00.243345 20393 net.cpp:454] relu5_1 <- conv5_1
I0611 14:11:00.243353 20393 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0611 14:11:00.243507 20393 net.cpp:150] Setting up relu5_1
I0611 14:11:00.243516 20393 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:00.243520 20393 net.cpp:165] Memory required for data: 1370708844
I0611 14:11:00.243525 20393 layer_factory.hpp:77] Creating layer conv5_2
I0611 14:11:00.243535 20393 net.cpp:106] Creating Layer conv5_2
I0611 14:11:00.243544 20393 net.cpp:454] conv5_2 <- conv5_1
I0611 14:11:00.243551 20393 net.cpp:411] conv5_2 -> conv5_2
I0611 14:11:00.249914 20393 net.cpp:150] Setting up conv5_2
I0611 14:11:00.249941 20393 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:00.249946 20393 net.cpp:165] Memory required for data: 1375611756
I0611 14:11:00.249958 20393 layer_factory.hpp:77] Creating layer relu5_2
I0611 14:11:00.249979 20393 net.cpp:106] Creating Layer relu5_2
I0611 14:11:00.249985 20393 net.cpp:454] relu5_2 <- conv5_2
I0611 14:11:00.249994 20393 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0611 14:11:00.250182 20393 net.cpp:150] Setting up relu5_2
I0611 14:11:00.250192 20393 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:00.250195 20393 net.cpp:165] Memory required for data: 1380514668
I0611 14:11:00.250200 20393 layer_factory.hpp:77] Creating layer conv5_3
I0611 14:11:00.250226 20393 net.cpp:106] Creating Layer conv5_3
I0611 14:11:00.250239 20393 net.cpp:454] conv5_3 <- conv5_2
I0611 14:11:00.250247 20393 net.cpp:411] conv5_3 -> conv5_3
I0611 14:11:00.257007 20393 net.cpp:150] Setting up conv5_3
I0611 14:11:00.257028 20393 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:00.257030 20393 net.cpp:165] Memory required for data: 1385417580
I0611 14:11:00.257048 20393 layer_factory.hpp:77] Creating layer relu5_3
I0611 14:11:00.257057 20393 net.cpp:106] Creating Layer relu5_3
I0611 14:11:00.257061 20393 net.cpp:454] relu5_3 <- conv5_3
I0611 14:11:00.257067 20393 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0611 14:11:00.257205 20393 net.cpp:150] Setting up relu5_3
I0611 14:11:00.257211 20393 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:00.257215 20393 net.cpp:165] Memory required for data: 1390320492
I0611 14:11:00.257217 20393 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0611 14:11:00.257231 20393 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0611 14:11:00.257236 20393 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0611 14:11:00.257239 20393 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0611 14:11:00.257244 20393 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0611 14:11:00.257248 20393 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0611 14:11:00.257287 20393 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0611 14:11:00.257292 20393 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:00.257294 20393 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:00.257297 20393 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:00.257299 20393 net.cpp:165] Memory required for data: 1405029228
I0611 14:11:00.257302 20393 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0611 14:11:00.257311 20393 net.cpp:106] Creating Layer rpn_conv/3x3
I0611 14:11:00.257315 20393 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0611 14:11:00.257319 20393 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0611 14:11:00.314616 20393 net.cpp:150] Setting up rpn_conv/3x3
I0611 14:11:00.314636 20393 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:00.314638 20393 net.cpp:165] Memory required for data: 1409932140
I0611 14:11:00.314646 20393 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0611 14:11:00.314656 20393 net.cpp:106] Creating Layer rpn_relu/3x3
I0611 14:11:00.314662 20393 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0611 14:11:00.314667 20393 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0611 14:11:00.314811 20393 net.cpp:150] Setting up rpn_relu/3x3
I0611 14:11:00.314821 20393 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:00.314823 20393 net.cpp:165] Memory required for data: 1414835052
I0611 14:11:00.314827 20393 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0611 14:11:00.314833 20393 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0611 14:11:00.314838 20393 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0611 14:11:00.314843 20393 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0611 14:11:00.314851 20393 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0611 14:11:00.314888 20393 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0611 14:11:00.314893 20393 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:00.314896 20393 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:00.314898 20393 net.cpp:165] Memory required for data: 1424640876
I0611 14:11:00.314901 20393 layer_factory.hpp:77] Creating layer rpn_cls_score
I0611 14:11:00.314911 20393 net.cpp:106] Creating Layer rpn_cls_score
I0611 14:11:00.314915 20393 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0611 14:11:00.314924 20393 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0611 14:11:00.319748 20393 net.cpp:150] Setting up rpn_cls_score
I0611 14:11:00.319774 20393 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 14:11:00.319779 20393 net.cpp:165] Memory required for data: 1424928156
I0611 14:11:00.319799 20393 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0611 14:11:00.319810 20393 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0611 14:11:00.319818 20393 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0611 14:11:00.319823 20393 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0611 14:11:00.319834 20393 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0611 14:11:00.319898 20393 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0611 14:11:00.319905 20393 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 14:11:00.319908 20393 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 14:11:00.319911 20393 net.cpp:165] Memory required for data: 1425502716
I0611 14:11:00.319914 20393 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0611 14:11:00.319938 20393 net.cpp:106] Creating Layer rpn_bbox_pred
I0611 14:11:00.319944 20393 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0611 14:11:00.319958 20393 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0611 14:11:00.322270 20393 net.cpp:150] Setting up rpn_bbox_pred
I0611 14:11:00.322284 20393 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:11:00.322288 20393 net.cpp:165] Memory required for data: 1426077276
I0611 14:11:00.322304 20393 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 14:11:00.322311 20393 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 14:11:00.322315 20393 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0611 14:11:00.322324 20393 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0611 14:11:00.322330 20393 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0611 14:11:00.322376 20393 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 14:11:00.322381 20393 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:11:00.322394 20393 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:11:00.322396 20393 net.cpp:165] Memory required for data: 1427226396
I0611 14:11:00.322399 20393 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0611 14:11:00.322432 20393 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0611 14:11:00.322437 20393 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0611 14:11:00.322450 20393 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0611 14:11:00.322484 20393 net.cpp:150] Setting up rpn_cls_score_reshape
I0611 14:11:00.322499 20393 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 14:11:00.322501 20393 net.cpp:165] Memory required for data: 1427513676
I0611 14:11:00.322504 20393 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 14:11:00.322518 20393 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 14:11:00.322521 20393 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0611 14:11:00.322525 20393 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0611 14:11:00.322540 20393 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0611 14:11:00.322579 20393 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 14:11:00.322585 20393 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 14:11:00.322587 20393 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 14:11:00.322592 20393 net.cpp:165] Memory required for data: 1428088236
I0611 14:11:00.322594 20393 layer_factory.hpp:77] Creating layer rpn-data
I0611 14:11:00.323863 20393 net.cpp:106] Creating Layer rpn-data
I0611 14:11:00.323879 20393 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0611 14:11:00.323887 20393 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0611 14:11:00.323894 20393 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0611 14:11:00.323899 20393 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0611 14:11:00.323905 20393 net.cpp:411] rpn-data -> rpn_labels
I0611 14:11:00.323915 20393 net.cpp:411] rpn-data -> rpn_bbox_targets
I0611 14:11:00.323922 20393 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0611 14:11:00.323930 20393 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0611 14:11:00.325299 20393 net.cpp:150] Setting up rpn-data
I0611 14:11:00.325316 20393 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0611 14:11:00.325320 20393 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:11:00.325325 20393 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:11:00.325328 20393 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:11:00.325330 20393 net.cpp:165] Memory required for data: 1429955556
I0611 14:11:00.325336 20393 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0611 14:11:00.325348 20393 net.cpp:106] Creating Layer rpn_loss_cls
I0611 14:11:00.325356 20393 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0611 14:11:00.325363 20393 net.cpp:454] rpn_loss_cls <- rpn_labels
I0611 14:11:00.325368 20393 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0611 14:11:00.325384 20393 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0611 14:11:00.327250 20393 net.cpp:150] Setting up rpn_loss_cls
I0611 14:11:00.327292 20393 net.cpp:157] Top shape: (1)
I0611 14:11:00.327298 20393 net.cpp:160]     with loss weight 1
I0611 14:11:00.327313 20393 net.cpp:165] Memory required for data: 1429955560
I0611 14:11:00.327319 20393 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0611 14:11:00.327335 20393 net.cpp:106] Creating Layer rpn_loss_bbox
I0611 14:11:00.327352 20393 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0611 14:11:00.327358 20393 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0611 14:11:00.327373 20393 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0611 14:11:00.327378 20393 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0611 14:11:00.327383 20393 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0611 14:11:00.328994 20393 net.cpp:150] Setting up rpn_loss_bbox
I0611 14:11:00.329007 20393 net.cpp:157] Top shape: (1)
I0611 14:11:00.329011 20393 net.cpp:160]     with loss weight 1
I0611 14:11:00.329018 20393 net.cpp:165] Memory required for data: 1429955564
I0611 14:11:00.329022 20393 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0611 14:11:00.329042 20393 net.cpp:106] Creating Layer rpn_cls_prob
I0611 14:11:00.329048 20393 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0611 14:11:00.329057 20393 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0611 14:11:00.329349 20393 net.cpp:150] Setting up rpn_cls_prob
I0611 14:11:00.329361 20393 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 14:11:00.329375 20393 net.cpp:165] Memory required for data: 1430242844
I0611 14:11:00.329380 20393 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0611 14:11:00.329391 20393 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0611 14:11:00.329397 20393 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0611 14:11:00.329406 20393 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0611 14:11:00.329470 20393 net.cpp:150] Setting up rpn_cls_prob_reshape
I0611 14:11:00.329480 20393 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 14:11:00.329484 20393 net.cpp:165] Memory required for data: 1430530124
I0611 14:11:00.329488 20393 layer_factory.hpp:77] Creating layer proposal
I0611 14:11:00.332084 20393 net.cpp:106] Creating Layer proposal
I0611 14:11:00.332093 20393 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0611 14:11:00.332096 20393 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0611 14:11:00.332100 20393 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0611 14:11:00.332104 20393 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0611 14:11:00.333263 20393 net.cpp:150] Setting up proposal
I0611 14:11:00.333273 20393 net.cpp:157] Top shape: 1 5 (5)
I0611 14:11:00.333276 20393 net.cpp:165] Memory required for data: 1430530144
I0611 14:11:00.333279 20393 layer_factory.hpp:77] Creating layer roi-data
I0611 14:11:00.335770 20393 net.cpp:106] Creating Layer roi-data
I0611 14:11:00.335778 20393 net.cpp:454] roi-data <- rpn_rois
I0611 14:11:00.335793 20393 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0611 14:11:00.335796 20393 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0611 14:11:00.335799 20393 net.cpp:454] roi-data <- seg_mask_inds
I0611 14:11:00.335813 20393 net.cpp:454] roi-data <- flipped
I0611 14:11:00.335816 20393 net.cpp:411] roi-data -> rois
I0611 14:11:00.335824 20393 net.cpp:411] roi-data -> labels
I0611 14:11:00.335829 20393 net.cpp:411] roi-data -> bbox_targets
I0611 14:11:00.335832 20393 net.cpp:411] roi-data -> bbox_inside_weights
I0611 14:11:00.335836 20393 net.cpp:411] roi-data -> bbox_outside_weights
I0611 14:11:00.335842 20393 net.cpp:411] roi-data -> mask_targets
I0611 14:11:00.335847 20393 net.cpp:411] roi-data -> rois_pos
I0611 14:11:00.336216 20393 net.cpp:150] Setting up roi-data
I0611 14:11:00.336230 20393 net.cpp:157] Top shape: 1 5 (5)
I0611 14:11:00.336246 20393 net.cpp:157] Top shape: 1 1 (1)
I0611 14:11:00.336259 20393 net.cpp:157] Top shape: 1 8 (8)
I0611 14:11:00.336263 20393 net.cpp:157] Top shape: 1 8 (8)
I0611 14:11:00.336266 20393 net.cpp:157] Top shape: 1 8 (8)
I0611 14:11:00.336282 20393 net.cpp:157] Top shape: 1 244 244 (59536)
I0611 14:11:00.336295 20393 net.cpp:157] Top shape: 1 5 (5)
I0611 14:11:00.336298 20393 net.cpp:165] Memory required for data: 1430768428
I0611 14:11:00.336303 20393 layer_factory.hpp:77] Creating layer roi_pool5
I0611 14:11:00.336319 20393 net.cpp:106] Creating Layer roi_pool5
I0611 14:11:00.336324 20393 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0611 14:11:00.336329 20393 net.cpp:454] roi_pool5 <- rois
I0611 14:11:00.336335 20393 net.cpp:411] roi_pool5 -> pool5
I0611 14:11:00.336344 20393 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0611 14:11:00.336436 20393 net.cpp:150] Setting up roi_pool5
I0611 14:11:00.336443 20393 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 14:11:00.336449 20393 net.cpp:165] Memory required for data: 1430868780
I0611 14:11:00.336454 20393 layer_factory.hpp:77] Creating layer fc6
I0611 14:11:00.336463 20393 net.cpp:106] Creating Layer fc6
I0611 14:11:00.336469 20393 net.cpp:454] fc6 <- pool5
I0611 14:11:00.336477 20393 net.cpp:411] fc6 -> fc6
I0611 14:11:00.488960 20393 net.cpp:150] Setting up fc6
I0611 14:11:00.488986 20393 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:11:00.488988 20393 net.cpp:165] Memory required for data: 1430885164
I0611 14:11:00.489004 20393 layer_factory.hpp:77] Creating layer relu6
I0611 14:11:00.489023 20393 net.cpp:106] Creating Layer relu6
I0611 14:11:00.489028 20393 net.cpp:454] relu6 <- fc6
I0611 14:11:00.489044 20393 net.cpp:397] relu6 -> fc6 (in-place)
I0611 14:11:00.489254 20393 net.cpp:150] Setting up relu6
I0611 14:11:00.489262 20393 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:11:00.489264 20393 net.cpp:165] Memory required for data: 1430901548
I0611 14:11:00.489267 20393 layer_factory.hpp:77] Creating layer fc7
I0611 14:11:00.489274 20393 net.cpp:106] Creating Layer fc7
I0611 14:11:00.489276 20393 net.cpp:454] fc7 <- fc6
I0611 14:11:00.489280 20393 net.cpp:411] fc7 -> fc7
I0611 14:11:00.516041 20393 net.cpp:150] Setting up fc7
I0611 14:11:00.516075 20393 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:11:00.516079 20393 net.cpp:165] Memory required for data: 1430917932
I0611 14:11:00.516089 20393 layer_factory.hpp:77] Creating layer relu7
I0611 14:11:00.516099 20393 net.cpp:106] Creating Layer relu7
I0611 14:11:00.516105 20393 net.cpp:454] relu7 <- fc7
I0611 14:11:00.516111 20393 net.cpp:397] relu7 -> fc7 (in-place)
I0611 14:11:00.516337 20393 net.cpp:150] Setting up relu7
I0611 14:11:00.516346 20393 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:11:00.516348 20393 net.cpp:165] Memory required for data: 1430934316
I0611 14:11:00.516351 20393 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0611 14:11:00.516356 20393 net.cpp:106] Creating Layer fc7_relu7_0_split
I0611 14:11:00.516360 20393 net.cpp:454] fc7_relu7_0_split <- fc7
I0611 14:11:00.516363 20393 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0611 14:11:00.516379 20393 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0611 14:11:00.516429 20393 net.cpp:150] Setting up fc7_relu7_0_split
I0611 14:11:00.516434 20393 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:11:00.516448 20393 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:11:00.516449 20393 net.cpp:165] Memory required for data: 1430967084
I0611 14:11:00.516451 20393 layer_factory.hpp:77] Creating layer cls_score
I0611 14:11:00.516468 20393 net.cpp:106] Creating Layer cls_score
I0611 14:11:00.516470 20393 net.cpp:454] cls_score <- fc7_relu7_0_split_0
I0611 14:11:00.516486 20393 net.cpp:411] cls_score -> cls_score
I0611 14:11:00.516726 20393 net.cpp:150] Setting up cls_score
I0611 14:11:00.516729 20393 net.cpp:157] Top shape: 1 2 (2)
I0611 14:11:00.516732 20393 net.cpp:165] Memory required for data: 1430967092
I0611 14:11:00.516736 20393 layer_factory.hpp:77] Creating layer bbox_pred
I0611 14:11:00.516741 20393 net.cpp:106] Creating Layer bbox_pred
I0611 14:11:00.516743 20393 net.cpp:454] bbox_pred <- fc7_relu7_0_split_1
I0611 14:11:00.516757 20393 net.cpp:411] bbox_pred -> bbox_pred
I0611 14:11:00.517621 20393 net.cpp:150] Setting up bbox_pred
I0611 14:11:00.517627 20393 net.cpp:157] Top shape: 1 8 (8)
I0611 14:11:00.517640 20393 net.cpp:165] Memory required for data: 1430967124
I0611 14:11:00.517644 20393 layer_factory.hpp:77] Creating layer loss_cls
I0611 14:11:00.517650 20393 net.cpp:106] Creating Layer loss_cls
I0611 14:11:00.517653 20393 net.cpp:454] loss_cls <- cls_score
I0611 14:11:00.517657 20393 net.cpp:454] loss_cls <- labels
I0611 14:11:00.517660 20393 net.cpp:411] loss_cls -> loss_cls
I0611 14:11:00.517666 20393 layer_factory.hpp:77] Creating layer loss_cls
I0611 14:11:00.518359 20393 net.cpp:150] Setting up loss_cls
I0611 14:11:00.518368 20393 net.cpp:157] Top shape: (1)
I0611 14:11:00.518381 20393 net.cpp:160]     with loss weight 3
I0611 14:11:00.518389 20393 net.cpp:165] Memory required for data: 1430967128
I0611 14:11:00.518391 20393 layer_factory.hpp:77] Creating layer loss_bbox
I0611 14:11:00.518407 20393 net.cpp:106] Creating Layer loss_bbox
I0611 14:11:00.518410 20393 net.cpp:454] loss_bbox <- bbox_pred
I0611 14:11:00.518414 20393 net.cpp:454] loss_bbox <- bbox_targets
I0611 14:11:00.518417 20393 net.cpp:454] loss_bbox <- bbox_inside_weights
I0611 14:11:00.518420 20393 net.cpp:454] loss_bbox <- bbox_outside_weights
I0611 14:11:00.518425 20393 net.cpp:411] loss_bbox -> loss_bbox
I0611 14:11:00.518502 20393 net.cpp:150] Setting up loss_bbox
I0611 14:11:00.518507 20393 net.cpp:157] Top shape: (1)
I0611 14:11:00.518519 20393 net.cpp:160]     with loss weight 2
I0611 14:11:00.518523 20393 net.cpp:165] Memory required for data: 1430967132
I0611 14:11:00.518525 20393 layer_factory.hpp:77] Creating layer roi_pool5_2
I0611 14:11:00.518533 20393 net.cpp:106] Creating Layer roi_pool5_2
I0611 14:11:00.518548 20393 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0611 14:11:00.518554 20393 net.cpp:454] roi_pool5_2 <- rois_pos
I0611 14:11:00.518563 20393 net.cpp:411] roi_pool5_2 -> pool5_2
I0611 14:11:00.518573 20393 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0611 14:11:00.518661 20393 net.cpp:150] Setting up roi_pool5_2
I0611 14:11:00.518666 20393 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 14:11:00.518669 20393 net.cpp:165] Memory required for data: 1431067484
I0611 14:11:00.518672 20393 layer_factory.hpp:77] Creating layer pool5_2_conv
I0611 14:11:00.518690 20393 net.cpp:106] Creating Layer pool5_2_conv
I0611 14:11:00.518694 20393 net.cpp:454] pool5_2_conv <- pool5_2
I0611 14:11:00.518698 20393 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0611 14:11:00.525492 20393 net.cpp:150] Setting up pool5_2_conv
I0611 14:11:00.525502 20393 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 14:11:00.525504 20393 net.cpp:165] Memory required for data: 1431167836
I0611 14:11:00.525511 20393 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0611 14:11:00.525516 20393 net.cpp:106] Creating Layer pool5_2_conv_relu
I0611 14:11:00.525518 20393 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0611 14:11:00.525521 20393 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0611 14:11:00.525655 20393 net.cpp:150] Setting up pool5_2_conv_relu
I0611 14:11:00.525660 20393 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 14:11:00.525662 20393 net.cpp:165] Memory required for data: 1431268188
I0611 14:11:00.525665 20393 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0611 14:11:00.525677 20393 net.cpp:106] Creating Layer pool5_2_conv2
I0611 14:11:00.525681 20393 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0611 14:11:00.525684 20393 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0611 14:11:00.593575 20393 net.cpp:150] Setting up pool5_2_conv2
I0611 14:11:00.593592 20393 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 14:11:00.593595 20393 net.cpp:165] Memory required for data: 1431368540
I0611 14:11:00.593603 20393 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0611 14:11:00.593611 20393 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0611 14:11:00.593616 20393 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0611 14:11:00.593632 20393 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0611 14:11:00.593780 20393 net.cpp:150] Setting up pool5_2_conv2_relu
I0611 14:11:00.593787 20393 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 14:11:00.593789 20393 net.cpp:165] Memory required for data: 1431468892
I0611 14:11:00.593792 20393 layer_factory.hpp:77] Creating layer mask_deconv1
I0611 14:11:00.593799 20393 net.cpp:106] Creating Layer mask_deconv1
I0611 14:11:00.593802 20393 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0611 14:11:00.593806 20393 net.cpp:411] mask_deconv1 -> mask_deconv1
I0611 14:11:00.594588 20393 net.cpp:150] Setting up mask_deconv1
I0611 14:11:00.594595 20393 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0611 14:11:00.594609 20393 net.cpp:165] Memory required for data: 1432390492
I0611 14:11:00.594614 20393 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0611 14:11:00.594620 20393 net.cpp:106] Creating Layer pool5_2_conv3
I0611 14:11:00.594622 20393 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0611 14:11:00.594641 20393 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0611 14:11:00.623530 20393 net.cpp:150] Setting up pool5_2_conv3
I0611 14:11:00.623558 20393 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:00.623561 20393 net.cpp:165] Memory required for data: 1434233692
I0611 14:11:00.623569 20393 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0611 14:11:00.623587 20393 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0611 14:11:00.623591 20393 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0611 14:11:00.623597 20393 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0611 14:11:00.623749 20393 net.cpp:150] Setting up pool5_2_conv3_relu
I0611 14:11:00.623754 20393 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:00.623767 20393 net.cpp:165] Memory required for data: 1436076892
I0611 14:11:00.623770 20393 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0611 14:11:00.623780 20393 net.cpp:106] Creating Layer pool5_2_conv4
I0611 14:11:00.623782 20393 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0611 14:11:00.623796 20393 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0611 14:11:00.675988 20393 net.cpp:150] Setting up pool5_2_conv4
I0611 14:11:00.676007 20393 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:00.676010 20393 net.cpp:165] Memory required for data: 1437920092
I0611 14:11:00.676017 20393 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0611 14:11:00.676026 20393 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0611 14:11:00.676031 20393 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0611 14:11:00.676046 20393 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0611 14:11:00.676190 20393 net.cpp:150] Setting up pool5_2_conv4_relu
I0611 14:11:00.676198 20393 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:00.676199 20393 net.cpp:165] Memory required for data: 1439763292
I0611 14:11:00.676203 20393 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 14:11:00.676208 20393 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 14:11:00.676211 20393 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0611 14:11:00.676215 20393 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0611 14:11:00.676229 20393 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0611 14:11:00.676234 20393 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0611 14:11:00.676239 20393 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0611 14:11:00.676290 20393 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 14:11:00.676295 20393 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:00.676297 20393 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:00.676299 20393 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:00.676301 20393 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:00.676303 20393 net.cpp:165] Memory required for data: 1447136092
I0611 14:11:00.676306 20393 layer_factory.hpp:77] Creating layer query_conv
I0611 14:11:00.676324 20393 net.cpp:106] Creating Layer query_conv
I0611 14:11:00.676326 20393 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0611 14:11:00.676333 20393 net.cpp:411] query_conv -> query_conv
I0611 14:11:00.678117 20393 net.cpp:150] Setting up query_conv
I0611 14:11:00.678138 20393 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0611 14:11:00.678143 20393 net.cpp:165] Memory required for data: 1447366492
I0611 14:11:00.678151 20393 layer_factory.hpp:77] Creating layer key_conv
I0611 14:11:00.678177 20393 net.cpp:106] Creating Layer key_conv
I0611 14:11:00.678192 20393 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0611 14:11:00.678200 20393 net.cpp:411] key_conv -> key_conv
I0611 14:11:00.680089 20393 net.cpp:150] Setting up key_conv
I0611 14:11:00.680099 20393 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0611 14:11:00.680101 20393 net.cpp:165] Memory required for data: 1447596892
I0611 14:11:00.680106 20393 layer_factory.hpp:77] Creating layer value_conv
I0611 14:11:00.680115 20393 net.cpp:106] Creating Layer value_conv
I0611 14:11:00.680119 20393 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0611 14:11:00.680137 20393 net.cpp:411] value_conv -> value_conv
I0611 14:11:00.687598 20393 net.cpp:150] Setting up value_conv
I0611 14:11:00.687613 20393 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:00.687614 20393 net.cpp:165] Memory required for data: 1449440092
I0611 14:11:00.687621 20393 layer_factory.hpp:77] Creating layer query_conv_reshape
I0611 14:11:00.687629 20393 net.cpp:106] Creating Layer query_conv_reshape
I0611 14:11:00.687633 20393 net.cpp:454] query_conv_reshape <- query_conv
I0611 14:11:00.687650 20393 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0611 14:11:00.687685 20393 net.cpp:150] Setting up query_conv_reshape
I0611 14:11:00.687690 20393 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0611 14:11:00.687702 20393 net.cpp:165] Memory required for data: 1449670492
I0611 14:11:00.687705 20393 layer_factory.hpp:77] Creating layer key_conv_reshape
I0611 14:11:00.687710 20393 net.cpp:106] Creating Layer key_conv_reshape
I0611 14:11:00.687712 20393 net.cpp:454] key_conv_reshape <- key_conv
I0611 14:11:00.687716 20393 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0611 14:11:00.687737 20393 net.cpp:150] Setting up key_conv_reshape
I0611 14:11:00.687752 20393 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0611 14:11:00.687753 20393 net.cpp:165] Memory required for data: 1449900892
I0611 14:11:00.687755 20393 layer_factory.hpp:77] Creating layer value_conv_reshape
I0611 14:11:00.687768 20393 net.cpp:106] Creating Layer value_conv_reshape
I0611 14:11:00.687772 20393 net.cpp:454] value_conv_reshape <- value_conv
I0611 14:11:00.687775 20393 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0611 14:11:00.687813 20393 net.cpp:150] Setting up value_conv_reshape
I0611 14:11:00.687826 20393 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0611 14:11:00.687829 20393 net.cpp:165] Memory required for data: 1451744092
I0611 14:11:00.687831 20393 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0611 14:11:00.703621 20393 net.cpp:106] Creating Layer query_conv_reshape_perm
I0611 14:11:00.703639 20393 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0611 14:11:00.703649 20393 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0611 14:11:00.703799 20393 net.cpp:150] Setting up query_conv_reshape_perm
I0611 14:11:00.703807 20393 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0611 14:11:00.703809 20393 net.cpp:165] Memory required for data: 1451974492
I0611 14:11:00.703814 20393 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0611 14:11:00.703819 20393 net.cpp:106] Creating Layer key_conv_reshape_perm
I0611 14:11:00.703822 20393 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0611 14:11:00.703825 20393 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0611 14:11:00.703899 20393 net.cpp:150] Setting up key_conv_reshape_perm
I0611 14:11:00.703904 20393 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0611 14:11:00.703907 20393 net.cpp:165] Memory required for data: 1452204892
I0611 14:11:00.703909 20393 layer_factory.hpp:77] Creating layer energy
I0611 14:11:00.703924 20393 net.cpp:106] Creating Layer energy
I0611 14:11:00.703927 20393 net.cpp:454] energy <- query_conv_reshape_perm
I0611 14:11:00.703932 20393 net.cpp:454] energy <- key_conv_reshape_perm
I0611 14:11:00.703935 20393 net.cpp:411] energy -> energy
I0611 14:11:00.703958 20393 net.cpp:150] Setting up energy
I0611 14:11:00.703963 20393 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 14:11:00.703964 20393 net.cpp:165] Memory required for data: 1455444892
I0611 14:11:00.703968 20393 layer_factory.hpp:77] Creating layer attention
I0611 14:11:00.703971 20393 net.cpp:106] Creating Layer attention
I0611 14:11:00.703974 20393 net.cpp:454] attention <- energy
I0611 14:11:00.703977 20393 net.cpp:411] attention -> attention
I0611 14:11:00.704239 20393 net.cpp:150] Setting up attention
I0611 14:11:00.704248 20393 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 14:11:00.704250 20393 net.cpp:165] Memory required for data: 1458684892
I0611 14:11:00.704253 20393 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0611 14:11:00.704257 20393 net.cpp:106] Creating Layer value_conv_reshape_perm
I0611 14:11:00.704260 20393 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0611 14:11:00.704265 20393 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0611 14:11:00.704334 20393 net.cpp:150] Setting up value_conv_reshape_perm
I0611 14:11:00.704339 20393 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0611 14:11:00.704341 20393 net.cpp:165] Memory required for data: 1460528092
I0611 14:11:00.704344 20393 layer_factory.hpp:77] Creating layer attention_perm
I0611 14:11:00.704347 20393 net.cpp:106] Creating Layer attention_perm
I0611 14:11:00.704349 20393 net.cpp:454] attention_perm <- attention
I0611 14:11:00.704354 20393 net.cpp:411] attention_perm -> attention_perm
I0611 14:11:00.704417 20393 net.cpp:150] Setting up attention_perm
I0611 14:11:00.704421 20393 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 14:11:00.704423 20393 net.cpp:165] Memory required for data: 1463768092
I0611 14:11:00.704425 20393 layer_factory.hpp:77] Creating layer out
I0611 14:11:00.704429 20393 net.cpp:106] Creating Layer out
I0611 14:11:00.704432 20393 net.cpp:454] out <- value_conv_reshape_perm
I0611 14:11:00.704435 20393 net.cpp:454] out <- attention_perm
I0611 14:11:00.704439 20393 net.cpp:411] out -> out
I0611 14:11:00.704453 20393 net.cpp:150] Setting up out
I0611 14:11:00.704457 20393 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0611 14:11:00.704459 20393 net.cpp:165] Memory required for data: 1465611292
I0611 14:11:00.704461 20393 layer_factory.hpp:77] Creating layer out_reshape
I0611 14:11:00.704466 20393 net.cpp:106] Creating Layer out_reshape
I0611 14:11:00.704468 20393 net.cpp:454] out_reshape <- out
I0611 14:11:00.704473 20393 net.cpp:411] out_reshape -> out_reshape
I0611 14:11:00.704489 20393 net.cpp:150] Setting up out_reshape
I0611 14:11:00.704493 20393 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:00.704495 20393 net.cpp:165] Memory required for data: 1467454492
I0611 14:11:00.704499 20393 layer_factory.hpp:77] Creating layer out_reshape_scale
I0611 14:11:00.704504 20393 net.cpp:106] Creating Layer out_reshape_scale
I0611 14:11:00.704506 20393 net.cpp:454] out_reshape_scale <- out_reshape
I0611 14:11:00.704510 20393 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0611 14:11:00.704581 20393 net.cpp:150] Setting up out_reshape_scale
I0611 14:11:00.704587 20393 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:00.704591 20393 net.cpp:165] Memory required for data: 1469297692
I0611 14:11:00.704593 20393 layer_factory.hpp:77] Creating layer out_x
I0611 14:11:00.704598 20393 net.cpp:106] Creating Layer out_x
I0611 14:11:00.704600 20393 net.cpp:454] out_x <- out_reshape_scale
I0611 14:11:00.704604 20393 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0611 14:11:00.704607 20393 net.cpp:411] out_x -> out_x
I0611 14:11:00.704624 20393 net.cpp:150] Setting up out_x
I0611 14:11:00.704629 20393 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:00.704632 20393 net.cpp:165] Memory required for data: 1471140892
I0611 14:11:00.704634 20393 layer_factory.hpp:77] Creating layer mask_deconv2
I0611 14:11:00.704644 20393 net.cpp:106] Creating Layer mask_deconv2
I0611 14:11:00.704648 20393 net.cpp:454] mask_deconv2 <- out_x
I0611 14:11:00.704653 20393 net.cpp:411] mask_deconv2 -> mask_deconv2
I0611 14:11:00.705485 20393 net.cpp:150] Setting up mask_deconv2
I0611 14:11:00.705492 20393 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0611 14:11:00.705495 20393 net.cpp:165] Memory required for data: 1486382108
I0611 14:11:00.705512 20393 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0611 14:11:00.705520 20393 net.cpp:106] Creating Layer pool5_2_conv5
I0611 14:11:00.705524 20393 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0611 14:11:00.705529 20393 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0611 14:11:00.732897 20393 net.cpp:150] Setting up pool5_2_conv5
I0611 14:11:00.732915 20393 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 14:11:00.732918 20393 net.cpp:165] Memory required for data: 1516864540
I0611 14:11:00.732926 20393 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0611 14:11:00.732945 20393 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0611 14:11:00.732950 20393 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0611 14:11:00.732956 20393 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0611 14:11:00.733114 20393 net.cpp:150] Setting up pool5_2_conv5_relu
I0611 14:11:00.733122 20393 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 14:11:00.733124 20393 net.cpp:165] Memory required for data: 1547346972
I0611 14:11:00.733126 20393 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0611 14:11:00.733136 20393 net.cpp:106] Creating Layer pool5_2_conv6
I0611 14:11:00.733139 20393 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0611 14:11:00.733155 20393 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0611 14:11:00.785624 20393 net.cpp:150] Setting up pool5_2_conv6
I0611 14:11:00.785643 20393 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 14:11:00.785647 20393 net.cpp:165] Memory required for data: 1577829404
I0611 14:11:00.785655 20393 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0611 14:11:00.785662 20393 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0611 14:11:00.785677 20393 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0611 14:11:00.785683 20393 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0611 14:11:00.786288 20393 net.cpp:150] Setting up pool5_2_conv6_relu
I0611 14:11:00.786298 20393 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 14:11:00.786300 20393 net.cpp:165] Memory required for data: 1608311836
I0611 14:11:00.786303 20393 layer_factory.hpp:77] Creating layer mask_deconv3
I0611 14:11:00.786310 20393 net.cpp:106] Creating Layer mask_deconv3
I0611 14:11:00.786314 20393 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0611 14:11:00.786329 20393 net.cpp:411] mask_deconv3 -> mask_deconv3
I0611 14:11:00.786749 20393 net.cpp:150] Setting up mask_deconv3
I0611 14:11:00.786757 20393 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0611 14:11:00.786759 20393 net.cpp:165] Memory required for data: 1669276700
I0611 14:11:00.786772 20393 layer_factory.hpp:77] Creating layer mask_score
I0611 14:11:00.786780 20393 net.cpp:106] Creating Layer mask_score
I0611 14:11:00.786795 20393 net.cpp:454] mask_score <- mask_deconv3
I0611 14:11:00.786800 20393 net.cpp:411] mask_score -> mask_score
I0611 14:11:00.787865 20393 net.cpp:150] Setting up mask_score
I0611 14:11:00.787889 20393 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0611 14:11:00.787892 20393 net.cpp:165] Memory required for data: 1671181852
I0611 14:11:00.787899 20393 layer_factory.hpp:77] Creating layer loss_mask
I0611 14:11:00.787919 20393 net.cpp:106] Creating Layer loss_mask
I0611 14:11:00.787925 20393 net.cpp:454] loss_mask <- mask_score
I0611 14:11:00.787927 20393 net.cpp:454] loss_mask <- mask_targets
I0611 14:11:00.787932 20393 net.cpp:411] loss_mask -> loss_mask
I0611 14:11:00.787938 20393 layer_factory.hpp:77] Creating layer loss_mask
I0611 14:11:00.789547 20393 net.cpp:150] Setting up loss_mask
I0611 14:11:00.789556 20393 net.cpp:157] Top shape: (1)
I0611 14:11:00.789558 20393 net.cpp:160]     with loss weight 3
I0611 14:11:00.789566 20393 net.cpp:165] Memory required for data: 1671181856
I0611 14:11:00.789567 20393 net.cpp:226] loss_mask needs backward computation.
I0611 14:11:00.789571 20393 net.cpp:226] mask_score needs backward computation.
I0611 14:11:00.789572 20393 net.cpp:226] mask_deconv3 needs backward computation.
I0611 14:11:00.789574 20393 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0611 14:11:00.789587 20393 net.cpp:226] pool5_2_conv6 needs backward computation.
I0611 14:11:00.789590 20393 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0611 14:11:00.789593 20393 net.cpp:226] pool5_2_conv5 needs backward computation.
I0611 14:11:00.789595 20393 net.cpp:226] mask_deconv2 needs backward computation.
I0611 14:11:00.789608 20393 net.cpp:226] out_x needs backward computation.
I0611 14:11:00.789614 20393 net.cpp:226] out_reshape_scale needs backward computation.
I0611 14:11:00.789616 20393 net.cpp:226] out_reshape needs backward computation.
I0611 14:11:00.789619 20393 net.cpp:226] out needs backward computation.
I0611 14:11:00.789623 20393 net.cpp:226] attention_perm needs backward computation.
I0611 14:11:00.789626 20393 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0611 14:11:00.789631 20393 net.cpp:226] attention needs backward computation.
I0611 14:11:00.789635 20393 net.cpp:226] energy needs backward computation.
I0611 14:11:00.789639 20393 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0611 14:11:00.789642 20393 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0611 14:11:00.789645 20393 net.cpp:226] value_conv_reshape needs backward computation.
I0611 14:11:00.789649 20393 net.cpp:226] key_conv_reshape needs backward computation.
I0611 14:11:00.789651 20393 net.cpp:226] query_conv_reshape needs backward computation.
I0611 14:11:00.789654 20393 net.cpp:226] value_conv needs backward computation.
I0611 14:11:00.789657 20393 net.cpp:226] key_conv needs backward computation.
I0611 14:11:00.789660 20393 net.cpp:226] query_conv needs backward computation.
I0611 14:11:00.789664 20393 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0611 14:11:00.789666 20393 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0611 14:11:00.789670 20393 net.cpp:226] pool5_2_conv4 needs backward computation.
I0611 14:11:00.789676 20393 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0611 14:11:00.789678 20393 net.cpp:226] pool5_2_conv3 needs backward computation.
I0611 14:11:00.789681 20393 net.cpp:226] mask_deconv1 needs backward computation.
I0611 14:11:00.789686 20393 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0611 14:11:00.789690 20393 net.cpp:226] pool5_2_conv2 needs backward computation.
I0611 14:11:00.789691 20393 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0611 14:11:00.789695 20393 net.cpp:226] pool5_2_conv needs backward computation.
I0611 14:11:00.789700 20393 net.cpp:226] roi_pool5_2 needs backward computation.
I0611 14:11:00.789702 20393 net.cpp:226] loss_bbox needs backward computation.
I0611 14:11:00.789707 20393 net.cpp:226] loss_cls needs backward computation.
I0611 14:11:00.789712 20393 net.cpp:226] bbox_pred needs backward computation.
I0611 14:11:00.789714 20393 net.cpp:226] cls_score needs backward computation.
I0611 14:11:00.789717 20393 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0611 14:11:00.789721 20393 net.cpp:226] relu7 needs backward computation.
I0611 14:11:00.789722 20393 net.cpp:226] fc7 needs backward computation.
I0611 14:11:00.789726 20393 net.cpp:226] relu6 needs backward computation.
I0611 14:11:00.789729 20393 net.cpp:226] fc6 needs backward computation.
I0611 14:11:00.789731 20393 net.cpp:226] roi_pool5 needs backward computation.
I0611 14:11:00.789736 20393 net.cpp:226] roi-data needs backward computation.
I0611 14:11:00.789741 20393 net.cpp:226] proposal needs backward computation.
I0611 14:11:00.789746 20393 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0611 14:11:00.789750 20393 net.cpp:226] rpn_cls_prob needs backward computation.
I0611 14:11:00.789755 20393 net.cpp:226] rpn_loss_bbox needs backward computation.
I0611 14:11:00.789758 20393 net.cpp:226] rpn_loss_cls needs backward computation.
I0611 14:11:00.789764 20393 net.cpp:226] rpn-data needs backward computation.
I0611 14:11:00.789768 20393 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0611 14:11:00.789772 20393 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0611 14:11:00.789774 20393 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0611 14:11:00.789778 20393 net.cpp:226] rpn_bbox_pred needs backward computation.
I0611 14:11:00.789783 20393 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0611 14:11:00.789786 20393 net.cpp:226] rpn_cls_score needs backward computation.
I0611 14:11:00.789789 20393 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0611 14:11:00.789793 20393 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0611 14:11:00.789796 20393 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0611 14:11:00.789799 20393 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0611 14:11:00.789803 20393 net.cpp:226] relu5_3 needs backward computation.
I0611 14:11:00.789806 20393 net.cpp:226] conv5_3 needs backward computation.
I0611 14:11:00.789810 20393 net.cpp:226] relu5_2 needs backward computation.
I0611 14:11:00.789813 20393 net.cpp:226] conv5_2 needs backward computation.
I0611 14:11:00.789816 20393 net.cpp:226] relu5_1 needs backward computation.
I0611 14:11:00.789821 20393 net.cpp:226] conv5_1 needs backward computation.
I0611 14:11:00.789824 20393 net.cpp:226] pool4 needs backward computation.
I0611 14:11:00.789829 20393 net.cpp:226] relu4_3 needs backward computation.
I0611 14:11:00.789830 20393 net.cpp:226] conv4_3 needs backward computation.
I0611 14:11:00.789834 20393 net.cpp:226] relu4_2 needs backward computation.
I0611 14:11:00.789839 20393 net.cpp:226] conv4_2 needs backward computation.
I0611 14:11:00.789841 20393 net.cpp:226] relu4_1 needs backward computation.
I0611 14:11:00.789844 20393 net.cpp:226] conv4_1 needs backward computation.
I0611 14:11:00.789849 20393 net.cpp:226] pool3 needs backward computation.
I0611 14:11:00.789852 20393 net.cpp:226] relu3_3 needs backward computation.
I0611 14:11:00.789855 20393 net.cpp:226] conv3_3 needs backward computation.
I0611 14:11:00.789860 20393 net.cpp:226] relu3_2 needs backward computation.
I0611 14:11:00.789862 20393 net.cpp:226] conv3_2 needs backward computation.
I0611 14:11:00.789865 20393 net.cpp:226] relu3_1 needs backward computation.
I0611 14:11:00.789870 20393 net.cpp:226] conv3_1 needs backward computation.
I0611 14:11:00.789873 20393 net.cpp:228] pool2 does not need backward computation.
I0611 14:11:00.789877 20393 net.cpp:228] relu2_2 does not need backward computation.
I0611 14:11:00.789881 20393 net.cpp:228] conv2_2 does not need backward computation.
I0611 14:11:00.789885 20393 net.cpp:228] relu2_1 does not need backward computation.
I0611 14:11:00.789888 20393 net.cpp:228] conv2_1 does not need backward computation.
I0611 14:11:00.789897 20393 net.cpp:228] pool1 does not need backward computation.
I0611 14:11:00.789901 20393 net.cpp:228] relu1_2 does not need backward computation.
I0611 14:11:00.789903 20393 net.cpp:228] conv1_2 does not need backward computation.
I0611 14:11:00.789906 20393 net.cpp:228] relu1_1 does not need backward computation.
I0611 14:11:00.789907 20393 net.cpp:228] conv1_1 does not need backward computation.
I0611 14:11:00.789911 20393 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0611 14:11:00.789916 20393 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0611 14:11:00.789922 20393 net.cpp:228] data_input-data_0_split does not need backward computation.
I0611 14:11:00.789927 20393 net.cpp:228] input-data does not need backward computation.
I0611 14:11:00.789930 20393 net.cpp:270] This network produces output loss_bbox
I0611 14:11:00.789935 20393 net.cpp:270] This network produces output loss_cls
I0611 14:11:00.789940 20393 net.cpp:270] This network produces output loss_mask
I0611 14:11:00.789943 20393 net.cpp:270] This network produces output rpn_cls_loss
I0611 14:11:00.789947 20393 net.cpp:270] This network produces output rpn_loss_bbox
I0611 14:11:00.789999 20393 net.cpp:283] Network initialization done.
I0611 14:11:00.790185 20393 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0611 14:11:04.061666 20393 net.cpp:816] Ignoring source layer pool5
I0611 14:11:04.144177 20393 net.cpp:816] Ignoring source layer drop6
I0611 14:11:04.160919 20393 net.cpp:816] Ignoring source layer drop7
I0611 14:11:04.160941 20393 net.cpp:816] Ignoring source layer fc8
I0611 14:11:04.160945 20393 net.cpp:816] Ignoring source layer prob
Solving...
[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
18529
[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
10901
[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
I0611 14:11:05.668843 20393 solver.cpp:229] Iteration 0, loss = 8.82055
I0611 14:11:05.668874 20393 solver.cpp:245]     Train net output #0: loss_bbox = 0.0930647 (* 2 = 0.186129 loss)
I0611 14:11:05.668880 20393 solver.cpp:245]     Train net output #1: loss_cls = 0.569136 (* 3 = 1.70741 loss)
I0611 14:11:05.668885 20393 solver.cpp:245]     Train net output #2: loss_mask = 2.08154 (* 3 = 6.24461 loss)
I0611 14:11:05.668889 20393 solver.cpp:245]     Train net output #3: rpn_cls_loss = 0.73882 (* 1 = 0.73882 loss)
I0611 14:11:05.668893 20393 solver.cpp:245]     Train net output #4: rpn_loss_bbox = 0.0189577 (* 1 = 0.0189577 loss)
I0611 14:11:05.668898 20393 sgd_solver.cpp:106] Iteration 0, lr = 0.001
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
15508
[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
5831
[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
28533
[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
22528
[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
11902
[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
12176
[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
12868
[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
5911
[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
11506
[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
11157
[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
12460
[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
11477
[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
23554
[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
