+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-05_18-44-45
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-05_18-44-45
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0605 18:44:52.571388 12093 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0605 18:44:52.571408 12093 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0605 18:44:52.572696 12093 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "pool5_2_conv4_relu"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv6_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv6_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv6_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 14884
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 14884
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 14884
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 122
      dim: 122
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv6_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_mask"
  type: "SoftmaxWithLoss"
  bottom: "mask_score"
  bottom: "mask_targets"
  top: "loss_mask"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
I0605 18:44:52.573097 12093 layer_factory.hpp:77] Creating layer input-data
I0605 18:44:52.586711 12093 net.cpp:106] Creating Layer input-data
I0605 18:44:52.586726 12093 net.cpp:411] input-data -> data
I0605 18:44:52.586733 12093 net.cpp:411] input-data -> im_info
I0605 18:44:52.586738 12093 net.cpp:411] input-data -> gt_boxes
I0605 18:44:52.586742 12093 net.cpp:411] input-data -> seg_mask_inds
I0605 18:44:52.586746 12093 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0605 18:44:52.597849 12093 net.cpp:150] Setting up input-data
I0605 18:44:52.597884 12093 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0605 18:44:52.597888 12093 net.cpp:157] Top shape: 1 3 (3)
I0605 18:44:52.597892 12093 net.cpp:157] Top shape: 1 4 (4)
I0605 18:44:52.597894 12093 net.cpp:157] Top shape: 1 2 (2)
I0605 18:44:52.597898 12093 net.cpp:157] Top shape: 1 1 (1)
I0605 18:44:52.597900 12093 net.cpp:165] Memory required for data: 7200040
I0605 18:44:52.597906 12093 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0605 18:44:52.597923 12093 net.cpp:106] Creating Layer data_input-data_0_split
I0605 18:44:52.597926 12093 net.cpp:454] data_input-data_0_split <- data
I0605 18:44:52.597940 12093 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0605 18:44:52.597957 12093 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0605 18:44:52.598003 12093 net.cpp:150] Setting up data_input-data_0_split
I0605 18:44:52.598019 12093 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0605 18:44:52.598021 12093 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0605 18:44:52.598023 12093 net.cpp:165] Memory required for data: 21600040
I0605 18:44:52.598026 12093 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0605 18:44:52.598031 12093 net.cpp:106] Creating Layer im_info_input-data_1_split
I0605 18:44:52.598034 12093 net.cpp:454] im_info_input-data_1_split <- im_info
I0605 18:44:52.598039 12093 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0605 18:44:52.598045 12093 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0605 18:44:52.598052 12093 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0605 18:44:52.598088 12093 net.cpp:150] Setting up im_info_input-data_1_split
I0605 18:44:52.598091 12093 net.cpp:157] Top shape: 1 3 (3)
I0605 18:44:52.598095 12093 net.cpp:157] Top shape: 1 3 (3)
I0605 18:44:52.598109 12093 net.cpp:157] Top shape: 1 3 (3)
I0605 18:44:52.598110 12093 net.cpp:165] Memory required for data: 21600076
I0605 18:44:52.598112 12093 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0605 18:44:52.598127 12093 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0605 18:44:52.598130 12093 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0605 18:44:52.598134 12093 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0605 18:44:52.598137 12093 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0605 18:44:52.598162 12093 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0605 18:44:52.598167 12093 net.cpp:157] Top shape: 1 4 (4)
I0605 18:44:52.598170 12093 net.cpp:157] Top shape: 1 4 (4)
I0605 18:44:52.598173 12093 net.cpp:165] Memory required for data: 21600108
I0605 18:44:52.598176 12093 layer_factory.hpp:77] Creating layer conv1_1
I0605 18:44:52.598183 12093 net.cpp:106] Creating Layer conv1_1
I0605 18:44:52.598186 12093 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0605 18:44:52.598191 12093 net.cpp:411] conv1_1 -> conv1_1
I0605 18:44:52.758810 12093 net.cpp:150] Setting up conv1_1
I0605 18:44:52.758831 12093 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0605 18:44:52.758833 12093 net.cpp:165] Memory required for data: 175200108
I0605 18:44:52.758846 12093 layer_factory.hpp:77] Creating layer relu1_1
I0605 18:44:52.758864 12093 net.cpp:106] Creating Layer relu1_1
I0605 18:44:52.758868 12093 net.cpp:454] relu1_1 <- conv1_1
I0605 18:44:52.758872 12093 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0605 18:44:52.759006 12093 net.cpp:150] Setting up relu1_1
I0605 18:44:52.759011 12093 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0605 18:44:52.759014 12093 net.cpp:165] Memory required for data: 328800108
I0605 18:44:52.759016 12093 layer_factory.hpp:77] Creating layer conv1_2
I0605 18:44:52.759023 12093 net.cpp:106] Creating Layer conv1_2
I0605 18:44:52.759025 12093 net.cpp:454] conv1_2 <- conv1_1
I0605 18:44:52.759029 12093 net.cpp:411] conv1_2 -> conv1_2
I0605 18:44:52.761168 12093 net.cpp:150] Setting up conv1_2
I0605 18:44:52.761193 12093 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0605 18:44:52.761194 12093 net.cpp:165] Memory required for data: 482400108
I0605 18:44:52.761204 12093 layer_factory.hpp:77] Creating layer relu1_2
I0605 18:44:52.761209 12093 net.cpp:106] Creating Layer relu1_2
I0605 18:44:52.761212 12093 net.cpp:454] relu1_2 <- conv1_2
I0605 18:44:52.761226 12093 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0605 18:44:52.761341 12093 net.cpp:150] Setting up relu1_2
I0605 18:44:52.761348 12093 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0605 18:44:52.761359 12093 net.cpp:165] Memory required for data: 636000108
I0605 18:44:52.761363 12093 layer_factory.hpp:77] Creating layer pool1
I0605 18:44:52.761368 12093 net.cpp:106] Creating Layer pool1
I0605 18:44:52.761371 12093 net.cpp:454] pool1 <- conv1_2
I0605 18:44:52.761374 12093 net.cpp:411] pool1 -> pool1
I0605 18:44:52.761409 12093 net.cpp:150] Setting up pool1
I0605 18:44:52.761425 12093 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0605 18:44:52.761428 12093 net.cpp:165] Memory required for data: 674400108
I0605 18:44:52.761430 12093 layer_factory.hpp:77] Creating layer conv2_1
I0605 18:44:52.761436 12093 net.cpp:106] Creating Layer conv2_1
I0605 18:44:52.761440 12093 net.cpp:454] conv2_1 <- pool1
I0605 18:44:52.761451 12093 net.cpp:411] conv2_1 -> conv2_1
I0605 18:44:52.763252 12093 net.cpp:150] Setting up conv2_1
I0605 18:44:52.763262 12093 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0605 18:44:52.763265 12093 net.cpp:165] Memory required for data: 751200108
I0605 18:44:52.763273 12093 layer_factory.hpp:77] Creating layer relu2_1
I0605 18:44:52.763278 12093 net.cpp:106] Creating Layer relu2_1
I0605 18:44:52.763279 12093 net.cpp:454] relu2_1 <- conv2_1
I0605 18:44:52.763293 12093 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0605 18:44:52.763926 12093 net.cpp:150] Setting up relu2_1
I0605 18:44:52.763934 12093 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0605 18:44:52.763947 12093 net.cpp:165] Memory required for data: 828000108
I0605 18:44:52.763950 12093 layer_factory.hpp:77] Creating layer conv2_2
I0605 18:44:52.763957 12093 net.cpp:106] Creating Layer conv2_2
I0605 18:44:52.763969 12093 net.cpp:454] conv2_2 <- conv2_1
I0605 18:44:52.763973 12093 net.cpp:411] conv2_2 -> conv2_2
I0605 18:44:52.765360 12093 net.cpp:150] Setting up conv2_2
I0605 18:44:52.765370 12093 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0605 18:44:52.765374 12093 net.cpp:165] Memory required for data: 904800108
I0605 18:44:52.765383 12093 layer_factory.hpp:77] Creating layer relu2_2
I0605 18:44:52.765389 12093 net.cpp:106] Creating Layer relu2_2
I0605 18:44:52.765404 12093 net.cpp:454] relu2_2 <- conv2_2
I0605 18:44:52.765444 12093 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0605 18:44:52.765595 12093 net.cpp:150] Setting up relu2_2
I0605 18:44:52.765602 12093 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0605 18:44:52.765605 12093 net.cpp:165] Memory required for data: 981600108
I0605 18:44:52.765609 12093 layer_factory.hpp:77] Creating layer pool2
I0605 18:44:52.765617 12093 net.cpp:106] Creating Layer pool2
I0605 18:44:52.765621 12093 net.cpp:454] pool2 <- conv2_2
I0605 18:44:52.765637 12093 net.cpp:411] pool2 -> pool2
I0605 18:44:52.765676 12093 net.cpp:150] Setting up pool2
I0605 18:44:52.765681 12093 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0605 18:44:52.765684 12093 net.cpp:165] Memory required for data: 1000800108
I0605 18:44:52.765697 12093 layer_factory.hpp:77] Creating layer conv3_1
I0605 18:44:52.765707 12093 net.cpp:106] Creating Layer conv3_1
I0605 18:44:52.765719 12093 net.cpp:454] conv3_1 <- pool2
I0605 18:44:52.765724 12093 net.cpp:411] conv3_1 -> conv3_1
I0605 18:44:52.767519 12093 net.cpp:150] Setting up conv3_1
I0605 18:44:52.767529 12093 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 18:44:52.767534 12093 net.cpp:165] Memory required for data: 1039200108
I0605 18:44:52.767544 12093 layer_factory.hpp:77] Creating layer relu3_1
I0605 18:44:52.767551 12093 net.cpp:106] Creating Layer relu3_1
I0605 18:44:52.767555 12093 net.cpp:454] relu3_1 <- conv3_1
I0605 18:44:52.767560 12093 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0605 18:44:52.767670 12093 net.cpp:150] Setting up relu3_1
I0605 18:44:52.767678 12093 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 18:44:52.767681 12093 net.cpp:165] Memory required for data: 1077600108
I0605 18:44:52.767684 12093 layer_factory.hpp:77] Creating layer conv3_2
I0605 18:44:52.767695 12093 net.cpp:106] Creating Layer conv3_2
I0605 18:44:52.767699 12093 net.cpp:454] conv3_2 <- conv3_1
I0605 18:44:52.767705 12093 net.cpp:411] conv3_2 -> conv3_2
I0605 18:44:52.769662 12093 net.cpp:150] Setting up conv3_2
I0605 18:44:52.769672 12093 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 18:44:52.769676 12093 net.cpp:165] Memory required for data: 1116000108
I0605 18:44:52.769693 12093 layer_factory.hpp:77] Creating layer relu3_2
I0605 18:44:52.769701 12093 net.cpp:106] Creating Layer relu3_2
I0605 18:44:52.769706 12093 net.cpp:454] relu3_2 <- conv3_2
I0605 18:44:52.769711 12093 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0605 18:44:52.769820 12093 net.cpp:150] Setting up relu3_2
I0605 18:44:52.769827 12093 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 18:44:52.769831 12093 net.cpp:165] Memory required for data: 1154400108
I0605 18:44:52.769835 12093 layer_factory.hpp:77] Creating layer conv3_3
I0605 18:44:52.769843 12093 net.cpp:106] Creating Layer conv3_3
I0605 18:44:52.769848 12093 net.cpp:454] conv3_3 <- conv3_2
I0605 18:44:52.769853 12093 net.cpp:411] conv3_3 -> conv3_3
I0605 18:44:52.771978 12093 net.cpp:150] Setting up conv3_3
I0605 18:44:52.771991 12093 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 18:44:52.771994 12093 net.cpp:165] Memory required for data: 1192800108
I0605 18:44:52.772011 12093 layer_factory.hpp:77] Creating layer relu3_3
I0605 18:44:52.772019 12093 net.cpp:106] Creating Layer relu3_3
I0605 18:44:52.772027 12093 net.cpp:454] relu3_3 <- conv3_3
I0605 18:44:52.772032 12093 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0605 18:44:52.772145 12093 net.cpp:150] Setting up relu3_3
I0605 18:44:52.772152 12093 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 18:44:52.772156 12093 net.cpp:165] Memory required for data: 1231200108
I0605 18:44:52.772168 12093 layer_factory.hpp:77] Creating layer pool3
I0605 18:44:52.772176 12093 net.cpp:106] Creating Layer pool3
I0605 18:44:52.772182 12093 net.cpp:454] pool3 <- conv3_3
I0605 18:44:52.772188 12093 net.cpp:411] pool3 -> pool3
I0605 18:44:52.772220 12093 net.cpp:150] Setting up pool3
I0605 18:44:52.772226 12093 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0605 18:44:52.772229 12093 net.cpp:165] Memory required for data: 1240800108
I0605 18:44:52.772233 12093 layer_factory.hpp:77] Creating layer conv4_1
I0605 18:44:52.772243 12093 net.cpp:106] Creating Layer conv4_1
I0605 18:44:52.772248 12093 net.cpp:454] conv4_1 <- pool3
I0605 18:44:52.772253 12093 net.cpp:411] conv4_1 -> conv4_1
I0605 18:44:52.776085 12093 net.cpp:150] Setting up conv4_1
I0605 18:44:52.776105 12093 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 18:44:52.776109 12093 net.cpp:165] Memory required for data: 1260000108
I0605 18:44:52.776119 12093 layer_factory.hpp:77] Creating layer relu4_1
I0605 18:44:52.776129 12093 net.cpp:106] Creating Layer relu4_1
I0605 18:44:52.776136 12093 net.cpp:454] relu4_1 <- conv4_1
I0605 18:44:52.776144 12093 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0605 18:44:52.776255 12093 net.cpp:150] Setting up relu4_1
I0605 18:44:52.776262 12093 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 18:44:52.776265 12093 net.cpp:165] Memory required for data: 1279200108
I0605 18:44:52.776269 12093 layer_factory.hpp:77] Creating layer conv4_2
I0605 18:44:52.776279 12093 net.cpp:106] Creating Layer conv4_2
I0605 18:44:52.776284 12093 net.cpp:454] conv4_2 <- conv4_1
I0605 18:44:52.776289 12093 net.cpp:411] conv4_2 -> conv4_2
I0605 18:44:52.781133 12093 net.cpp:150] Setting up conv4_2
I0605 18:44:52.781164 12093 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 18:44:52.781167 12093 net.cpp:165] Memory required for data: 1298400108
I0605 18:44:52.781183 12093 layer_factory.hpp:77] Creating layer relu4_2
I0605 18:44:52.781204 12093 net.cpp:106] Creating Layer relu4_2
I0605 18:44:52.781211 12093 net.cpp:454] relu4_2 <- conv4_2
I0605 18:44:52.781217 12093 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0605 18:44:52.781795 12093 net.cpp:150] Setting up relu4_2
I0605 18:44:52.781814 12093 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 18:44:52.781818 12093 net.cpp:165] Memory required for data: 1317600108
I0605 18:44:52.781822 12093 layer_factory.hpp:77] Creating layer conv4_3
I0605 18:44:52.781842 12093 net.cpp:106] Creating Layer conv4_3
I0605 18:44:52.781847 12093 net.cpp:454] conv4_3 <- conv4_2
I0605 18:44:52.781852 12093 net.cpp:411] conv4_3 -> conv4_3
I0605 18:44:52.786281 12093 net.cpp:150] Setting up conv4_3
I0605 18:44:52.786306 12093 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 18:44:52.786310 12093 net.cpp:165] Memory required for data: 1336800108
I0605 18:44:52.786331 12093 layer_factory.hpp:77] Creating layer relu4_3
I0605 18:44:52.786351 12093 net.cpp:106] Creating Layer relu4_3
I0605 18:44:52.786357 12093 net.cpp:454] relu4_3 <- conv4_3
I0605 18:44:52.786370 12093 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0605 18:44:52.786497 12093 net.cpp:150] Setting up relu4_3
I0605 18:44:52.786505 12093 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 18:44:52.786509 12093 net.cpp:165] Memory required for data: 1356000108
I0605 18:44:52.786512 12093 layer_factory.hpp:77] Creating layer pool4
I0605 18:44:52.786531 12093 net.cpp:106] Creating Layer pool4
I0605 18:44:52.786535 12093 net.cpp:454] pool4 <- conv4_3
I0605 18:44:52.786541 12093 net.cpp:411] pool4 -> pool4
I0605 18:44:52.786579 12093 net.cpp:150] Setting up pool4
I0605 18:44:52.786586 12093 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:44:52.786597 12093 net.cpp:165] Memory required for data: 1360903020
I0605 18:44:52.786602 12093 layer_factory.hpp:77] Creating layer conv5_1
I0605 18:44:52.786623 12093 net.cpp:106] Creating Layer conv5_1
I0605 18:44:52.786628 12093 net.cpp:454] conv5_1 <- pool4
I0605 18:44:52.786633 12093 net.cpp:411] conv5_1 -> conv5_1
I0605 18:44:52.790962 12093 net.cpp:150] Setting up conv5_1
I0605 18:44:52.790982 12093 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:44:52.790984 12093 net.cpp:165] Memory required for data: 1365805932
I0605 18:44:52.790994 12093 layer_factory.hpp:77] Creating layer relu5_1
I0605 18:44:52.791002 12093 net.cpp:106] Creating Layer relu5_1
I0605 18:44:52.791009 12093 net.cpp:454] relu5_1 <- conv5_1
I0605 18:44:52.791016 12093 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0605 18:44:52.791136 12093 net.cpp:150] Setting up relu5_1
I0605 18:44:52.791143 12093 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:44:52.791147 12093 net.cpp:165] Memory required for data: 1370708844
I0605 18:44:52.791152 12093 layer_factory.hpp:77] Creating layer conv5_2
I0605 18:44:52.791160 12093 net.cpp:106] Creating Layer conv5_2
I0605 18:44:52.791165 12093 net.cpp:454] conv5_2 <- conv5_1
I0605 18:44:52.791172 12093 net.cpp:411] conv5_2 -> conv5_2
I0605 18:44:52.795554 12093 net.cpp:150] Setting up conv5_2
I0605 18:44:52.795573 12093 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:44:52.795578 12093 net.cpp:165] Memory required for data: 1375611756
I0605 18:44:52.795585 12093 layer_factory.hpp:77] Creating layer relu5_2
I0605 18:44:52.795594 12093 net.cpp:106] Creating Layer relu5_2
I0605 18:44:52.795612 12093 net.cpp:454] relu5_2 <- conv5_2
I0605 18:44:52.795627 12093 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0605 18:44:52.795750 12093 net.cpp:150] Setting up relu5_2
I0605 18:44:52.795758 12093 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:44:52.795761 12093 net.cpp:165] Memory required for data: 1380514668
I0605 18:44:52.795765 12093 layer_factory.hpp:77] Creating layer conv5_3
I0605 18:44:52.795778 12093 net.cpp:106] Creating Layer conv5_3
I0605 18:44:52.795781 12093 net.cpp:454] conv5_3 <- conv5_2
I0605 18:44:52.795787 12093 net.cpp:411] conv5_3 -> conv5_3
I0605 18:44:52.800705 12093 net.cpp:150] Setting up conv5_3
I0605 18:44:52.800726 12093 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:44:52.800730 12093 net.cpp:165] Memory required for data: 1385417580
I0605 18:44:52.800741 12093 layer_factory.hpp:77] Creating layer relu5_3
I0605 18:44:52.800762 12093 net.cpp:106] Creating Layer relu5_3
I0605 18:44:52.800770 12093 net.cpp:454] relu5_3 <- conv5_3
I0605 18:44:52.800776 12093 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0605 18:44:52.800906 12093 net.cpp:150] Setting up relu5_3
I0605 18:44:52.800915 12093 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:44:52.800918 12093 net.cpp:165] Memory required for data: 1390320492
I0605 18:44:52.800933 12093 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0605 18:44:52.800941 12093 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0605 18:44:52.800949 12093 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0605 18:44:52.800957 12093 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0605 18:44:52.800966 12093 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0605 18:44:52.800974 12093 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0605 18:44:52.801030 12093 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0605 18:44:52.801036 12093 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:44:52.801040 12093 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:44:52.801056 12093 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:44:52.801062 12093 net.cpp:165] Memory required for data: 1405029228
I0605 18:44:52.801065 12093 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0605 18:44:52.801077 12093 net.cpp:106] Creating Layer rpn_conv/3x3
I0605 18:44:52.801082 12093 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0605 18:44:52.801089 12093 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0605 18:44:52.851871 12093 net.cpp:150] Setting up rpn_conv/3x3
I0605 18:44:52.851892 12093 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:44:52.851897 12093 net.cpp:165] Memory required for data: 1409932140
I0605 18:44:52.851907 12093 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0605 18:44:52.851917 12093 net.cpp:106] Creating Layer rpn_relu/3x3
I0605 18:44:52.851934 12093 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0605 18:44:52.851951 12093 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0605 18:44:52.852114 12093 net.cpp:150] Setting up rpn_relu/3x3
I0605 18:44:52.852123 12093 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:44:52.852125 12093 net.cpp:165] Memory required for data: 1414835052
I0605 18:44:52.852129 12093 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0605 18:44:52.852136 12093 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0605 18:44:52.852140 12093 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0605 18:44:52.852157 12093 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0605 18:44:52.852164 12093 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0605 18:44:52.852207 12093 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0605 18:44:52.852213 12093 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:44:52.852217 12093 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:44:52.852221 12093 net.cpp:165] Memory required for data: 1424640876
I0605 18:44:52.852224 12093 layer_factory.hpp:77] Creating layer rpn_cls_score
I0605 18:44:52.852236 12093 net.cpp:106] Creating Layer rpn_cls_score
I0605 18:44:52.852250 12093 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0605 18:44:52.852257 12093 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0605 18:44:52.853893 12093 net.cpp:150] Setting up rpn_cls_score
I0605 18:44:52.853902 12093 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0605 18:44:52.853906 12093 net.cpp:165] Memory required for data: 1424928156
I0605 18:44:52.853914 12093 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0605 18:44:52.853920 12093 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0605 18:44:52.853925 12093 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0605 18:44:52.853941 12093 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0605 18:44:52.853950 12093 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0605 18:44:52.853979 12093 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0605 18:44:52.853984 12093 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0605 18:44:52.853997 12093 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0605 18:44:52.854001 12093 net.cpp:165] Memory required for data: 1425502716
I0605 18:44:52.854014 12093 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0605 18:44:52.854024 12093 net.cpp:106] Creating Layer rpn_bbox_pred
I0605 18:44:52.854027 12093 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0605 18:44:52.854034 12093 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0605 18:44:52.855495 12093 net.cpp:150] Setting up rpn_bbox_pred
I0605 18:44:52.855504 12093 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 18:44:52.855509 12093 net.cpp:165] Memory required for data: 1426077276
I0605 18:44:52.855525 12093 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0605 18:44:52.855531 12093 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0605 18:44:52.855546 12093 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0605 18:44:52.855552 12093 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0605 18:44:52.855561 12093 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0605 18:44:52.855602 12093 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0605 18:44:52.855608 12093 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 18:44:52.855612 12093 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 18:44:52.855628 12093 net.cpp:165] Memory required for data: 1427226396
I0605 18:44:52.855630 12093 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0605 18:44:52.855664 12093 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0605 18:44:52.855667 12093 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0605 18:44:52.855682 12093 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0605 18:44:52.855705 12093 net.cpp:150] Setting up rpn_cls_score_reshape
I0605 18:44:52.855711 12093 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0605 18:44:52.855715 12093 net.cpp:165] Memory required for data: 1427513676
I0605 18:44:52.855717 12093 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0605 18:44:52.855732 12093 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0605 18:44:52.855736 12093 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0605 18:44:52.855741 12093 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0605 18:44:52.855748 12093 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0605 18:44:52.855773 12093 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0605 18:44:52.855777 12093 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0605 18:44:52.855782 12093 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0605 18:44:52.855785 12093 net.cpp:165] Memory required for data: 1428088236
I0605 18:44:52.855790 12093 layer_factory.hpp:77] Creating layer rpn-data
I0605 18:44:52.856114 12093 net.cpp:106] Creating Layer rpn-data
I0605 18:44:52.856122 12093 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0605 18:44:52.856127 12093 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0605 18:44:52.856132 12093 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0605 18:44:52.856137 12093 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0605 18:44:52.856144 12093 net.cpp:411] rpn-data -> rpn_labels
I0605 18:44:52.856153 12093 net.cpp:411] rpn-data -> rpn_bbox_targets
I0605 18:44:52.856160 12093 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0605 18:44:52.856168 12093 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0605 18:44:52.856997 12093 net.cpp:150] Setting up rpn-data
I0605 18:44:52.857007 12093 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0605 18:44:52.857012 12093 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 18:44:52.857015 12093 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 18:44:52.857023 12093 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 18:44:52.857038 12093 net.cpp:165] Memory required for data: 1429955556
I0605 18:44:52.857044 12093 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0605 18:44:52.857062 12093 net.cpp:106] Creating Layer rpn_loss_cls
I0605 18:44:52.857076 12093 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0605 18:44:52.857081 12093 net.cpp:454] rpn_loss_cls <- rpn_labels
I0605 18:44:52.857087 12093 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0605 18:44:52.857102 12093 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0605 18:44:52.857717 12093 net.cpp:150] Setting up rpn_loss_cls
I0605 18:44:52.857726 12093 net.cpp:157] Top shape: (1)
I0605 18:44:52.857730 12093 net.cpp:160]     with loss weight 1
I0605 18:44:52.857740 12093 net.cpp:165] Memory required for data: 1429955560
I0605 18:44:52.857744 12093 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0605 18:44:52.857751 12093 net.cpp:106] Creating Layer rpn_loss_bbox
I0605 18:44:52.857756 12093 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0605 18:44:52.857761 12093 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0605 18:44:52.857766 12093 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0605 18:44:52.857770 12093 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0605 18:44:52.857776 12093 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0605 18:44:52.858845 12093 net.cpp:150] Setting up rpn_loss_bbox
I0605 18:44:52.858853 12093 net.cpp:157] Top shape: (1)
I0605 18:44:52.858857 12093 net.cpp:160]     with loss weight 1
I0605 18:44:52.858863 12093 net.cpp:165] Memory required for data: 1429955564
I0605 18:44:52.858867 12093 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0605 18:44:52.858873 12093 net.cpp:106] Creating Layer rpn_cls_prob
I0605 18:44:52.858878 12093 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0605 18:44:52.858884 12093 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0605 18:44:52.859026 12093 net.cpp:150] Setting up rpn_cls_prob
I0605 18:44:52.859035 12093 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0605 18:44:52.859037 12093 net.cpp:165] Memory required for data: 1430242844
I0605 18:44:52.859041 12093 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0605 18:44:52.859048 12093 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0605 18:44:52.859053 12093 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0605 18:44:52.859059 12093 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0605 18:44:52.859081 12093 net.cpp:150] Setting up rpn_cls_prob_reshape
I0605 18:44:52.859086 12093 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0605 18:44:52.859088 12093 net.cpp:165] Memory required for data: 1430530124
I0605 18:44:52.859092 12093 layer_factory.hpp:77] Creating layer proposal
I0605 18:44:52.859524 12093 net.cpp:106] Creating Layer proposal
I0605 18:44:52.859531 12093 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0605 18:44:52.859537 12093 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0605 18:44:52.859541 12093 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0605 18:44:52.859547 12093 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0605 18:44:52.860306 12093 net.cpp:150] Setting up proposal
I0605 18:44:52.860316 12093 net.cpp:157] Top shape: 1 5 (5)
I0605 18:44:52.860329 12093 net.cpp:165] Memory required for data: 1430530144
I0605 18:44:52.860333 12093 layer_factory.hpp:77] Creating layer roi-data
I0605 18:44:52.860548 12093 net.cpp:106] Creating Layer roi-data
I0605 18:44:52.860555 12093 net.cpp:454] roi-data <- rpn_rois
I0605 18:44:52.860560 12093 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0605 18:44:52.860574 12093 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0605 18:44:52.860579 12093 net.cpp:454] roi-data <- seg_mask_inds
I0605 18:44:52.860594 12093 net.cpp:454] roi-data <- flipped
I0605 18:44:52.860600 12093 net.cpp:411] roi-data -> rois
I0605 18:44:52.860610 12093 net.cpp:411] roi-data -> labels
I0605 18:44:52.860617 12093 net.cpp:411] roi-data -> bbox_targets
I0605 18:44:52.860625 12093 net.cpp:411] roi-data -> bbox_inside_weights
I0605 18:44:52.860631 12093 net.cpp:411] roi-data -> bbox_outside_weights
I0605 18:44:52.860639 12093 net.cpp:411] roi-data -> mask_targets
I0605 18:44:52.860646 12093 net.cpp:411] roi-data -> rois_pos
I0605 18:44:52.860908 12093 net.cpp:150] Setting up roi-data
I0605 18:44:52.860916 12093 net.cpp:157] Top shape: 1 5 (5)
I0605 18:44:52.860921 12093 net.cpp:157] Top shape: 1 1 (1)
I0605 18:44:52.860925 12093 net.cpp:157] Top shape: 1 8 (8)
I0605 18:44:52.860941 12093 net.cpp:157] Top shape: 1 8 (8)
I0605 18:44:52.860945 12093 net.cpp:157] Top shape: 1 8 (8)
I0605 18:44:52.860950 12093 net.cpp:157] Top shape: 1 244 244 (59536)
I0605 18:44:52.860954 12093 net.cpp:157] Top shape: 1 5 (5)
I0605 18:44:52.860958 12093 net.cpp:165] Memory required for data: 1430768428
I0605 18:44:52.860962 12093 layer_factory.hpp:77] Creating layer roi_pool5
I0605 18:44:52.860978 12093 net.cpp:106] Creating Layer roi_pool5
I0605 18:44:52.860982 12093 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0605 18:44:52.860987 12093 net.cpp:454] roi_pool5 <- rois
I0605 18:44:52.861003 12093 net.cpp:411] roi_pool5 -> pool5
I0605 18:44:52.861021 12093 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0605 18:44:52.861116 12093 net.cpp:150] Setting up roi_pool5
I0605 18:44:52.861122 12093 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 18:44:52.861125 12093 net.cpp:165] Memory required for data: 1430868780
I0605 18:44:52.861140 12093 layer_factory.hpp:77] Creating layer fc6
I0605 18:44:52.861147 12093 net.cpp:106] Creating Layer fc6
I0605 18:44:52.861151 12093 net.cpp:454] fc6 <- pool5
I0605 18:44:52.861157 12093 net.cpp:411] fc6 -> fc6
I0605 18:44:53.000999 12093 net.cpp:150] Setting up fc6
I0605 18:44:53.001029 12093 net.cpp:157] Top shape: 1 4096 (4096)
I0605 18:44:53.001032 12093 net.cpp:165] Memory required for data: 1430885164
I0605 18:44:53.001050 12093 layer_factory.hpp:77] Creating layer relu6
I0605 18:44:53.001073 12093 net.cpp:106] Creating Layer relu6
I0605 18:44:53.001094 12093 net.cpp:454] relu6 <- fc6
I0605 18:44:53.001113 12093 net.cpp:397] relu6 -> fc6 (in-place)
I0605 18:44:53.001309 12093 net.cpp:150] Setting up relu6
I0605 18:44:53.001318 12093 net.cpp:157] Top shape: 1 4096 (4096)
I0605 18:44:53.001322 12093 net.cpp:165] Memory required for data: 1430901548
I0605 18:44:53.001327 12093 layer_factory.hpp:77] Creating layer fc7
I0605 18:44:53.001333 12093 net.cpp:106] Creating Layer fc7
I0605 18:44:53.001339 12093 net.cpp:454] fc7 <- fc6
I0605 18:44:53.001356 12093 net.cpp:411] fc7 -> fc7
I0605 18:44:53.025249 12093 net.cpp:150] Setting up fc7
I0605 18:44:53.025274 12093 net.cpp:157] Top shape: 1 4096 (4096)
I0605 18:44:53.025279 12093 net.cpp:165] Memory required for data: 1430917932
I0605 18:44:53.025301 12093 layer_factory.hpp:77] Creating layer relu7
I0605 18:44:53.025315 12093 net.cpp:106] Creating Layer relu7
I0605 18:44:53.025321 12093 net.cpp:454] relu7 <- fc7
I0605 18:44:53.025329 12093 net.cpp:397] relu7 -> fc7 (in-place)
I0605 18:44:53.025537 12093 net.cpp:150] Setting up relu7
I0605 18:44:53.025547 12093 net.cpp:157] Top shape: 1 4096 (4096)
I0605 18:44:53.025550 12093 net.cpp:165] Memory required for data: 1430934316
I0605 18:44:53.025565 12093 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0605 18:44:53.025576 12093 net.cpp:106] Creating Layer fc7_relu7_0_split
I0605 18:44:53.025585 12093 net.cpp:454] fc7_relu7_0_split <- fc7
I0605 18:44:53.025596 12093 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0605 18:44:53.025609 12093 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0605 18:44:53.025655 12093 net.cpp:150] Setting up fc7_relu7_0_split
I0605 18:44:53.025662 12093 net.cpp:157] Top shape: 1 4096 (4096)
I0605 18:44:53.025667 12093 net.cpp:157] Top shape: 1 4096 (4096)
I0605 18:44:53.025671 12093 net.cpp:165] Memory required for data: 1430967084
I0605 18:44:53.025676 12093 layer_factory.hpp:77] Creating layer cls_score
I0605 18:44:53.025691 12093 net.cpp:106] Creating Layer cls_score
I0605 18:44:53.025696 12093 net.cpp:454] cls_score <- fc7_relu7_0_split_0
I0605 18:44:53.025702 12093 net.cpp:411] cls_score -> cls_score
I0605 18:44:53.025941 12093 net.cpp:150] Setting up cls_score
I0605 18:44:53.025950 12093 net.cpp:157] Top shape: 1 2 (2)
I0605 18:44:53.025957 12093 net.cpp:165] Memory required for data: 1430967092
I0605 18:44:53.025965 12093 layer_factory.hpp:77] Creating layer bbox_pred
I0605 18:44:53.025971 12093 net.cpp:106] Creating Layer bbox_pred
I0605 18:44:53.025977 12093 net.cpp:454] bbox_pred <- fc7_relu7_0_split_1
I0605 18:44:53.025985 12093 net.cpp:411] bbox_pred -> bbox_pred
I0605 18:44:53.026746 12093 net.cpp:150] Setting up bbox_pred
I0605 18:44:53.026751 12093 net.cpp:157] Top shape: 1 8 (8)
I0605 18:44:53.026754 12093 net.cpp:165] Memory required for data: 1430967124
I0605 18:44:53.026762 12093 layer_factory.hpp:77] Creating layer loss_cls
I0605 18:44:53.026772 12093 net.cpp:106] Creating Layer loss_cls
I0605 18:44:53.026778 12093 net.cpp:454] loss_cls <- cls_score
I0605 18:44:53.026784 12093 net.cpp:454] loss_cls <- labels
I0605 18:44:53.026793 12093 net.cpp:411] loss_cls -> loss_cls
I0605 18:44:53.026803 12093 layer_factory.hpp:77] Creating layer loss_cls
I0605 18:44:53.029237 12093 net.cpp:150] Setting up loss_cls
I0605 18:44:53.029248 12093 net.cpp:157] Top shape: (1)
I0605 18:44:53.029253 12093 net.cpp:160]     with loss weight 3
I0605 18:44:53.029265 12093 net.cpp:165] Memory required for data: 1430967128
I0605 18:44:53.029269 12093 layer_factory.hpp:77] Creating layer loss_bbox
I0605 18:44:53.029278 12093 net.cpp:106] Creating Layer loss_bbox
I0605 18:44:53.029284 12093 net.cpp:454] loss_bbox <- bbox_pred
I0605 18:44:53.029289 12093 net.cpp:454] loss_bbox <- bbox_targets
I0605 18:44:53.029294 12093 net.cpp:454] loss_bbox <- bbox_inside_weights
I0605 18:44:53.029299 12093 net.cpp:454] loss_bbox <- bbox_outside_weights
I0605 18:44:53.029304 12093 net.cpp:411] loss_bbox -> loss_bbox
I0605 18:44:53.029402 12093 net.cpp:150] Setting up loss_bbox
I0605 18:44:53.029407 12093 net.cpp:157] Top shape: (1)
I0605 18:44:53.029441 12093 net.cpp:160]     with loss weight 2
I0605 18:44:53.029458 12093 net.cpp:165] Memory required for data: 1430967132
I0605 18:44:53.029464 12093 layer_factory.hpp:77] Creating layer roi_pool5_2
I0605 18:44:53.029484 12093 net.cpp:106] Creating Layer roi_pool5_2
I0605 18:44:53.029489 12093 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0605 18:44:53.029495 12093 net.cpp:454] roi_pool5_2 <- rois_pos
I0605 18:44:53.029510 12093 net.cpp:411] roi_pool5_2 -> pool5_2
I0605 18:44:53.029530 12093 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0605 18:44:53.029624 12093 net.cpp:150] Setting up roi_pool5_2
I0605 18:44:53.029630 12093 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 18:44:53.029634 12093 net.cpp:165] Memory required for data: 1431067484
I0605 18:44:53.029639 12093 layer_factory.hpp:77] Creating layer pool5_2_conv
I0605 18:44:53.029650 12093 net.cpp:106] Creating Layer pool5_2_conv
I0605 18:44:53.029657 12093 net.cpp:454] pool5_2_conv <- pool5_2
I0605 18:44:53.029664 12093 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0605 18:44:53.036554 12093 net.cpp:150] Setting up pool5_2_conv
I0605 18:44:53.036566 12093 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 18:44:53.036569 12093 net.cpp:165] Memory required for data: 1431167836
I0605 18:44:53.036588 12093 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0605 18:44:53.036597 12093 net.cpp:106] Creating Layer pool5_2_conv_relu
I0605 18:44:53.036603 12093 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0605 18:44:53.036610 12093 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0605 18:44:53.036792 12093 net.cpp:150] Setting up pool5_2_conv_relu
I0605 18:44:53.036799 12093 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 18:44:53.036803 12093 net.cpp:165] Memory required for data: 1431268188
I0605 18:44:53.036815 12093 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0605 18:44:53.036833 12093 net.cpp:106] Creating Layer pool5_2_conv2
I0605 18:44:53.036836 12093 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0605 18:44:53.036842 12093 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0605 18:44:53.087218 12093 net.cpp:150] Setting up pool5_2_conv2
I0605 18:44:53.087240 12093 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 18:44:53.087244 12093 net.cpp:165] Memory required for data: 1431368540
I0605 18:44:53.087255 12093 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0605 18:44:53.087265 12093 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0605 18:44:53.087280 12093 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0605 18:44:53.087290 12093 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0605 18:44:53.087431 12093 net.cpp:150] Setting up pool5_2_conv2_relu
I0605 18:44:53.087440 12093 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 18:44:53.087443 12093 net.cpp:165] Memory required for data: 1431468892
I0605 18:44:53.087446 12093 layer_factory.hpp:77] Creating layer mask_deconv1
I0605 18:44:53.087456 12093 net.cpp:106] Creating Layer mask_deconv1
I0605 18:44:53.087461 12093 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0605 18:44:53.087482 12093 net.cpp:411] mask_deconv1 -> mask_deconv1
I0605 18:44:53.088286 12093 net.cpp:150] Setting up mask_deconv1
I0605 18:44:53.088294 12093 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0605 18:44:53.088296 12093 net.cpp:165] Memory required for data: 1432390492
I0605 18:44:53.088304 12093 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0605 18:44:53.088333 12093 net.cpp:106] Creating Layer pool5_2_conv3
I0605 18:44:53.088338 12093 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0605 18:44:53.088359 12093 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0605 18:44:53.114789 12093 net.cpp:150] Setting up pool5_2_conv3
I0605 18:44:53.114809 12093 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 18:44:53.114814 12093 net.cpp:165] Memory required for data: 1434233692
I0605 18:44:53.114823 12093 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0605 18:44:53.114833 12093 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0605 18:44:53.114850 12093 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0605 18:44:53.114857 12093 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0605 18:44:53.115011 12093 net.cpp:150] Setting up pool5_2_conv3_relu
I0605 18:44:53.115020 12093 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 18:44:53.115022 12093 net.cpp:165] Memory required for data: 1436076892
I0605 18:44:53.115036 12093 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0605 18:44:53.115061 12093 net.cpp:106] Creating Layer pool5_2_conv4
I0605 18:44:53.115069 12093 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0605 18:44:53.115078 12093 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0605 18:44:53.165922 12093 net.cpp:150] Setting up pool5_2_conv4
I0605 18:44:53.165944 12093 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 18:44:53.165947 12093 net.cpp:165] Memory required for data: 1437920092
I0605 18:44:53.165957 12093 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0605 18:44:53.165977 12093 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0605 18:44:53.165985 12093 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0605 18:44:53.166003 12093 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0605 18:44:53.166162 12093 net.cpp:150] Setting up pool5_2_conv4_relu
I0605 18:44:53.166170 12093 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 18:44:53.166174 12093 net.cpp:165] Memory required for data: 1439763292
I0605 18:44:53.166177 12093 layer_factory.hpp:77] Creating layer mask_deconv2
I0605 18:44:53.166188 12093 net.cpp:106] Creating Layer mask_deconv2
I0605 18:44:53.166193 12093 net.cpp:454] mask_deconv2 <- pool5_2_conv4_relu
I0605 18:44:53.166209 12093 net.cpp:411] mask_deconv2 -> mask_deconv2
I0605 18:44:53.166988 12093 net.cpp:150] Setting up mask_deconv2
I0605 18:44:53.166995 12093 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0605 18:44:53.166997 12093 net.cpp:165] Memory required for data: 1455004508
I0605 18:44:53.167004 12093 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0605 18:44:53.167016 12093 net.cpp:106] Creating Layer pool5_2_conv5
I0605 18:44:53.167030 12093 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0605 18:44:53.167045 12093 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0605 18:44:53.193718 12093 net.cpp:150] Setting up pool5_2_conv5
I0605 18:44:53.193738 12093 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:44:53.193742 12093 net.cpp:165] Memory required for data: 1485486940
I0605 18:44:53.193761 12093 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0605 18:44:53.193770 12093 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0605 18:44:53.193778 12093 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0605 18:44:53.193795 12093 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0605 18:44:53.193960 12093 net.cpp:150] Setting up pool5_2_conv5_relu
I0605 18:44:53.193969 12093 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:44:53.193972 12093 net.cpp:165] Memory required for data: 1515969372
I0605 18:44:53.193975 12093 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0605 18:44:53.194001 12093 net.cpp:106] Creating Layer pool5_2_conv6
I0605 18:44:53.194006 12093 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0605 18:44:53.194021 12093 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0605 18:44:53.247329 12093 net.cpp:150] Setting up pool5_2_conv6
I0605 18:44:53.247359 12093 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:44:53.247364 12093 net.cpp:165] Memory required for data: 1546451804
I0605 18:44:53.247381 12093 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0605 18:44:53.247403 12093 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0605 18:44:53.247411 12093 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0605 18:44:53.247418 12093 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0605 18:44:53.248042 12093 net.cpp:150] Setting up pool5_2_conv6_relu
I0605 18:44:53.248054 12093 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:44:53.248059 12093 net.cpp:165] Memory required for data: 1576934236
I0605 18:44:53.248072 12093 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu_pool5_2_conv6_relu_0_split
I0605 18:44:53.248095 12093 net.cpp:106] Creating Layer pool5_2_conv6_relu_pool5_2_conv6_relu_0_split
I0605 18:44:53.248100 12093 net.cpp:454] pool5_2_conv6_relu_pool5_2_conv6_relu_0_split <- pool5_2_conv6_relu
I0605 18:44:53.248116 12093 net.cpp:411] pool5_2_conv6_relu_pool5_2_conv6_relu_0_split -> pool5_2_conv6_relu_pool5_2_conv6_relu_0_split_0
I0605 18:44:53.248134 12093 net.cpp:411] pool5_2_conv6_relu_pool5_2_conv6_relu_0_split -> pool5_2_conv6_relu_pool5_2_conv6_relu_0_split_1
I0605 18:44:53.248155 12093 net.cpp:411] pool5_2_conv6_relu_pool5_2_conv6_relu_0_split -> pool5_2_conv6_relu_pool5_2_conv6_relu_0_split_2
I0605 18:44:53.248162 12093 net.cpp:411] pool5_2_conv6_relu_pool5_2_conv6_relu_0_split -> pool5_2_conv6_relu_pool5_2_conv6_relu_0_split_3
I0605 18:44:53.248239 12093 net.cpp:150] Setting up pool5_2_conv6_relu_pool5_2_conv6_relu_0_split
I0605 18:44:53.248255 12093 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:44:53.248258 12093 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:44:53.248272 12093 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:44:53.248277 12093 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:44:53.248291 12093 net.cpp:165] Memory required for data: 1698863964
I0605 18:44:53.248296 12093 layer_factory.hpp:77] Creating layer query_conv
I0605 18:44:53.248309 12093 net.cpp:106] Creating Layer query_conv
I0605 18:44:53.248315 12093 net.cpp:454] query_conv <- pool5_2_conv6_relu_pool5_2_conv6_relu_0_split_0
I0605 18:44:53.248332 12093 net.cpp:411] query_conv -> query_conv
I0605 18:44:53.250035 12093 net.cpp:150] Setting up query_conv
I0605 18:44:53.250044 12093 net.cpp:157] Top shape: 1 64 122 122 (952576)
I0605 18:44:53.250049 12093 net.cpp:165] Memory required for data: 1702674268
I0605 18:44:53.250067 12093 layer_factory.hpp:77] Creating layer key_conv
I0605 18:44:53.250080 12093 net.cpp:106] Creating Layer key_conv
I0605 18:44:53.250085 12093 net.cpp:454] key_conv <- pool5_2_conv6_relu_pool5_2_conv6_relu_0_split_1
I0605 18:44:53.250093 12093 net.cpp:411] key_conv -> key_conv
I0605 18:44:53.251276 12093 net.cpp:150] Setting up key_conv
I0605 18:44:53.251284 12093 net.cpp:157] Top shape: 1 64 122 122 (952576)
I0605 18:44:53.251287 12093 net.cpp:165] Memory required for data: 1706484572
I0605 18:44:53.251307 12093 layer_factory.hpp:77] Creating layer value_conv
I0605 18:44:53.251319 12093 net.cpp:106] Creating Layer value_conv
I0605 18:44:53.251324 12093 net.cpp:454] value_conv <- pool5_2_conv6_relu_pool5_2_conv6_relu_0_split_2
I0605 18:44:53.251335 12093 net.cpp:411] value_conv -> value_conv
I0605 18:44:53.258412 12093 net.cpp:150] Setting up value_conv
I0605 18:44:53.258424 12093 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:44:53.258428 12093 net.cpp:165] Memory required for data: 1736967004
I0605 18:44:53.258435 12093 layer_factory.hpp:77] Creating layer query_conv_reshape
I0605 18:44:53.258445 12093 net.cpp:106] Creating Layer query_conv_reshape
I0605 18:44:53.258466 12093 net.cpp:454] query_conv_reshape <- query_conv
I0605 18:44:53.258483 12093 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0605 18:44:53.258529 12093 net.cpp:150] Setting up query_conv_reshape
I0605 18:44:53.258536 12093 net.cpp:157] Top shape: 1 64 14884 1 (952576)
I0605 18:44:53.258539 12093 net.cpp:165] Memory required for data: 1740777308
I0605 18:44:53.258555 12093 layer_factory.hpp:77] Creating layer key_conv_reshape
I0605 18:44:53.258577 12093 net.cpp:106] Creating Layer key_conv_reshape
I0605 18:44:53.258584 12093 net.cpp:454] key_conv_reshape <- key_conv
I0605 18:44:53.258599 12093 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0605 18:44:53.258638 12093 net.cpp:150] Setting up key_conv_reshape
I0605 18:44:53.258652 12093 net.cpp:157] Top shape: 1 64 14884 1 (952576)
I0605 18:44:53.258656 12093 net.cpp:165] Memory required for data: 1744587612
I0605 18:44:53.258669 12093 layer_factory.hpp:77] Creating layer value_conv_reshape
I0605 18:44:53.258674 12093 net.cpp:106] Creating Layer value_conv_reshape
I0605 18:44:53.258680 12093 net.cpp:454] value_conv_reshape <- value_conv
I0605 18:44:53.258689 12093 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0605 18:44:53.258713 12093 net.cpp:150] Setting up value_conv_reshape
I0605 18:44:53.258718 12093 net.cpp:157] Top shape: 1 512 14884 1 (7620608)
I0605 18:44:53.258721 12093 net.cpp:165] Memory required for data: 1775070044
I0605 18:44:53.258725 12093 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0605 18:44:53.258733 12093 net.cpp:106] Creating Layer query_conv_reshape_perm
I0605 18:44:53.258738 12093 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0605 18:44:53.258744 12093 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0605 18:44:53.258833 12093 net.cpp:150] Setting up query_conv_reshape_perm
I0605 18:44:53.258838 12093 net.cpp:157] Top shape: 1 1 14884 64 (952576)
I0605 18:44:53.258841 12093 net.cpp:165] Memory required for data: 1778880348
I0605 18:44:53.258855 12093 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0605 18:44:53.258867 12093 net.cpp:106] Creating Layer key_conv_reshape_perm
I0605 18:44:53.258872 12093 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0605 18:44:53.258888 12093 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0605 18:44:53.258955 12093 net.cpp:150] Setting up key_conv_reshape_perm
I0605 18:44:53.258961 12093 net.cpp:157] Top shape: 1 1 64 14884 (952576)
I0605 18:44:53.258965 12093 net.cpp:165] Memory required for data: 1782690652
I0605 18:44:53.258967 12093 layer_factory.hpp:77] Creating layer energy
I0605 18:44:53.258975 12093 net.cpp:106] Creating Layer energy
I0605 18:44:53.258991 12093 net.cpp:454] energy <- query_conv_reshape_perm
I0605 18:44:53.258996 12093 net.cpp:454] energy <- key_conv_reshape_perm
I0605 18:44:53.259003 12093 net.cpp:411] energy -> energy
I0605 18:44:53.259032 12093 net.cpp:150] Setting up energy
I0605 18:44:53.259037 12093 net.cpp:157] Top shape: 1 1 14884 14884 (221533456)
I0605 18:44:53.259042 12093 net.cpp:165] Memory required for data: 2668824476
I0605 18:44:53.259044 12093 layer_factory.hpp:77] Creating layer attention
I0605 18:44:53.259053 12093 net.cpp:106] Creating Layer attention
I0605 18:44:53.259057 12093 net.cpp:454] attention <- energy
I0605 18:44:53.259063 12093 net.cpp:411] attention -> attention
I0605 18:44:53.259657 12093 net.cpp:150] Setting up attention
I0605 18:44:53.259667 12093 net.cpp:157] Top shape: 1 1 14884 14884 (221533456)
I0605 18:44:53.259670 12093 net.cpp:165] Memory required for data: 3554958300
I0605 18:44:53.259685 12093 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0605 18:44:53.259691 12093 net.cpp:106] Creating Layer value_conv_reshape_perm
I0605 18:44:53.259696 12093 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0605 18:44:53.259704 12093 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0605 18:44:53.259786 12093 net.cpp:150] Setting up value_conv_reshape_perm
I0605 18:44:53.259791 12093 net.cpp:157] Top shape: 1 1 512 14884 (7620608)
I0605 18:44:53.259794 12093 net.cpp:165] Memory required for data: 3585440732
I0605 18:44:53.259807 12093 layer_factory.hpp:77] Creating layer attention_perm
I0605 18:44:53.259819 12093 net.cpp:106] Creating Layer attention_perm
I0605 18:44:53.259825 12093 net.cpp:454] attention_perm <- attention
I0605 18:44:53.259831 12093 net.cpp:411] attention_perm -> attention_perm
I0605 18:44:53.259912 12093 net.cpp:150] Setting up attention_perm
I0605 18:44:53.259917 12093 net.cpp:157] Top shape: 1 1 14884 14884 (221533456)
I0605 18:44:53.259920 12093 net.cpp:165] Memory required for data: 4471574556
I0605 18:44:53.259924 12093 layer_factory.hpp:77] Creating layer out
I0605 18:44:53.259929 12093 net.cpp:106] Creating Layer out
I0605 18:44:53.259935 12093 net.cpp:454] out <- value_conv_reshape_perm
I0605 18:44:53.259939 12093 net.cpp:454] out <- attention_perm
I0605 18:44:53.259945 12093 net.cpp:411] out -> out
I0605 18:44:53.259966 12093 net.cpp:150] Setting up out
I0605 18:44:53.259982 12093 net.cpp:157] Top shape: 1 1 512 14884 (7620608)
I0605 18:44:53.259984 12093 net.cpp:165] Memory required for data: 4502056988
I0605 18:44:53.259989 12093 layer_factory.hpp:77] Creating layer out_reshape
I0605 18:44:53.260007 12093 net.cpp:106] Creating Layer out_reshape
I0605 18:44:53.260013 12093 net.cpp:454] out_reshape <- out
I0605 18:44:53.260028 12093 net.cpp:411] out_reshape -> out_reshape
I0605 18:44:53.260058 12093 net.cpp:150] Setting up out_reshape
I0605 18:44:53.260064 12093 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:44:53.260067 12093 net.cpp:165] Memory required for data: 4532539420
I0605 18:44:53.260071 12093 layer_factory.hpp:77] Creating layer out_reshape_scale
I0605 18:44:53.260082 12093 net.cpp:106] Creating Layer out_reshape_scale
I0605 18:44:53.260085 12093 net.cpp:454] out_reshape_scale <- out_reshape
I0605 18:44:53.260092 12093 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0605 18:44:53.260167 12093 net.cpp:150] Setting up out_reshape_scale
I0605 18:44:53.260174 12093 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:44:53.260176 12093 net.cpp:165] Memory required for data: 4563021852
I0605 18:44:53.260181 12093 layer_factory.hpp:77] Creating layer out_x
I0605 18:44:53.260191 12093 net.cpp:106] Creating Layer out_x
I0605 18:44:53.260196 12093 net.cpp:454] out_x <- out_reshape_scale
I0605 18:44:53.260201 12093 net.cpp:454] out_x <- pool5_2_conv6_relu_pool5_2_conv6_relu_0_split_3
I0605 18:44:53.260216 12093 net.cpp:411] out_x -> out_x
I0605 18:44:53.260243 12093 net.cpp:150] Setting up out_x
I0605 18:44:53.260249 12093 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:44:53.260252 12093 net.cpp:165] Memory required for data: 4593504284
I0605 18:44:53.260257 12093 layer_factory.hpp:77] Creating layer mask_deconv3
I0605 18:44:53.260267 12093 net.cpp:106] Creating Layer mask_deconv3
I0605 18:44:53.260272 12093 net.cpp:454] mask_deconv3 <- out_x
I0605 18:44:53.260279 12093 net.cpp:411] mask_deconv3 -> mask_deconv3
I0605 18:44:53.260635 12093 net.cpp:150] Setting up mask_deconv3
I0605 18:44:53.260643 12093 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0605 18:44:53.260646 12093 net.cpp:165] Memory required for data: 4654469148
I0605 18:44:53.260663 12093 layer_factory.hpp:77] Creating layer mask_score
I0605 18:44:53.260675 12093 net.cpp:106] Creating Layer mask_score
I0605 18:44:53.260681 12093 net.cpp:454] mask_score <- mask_deconv3
I0605 18:44:53.260689 12093 net.cpp:411] mask_score -> mask_score
I0605 18:44:53.261723 12093 net.cpp:150] Setting up mask_score
I0605 18:44:53.261734 12093 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0605 18:44:53.261736 12093 net.cpp:165] Memory required for data: 4656374300
I0605 18:44:53.261744 12093 layer_factory.hpp:77] Creating layer loss_mask
I0605 18:44:53.261755 12093 net.cpp:106] Creating Layer loss_mask
I0605 18:44:53.261760 12093 net.cpp:454] loss_mask <- mask_score
I0605 18:44:53.261766 12093 net.cpp:454] loss_mask <- mask_targets
I0605 18:44:53.261775 12093 net.cpp:411] loss_mask -> loss_mask
I0605 18:44:53.261785 12093 layer_factory.hpp:77] Creating layer loss_mask
I0605 18:44:53.263193 12093 net.cpp:150] Setting up loss_mask
I0605 18:44:53.263213 12093 net.cpp:157] Top shape: (1)
I0605 18:44:53.263217 12093 net.cpp:160]     with loss weight 3
I0605 18:44:53.263232 12093 net.cpp:165] Memory required for data: 4656374304
I0605 18:44:53.263236 12093 net.cpp:226] loss_mask needs backward computation.
I0605 18:44:53.263242 12093 net.cpp:226] mask_score needs backward computation.
I0605 18:44:53.263245 12093 net.cpp:226] mask_deconv3 needs backward computation.
I0605 18:44:53.263248 12093 net.cpp:226] out_x needs backward computation.
I0605 18:44:53.263252 12093 net.cpp:226] out_reshape_scale needs backward computation.
I0605 18:44:53.263257 12093 net.cpp:226] out_reshape needs backward computation.
I0605 18:44:53.263259 12093 net.cpp:226] out needs backward computation.
I0605 18:44:53.263263 12093 net.cpp:226] attention_perm needs backward computation.
I0605 18:44:53.263269 12093 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0605 18:44:53.263273 12093 net.cpp:226] attention needs backward computation.
I0605 18:44:53.263278 12093 net.cpp:226] energy needs backward computation.
I0605 18:44:53.263281 12093 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0605 18:44:53.263286 12093 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0605 18:44:53.263290 12093 net.cpp:226] value_conv_reshape needs backward computation.
I0605 18:44:53.263294 12093 net.cpp:226] key_conv_reshape needs backward computation.
I0605 18:44:53.263298 12093 net.cpp:226] query_conv_reshape needs backward computation.
I0605 18:44:53.263301 12093 net.cpp:226] value_conv needs backward computation.
I0605 18:44:53.263306 12093 net.cpp:226] key_conv needs backward computation.
I0605 18:44:53.263310 12093 net.cpp:226] query_conv needs backward computation.
I0605 18:44:53.263315 12093 net.cpp:226] pool5_2_conv6_relu_pool5_2_conv6_relu_0_split needs backward computation.
I0605 18:44:53.263319 12093 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0605 18:44:53.263324 12093 net.cpp:226] pool5_2_conv6 needs backward computation.
I0605 18:44:53.263329 12093 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0605 18:44:53.263334 12093 net.cpp:226] pool5_2_conv5 needs backward computation.
I0605 18:44:53.263339 12093 net.cpp:226] mask_deconv2 needs backward computation.
I0605 18:44:53.263343 12093 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0605 18:44:53.263348 12093 net.cpp:226] pool5_2_conv4 needs backward computation.
I0605 18:44:53.263352 12093 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0605 18:44:53.263356 12093 net.cpp:226] pool5_2_conv3 needs backward computation.
I0605 18:44:53.263360 12093 net.cpp:226] mask_deconv1 needs backward computation.
I0605 18:44:53.263365 12093 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0605 18:44:53.263370 12093 net.cpp:226] pool5_2_conv2 needs backward computation.
I0605 18:44:53.263375 12093 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0605 18:44:53.263379 12093 net.cpp:226] pool5_2_conv needs backward computation.
I0605 18:44:53.263383 12093 net.cpp:226] roi_pool5_2 needs backward computation.
I0605 18:44:53.263388 12093 net.cpp:226] loss_bbox needs backward computation.
I0605 18:44:53.263394 12093 net.cpp:226] loss_cls needs backward computation.
I0605 18:44:53.263401 12093 net.cpp:226] bbox_pred needs backward computation.
I0605 18:44:53.263406 12093 net.cpp:226] cls_score needs backward computation.
I0605 18:44:53.263411 12093 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0605 18:44:53.263415 12093 net.cpp:226] relu7 needs backward computation.
I0605 18:44:53.263420 12093 net.cpp:226] fc7 needs backward computation.
I0605 18:44:53.263425 12093 net.cpp:226] relu6 needs backward computation.
I0605 18:44:53.263430 12093 net.cpp:226] fc6 needs backward computation.
I0605 18:44:53.263435 12093 net.cpp:226] roi_pool5 needs backward computation.
I0605 18:44:53.263440 12093 net.cpp:226] roi-data needs backward computation.
I0605 18:44:53.263450 12093 net.cpp:226] proposal needs backward computation.
I0605 18:44:53.263458 12093 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0605 18:44:53.263461 12093 net.cpp:226] rpn_cls_prob needs backward computation.
I0605 18:44:53.263466 12093 net.cpp:226] rpn_loss_bbox needs backward computation.
I0605 18:44:53.263473 12093 net.cpp:226] rpn_loss_cls needs backward computation.
I0605 18:44:53.263479 12093 net.cpp:226] rpn-data needs backward computation.
I0605 18:44:53.263484 12093 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0605 18:44:53.263490 12093 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0605 18:44:53.263495 12093 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0605 18:44:53.263499 12093 net.cpp:226] rpn_bbox_pred needs backward computation.
I0605 18:44:53.263505 12093 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0605 18:44:53.263511 12093 net.cpp:226] rpn_cls_score needs backward computation.
I0605 18:44:53.263515 12093 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0605 18:44:53.263522 12093 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0605 18:44:53.263526 12093 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0605 18:44:53.263532 12093 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0605 18:44:53.263537 12093 net.cpp:226] relu5_3 needs backward computation.
I0605 18:44:53.263540 12093 net.cpp:226] conv5_3 needs backward computation.
I0605 18:44:53.263545 12093 net.cpp:226] relu5_2 needs backward computation.
I0605 18:44:53.263551 12093 net.cpp:226] conv5_2 needs backward computation.
I0605 18:44:53.263554 12093 net.cpp:226] relu5_1 needs backward computation.
I0605 18:44:53.263559 12093 net.cpp:226] conv5_1 needs backward computation.
I0605 18:44:53.263564 12093 net.cpp:226] pool4 needs backward computation.
I0605 18:44:53.263571 12093 net.cpp:226] relu4_3 needs backward computation.
I0605 18:44:53.263576 12093 net.cpp:226] conv4_3 needs backward computation.
I0605 18:44:53.263579 12093 net.cpp:226] relu4_2 needs backward computation.
I0605 18:44:53.263584 12093 net.cpp:226] conv4_2 needs backward computation.
I0605 18:44:53.263588 12093 net.cpp:226] relu4_1 needs backward computation.
I0605 18:44:53.263592 12093 net.cpp:226] conv4_1 needs backward computation.
I0605 18:44:53.263599 12093 net.cpp:226] pool3 needs backward computation.
I0605 18:44:53.263603 12093 net.cpp:226] relu3_3 needs backward computation.
I0605 18:44:53.263608 12093 net.cpp:226] conv3_3 needs backward computation.
I0605 18:44:53.263612 12093 net.cpp:226] relu3_2 needs backward computation.
I0605 18:44:53.263617 12093 net.cpp:226] conv3_2 needs backward computation.
I0605 18:44:53.263620 12093 net.cpp:226] relu3_1 needs backward computation.
I0605 18:44:53.263625 12093 net.cpp:226] conv3_1 needs backward computation.
I0605 18:44:53.263630 12093 net.cpp:228] pool2 does not need backward computation.
I0605 18:44:53.263636 12093 net.cpp:228] relu2_2 does not need backward computation.
I0605 18:44:53.263640 12093 net.cpp:228] conv2_2 does not need backward computation.
I0605 18:44:53.263646 12093 net.cpp:228] relu2_1 does not need backward computation.
I0605 18:44:53.263653 12093 net.cpp:228] conv2_1 does not need backward computation.
I0605 18:44:53.263656 12093 net.cpp:228] pool1 does not need backward computation.
I0605 18:44:53.263661 12093 net.cpp:228] relu1_2 does not need backward computation.
I0605 18:44:53.263665 12093 net.cpp:228] conv1_2 does not need backward computation.
I0605 18:44:53.263669 12093 net.cpp:228] relu1_1 does not need backward computation.
I0605 18:44:53.263674 12093 net.cpp:228] conv1_1 does not need backward computation.
I0605 18:44:53.263679 12093 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0605 18:44:53.263686 12093 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0605 18:44:53.263691 12093 net.cpp:228] data_input-data_0_split does not need backward computation.
I0605 18:44:53.263697 12093 net.cpp:228] input-data does not need backward computation.
I0605 18:44:53.263702 12093 net.cpp:270] This network produces output loss_bbox
I0605 18:44:53.263707 12093 net.cpp:270] This network produces output loss_cls
I0605 18:44:53.263713 12093 net.cpp:270] This network produces output loss_mask
I0605 18:44:53.263718 12093 net.cpp:270] This network produces output rpn_cls_loss
I0605 18:44:53.263721 12093 net.cpp:270] This network produces output rpn_loss_bbox
I0605 18:44:53.263778 12093 net.cpp:283] Network initialization done.
I0605 18:44:53.263970 12093 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0605 18:44:59.480433 12093 net.cpp:816] Ignoring source layer pool5
I0605 18:44:59.549034 12093 net.cpp:816] Ignoring source layer drop6
I0605 18:44:59.559856 12093 net.cpp:816] Ignoring source layer drop7
I0605 18:44:59.559873 12093 net.cpp:816] Ignoring source layer fc8
I0605 18:44:59.559877 12093 net.cpp:816] Ignoring source layer prob
Solving...
F0605 18:45:00.007959 12093 syncedmem.cpp:56] Check failed: error == cudaSuccess (2 vs. 0)  out of memory
*** Check failure stack trace: ***
./experiments/scripts/faster_rcnn_end2end.sh: line 65: 12093 Aborted                 /usr/bin/python ./tools/train_net.py --gpu ${GPU_ID} --solver models/${PT_DIR}/${NET}/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb ${TRAIN_IMDB} --iters ${ITERS} --cfg experiments/cfgs/faster_rcnn_end2end.yml ${EXTRA_ARGS}
