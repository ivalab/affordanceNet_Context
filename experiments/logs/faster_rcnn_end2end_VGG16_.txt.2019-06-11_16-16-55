+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-11_16-16-55
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-11_16-16-55
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0611 16:17:02.775869  8258 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0611 16:17:02.775888  8258 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0611 16:17:02.777185  8258 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  top: "attrArray"
  top: "attrArrayInd"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "attr_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "attr_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "attr_score_pos"
  type: "Eltwise"
  bottom: "attr_score"
  bottom: "attrArrayInd"
  top: "attr_score_pos"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_attribute"
  type: "SigmoidCrossEntropyLoss"
  bottom: "attr_score_pos"
  bottom: "attrArray"
  top: "loss_attribute"
  loss_weight: 0.1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_mask"
  type: "SoftmaxWithLoss"
  bottom: "mask_score"
  bottom: "mask_targets"
  top: "loss_mask"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
I0611 16:17:02.777503  8258 layer_factory.hpp:77] Creating layer input-data
I0611 16:17:02.816715  8258 net.cpp:106] Creating Layer input-data
I0611 16:17:02.816730  8258 net.cpp:411] input-data -> data
I0611 16:17:02.816738  8258 net.cpp:411] input-data -> im_info
I0611 16:17:02.816745  8258 net.cpp:411] input-data -> gt_boxes
I0611 16:17:02.816748  8258 net.cpp:411] input-data -> seg_mask_inds
I0611 16:17:02.816763  8258 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0611 16:17:02.827672  8258 net.cpp:150] Setting up input-data
I0611 16:17:02.827708  8258 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 16:17:02.827711  8258 net.cpp:157] Top shape: 1 3 (3)
I0611 16:17:02.827713  8258 net.cpp:157] Top shape: 1 4 (4)
I0611 16:17:02.827726  8258 net.cpp:157] Top shape: 1 2 (2)
I0611 16:17:02.827729  8258 net.cpp:157] Top shape: 1 1 (1)
I0611 16:17:02.827731  8258 net.cpp:165] Memory required for data: 7200040
I0611 16:17:02.827738  8258 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0611 16:17:02.827761  8258 net.cpp:106] Creating Layer data_input-data_0_split
I0611 16:17:02.827765  8258 net.cpp:454] data_input-data_0_split <- data
I0611 16:17:02.827771  8258 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0611 16:17:02.827780  8258 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0611 16:17:02.827811  8258 net.cpp:150] Setting up data_input-data_0_split
I0611 16:17:02.827816  8258 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 16:17:02.827827  8258 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 16:17:02.827831  8258 net.cpp:165] Memory required for data: 21600040
I0611 16:17:02.827832  8258 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0611 16:17:02.827849  8258 net.cpp:106] Creating Layer im_info_input-data_1_split
I0611 16:17:02.827852  8258 net.cpp:454] im_info_input-data_1_split <- im_info
I0611 16:17:02.827854  8258 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0611 16:17:02.827867  8258 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0611 16:17:02.827872  8258 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0611 16:17:02.827929  8258 net.cpp:150] Setting up im_info_input-data_1_split
I0611 16:17:02.827934  8258 net.cpp:157] Top shape: 1 3 (3)
I0611 16:17:02.827936  8258 net.cpp:157] Top shape: 1 3 (3)
I0611 16:17:02.827949  8258 net.cpp:157] Top shape: 1 3 (3)
I0611 16:17:02.827950  8258 net.cpp:165] Memory required for data: 21600076
I0611 16:17:02.827952  8258 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0611 16:17:02.827965  8258 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0611 16:17:02.827970  8258 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0611 16:17:02.827975  8258 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0611 16:17:02.827980  8258 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0611 16:17:02.828007  8258 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0611 16:17:02.828011  8258 net.cpp:157] Top shape: 1 4 (4)
I0611 16:17:02.828014  8258 net.cpp:157] Top shape: 1 4 (4)
I0611 16:17:02.828017  8258 net.cpp:165] Memory required for data: 21600108
I0611 16:17:02.828019  8258 layer_factory.hpp:77] Creating layer conv1_1
I0611 16:17:02.828028  8258 net.cpp:106] Creating Layer conv1_1
I0611 16:17:02.828032  8258 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0611 16:17:02.828035  8258 net.cpp:411] conv1_1 -> conv1_1
I0611 16:17:03.024366  8258 net.cpp:150] Setting up conv1_1
I0611 16:17:03.024395  8258 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 16:17:03.024399  8258 net.cpp:165] Memory required for data: 175200108
I0611 16:17:03.024412  8258 layer_factory.hpp:77] Creating layer relu1_1
I0611 16:17:03.024422  8258 net.cpp:106] Creating Layer relu1_1
I0611 16:17:03.024426  8258 net.cpp:454] relu1_1 <- conv1_1
I0611 16:17:03.024430  8258 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0611 16:17:03.024588  8258 net.cpp:150] Setting up relu1_1
I0611 16:17:03.024595  8258 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 16:17:03.024598  8258 net.cpp:165] Memory required for data: 328800108
I0611 16:17:03.024612  8258 layer_factory.hpp:77] Creating layer conv1_2
I0611 16:17:03.024631  8258 net.cpp:106] Creating Layer conv1_2
I0611 16:17:03.024633  8258 net.cpp:454] conv1_2 <- conv1_1
I0611 16:17:03.024638  8258 net.cpp:411] conv1_2 -> conv1_2
I0611 16:17:03.026805  8258 net.cpp:150] Setting up conv1_2
I0611 16:17:03.026815  8258 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 16:17:03.026818  8258 net.cpp:165] Memory required for data: 482400108
I0611 16:17:03.026826  8258 layer_factory.hpp:77] Creating layer relu1_2
I0611 16:17:03.026831  8258 net.cpp:106] Creating Layer relu1_2
I0611 16:17:03.026834  8258 net.cpp:454] relu1_2 <- conv1_2
I0611 16:17:03.026847  8258 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0611 16:17:03.027007  8258 net.cpp:150] Setting up relu1_2
I0611 16:17:03.027014  8258 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 16:17:03.027016  8258 net.cpp:165] Memory required for data: 636000108
I0611 16:17:03.027019  8258 layer_factory.hpp:77] Creating layer pool1
I0611 16:17:03.027025  8258 net.cpp:106] Creating Layer pool1
I0611 16:17:03.027027  8258 net.cpp:454] pool1 <- conv1_2
I0611 16:17:03.027042  8258 net.cpp:411] pool1 -> pool1
I0611 16:17:03.027102  8258 net.cpp:150] Setting up pool1
I0611 16:17:03.027117  8258 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0611 16:17:03.027118  8258 net.cpp:165] Memory required for data: 674400108
I0611 16:17:03.027120  8258 layer_factory.hpp:77] Creating layer conv2_1
I0611 16:17:03.027137  8258 net.cpp:106] Creating Layer conv2_1
I0611 16:17:03.027139  8258 net.cpp:454] conv2_1 <- pool1
I0611 16:17:03.027143  8258 net.cpp:411] conv2_1 -> conv2_1
I0611 16:17:03.029063  8258 net.cpp:150] Setting up conv2_1
I0611 16:17:03.029084  8258 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 16:17:03.029088  8258 net.cpp:165] Memory required for data: 751200108
I0611 16:17:03.029094  8258 layer_factory.hpp:77] Creating layer relu2_1
I0611 16:17:03.029111  8258 net.cpp:106] Creating Layer relu2_1
I0611 16:17:03.029115  8258 net.cpp:454] relu2_1 <- conv2_1
I0611 16:17:03.029119  8258 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0611 16:17:03.029680  8258 net.cpp:150] Setting up relu2_1
I0611 16:17:03.029690  8258 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 16:17:03.029692  8258 net.cpp:165] Memory required for data: 828000108
I0611 16:17:03.029695  8258 layer_factory.hpp:77] Creating layer conv2_2
I0611 16:17:03.029700  8258 net.cpp:106] Creating Layer conv2_2
I0611 16:17:03.029703  8258 net.cpp:454] conv2_2 <- conv2_1
I0611 16:17:03.029717  8258 net.cpp:411] conv2_2 -> conv2_2
I0611 16:17:03.031025  8258 net.cpp:150] Setting up conv2_2
I0611 16:17:03.031033  8258 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 16:17:03.031036  8258 net.cpp:165] Memory required for data: 904800108
I0611 16:17:03.031040  8258 layer_factory.hpp:77] Creating layer relu2_2
I0611 16:17:03.031045  8258 net.cpp:106] Creating Layer relu2_2
I0611 16:17:03.031049  8258 net.cpp:454] relu2_2 <- conv2_2
I0611 16:17:03.031061  8258 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0611 16:17:03.031193  8258 net.cpp:150] Setting up relu2_2
I0611 16:17:03.031199  8258 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 16:17:03.031201  8258 net.cpp:165] Memory required for data: 981600108
I0611 16:17:03.031203  8258 layer_factory.hpp:77] Creating layer pool2
I0611 16:17:03.031208  8258 net.cpp:106] Creating Layer pool2
I0611 16:17:03.031211  8258 net.cpp:454] pool2 <- conv2_2
I0611 16:17:03.031214  8258 net.cpp:411] pool2 -> pool2
I0611 16:17:03.031273  8258 net.cpp:150] Setting up pool2
I0611 16:17:03.031277  8258 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0611 16:17:03.031291  8258 net.cpp:165] Memory required for data: 1000800108
I0611 16:17:03.031293  8258 layer_factory.hpp:77] Creating layer conv3_1
I0611 16:17:03.031299  8258 net.cpp:106] Creating Layer conv3_1
I0611 16:17:03.031301  8258 net.cpp:454] conv3_1 <- pool2
I0611 16:17:03.031316  8258 net.cpp:411] conv3_1 -> conv3_1
I0611 16:17:03.033103  8258 net.cpp:150] Setting up conv3_1
I0611 16:17:03.033113  8258 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 16:17:03.033114  8258 net.cpp:165] Memory required for data: 1039200108
I0611 16:17:03.033123  8258 layer_factory.hpp:77] Creating layer relu3_1
I0611 16:17:03.033128  8258 net.cpp:106] Creating Layer relu3_1
I0611 16:17:03.033129  8258 net.cpp:454] relu3_1 <- conv3_1
I0611 16:17:03.033143  8258 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0611 16:17:03.033288  8258 net.cpp:150] Setting up relu3_1
I0611 16:17:03.033295  8258 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 16:17:03.033308  8258 net.cpp:165] Memory required for data: 1077600108
I0611 16:17:03.033311  8258 layer_factory.hpp:77] Creating layer conv3_2
I0611 16:17:03.033318  8258 net.cpp:106] Creating Layer conv3_2
I0611 16:17:03.033322  8258 net.cpp:454] conv3_2 <- conv3_1
I0611 16:17:03.033326  8258 net.cpp:411] conv3_2 -> conv3_2
I0611 16:17:03.035303  8258 net.cpp:150] Setting up conv3_2
I0611 16:17:03.035312  8258 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 16:17:03.035315  8258 net.cpp:165] Memory required for data: 1116000108
I0611 16:17:03.035320  8258 layer_factory.hpp:77] Creating layer relu3_2
I0611 16:17:03.035323  8258 net.cpp:106] Creating Layer relu3_2
I0611 16:17:03.035326  8258 net.cpp:454] relu3_2 <- conv3_2
I0611 16:17:03.035329  8258 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0611 16:17:03.035461  8258 net.cpp:150] Setting up relu3_2
I0611 16:17:03.035467  8258 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 16:17:03.035480  8258 net.cpp:165] Memory required for data: 1154400108
I0611 16:17:03.035482  8258 layer_factory.hpp:77] Creating layer conv3_3
I0611 16:17:03.035488  8258 net.cpp:106] Creating Layer conv3_3
I0611 16:17:03.035490  8258 net.cpp:454] conv3_3 <- conv3_2
I0611 16:17:03.035495  8258 net.cpp:411] conv3_3 -> conv3_3
I0611 16:17:03.037614  8258 net.cpp:150] Setting up conv3_3
I0611 16:17:03.037626  8258 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 16:17:03.037628  8258 net.cpp:165] Memory required for data: 1192800108
I0611 16:17:03.037633  8258 layer_factory.hpp:77] Creating layer relu3_3
I0611 16:17:03.037638  8258 net.cpp:106] Creating Layer relu3_3
I0611 16:17:03.037642  8258 net.cpp:454] relu3_3 <- conv3_3
I0611 16:17:03.037654  8258 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0611 16:17:03.037796  8258 net.cpp:150] Setting up relu3_3
I0611 16:17:03.037802  8258 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 16:17:03.037804  8258 net.cpp:165] Memory required for data: 1231200108
I0611 16:17:03.037806  8258 layer_factory.hpp:77] Creating layer pool3
I0611 16:17:03.037811  8258 net.cpp:106] Creating Layer pool3
I0611 16:17:03.037814  8258 net.cpp:454] pool3 <- conv3_3
I0611 16:17:03.037818  8258 net.cpp:411] pool3 -> pool3
I0611 16:17:03.037878  8258 net.cpp:150] Setting up pool3
I0611 16:17:03.037880  8258 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0611 16:17:03.037894  8258 net.cpp:165] Memory required for data: 1240800108
I0611 16:17:03.037896  8258 layer_factory.hpp:77] Creating layer conv4_1
I0611 16:17:03.037902  8258 net.cpp:106] Creating Layer conv4_1
I0611 16:17:03.037904  8258 net.cpp:454] conv4_1 <- pool3
I0611 16:17:03.037919  8258 net.cpp:411] conv4_1 -> conv4_1
I0611 16:17:03.041656  8258 net.cpp:150] Setting up conv4_1
I0611 16:17:03.041684  8258 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 16:17:03.041687  8258 net.cpp:165] Memory required for data: 1260000108
I0611 16:17:03.041697  8258 layer_factory.hpp:77] Creating layer relu4_1
I0611 16:17:03.041715  8258 net.cpp:106] Creating Layer relu4_1
I0611 16:17:03.041719  8258 net.cpp:454] relu4_1 <- conv4_1
I0611 16:17:03.041724  8258 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0611 16:17:03.041901  8258 net.cpp:150] Setting up relu4_1
I0611 16:17:03.041918  8258 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 16:17:03.041919  8258 net.cpp:165] Memory required for data: 1279200108
I0611 16:17:03.041923  8258 layer_factory.hpp:77] Creating layer conv4_2
I0611 16:17:03.041939  8258 net.cpp:106] Creating Layer conv4_2
I0611 16:17:03.041940  8258 net.cpp:454] conv4_2 <- conv4_1
I0611 16:17:03.041954  8258 net.cpp:411] conv4_2 -> conv4_2
I0611 16:17:03.046958  8258 net.cpp:150] Setting up conv4_2
I0611 16:17:03.046977  8258 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 16:17:03.046979  8258 net.cpp:165] Memory required for data: 1298400108
I0611 16:17:03.046990  8258 layer_factory.hpp:77] Creating layer relu4_2
I0611 16:17:03.046999  8258 net.cpp:106] Creating Layer relu4_2
I0611 16:17:03.047003  8258 net.cpp:454] relu4_2 <- conv4_2
I0611 16:17:03.047019  8258 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0611 16:17:03.047492  8258 net.cpp:150] Setting up relu4_2
I0611 16:17:03.047500  8258 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 16:17:03.047502  8258 net.cpp:165] Memory required for data: 1317600108
I0611 16:17:03.047505  8258 layer_factory.hpp:77] Creating layer conv4_3
I0611 16:17:03.047513  8258 net.cpp:106] Creating Layer conv4_3
I0611 16:17:03.047515  8258 net.cpp:454] conv4_3 <- conv4_2
I0611 16:17:03.047519  8258 net.cpp:411] conv4_3 -> conv4_3
I0611 16:17:03.052182  8258 net.cpp:150] Setting up conv4_3
I0611 16:17:03.052211  8258 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 16:17:03.052213  8258 net.cpp:165] Memory required for data: 1336800108
I0611 16:17:03.052220  8258 layer_factory.hpp:77] Creating layer relu4_3
I0611 16:17:03.052228  8258 net.cpp:106] Creating Layer relu4_3
I0611 16:17:03.052232  8258 net.cpp:454] relu4_3 <- conv4_3
I0611 16:17:03.052247  8258 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0611 16:17:03.052366  8258 net.cpp:150] Setting up relu4_3
I0611 16:17:03.052371  8258 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 16:17:03.052373  8258 net.cpp:165] Memory required for data: 1356000108
I0611 16:17:03.052376  8258 layer_factory.hpp:77] Creating layer pool4
I0611 16:17:03.052381  8258 net.cpp:106] Creating Layer pool4
I0611 16:17:03.052383  8258 net.cpp:454] pool4 <- conv4_3
I0611 16:17:03.052387  8258 net.cpp:411] pool4 -> pool4
I0611 16:17:03.052436  8258 net.cpp:150] Setting up pool4
I0611 16:17:03.052440  8258 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:17:03.052453  8258 net.cpp:165] Memory required for data: 1360903020
I0611 16:17:03.052455  8258 layer_factory.hpp:77] Creating layer conv5_1
I0611 16:17:03.052462  8258 net.cpp:106] Creating Layer conv5_1
I0611 16:17:03.052465  8258 net.cpp:454] conv5_1 <- pool4
I0611 16:17:03.052469  8258 net.cpp:411] conv5_1 -> conv5_1
I0611 16:17:03.056674  8258 net.cpp:150] Setting up conv5_1
I0611 16:17:03.056694  8258 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:17:03.056696  8258 net.cpp:165] Memory required for data: 1365805932
I0611 16:17:03.056704  8258 layer_factory.hpp:77] Creating layer relu5_1
I0611 16:17:03.056712  8258 net.cpp:106] Creating Layer relu5_1
I0611 16:17:03.056716  8258 net.cpp:454] relu5_1 <- conv5_1
I0611 16:17:03.056721  8258 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0611 16:17:03.056852  8258 net.cpp:150] Setting up relu5_1
I0611 16:17:03.056859  8258 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:17:03.056860  8258 net.cpp:165] Memory required for data: 1370708844
I0611 16:17:03.056864  8258 layer_factory.hpp:77] Creating layer conv5_2
I0611 16:17:03.056869  8258 net.cpp:106] Creating Layer conv5_2
I0611 16:17:03.056872  8258 net.cpp:454] conv5_2 <- conv5_1
I0611 16:17:03.056877  8258 net.cpp:411] conv5_2 -> conv5_2
I0611 16:17:03.061136  8258 net.cpp:150] Setting up conv5_2
I0611 16:17:03.061164  8258 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:17:03.061167  8258 net.cpp:165] Memory required for data: 1375611756
I0611 16:17:03.061185  8258 layer_factory.hpp:77] Creating layer relu5_2
I0611 16:17:03.061195  8258 net.cpp:106] Creating Layer relu5_2
I0611 16:17:03.061200  8258 net.cpp:454] relu5_2 <- conv5_2
I0611 16:17:03.061204  8258 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0611 16:17:03.061331  8258 net.cpp:150] Setting up relu5_2
I0611 16:17:03.061338  8258 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:17:03.061341  8258 net.cpp:165] Memory required for data: 1380514668
I0611 16:17:03.061342  8258 layer_factory.hpp:77] Creating layer conv5_3
I0611 16:17:03.061364  8258 net.cpp:106] Creating Layer conv5_3
I0611 16:17:03.061368  8258 net.cpp:454] conv5_3 <- conv5_2
I0611 16:17:03.061373  8258 net.cpp:411] conv5_3 -> conv5_3
I0611 16:17:03.065734  8258 net.cpp:150] Setting up conv5_3
I0611 16:17:03.065753  8258 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:17:03.065757  8258 net.cpp:165] Memory required for data: 1385417580
I0611 16:17:03.065764  8258 layer_factory.hpp:77] Creating layer relu5_3
I0611 16:17:03.065773  8258 net.cpp:106] Creating Layer relu5_3
I0611 16:17:03.065776  8258 net.cpp:454] relu5_3 <- conv5_3
I0611 16:17:03.065781  8258 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0611 16:17:03.065912  8258 net.cpp:150] Setting up relu5_3
I0611 16:17:03.065918  8258 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:17:03.065922  8258 net.cpp:165] Memory required for data: 1390320492
I0611 16:17:03.065923  8258 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0611 16:17:03.065928  8258 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0611 16:17:03.065930  8258 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0611 16:17:03.065934  8258 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0611 16:17:03.065939  8258 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0611 16:17:03.065943  8258 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0611 16:17:03.065995  8258 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0611 16:17:03.065999  8258 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:17:03.066012  8258 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:17:03.066015  8258 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:17:03.066017  8258 net.cpp:165] Memory required for data: 1405029228
I0611 16:17:03.066020  8258 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0611 16:17:03.066036  8258 net.cpp:106] Creating Layer rpn_conv/3x3
I0611 16:17:03.066040  8258 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0611 16:17:03.066054  8258 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0611 16:17:03.116690  8258 net.cpp:150] Setting up rpn_conv/3x3
I0611 16:17:03.116708  8258 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:17:03.116710  8258 net.cpp:165] Memory required for data: 1409932140
I0611 16:17:03.116717  8258 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0611 16:17:03.116725  8258 net.cpp:106] Creating Layer rpn_relu/3x3
I0611 16:17:03.116729  8258 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0611 16:17:03.116734  8258 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0611 16:17:03.116866  8258 net.cpp:150] Setting up rpn_relu/3x3
I0611 16:17:03.116873  8258 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:17:03.116875  8258 net.cpp:165] Memory required for data: 1414835052
I0611 16:17:03.116878  8258 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0611 16:17:03.116883  8258 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0611 16:17:03.116884  8258 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0611 16:17:03.116888  8258 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0611 16:17:03.116892  8258 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0611 16:17:03.116938  8258 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0611 16:17:03.116942  8258 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:17:03.116956  8258 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:17:03.116958  8258 net.cpp:165] Memory required for data: 1424640876
I0611 16:17:03.116961  8258 layer_factory.hpp:77] Creating layer rpn_cls_score
I0611 16:17:03.116969  8258 net.cpp:106] Creating Layer rpn_cls_score
I0611 16:17:03.116972  8258 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0611 16:17:03.116977  8258 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0611 16:17:03.118656  8258 net.cpp:150] Setting up rpn_cls_score
I0611 16:17:03.118664  8258 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 16:17:03.118677  8258 net.cpp:165] Memory required for data: 1424928156
I0611 16:17:03.118681  8258 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0611 16:17:03.118687  8258 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0611 16:17:03.118690  8258 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0611 16:17:03.118695  8258 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0611 16:17:03.118711  8258 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0611 16:17:03.118752  8258 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0611 16:17:03.118757  8258 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 16:17:03.118770  8258 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 16:17:03.118772  8258 net.cpp:165] Memory required for data: 1425502716
I0611 16:17:03.118774  8258 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0611 16:17:03.118791  8258 net.cpp:106] Creating Layer rpn_bbox_pred
I0611 16:17:03.118793  8258 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0611 16:17:03.118800  8258 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0611 16:17:03.120337  8258 net.cpp:150] Setting up rpn_bbox_pred
I0611 16:17:03.120344  8258 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 16:17:03.120347  8258 net.cpp:165] Memory required for data: 1426077276
I0611 16:17:03.120352  8258 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 16:17:03.120355  8258 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 16:17:03.120358  8258 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0611 16:17:03.120362  8258 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0611 16:17:03.120368  8258 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0611 16:17:03.120412  8258 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 16:17:03.120417  8258 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 16:17:03.120430  8258 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 16:17:03.120432  8258 net.cpp:165] Memory required for data: 1427226396
I0611 16:17:03.120434  8258 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0611 16:17:03.120440  8258 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0611 16:17:03.120442  8258 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0611 16:17:03.120455  8258 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0611 16:17:03.120481  8258 net.cpp:150] Setting up rpn_cls_score_reshape
I0611 16:17:03.120496  8258 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 16:17:03.120497  8258 net.cpp:165] Memory required for data: 1427513676
I0611 16:17:03.120499  8258 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 16:17:03.120512  8258 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 16:17:03.120515  8258 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0611 16:17:03.120520  8258 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0611 16:17:03.120523  8258 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0611 16:17:03.120554  8258 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 16:17:03.120558  8258 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 16:17:03.120561  8258 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 16:17:03.120563  8258 net.cpp:165] Memory required for data: 1428088236
I0611 16:17:03.120565  8258 layer_factory.hpp:77] Creating layer rpn-data
I0611 16:17:03.120870  8258 net.cpp:106] Creating Layer rpn-data
I0611 16:17:03.120877  8258 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0611 16:17:03.120882  8258 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0611 16:17:03.120884  8258 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0611 16:17:03.120887  8258 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0611 16:17:03.120892  8258 net.cpp:411] rpn-data -> rpn_labels
I0611 16:17:03.120896  8258 net.cpp:411] rpn-data -> rpn_bbox_targets
I0611 16:17:03.120901  8258 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0611 16:17:03.120905  8258 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0611 16:17:03.121726  8258 net.cpp:150] Setting up rpn-data
I0611 16:17:03.121735  8258 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0611 16:17:03.121738  8258 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 16:17:03.121740  8258 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 16:17:03.121743  8258 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 16:17:03.121745  8258 net.cpp:165] Memory required for data: 1429955556
I0611 16:17:03.121747  8258 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0611 16:17:03.121753  8258 net.cpp:106] Creating Layer rpn_loss_cls
I0611 16:17:03.121757  8258 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0611 16:17:03.121760  8258 net.cpp:454] rpn_loss_cls <- rpn_labels
I0611 16:17:03.121764  8258 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0611 16:17:03.121771  8258 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0611 16:17:03.122380  8258 net.cpp:150] Setting up rpn_loss_cls
I0611 16:17:03.122387  8258 net.cpp:157] Top shape: (1)
I0611 16:17:03.122390  8258 net.cpp:160]     with loss weight 1
I0611 16:17:03.122396  8258 net.cpp:165] Memory required for data: 1429955560
I0611 16:17:03.122400  8258 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0611 16:17:03.122416  8258 net.cpp:106] Creating Layer rpn_loss_bbox
I0611 16:17:03.122421  8258 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0611 16:17:03.122424  8258 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0611 16:17:03.122427  8258 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0611 16:17:03.122431  8258 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0611 16:17:03.122434  8258 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0611 16:17:03.123459  8258 net.cpp:150] Setting up rpn_loss_bbox
I0611 16:17:03.123467  8258 net.cpp:157] Top shape: (1)
I0611 16:17:03.123469  8258 net.cpp:160]     with loss weight 1
I0611 16:17:03.123473  8258 net.cpp:165] Memory required for data: 1429955564
I0611 16:17:03.123476  8258 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0611 16:17:03.123481  8258 net.cpp:106] Creating Layer rpn_cls_prob
I0611 16:17:03.123494  8258 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0611 16:17:03.123499  8258 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0611 16:17:03.123664  8258 net.cpp:150] Setting up rpn_cls_prob
I0611 16:17:03.123670  8258 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 16:17:03.123672  8258 net.cpp:165] Memory required for data: 1430242844
I0611 16:17:03.123675  8258 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0611 16:17:03.123680  8258 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0611 16:17:03.123682  8258 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0611 16:17:03.123697  8258 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0611 16:17:03.123718  8258 net.cpp:150] Setting up rpn_cls_prob_reshape
I0611 16:17:03.123731  8258 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 16:17:03.123733  8258 net.cpp:165] Memory required for data: 1430530124
I0611 16:17:03.123735  8258 layer_factory.hpp:77] Creating layer proposal
I0611 16:17:03.124169  8258 net.cpp:106] Creating Layer proposal
I0611 16:17:03.124177  8258 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0611 16:17:03.124181  8258 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0611 16:17:03.124184  8258 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0611 16:17:03.124188  8258 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0611 16:17:03.125005  8258 net.cpp:150] Setting up proposal
I0611 16:17:03.125013  8258 net.cpp:157] Top shape: 1 5 (5)
I0611 16:17:03.125015  8258 net.cpp:165] Memory required for data: 1430530144
I0611 16:17:03.125018  8258 layer_factory.hpp:77] Creating layer roi-data
I0611 16:17:03.125224  8258 net.cpp:106] Creating Layer roi-data
I0611 16:17:03.125231  8258 net.cpp:454] roi-data <- rpn_rois
I0611 16:17:03.125234  8258 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0611 16:17:03.125237  8258 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0611 16:17:03.125250  8258 net.cpp:454] roi-data <- seg_mask_inds
I0611 16:17:03.125253  8258 net.cpp:454] roi-data <- flipped
I0611 16:17:03.125258  8258 net.cpp:411] roi-data -> rois
I0611 16:17:03.125274  8258 net.cpp:411] roi-data -> labels
I0611 16:17:03.125280  8258 net.cpp:411] roi-data -> bbox_targets
I0611 16:17:03.125285  8258 net.cpp:411] roi-data -> bbox_inside_weights
I0611 16:17:03.125290  8258 net.cpp:411] roi-data -> bbox_outside_weights
I0611 16:17:03.125295  8258 net.cpp:411] roi-data -> mask_targets
I0611 16:17:03.125300  8258 net.cpp:411] roi-data -> rois_pos
I0611 16:17:03.125304  8258 net.cpp:411] roi-data -> attrArray
I0611 16:17:03.125308  8258 net.cpp:411] roi-data -> attrArrayInd
I0611 16:17:03.125604  8258 net.cpp:150] Setting up roi-data
I0611 16:17:03.125613  8258 net.cpp:157] Top shape: 1 5 (5)
I0611 16:17:03.125627  8258 net.cpp:157] Top shape: 1 1 (1)
I0611 16:17:03.125628  8258 net.cpp:157] Top shape: 1 8 (8)
I0611 16:17:03.125632  8258 net.cpp:157] Top shape: 1 8 (8)
I0611 16:17:03.125633  8258 net.cpp:157] Top shape: 1 8 (8)
I0611 16:17:03.125646  8258 net.cpp:157] Top shape: 1 244 244 (59536)
I0611 16:17:03.125649  8258 net.cpp:157] Top shape: 1 5 (5)
I0611 16:17:03.125653  8258 net.cpp:157] Top shape: 1 7 (7)
I0611 16:17:03.125655  8258 net.cpp:157] Top shape: 1 7 (7)
I0611 16:17:03.125658  8258 net.cpp:165] Memory required for data: 1430768484
I0611 16:17:03.125661  8258 layer_factory.hpp:77] Creating layer roi_pool5
I0611 16:17:03.125667  8258 net.cpp:106] Creating Layer roi_pool5
I0611 16:17:03.125671  8258 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0611 16:17:03.125675  8258 net.cpp:454] roi_pool5 <- rois
I0611 16:17:03.125679  8258 net.cpp:411] roi_pool5 -> pool5
I0611 16:17:03.125685  8258 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0611 16:17:03.125762  8258 net.cpp:150] Setting up roi_pool5
I0611 16:17:03.125766  8258 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 16:17:03.125768  8258 net.cpp:165] Memory required for data: 1430868836
I0611 16:17:03.125782  8258 layer_factory.hpp:77] Creating layer fc6
I0611 16:17:03.125788  8258 net.cpp:106] Creating Layer fc6
I0611 16:17:03.125792  8258 net.cpp:454] fc6 <- pool5
I0611 16:17:03.125795  8258 net.cpp:411] fc6 -> fc6
I0611 16:17:03.264297  8258 net.cpp:150] Setting up fc6
I0611 16:17:03.264322  8258 net.cpp:157] Top shape: 1 4096 (4096)
I0611 16:17:03.264324  8258 net.cpp:165] Memory required for data: 1430885220
I0611 16:17:03.264339  8258 layer_factory.hpp:77] Creating layer relu6
I0611 16:17:03.264360  8258 net.cpp:106] Creating Layer relu6
I0611 16:17:03.264365  8258 net.cpp:454] relu6 <- fc6
I0611 16:17:03.264381  8258 net.cpp:397] relu6 -> fc6 (in-place)
I0611 16:17:03.264626  8258 net.cpp:150] Setting up relu6
I0611 16:17:03.264633  8258 net.cpp:157] Top shape: 1 4096 (4096)
I0611 16:17:03.264636  8258 net.cpp:165] Memory required for data: 1430901604
I0611 16:17:03.264638  8258 layer_factory.hpp:77] Creating layer fc7
I0611 16:17:03.264644  8258 net.cpp:106] Creating Layer fc7
I0611 16:17:03.264647  8258 net.cpp:454] fc7 <- fc6
I0611 16:17:03.264662  8258 net.cpp:411] fc7 -> fc7
I0611 16:17:03.288045  8258 net.cpp:150] Setting up fc7
I0611 16:17:03.288070  8258 net.cpp:157] Top shape: 1 4096 (4096)
I0611 16:17:03.288074  8258 net.cpp:165] Memory required for data: 1430917988
I0611 16:17:03.288084  8258 layer_factory.hpp:77] Creating layer relu7
I0611 16:17:03.288103  8258 net.cpp:106] Creating Layer relu7
I0611 16:17:03.288110  8258 net.cpp:454] relu7 <- fc7
I0611 16:17:03.288125  8258 net.cpp:397] relu7 -> fc7 (in-place)
I0611 16:17:03.288334  8258 net.cpp:150] Setting up relu7
I0611 16:17:03.288341  8258 net.cpp:157] Top shape: 1 4096 (4096)
I0611 16:17:03.288344  8258 net.cpp:165] Memory required for data: 1430934372
I0611 16:17:03.288347  8258 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0611 16:17:03.288353  8258 net.cpp:106] Creating Layer fc7_relu7_0_split
I0611 16:17:03.288355  8258 net.cpp:454] fc7_relu7_0_split <- fc7
I0611 16:17:03.288359  8258 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0611 16:17:03.288374  8258 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0611 16:17:03.288380  8258 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0611 16:17:03.288451  8258 net.cpp:150] Setting up fc7_relu7_0_split
I0611 16:17:03.288455  8258 net.cpp:157] Top shape: 1 4096 (4096)
I0611 16:17:03.288471  8258 net.cpp:157] Top shape: 1 4096 (4096)
I0611 16:17:03.288473  8258 net.cpp:157] Top shape: 1 4096 (4096)
I0611 16:17:03.288476  8258 net.cpp:165] Memory required for data: 1430983524
I0611 16:17:03.288478  8258 layer_factory.hpp:77] Creating layer attr_score
I0611 16:17:03.288494  8258 net.cpp:106] Creating Layer attr_score
I0611 16:17:03.288507  8258 net.cpp:454] attr_score <- fc7_relu7_0_split_0
I0611 16:17:03.288513  8258 net.cpp:411] attr_score -> attr_score
I0611 16:17:03.289186  8258 net.cpp:150] Setting up attr_score
I0611 16:17:03.289191  8258 net.cpp:157] Top shape: 1 7 (7)
I0611 16:17:03.289193  8258 net.cpp:165] Memory required for data: 1430983552
I0611 16:17:03.289197  8258 layer_factory.hpp:77] Creating layer attr_score_pos
I0611 16:17:03.289202  8258 net.cpp:106] Creating Layer attr_score_pos
I0611 16:17:03.289204  8258 net.cpp:454] attr_score_pos <- attr_score
I0611 16:17:03.289207  8258 net.cpp:454] attr_score_pos <- attrArrayInd
I0611 16:17:03.289222  8258 net.cpp:411] attr_score_pos -> attr_score_pos
I0611 16:17:03.289247  8258 net.cpp:150] Setting up attr_score_pos
I0611 16:17:03.289252  8258 net.cpp:157] Top shape: 1 7 (7)
I0611 16:17:03.289253  8258 net.cpp:165] Memory required for data: 1430983580
I0611 16:17:03.289265  8258 layer_factory.hpp:77] Creating layer cls_score
I0611 16:17:03.289270  8258 net.cpp:106] Creating Layer cls_score
I0611 16:17:03.289273  8258 net.cpp:454] cls_score <- fc7_relu7_0_split_1
I0611 16:17:03.289278  8258 net.cpp:411] cls_score -> cls_score
I0611 16:17:03.289548  8258 net.cpp:150] Setting up cls_score
I0611 16:17:03.289554  8258 net.cpp:157] Top shape: 1 2 (2)
I0611 16:17:03.289556  8258 net.cpp:165] Memory required for data: 1430983588
I0611 16:17:03.289559  8258 layer_factory.hpp:77] Creating layer bbox_pred
I0611 16:17:03.289564  8258 net.cpp:106] Creating Layer bbox_pred
I0611 16:17:03.289567  8258 net.cpp:454] bbox_pred <- fc7_relu7_0_split_2
I0611 16:17:03.289572  8258 net.cpp:411] bbox_pred -> bbox_pred
I0611 16:17:03.290302  8258 net.cpp:150] Setting up bbox_pred
I0611 16:17:03.290307  8258 net.cpp:157] Top shape: 1 8 (8)
I0611 16:17:03.290309  8258 net.cpp:165] Memory required for data: 1430983620
I0611 16:17:03.290313  8258 layer_factory.hpp:77] Creating layer loss_attribute
I0611 16:17:03.290319  8258 net.cpp:106] Creating Layer loss_attribute
I0611 16:17:03.290323  8258 net.cpp:454] loss_attribute <- attr_score_pos
I0611 16:17:03.290325  8258 net.cpp:454] loss_attribute <- attrArray
I0611 16:17:03.290338  8258 net.cpp:411] loss_attribute -> loss_attribute
I0611 16:17:03.290410  8258 net.cpp:150] Setting up loss_attribute
I0611 16:17:03.290415  8258 net.cpp:157] Top shape: (1)
I0611 16:17:03.290416  8258 net.cpp:160]     with loss weight 0.1
I0611 16:17:03.290436  8258 net.cpp:165] Memory required for data: 1430983624
I0611 16:17:03.290447  8258 layer_factory.hpp:77] Creating layer loss_cls
I0611 16:17:03.290452  8258 net.cpp:106] Creating Layer loss_cls
I0611 16:17:03.290467  8258 net.cpp:454] loss_cls <- cls_score
I0611 16:17:03.290469  8258 net.cpp:454] loss_cls <- labels
I0611 16:17:03.290473  8258 net.cpp:411] loss_cls -> loss_cls
I0611 16:17:03.290488  8258 layer_factory.hpp:77] Creating layer loss_cls
I0611 16:17:03.291168  8258 net.cpp:150] Setting up loss_cls
I0611 16:17:03.291175  8258 net.cpp:157] Top shape: (1)
I0611 16:17:03.291178  8258 net.cpp:160]     with loss weight 3
I0611 16:17:03.291182  8258 net.cpp:165] Memory required for data: 1430983628
I0611 16:17:03.291185  8258 layer_factory.hpp:77] Creating layer loss_bbox
I0611 16:17:03.291190  8258 net.cpp:106] Creating Layer loss_bbox
I0611 16:17:03.291193  8258 net.cpp:454] loss_bbox <- bbox_pred
I0611 16:17:03.291206  8258 net.cpp:454] loss_bbox <- bbox_targets
I0611 16:17:03.291209  8258 net.cpp:454] loss_bbox <- bbox_inside_weights
I0611 16:17:03.291213  8258 net.cpp:454] loss_bbox <- bbox_outside_weights
I0611 16:17:03.291226  8258 net.cpp:411] loss_bbox -> loss_bbox
I0611 16:17:03.291306  8258 net.cpp:150] Setting up loss_bbox
I0611 16:17:03.291309  8258 net.cpp:157] Top shape: (1)
I0611 16:17:03.291311  8258 net.cpp:160]     with loss weight 2
I0611 16:17:03.291314  8258 net.cpp:165] Memory required for data: 1430983632
I0611 16:17:03.291316  8258 layer_factory.hpp:77] Creating layer roi_pool5_2
I0611 16:17:03.291327  8258 net.cpp:106] Creating Layer roi_pool5_2
I0611 16:17:03.291342  8258 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0611 16:17:03.291345  8258 net.cpp:454] roi_pool5_2 <- rois_pos
I0611 16:17:03.291360  8258 net.cpp:411] roi_pool5_2 -> pool5_2
I0611 16:17:03.291365  8258 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0611 16:17:03.291450  8258 net.cpp:150] Setting up roi_pool5_2
I0611 16:17:03.291455  8258 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 16:17:03.291466  8258 net.cpp:165] Memory required for data: 1431083984
I0611 16:17:03.291471  8258 layer_factory.hpp:77] Creating layer pool5_2_conv
I0611 16:17:03.291487  8258 net.cpp:106] Creating Layer pool5_2_conv
I0611 16:17:03.291491  8258 net.cpp:454] pool5_2_conv <- pool5_2
I0611 16:17:03.291494  8258 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0611 16:17:03.298259  8258 net.cpp:150] Setting up pool5_2_conv
I0611 16:17:03.298269  8258 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 16:17:03.298271  8258 net.cpp:165] Memory required for data: 1431184336
I0611 16:17:03.298276  8258 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0611 16:17:03.298280  8258 net.cpp:106] Creating Layer pool5_2_conv_relu
I0611 16:17:03.298283  8258 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0611 16:17:03.298287  8258 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0611 16:17:03.298439  8258 net.cpp:150] Setting up pool5_2_conv_relu
I0611 16:17:03.298444  8258 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 16:17:03.298446  8258 net.cpp:165] Memory required for data: 1431284688
I0611 16:17:03.298449  8258 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0611 16:17:03.298456  8258 net.cpp:106] Creating Layer pool5_2_conv2
I0611 16:17:03.298458  8258 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0611 16:17:03.298462  8258 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0611 16:17:03.350303  8258 net.cpp:150] Setting up pool5_2_conv2
I0611 16:17:03.350332  8258 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 16:17:03.350335  8258 net.cpp:165] Memory required for data: 1431385040
I0611 16:17:03.350344  8258 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0611 16:17:03.350355  8258 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0611 16:17:03.350361  8258 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0611 16:17:03.350370  8258 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0611 16:17:03.350577  8258 net.cpp:150] Setting up pool5_2_conv2_relu
I0611 16:17:03.350587  8258 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 16:17:03.350591  8258 net.cpp:165] Memory required for data: 1431485392
I0611 16:17:03.350606  8258 layer_factory.hpp:77] Creating layer mask_deconv1
I0611 16:17:03.350630  8258 net.cpp:106] Creating Layer mask_deconv1
I0611 16:17:03.350636  8258 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0611 16:17:03.350646  8258 net.cpp:411] mask_deconv1 -> mask_deconv1
I0611 16:17:03.351447  8258 net.cpp:150] Setting up mask_deconv1
I0611 16:17:03.351455  8258 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0611 16:17:03.351459  8258 net.cpp:165] Memory required for data: 1432406992
I0611 16:17:03.351476  8258 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0611 16:17:03.351503  8258 net.cpp:106] Creating Layer pool5_2_conv3
I0611 16:17:03.351511  8258 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0611 16:17:03.351521  8258 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0611 16:17:03.378665  8258 net.cpp:150] Setting up pool5_2_conv3
I0611 16:17:03.378685  8258 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:17:03.378690  8258 net.cpp:165] Memory required for data: 1434250192
I0611 16:17:03.378700  8258 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0611 16:17:03.378721  8258 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0611 16:17:03.378738  8258 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0611 16:17:03.378746  8258 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0611 16:17:03.378890  8258 net.cpp:150] Setting up pool5_2_conv3_relu
I0611 16:17:03.378899  8258 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:17:03.378903  8258 net.cpp:165] Memory required for data: 1436093392
I0611 16:17:03.378907  8258 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0611 16:17:03.378921  8258 net.cpp:106] Creating Layer pool5_2_conv4
I0611 16:17:03.378927  8258 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0611 16:17:03.378934  8258 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0611 16:17:03.430158  8258 net.cpp:150] Setting up pool5_2_conv4
I0611 16:17:03.430178  8258 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:17:03.430183  8258 net.cpp:165] Memory required for data: 1437936592
I0611 16:17:03.430194  8258 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0611 16:17:03.430219  8258 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0611 16:17:03.430225  8258 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0611 16:17:03.430241  8258 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0611 16:17:03.430398  8258 net.cpp:150] Setting up pool5_2_conv4_relu
I0611 16:17:03.430407  8258 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:17:03.430410  8258 net.cpp:165] Memory required for data: 1439779792
I0611 16:17:03.430414  8258 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 16:17:03.430421  8258 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 16:17:03.430426  8258 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0611 16:17:03.430444  8258 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0611 16:17:03.430452  8258 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0611 16:17:03.430460  8258 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0611 16:17:03.430480  8258 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0611 16:17:03.430554  8258 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 16:17:03.430560  8258 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:17:03.430564  8258 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:17:03.430569  8258 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:17:03.430574  8258 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:17:03.430578  8258 net.cpp:165] Memory required for data: 1447152592
I0611 16:17:03.430582  8258 layer_factory.hpp:77] Creating layer query_conv
I0611 16:17:03.430616  8258 net.cpp:106] Creating Layer query_conv
I0611 16:17:03.430621  8258 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0611 16:17:03.430637  8258 net.cpp:411] query_conv -> query_conv
I0611 16:17:03.432265  8258 net.cpp:150] Setting up query_conv
I0611 16:17:03.432273  8258 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0611 16:17:03.432276  8258 net.cpp:165] Memory required for data: 1447382992
I0611 16:17:03.432294  8258 layer_factory.hpp:77] Creating layer key_conv
I0611 16:17:03.432318  8258 net.cpp:106] Creating Layer key_conv
I0611 16:17:03.432323  8258 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0611 16:17:03.432330  8258 net.cpp:411] key_conv -> key_conv
I0611 16:17:03.433928  8258 net.cpp:150] Setting up key_conv
I0611 16:17:03.433938  8258 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0611 16:17:03.433941  8258 net.cpp:165] Memory required for data: 1447613392
I0611 16:17:03.433959  8258 layer_factory.hpp:77] Creating layer value_conv
I0611 16:17:03.433982  8258 net.cpp:106] Creating Layer value_conv
I0611 16:17:03.433987  8258 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0611 16:17:03.434005  8258 net.cpp:411] value_conv -> value_conv
I0611 16:17:03.440743  8258 net.cpp:150] Setting up value_conv
I0611 16:17:03.440753  8258 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:17:03.440757  8258 net.cpp:165] Memory required for data: 1449456592
I0611 16:17:03.440764  8258 layer_factory.hpp:77] Creating layer query_conv_reshape
I0611 16:17:03.440773  8258 net.cpp:106] Creating Layer query_conv_reshape
I0611 16:17:03.440788  8258 net.cpp:454] query_conv_reshape <- query_conv
I0611 16:17:03.440807  8258 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0611 16:17:03.440853  8258 net.cpp:150] Setting up query_conv_reshape
I0611 16:17:03.440860  8258 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0611 16:17:03.440862  8258 net.cpp:165] Memory required for data: 1449686992
I0611 16:17:03.440876  8258 layer_factory.hpp:77] Creating layer key_conv_reshape
I0611 16:17:03.440883  8258 net.cpp:106] Creating Layer key_conv_reshape
I0611 16:17:03.440896  8258 net.cpp:454] key_conv_reshape <- key_conv
I0611 16:17:03.440917  8258 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0611 16:17:03.440949  8258 net.cpp:150] Setting up key_conv_reshape
I0611 16:17:03.440965  8258 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0611 16:17:03.440980  8258 net.cpp:165] Memory required for data: 1449917392
I0611 16:17:03.440984  8258 layer_factory.hpp:77] Creating layer value_conv_reshape
I0611 16:17:03.440999  8258 net.cpp:106] Creating Layer value_conv_reshape
I0611 16:17:03.441005  8258 net.cpp:454] value_conv_reshape <- value_conv
I0611 16:17:03.441020  8258 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0611 16:17:03.441041  8258 net.cpp:150] Setting up value_conv_reshape
I0611 16:17:03.441047  8258 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0611 16:17:03.441059  8258 net.cpp:165] Memory required for data: 1451760592
I0611 16:17:03.441063  8258 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0611 16:17:03.441097  8258 net.cpp:106] Creating Layer query_conv_reshape_perm
I0611 16:17:03.441100  8258 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0611 16:17:03.441115  8258 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0611 16:17:03.441188  8258 net.cpp:150] Setting up query_conv_reshape_perm
I0611 16:17:03.441195  8258 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0611 16:17:03.441197  8258 net.cpp:165] Memory required for data: 1451990992
I0611 16:17:03.441213  8258 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0611 16:17:03.441220  8258 net.cpp:106] Creating Layer key_conv_reshape_perm
I0611 16:17:03.441226  8258 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0611 16:17:03.441246  8258 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0611 16:17:03.441335  8258 net.cpp:150] Setting up key_conv_reshape_perm
I0611 16:17:03.441341  8258 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0611 16:17:03.441344  8258 net.cpp:165] Memory required for data: 1452221392
I0611 16:17:03.441359  8258 layer_factory.hpp:77] Creating layer energy
I0611 16:17:03.441368  8258 net.cpp:106] Creating Layer energy
I0611 16:17:03.441375  8258 net.cpp:454] energy <- query_conv_reshape_perm
I0611 16:17:03.441380  8258 net.cpp:454] energy <- key_conv_reshape_perm
I0611 16:17:03.441396  8258 net.cpp:411] energy -> energy
I0611 16:17:03.441445  8258 net.cpp:150] Setting up energy
I0611 16:17:03.441452  8258 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 16:17:03.441457  8258 net.cpp:165] Memory required for data: 1455461392
I0611 16:17:03.441460  8258 layer_factory.hpp:77] Creating layer attention
I0611 16:17:03.441468  8258 net.cpp:106] Creating Layer attention
I0611 16:17:03.441471  8258 net.cpp:454] attention <- energy
I0611 16:17:03.441479  8258 net.cpp:411] attention -> attention
I0611 16:17:03.441653  8258 net.cpp:150] Setting up attention
I0611 16:17:03.441660  8258 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 16:17:03.441663  8258 net.cpp:165] Memory required for data: 1458701392
I0611 16:17:03.441675  8258 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0611 16:17:03.441682  8258 net.cpp:106] Creating Layer value_conv_reshape_perm
I0611 16:17:03.441689  8258 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0611 16:17:03.441697  8258 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0611 16:17:03.441772  8258 net.cpp:150] Setting up value_conv_reshape_perm
I0611 16:17:03.441778  8258 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0611 16:17:03.441781  8258 net.cpp:165] Memory required for data: 1460544592
I0611 16:17:03.441787  8258 layer_factory.hpp:77] Creating layer attention_perm
I0611 16:17:03.441793  8258 net.cpp:106] Creating Layer attention_perm
I0611 16:17:03.441797  8258 net.cpp:454] attention_perm <- attention
I0611 16:17:03.441805  8258 net.cpp:411] attention_perm -> attention_perm
I0611 16:17:03.441875  8258 net.cpp:150] Setting up attention_perm
I0611 16:17:03.441880  8258 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 16:17:03.441884  8258 net.cpp:165] Memory required for data: 1463784592
I0611 16:17:03.441887  8258 layer_factory.hpp:77] Creating layer out
I0611 16:17:03.441893  8258 net.cpp:106] Creating Layer out
I0611 16:17:03.441898  8258 net.cpp:454] out <- value_conv_reshape_perm
I0611 16:17:03.441902  8258 net.cpp:454] out <- attention_perm
I0611 16:17:03.441910  8258 net.cpp:411] out -> out
I0611 16:17:03.441931  8258 net.cpp:150] Setting up out
I0611 16:17:03.441936  8258 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0611 16:17:03.441939  8258 net.cpp:165] Memory required for data: 1465627792
I0611 16:17:03.441943  8258 layer_factory.hpp:77] Creating layer out_reshape
I0611 16:17:03.441949  8258 net.cpp:106] Creating Layer out_reshape
I0611 16:17:03.441953  8258 net.cpp:454] out_reshape <- out
I0611 16:17:03.441958  8258 net.cpp:411] out_reshape -> out_reshape
I0611 16:17:03.441982  8258 net.cpp:150] Setting up out_reshape
I0611 16:17:03.441987  8258 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:17:03.441989  8258 net.cpp:165] Memory required for data: 1467470992
I0611 16:17:03.441993  8258 layer_factory.hpp:77] Creating layer out_reshape_scale
I0611 16:17:03.442005  8258 net.cpp:106] Creating Layer out_reshape_scale
I0611 16:17:03.442009  8258 net.cpp:454] out_reshape_scale <- out_reshape
I0611 16:17:03.442016  8258 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0611 16:17:03.442081  8258 net.cpp:150] Setting up out_reshape_scale
I0611 16:17:03.442087  8258 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:17:03.442090  8258 net.cpp:165] Memory required for data: 1469314192
I0611 16:17:03.442095  8258 layer_factory.hpp:77] Creating layer out_x
I0611 16:17:03.442107  8258 net.cpp:106] Creating Layer out_x
I0611 16:17:03.442111  8258 net.cpp:454] out_x <- out_reshape_scale
I0611 16:17:03.442116  8258 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0611 16:17:03.442123  8258 net.cpp:411] out_x -> out_x
I0611 16:17:03.442145  8258 net.cpp:150] Setting up out_x
I0611 16:17:03.442150  8258 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:17:03.442153  8258 net.cpp:165] Memory required for data: 1471157392
I0611 16:17:03.442157  8258 layer_factory.hpp:77] Creating layer mask_deconv2
I0611 16:17:03.442167  8258 net.cpp:106] Creating Layer mask_deconv2
I0611 16:17:03.442170  8258 net.cpp:454] mask_deconv2 <- out_x
I0611 16:17:03.442178  8258 net.cpp:411] mask_deconv2 -> mask_deconv2
I0611 16:17:03.442979  8258 net.cpp:150] Setting up mask_deconv2
I0611 16:17:03.442986  8258 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0611 16:17:03.442989  8258 net.cpp:165] Memory required for data: 1486398608
I0611 16:17:03.442996  8258 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0611 16:17:03.443008  8258 net.cpp:106] Creating Layer pool5_2_conv5
I0611 16:17:03.443013  8258 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0611 16:17:03.443019  8258 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0611 16:17:03.469661  8258 net.cpp:150] Setting up pool5_2_conv5
I0611 16:17:03.469681  8258 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 16:17:03.469686  8258 net.cpp:165] Memory required for data: 1516881040
I0611 16:17:03.469707  8258 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0611 16:17:03.469717  8258 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0611 16:17:03.469725  8258 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0611 16:17:03.469743  8258 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0611 16:17:03.469939  8258 net.cpp:150] Setting up pool5_2_conv5_relu
I0611 16:17:03.469959  8258 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 16:17:03.469962  8258 net.cpp:165] Memory required for data: 1547363472
I0611 16:17:03.469976  8258 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0611 16:17:03.469990  8258 net.cpp:106] Creating Layer pool5_2_conv6
I0611 16:17:03.469995  8258 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0611 16:17:03.470012  8258 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0611 16:17:03.521457  8258 net.cpp:150] Setting up pool5_2_conv6
I0611 16:17:03.521476  8258 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 16:17:03.521481  8258 net.cpp:165] Memory required for data: 1577845904
I0611 16:17:03.521502  8258 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0611 16:17:03.521536  8258 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0611 16:17:03.521543  8258 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0611 16:17:03.521562  8258 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0611 16:17:03.522173  8258 net.cpp:150] Setting up pool5_2_conv6_relu
I0611 16:17:03.522183  8258 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 16:17:03.522187  8258 net.cpp:165] Memory required for data: 1608328336
I0611 16:17:03.522192  8258 layer_factory.hpp:77] Creating layer mask_deconv3
I0611 16:17:03.522203  8258 net.cpp:106] Creating Layer mask_deconv3
I0611 16:17:03.522219  8258 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0611 16:17:03.522235  8258 net.cpp:411] mask_deconv3 -> mask_deconv3
I0611 16:17:03.522642  8258 net.cpp:150] Setting up mask_deconv3
I0611 16:17:03.522650  8258 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0611 16:17:03.522653  8258 net.cpp:165] Memory required for data: 1669293200
I0611 16:17:03.522660  8258 layer_factory.hpp:77] Creating layer mask_score
I0611 16:17:03.522671  8258 net.cpp:106] Creating Layer mask_score
I0611 16:17:03.522687  8258 net.cpp:454] mask_score <- mask_deconv3
I0611 16:17:03.522704  8258 net.cpp:411] mask_score -> mask_score
I0611 16:17:03.523319  8258 net.cpp:150] Setting up mask_score
I0611 16:17:03.523327  8258 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0611 16:17:03.523331  8258 net.cpp:165] Memory required for data: 1671198352
I0611 16:17:03.523337  8258 layer_factory.hpp:77] Creating layer loss_mask
I0611 16:17:03.523349  8258 net.cpp:106] Creating Layer loss_mask
I0611 16:17:03.523365  8258 net.cpp:454] loss_mask <- mask_score
I0611 16:17:03.523378  8258 net.cpp:454] loss_mask <- mask_targets
I0611 16:17:03.523385  8258 net.cpp:411] loss_mask -> loss_mask
I0611 16:17:03.523403  8258 layer_factory.hpp:77] Creating layer loss_mask
I0611 16:17:03.524830  8258 net.cpp:150] Setting up loss_mask
I0611 16:17:03.524839  8258 net.cpp:157] Top shape: (1)
I0611 16:17:03.524842  8258 net.cpp:160]     with loss weight 3
I0611 16:17:03.524853  8258 net.cpp:165] Memory required for data: 1671198356
I0611 16:17:03.524858  8258 net.cpp:226] loss_mask needs backward computation.
I0611 16:17:03.524863  8258 net.cpp:226] mask_score needs backward computation.
I0611 16:17:03.524878  8258 net.cpp:226] mask_deconv3 needs backward computation.
I0611 16:17:03.524894  8258 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0611 16:17:03.524899  8258 net.cpp:226] pool5_2_conv6 needs backward computation.
I0611 16:17:03.524904  8258 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0611 16:17:03.524907  8258 net.cpp:226] pool5_2_conv5 needs backward computation.
I0611 16:17:03.524910  8258 net.cpp:226] mask_deconv2 needs backward computation.
I0611 16:17:03.524924  8258 net.cpp:226] out_x needs backward computation.
I0611 16:17:03.524929  8258 net.cpp:226] out_reshape_scale needs backward computation.
I0611 16:17:03.524935  8258 net.cpp:226] out_reshape needs backward computation.
I0611 16:17:03.524940  8258 net.cpp:226] out needs backward computation.
I0611 16:17:03.524945  8258 net.cpp:226] attention_perm needs backward computation.
I0611 16:17:03.524950  8258 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0611 16:17:03.524955  8258 net.cpp:226] attention needs backward computation.
I0611 16:17:03.524960  8258 net.cpp:226] energy needs backward computation.
I0611 16:17:03.524976  8258 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0611 16:17:03.524981  8258 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0611 16:17:03.524987  8258 net.cpp:226] value_conv_reshape needs backward computation.
I0611 16:17:03.524991  8258 net.cpp:226] key_conv_reshape needs backward computation.
I0611 16:17:03.524997  8258 net.cpp:226] query_conv_reshape needs backward computation.
I0611 16:17:03.525002  8258 net.cpp:226] value_conv needs backward computation.
I0611 16:17:03.525007  8258 net.cpp:226] key_conv needs backward computation.
I0611 16:17:03.525010  8258 net.cpp:226] query_conv needs backward computation.
I0611 16:17:03.525015  8258 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0611 16:17:03.525020  8258 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0611 16:17:03.525027  8258 net.cpp:226] pool5_2_conv4 needs backward computation.
I0611 16:17:03.525039  8258 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0611 16:17:03.525055  8258 net.cpp:226] pool5_2_conv3 needs backward computation.
I0611 16:17:03.525059  8258 net.cpp:226] mask_deconv1 needs backward computation.
I0611 16:17:03.525064  8258 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0611 16:17:03.525070  8258 net.cpp:226] pool5_2_conv2 needs backward computation.
I0611 16:17:03.525075  8258 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0611 16:17:03.525079  8258 net.cpp:226] pool5_2_conv needs backward computation.
I0611 16:17:03.525092  8258 net.cpp:226] roi_pool5_2 needs backward computation.
I0611 16:17:03.525097  8258 net.cpp:226] loss_bbox needs backward computation.
I0611 16:17:03.525104  8258 net.cpp:226] loss_cls needs backward computation.
I0611 16:17:03.525108  8258 net.cpp:226] loss_attribute needs backward computation.
I0611 16:17:03.525115  8258 net.cpp:226] bbox_pred needs backward computation.
I0611 16:17:03.525120  8258 net.cpp:226] cls_score needs backward computation.
I0611 16:17:03.525123  8258 net.cpp:226] attr_score_pos needs backward computation.
I0611 16:17:03.525130  8258 net.cpp:226] attr_score needs backward computation.
I0611 16:17:03.525135  8258 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0611 16:17:03.525140  8258 net.cpp:226] relu7 needs backward computation.
I0611 16:17:03.525143  8258 net.cpp:226] fc7 needs backward computation.
I0611 16:17:03.525147  8258 net.cpp:226] relu6 needs backward computation.
I0611 16:17:03.525151  8258 net.cpp:226] fc6 needs backward computation.
I0611 16:17:03.525156  8258 net.cpp:226] roi_pool5 needs backward computation.
I0611 16:17:03.525159  8258 net.cpp:226] roi-data needs backward computation.
I0611 16:17:03.525166  8258 net.cpp:226] proposal needs backward computation.
I0611 16:17:03.525172  8258 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0611 16:17:03.525178  8258 net.cpp:226] rpn_cls_prob needs backward computation.
I0611 16:17:03.525183  8258 net.cpp:226] rpn_loss_bbox needs backward computation.
I0611 16:17:03.525187  8258 net.cpp:226] rpn_loss_cls needs backward computation.
I0611 16:17:03.525192  8258 net.cpp:226] rpn-data needs backward computation.
I0611 16:17:03.525199  8258 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0611 16:17:03.525204  8258 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0611 16:17:03.525208  8258 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0611 16:17:03.525213  8258 net.cpp:226] rpn_bbox_pred needs backward computation.
I0611 16:17:03.525228  8258 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0611 16:17:03.525233  8258 net.cpp:226] rpn_cls_score needs backward computation.
I0611 16:17:03.525238  8258 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0611 16:17:03.525243  8258 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0611 16:17:03.525246  8258 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0611 16:17:03.525260  8258 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0611 16:17:03.525265  8258 net.cpp:226] relu5_3 needs backward computation.
I0611 16:17:03.525269  8258 net.cpp:226] conv5_3 needs backward computation.
I0611 16:17:03.525272  8258 net.cpp:226] relu5_2 needs backward computation.
I0611 16:17:03.525276  8258 net.cpp:226] conv5_2 needs backward computation.
I0611 16:17:03.525291  8258 net.cpp:226] relu5_1 needs backward computation.
I0611 16:17:03.525297  8258 net.cpp:226] conv5_1 needs backward computation.
I0611 16:17:03.525302  8258 net.cpp:226] pool4 needs backward computation.
I0611 16:17:03.525308  8258 net.cpp:226] relu4_3 needs backward computation.
I0611 16:17:03.525321  8258 net.cpp:226] conv4_3 needs backward computation.
I0611 16:17:03.525326  8258 net.cpp:226] relu4_2 needs backward computation.
I0611 16:17:03.525328  8258 net.cpp:226] conv4_2 needs backward computation.
I0611 16:17:03.525333  8258 net.cpp:226] relu4_1 needs backward computation.
I0611 16:17:03.525338  8258 net.cpp:226] conv4_1 needs backward computation.
I0611 16:17:03.525342  8258 net.cpp:226] pool3 needs backward computation.
I0611 16:17:03.525346  8258 net.cpp:226] relu3_3 needs backward computation.
I0611 16:17:03.525351  8258 net.cpp:226] conv3_3 needs backward computation.
I0611 16:17:03.525354  8258 net.cpp:226] relu3_2 needs backward computation.
I0611 16:17:03.525359  8258 net.cpp:226] conv3_2 needs backward computation.
I0611 16:17:03.525372  8258 net.cpp:226] relu3_1 needs backward computation.
I0611 16:17:03.525377  8258 net.cpp:226] conv3_1 needs backward computation.
I0611 16:17:03.525380  8258 net.cpp:228] pool2 does not need backward computation.
I0611 16:17:03.525395  8258 net.cpp:228] relu2_2 does not need backward computation.
I0611 16:17:03.525400  8258 net.cpp:228] conv2_2 does not need backward computation.
I0611 16:17:03.525404  8258 net.cpp:228] relu2_1 does not need backward computation.
I0611 16:17:03.525408  8258 net.cpp:228] conv2_1 does not need backward computation.
I0611 16:17:03.525430  8258 net.cpp:228] pool1 does not need backward computation.
I0611 16:17:03.525435  8258 net.cpp:228] relu1_2 does not need backward computation.
I0611 16:17:03.525439  8258 net.cpp:228] conv1_2 does not need backward computation.
I0611 16:17:03.525444  8258 net.cpp:228] relu1_1 does not need backward computation.
I0611 16:17:03.525447  8258 net.cpp:228] conv1_1 does not need backward computation.
I0611 16:17:03.525454  8258 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0611 16:17:03.525458  8258 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0611 16:17:03.525465  8258 net.cpp:228] data_input-data_0_split does not need backward computation.
I0611 16:17:03.525471  8258 net.cpp:228] input-data does not need backward computation.
I0611 16:17:03.525475  8258 net.cpp:270] This network produces output loss_attribute
I0611 16:17:03.525480  8258 net.cpp:270] This network produces output loss_bbox
I0611 16:17:03.525485  8258 net.cpp:270] This network produces output loss_cls
I0611 16:17:03.525490  8258 net.cpp:270] This network produces output loss_mask
I0611 16:17:03.525494  8258 net.cpp:270] This network produces output rpn_cls_loss
I0611 16:17:03.525498  8258 net.cpp:270] This network produces output rpn_loss_bbox
I0611 16:17:03.525553  8258 net.cpp:283] Network initialization done.
I0611 16:17:03.525750  8258 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0611 16:17:05.498009  8258 net.cpp:816] Ignoring source layer pool5
I0611 16:17:05.565189  8258 net.cpp:816] Ignoring source layer drop6
I0611 16:17:05.575968  8258 net.cpp:816] Ignoring source layer drop7
I0611 16:17:05.575984  8258 net.cpp:816] Ignoring source layer fc8
I0611 16:17:05.575989  8258 net.cpp:816] Ignoring source layer prob
Solving...
I0611 16:17:06.972594  8258 solver.cpp:229] Iteration 0, loss = 10.3894
I0611 16:17:06.972620  8258 solver.cpp:245]     Train net output #0: loss_attribute = 4.85356 (* 0.1 = 0.485356 loss)
I0611 16:17:06.972626  8258 solver.cpp:245]     Train net output #1: loss_bbox = 0.0916567 (* 2 = 0.183313 loss)
I0611 16:17:06.972630  8258 solver.cpp:245]     Train net output #2: loss_cls = 0.947394 (* 3 = 2.84218 loss)
I0611 16:17:06.972635  8258 solver.cpp:245]     Train net output #3: loss_mask = 2.08166 (* 3 = 6.24497 loss)
I0611 16:17:06.972640  8258 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.73882 (* 1 = 0.73882 loss)
I0611 16:17:06.972643  8258 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0189577 (* 1 = 0.0189577 loss)
I0611 16:17:06.972658  8258 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0611 16:17:25.181787  8258 solver.cpp:229] Iteration 20, loss = 7.13654
I0611 16:17:25.181815  8258 solver.cpp:245]     Train net output #0: loss_attribute = 4.83716 (* 0.1 = 0.483716 loss)
I0611 16:17:25.181833  8258 solver.cpp:245]     Train net output #1: loss_bbox = 0.0964804 (* 2 = 0.192961 loss)
I0611 16:17:25.181839  8258 solver.cpp:245]     Train net output #2: loss_cls = 0.0726647 (* 3 = 0.217994 loss)
I0611 16:17:25.181845  8258 solver.cpp:245]     Train net output #3: loss_mask = 1.84993 (* 3 = 5.54978 loss)
I0611 16:17:25.181852  8258 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.185448 (* 1 = 0.185448 loss)
I0611 16:17:25.181859  8258 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0153267 (* 1 = 0.0153267 loss)
I0611 16:17:25.181869  8258 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0611 16:17:50.363279  8258 solver.cpp:229] Iteration 40, loss = 6.37927
I0611 16:17:50.363317  8258 solver.cpp:245]     Train net output #0: loss_attribute = 4.82959 (* 0.1 = 0.482959 loss)
I0611 16:17:50.363327  8258 solver.cpp:245]     Train net output #1: loss_bbox = 0.0681671 (* 2 = 0.136334 loss)
I0611 16:17:50.363335  8258 solver.cpp:245]     Train net output #2: loss_cls = 0.0253777 (* 3 = 0.0761332 loss)
I0611 16:17:50.363342  8258 solver.cpp:245]     Train net output #3: loss_mask = 1.51288 (* 3 = 4.53865 loss)
I0611 16:17:50.363348  8258 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00494716 (* 1 = 0.00494716 loss)
I0611 16:17:50.363366  8258 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.022781 (* 1 = 0.022781 loss)
I0611 16:17:50.363373  8258 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0611 16:18:14.483847  8258 solver.cpp:229] Iteration 60, loss = 5.10411
I0611 16:18:14.483873  8258 solver.cpp:245]     Train net output #0: loss_attribute = 4.80255 (* 0.1 = 0.480255 loss)
I0611 16:18:14.483878  8258 solver.cpp:245]     Train net output #1: loss_bbox = 0.214963 (* 2 = 0.429927 loss)
I0611 16:18:14.483882  8258 solver.cpp:245]     Train net output #2: loss_cls = 0.0909121 (* 3 = 0.272736 loss)
I0611 16:18:14.483886  8258 solver.cpp:245]     Train net output #3: loss_mask = 1.38097 (* 3 = 4.14292 loss)
I0611 16:18:14.483891  8258 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0466514 (* 1 = 0.0466514 loss)
I0611 16:18:14.483904  8258 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00974656 (* 1 = 0.00974656 loss)
I0611 16:18:14.483909  8258 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0611 16:18:49.263257  8258 solver.cpp:229] Iteration 80, loss = 4.59704
I0611 16:18:49.263424  8258 solver.cpp:245]     Train net output #0: loss_attribute = 4.79803 (* 0.1 = 0.479803 loss)
I0611 16:18:49.263504  8258 solver.cpp:245]     Train net output #1: loss_bbox = 0.322958 (* 2 = 0.645917 loss)
I0611 16:18:49.263571  8258 solver.cpp:245]     Train net output #2: loss_cls = 0.139146 (* 3 = 0.417439 loss)
I0611 16:18:49.263622  8258 solver.cpp:245]     Train net output #3: loss_mask = 1.2941 (* 3 = 3.88229 loss)
I0611 16:18:49.263671  8258 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0851302 (* 1 = 0.0851302 loss)
I0611 16:18:49.263738  8258 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0637143 (* 1 = 0.0637143 loss)
I0611 16:18:49.263773  8258 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0611 16:19:16.580915  8258 solver.cpp:229] Iteration 100, loss = 5.65564
I0611 16:19:16.580941  8258 solver.cpp:245]     Train net output #0: loss_attribute = 4.83631 (* 0.1 = 0.483631 loss)
I0611 16:19:16.580947  8258 solver.cpp:245]     Train net output #1: loss_bbox = 0.00777418 (* 2 = 0.0155484 loss)
I0611 16:19:16.580952  8258 solver.cpp:245]     Train net output #2: loss_cls = 0.0806663 (* 3 = 0.241999 loss)
I0611 16:19:16.580957  8258 solver.cpp:245]     Train net output #3: loss_mask = 1.36687 (* 3 = 4.10062 loss)
I0611 16:19:16.580965  8258 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.236137 (* 1 = 0.236137 loss)
I0611 16:19:16.580981  8258 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.179667 (* 1 = 0.179667 loss)
I0611 16:19:16.580986  8258 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0611 16:19:43.234351  8258 solver.cpp:229] Iteration 120, loss = 4.53222
I0611 16:19:43.234378  8258 solver.cpp:245]     Train net output #0: loss_attribute = 4.78586 (* 0.1 = 0.478586 loss)
I0611 16:19:43.234385  8258 solver.cpp:245]     Train net output #1: loss_bbox = 0.0380488 (* 2 = 0.0760976 loss)
I0611 16:19:43.234390  8258 solver.cpp:245]     Train net output #2: loss_cls = 0.0729586 (* 3 = 0.218876 loss)
I0611 16:19:43.234395  8258 solver.cpp:245]     Train net output #3: loss_mask = 1.6683 (* 3 = 5.00491 loss)
I0611 16:19:43.234400  8258 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0101994 (* 1 = 0.0101994 loss)
I0611 16:19:43.234405  8258 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0500185 (* 1 = 0.0500185 loss)
I0611 16:19:43.234411  8258 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0611 16:20:06.806394  8258 solver.cpp:229] Iteration 140, loss = 4.41872
I0611 16:20:06.806421  8258 solver.cpp:245]     Train net output #0: loss_attribute = 4.79949 (* 0.1 = 0.479949 loss)
I0611 16:20:06.806427  8258 solver.cpp:245]     Train net output #1: loss_bbox = 0.0934453 (* 2 = 0.186891 loss)
I0611 16:20:06.806432  8258 solver.cpp:245]     Train net output #2: loss_cls = 0.0320405 (* 3 = 0.0961215 loss)
I0611 16:20:06.806437  8258 solver.cpp:245]     Train net output #3: loss_mask = 0.934754 (* 3 = 2.80426 loss)
I0611 16:20:06.806440  8258 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0209208 (* 1 = 0.0209208 loss)
I0611 16:20:06.806444  8258 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0640155 (* 1 = 0.0640155 loss)
I0611 16:20:06.806449  8258 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0611 16:20:36.370080  8258 solver.cpp:229] Iteration 160, loss = 4.36024
I0611 16:20:36.370162  8258 solver.cpp:245]     Train net output #0: loss_attribute = 4.72831 (* 0.1 = 0.472831 loss)
I0611 16:20:36.370190  8258 solver.cpp:245]     Train net output #1: loss_bbox = 0.149017 (* 2 = 0.298034 loss)
I0611 16:20:36.370208  8258 solver.cpp:245]     Train net output #2: loss_cls = 0.0572569 (* 3 = 0.171771 loss)
I0611 16:20:36.370229  8258 solver.cpp:245]     Train net output #3: loss_mask = 1.14895 (* 3 = 3.44686 loss)
I0611 16:20:36.370246  8258 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0250201 (* 1 = 0.0250201 loss)
I0611 16:20:36.370263  8258 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0285981 (* 1 = 0.0285981 loss)
I0611 16:20:36.370276  8258 sgd_solver.cpp:106] Iteration 160, lr = 0.001
