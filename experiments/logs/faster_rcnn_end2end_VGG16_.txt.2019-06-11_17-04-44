+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-11_17-04-44
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-11_17-04-44
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0611 17:04:52.070471 23394 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0611 17:04:52.070490 23394 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0611 17:04:52.071811 23394 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  top: "attrArray"
  top: "attrArrayInd"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "attr_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "attr_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "attr_score_pos"
  type: "Eltwise"
  bottom: "attr_score"
  bottom: "attrArrayInd"
  top: "attr_score_pos"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_attribute"
  type: "Python"
  bottom: "attr_score_pos"
  bottom: "attrArray"
  top: "loss_attribute"
  loss_weight: 0.5
  include {
    phase: TRAIN
  }
  python_param {
    module: "utils.SigmoidCrossEntropyWeightLossLayer"
    layer: "SigmoidCrossEntropyWeightLossLayer"
    param_str: "{\"cls_weight\":1}"
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_mask"
  type: "SoftmaxWithLoss"
  bottom: "mask_score"
  bottom: "mask_targets"
  top: "loss_mask"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
I0611 17:04:52.072136 23394 layer_factory.hpp:77] Creating layer input-data
I0611 17:04:52.112148 23394 net.cpp:106] Creating Layer input-data
I0611 17:04:52.112164 23394 net.cpp:411] input-data -> data
I0611 17:04:52.112171 23394 net.cpp:411] input-data -> im_info
I0611 17:04:52.112175 23394 net.cpp:411] input-data -> gt_boxes
I0611 17:04:52.112180 23394 net.cpp:411] input-data -> seg_mask_inds
I0611 17:04:52.112185 23394 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0611 17:04:52.122921 23394 net.cpp:150] Setting up input-data
I0611 17:04:52.122957 23394 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 17:04:52.122979 23394 net.cpp:157] Top shape: 1 3 (3)
I0611 17:04:52.122984 23394 net.cpp:157] Top shape: 1 4 (4)
I0611 17:04:52.122987 23394 net.cpp:157] Top shape: 1 2 (2)
I0611 17:04:52.122992 23394 net.cpp:157] Top shape: 1 1 (1)
I0611 17:04:52.122994 23394 net.cpp:165] Memory required for data: 7200040
I0611 17:04:52.123025 23394 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0611 17:04:52.123044 23394 net.cpp:106] Creating Layer data_input-data_0_split
I0611 17:04:52.123050 23394 net.cpp:454] data_input-data_0_split <- data
I0611 17:04:52.123057 23394 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0611 17:04:52.123069 23394 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0611 17:04:52.123109 23394 net.cpp:150] Setting up data_input-data_0_split
I0611 17:04:52.123116 23394 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 17:04:52.123131 23394 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 17:04:52.123134 23394 net.cpp:165] Memory required for data: 21600040
I0611 17:04:52.123137 23394 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0611 17:04:52.123147 23394 net.cpp:106] Creating Layer im_info_input-data_1_split
I0611 17:04:52.123152 23394 net.cpp:454] im_info_input-data_1_split <- im_info
I0611 17:04:52.123157 23394 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0611 17:04:52.123165 23394 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0611 17:04:52.123176 23394 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0611 17:04:52.123206 23394 net.cpp:150] Setting up im_info_input-data_1_split
I0611 17:04:52.123212 23394 net.cpp:157] Top shape: 1 3 (3)
I0611 17:04:52.123219 23394 net.cpp:157] Top shape: 1 3 (3)
I0611 17:04:52.123225 23394 net.cpp:157] Top shape: 1 3 (3)
I0611 17:04:52.123229 23394 net.cpp:165] Memory required for data: 21600076
I0611 17:04:52.123235 23394 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0611 17:04:52.123241 23394 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0611 17:04:52.123247 23394 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0611 17:04:52.123253 23394 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0611 17:04:52.123263 23394 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0611 17:04:52.123286 23394 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0611 17:04:52.123291 23394 net.cpp:157] Top shape: 1 4 (4)
I0611 17:04:52.123297 23394 net.cpp:157] Top shape: 1 4 (4)
I0611 17:04:52.123301 23394 net.cpp:165] Memory required for data: 21600108
I0611 17:04:52.123306 23394 layer_factory.hpp:77] Creating layer conv1_1
I0611 17:04:52.123319 23394 net.cpp:106] Creating Layer conv1_1
I0611 17:04:52.123324 23394 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0611 17:04:52.123330 23394 net.cpp:411] conv1_1 -> conv1_1
I0611 17:04:52.312069 23394 net.cpp:150] Setting up conv1_1
I0611 17:04:52.312090 23394 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 17:04:52.312094 23394 net.cpp:165] Memory required for data: 175200108
I0611 17:04:52.312109 23394 layer_factory.hpp:77] Creating layer relu1_1
I0611 17:04:52.312120 23394 net.cpp:106] Creating Layer relu1_1
I0611 17:04:52.312139 23394 net.cpp:454] relu1_1 <- conv1_1
I0611 17:04:52.312144 23394 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0611 17:04:52.312265 23394 net.cpp:150] Setting up relu1_1
I0611 17:04:52.312273 23394 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 17:04:52.312276 23394 net.cpp:165] Memory required for data: 328800108
I0611 17:04:52.312279 23394 layer_factory.hpp:77] Creating layer conv1_2
I0611 17:04:52.312289 23394 net.cpp:106] Creating Layer conv1_2
I0611 17:04:52.312294 23394 net.cpp:454] conv1_2 <- conv1_1
I0611 17:04:52.312300 23394 net.cpp:411] conv1_2 -> conv1_2
I0611 17:04:52.314375 23394 net.cpp:150] Setting up conv1_2
I0611 17:04:52.314385 23394 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 17:04:52.314389 23394 net.cpp:165] Memory required for data: 482400108
I0611 17:04:52.314399 23394 layer_factory.hpp:77] Creating layer relu1_2
I0611 17:04:52.314404 23394 net.cpp:106] Creating Layer relu1_2
I0611 17:04:52.314409 23394 net.cpp:454] relu1_2 <- conv1_2
I0611 17:04:52.314424 23394 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0611 17:04:52.314540 23394 net.cpp:150] Setting up relu1_2
I0611 17:04:52.314548 23394 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 17:04:52.314550 23394 net.cpp:165] Memory required for data: 636000108
I0611 17:04:52.314554 23394 layer_factory.hpp:77] Creating layer pool1
I0611 17:04:52.314564 23394 net.cpp:106] Creating Layer pool1
I0611 17:04:52.314569 23394 net.cpp:454] pool1 <- conv1_2
I0611 17:04:52.314575 23394 net.cpp:411] pool1 -> pool1
I0611 17:04:52.314612 23394 net.cpp:150] Setting up pool1
I0611 17:04:52.314618 23394 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0611 17:04:52.314621 23394 net.cpp:165] Memory required for data: 674400108
I0611 17:04:52.314625 23394 layer_factory.hpp:77] Creating layer conv2_1
I0611 17:04:52.314633 23394 net.cpp:106] Creating Layer conv2_1
I0611 17:04:52.314638 23394 net.cpp:454] conv2_1 <- pool1
I0611 17:04:52.314644 23394 net.cpp:411] conv2_1 -> conv2_1
I0611 17:04:52.316310 23394 net.cpp:150] Setting up conv2_1
I0611 17:04:52.316319 23394 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 17:04:52.316323 23394 net.cpp:165] Memory required for data: 751200108
I0611 17:04:52.316332 23394 layer_factory.hpp:77] Creating layer relu2_1
I0611 17:04:52.316341 23394 net.cpp:106] Creating Layer relu2_1
I0611 17:04:52.316345 23394 net.cpp:454] relu2_1 <- conv2_1
I0611 17:04:52.316361 23394 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0611 17:04:52.316823 23394 net.cpp:150] Setting up relu2_1
I0611 17:04:52.316830 23394 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 17:04:52.316834 23394 net.cpp:165] Memory required for data: 828000108
I0611 17:04:52.316838 23394 layer_factory.hpp:77] Creating layer conv2_2
I0611 17:04:52.316846 23394 net.cpp:106] Creating Layer conv2_2
I0611 17:04:52.316851 23394 net.cpp:454] conv2_2 <- conv2_1
I0611 17:04:52.316867 23394 net.cpp:411] conv2_2 -> conv2_2
I0611 17:04:52.318123 23394 net.cpp:150] Setting up conv2_2
I0611 17:04:52.318133 23394 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 17:04:52.318136 23394 net.cpp:165] Memory required for data: 904800108
I0611 17:04:52.318143 23394 layer_factory.hpp:77] Creating layer relu2_2
I0611 17:04:52.318151 23394 net.cpp:106] Creating Layer relu2_2
I0611 17:04:52.318156 23394 net.cpp:454] relu2_2 <- conv2_2
I0611 17:04:52.318174 23394 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0611 17:04:52.318292 23394 net.cpp:150] Setting up relu2_2
I0611 17:04:52.318300 23394 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 17:04:52.318302 23394 net.cpp:165] Memory required for data: 981600108
I0611 17:04:52.318306 23394 layer_factory.hpp:77] Creating layer pool2
I0611 17:04:52.318323 23394 net.cpp:106] Creating Layer pool2
I0611 17:04:52.318327 23394 net.cpp:454] pool2 <- conv2_2
I0611 17:04:52.318333 23394 net.cpp:411] pool2 -> pool2
I0611 17:04:52.318365 23394 net.cpp:150] Setting up pool2
I0611 17:04:52.318372 23394 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0611 17:04:52.318374 23394 net.cpp:165] Memory required for data: 1000800108
I0611 17:04:52.318387 23394 layer_factory.hpp:77] Creating layer conv3_1
I0611 17:04:52.318408 23394 net.cpp:106] Creating Layer conv3_1
I0611 17:04:52.318413 23394 net.cpp:454] conv3_1 <- pool2
I0611 17:04:52.318418 23394 net.cpp:411] conv3_1 -> conv3_1
I0611 17:04:52.320253 23394 net.cpp:150] Setting up conv3_1
I0611 17:04:52.320263 23394 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 17:04:52.320267 23394 net.cpp:165] Memory required for data: 1039200108
I0611 17:04:52.320288 23394 layer_factory.hpp:77] Creating layer relu3_1
I0611 17:04:52.320307 23394 net.cpp:106] Creating Layer relu3_1
I0611 17:04:52.320312 23394 net.cpp:454] relu3_1 <- conv3_1
I0611 17:04:52.320319 23394 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0611 17:04:52.320448 23394 net.cpp:150] Setting up relu3_1
I0611 17:04:52.320456 23394 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 17:04:52.320458 23394 net.cpp:165] Memory required for data: 1077600108
I0611 17:04:52.320462 23394 layer_factory.hpp:77] Creating layer conv3_2
I0611 17:04:52.320482 23394 net.cpp:106] Creating Layer conv3_2
I0611 17:04:52.320497 23394 net.cpp:454] conv3_2 <- conv3_1
I0611 17:04:52.320513 23394 net.cpp:411] conv3_2 -> conv3_2
I0611 17:04:52.322613 23394 net.cpp:150] Setting up conv3_2
I0611 17:04:52.322624 23394 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 17:04:52.322628 23394 net.cpp:165] Memory required for data: 1116000108
I0611 17:04:52.322644 23394 layer_factory.hpp:77] Creating layer relu3_2
I0611 17:04:52.322651 23394 net.cpp:106] Creating Layer relu3_2
I0611 17:04:52.322669 23394 net.cpp:454] relu3_2 <- conv3_2
I0611 17:04:52.322677 23394 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0611 17:04:52.322831 23394 net.cpp:150] Setting up relu3_2
I0611 17:04:52.322839 23394 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 17:04:52.322841 23394 net.cpp:165] Memory required for data: 1154400108
I0611 17:04:52.322845 23394 layer_factory.hpp:77] Creating layer conv3_3
I0611 17:04:52.322856 23394 net.cpp:106] Creating Layer conv3_3
I0611 17:04:52.322861 23394 net.cpp:454] conv3_3 <- conv3_2
I0611 17:04:52.322876 23394 net.cpp:411] conv3_3 -> conv3_3
I0611 17:04:52.324836 23394 net.cpp:150] Setting up conv3_3
I0611 17:04:52.324846 23394 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 17:04:52.324849 23394 net.cpp:165] Memory required for data: 1192800108
I0611 17:04:52.324867 23394 layer_factory.hpp:77] Creating layer relu3_3
I0611 17:04:52.324877 23394 net.cpp:106] Creating Layer relu3_3
I0611 17:04:52.324882 23394 net.cpp:454] relu3_3 <- conv3_3
I0611 17:04:52.324892 23394 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0611 17:04:52.325011 23394 net.cpp:150] Setting up relu3_3
I0611 17:04:52.325018 23394 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 17:04:52.325021 23394 net.cpp:165] Memory required for data: 1231200108
I0611 17:04:52.325026 23394 layer_factory.hpp:77] Creating layer pool3
I0611 17:04:52.325034 23394 net.cpp:106] Creating Layer pool3
I0611 17:04:52.325039 23394 net.cpp:454] pool3 <- conv3_3
I0611 17:04:52.325047 23394 net.cpp:411] pool3 -> pool3
I0611 17:04:52.325085 23394 net.cpp:150] Setting up pool3
I0611 17:04:52.325093 23394 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0611 17:04:52.325095 23394 net.cpp:165] Memory required for data: 1240800108
I0611 17:04:52.325098 23394 layer_factory.hpp:77] Creating layer conv4_1
I0611 17:04:52.325107 23394 net.cpp:106] Creating Layer conv4_1
I0611 17:04:52.325114 23394 net.cpp:454] conv4_1 <- pool3
I0611 17:04:52.325121 23394 net.cpp:411] conv4_1 -> conv4_1
I0611 17:04:52.328842 23394 net.cpp:150] Setting up conv4_1
I0611 17:04:52.328863 23394 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 17:04:52.328866 23394 net.cpp:165] Memory required for data: 1260000108
I0611 17:04:52.328876 23394 layer_factory.hpp:77] Creating layer relu4_1
I0611 17:04:52.328886 23394 net.cpp:106] Creating Layer relu4_1
I0611 17:04:52.328892 23394 net.cpp:454] relu4_1 <- conv4_1
I0611 17:04:52.328899 23394 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0611 17:04:52.329022 23394 net.cpp:150] Setting up relu4_1
I0611 17:04:52.329030 23394 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 17:04:52.329032 23394 net.cpp:165] Memory required for data: 1279200108
I0611 17:04:52.329036 23394 layer_factory.hpp:77] Creating layer conv4_2
I0611 17:04:52.329047 23394 net.cpp:106] Creating Layer conv4_2
I0611 17:04:52.329052 23394 net.cpp:454] conv4_2 <- conv4_1
I0611 17:04:52.329058 23394 net.cpp:411] conv4_2 -> conv4_2
I0611 17:04:52.333662 23394 net.cpp:150] Setting up conv4_2
I0611 17:04:52.333683 23394 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 17:04:52.333685 23394 net.cpp:165] Memory required for data: 1298400108
I0611 17:04:52.333701 23394 layer_factory.hpp:77] Creating layer relu4_2
I0611 17:04:52.333711 23394 net.cpp:106] Creating Layer relu4_2
I0611 17:04:52.333717 23394 net.cpp:454] relu4_2 <- conv4_2
I0611 17:04:52.333725 23394 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0611 17:04:52.334226 23394 net.cpp:150] Setting up relu4_2
I0611 17:04:52.334235 23394 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 17:04:52.334239 23394 net.cpp:165] Memory required for data: 1317600108
I0611 17:04:52.334242 23394 layer_factory.hpp:77] Creating layer conv4_3
I0611 17:04:52.334254 23394 net.cpp:106] Creating Layer conv4_3
I0611 17:04:52.334260 23394 net.cpp:454] conv4_3 <- conv4_2
I0611 17:04:52.334269 23394 net.cpp:411] conv4_3 -> conv4_3
I0611 17:04:52.339015 23394 net.cpp:150] Setting up conv4_3
I0611 17:04:52.339035 23394 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 17:04:52.339038 23394 net.cpp:165] Memory required for data: 1336800108
I0611 17:04:52.339047 23394 layer_factory.hpp:77] Creating layer relu4_3
I0611 17:04:52.339058 23394 net.cpp:106] Creating Layer relu4_3
I0611 17:04:52.339066 23394 net.cpp:454] relu4_3 <- conv4_3
I0611 17:04:52.339083 23394 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0611 17:04:52.339210 23394 net.cpp:150] Setting up relu4_3
I0611 17:04:52.339216 23394 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 17:04:52.339220 23394 net.cpp:165] Memory required for data: 1356000108
I0611 17:04:52.339223 23394 layer_factory.hpp:77] Creating layer pool4
I0611 17:04:52.339243 23394 net.cpp:106] Creating Layer pool4
I0611 17:04:52.339249 23394 net.cpp:454] pool4 <- conv4_3
I0611 17:04:52.339256 23394 net.cpp:411] pool4 -> pool4
I0611 17:04:52.339301 23394 net.cpp:150] Setting up pool4
I0611 17:04:52.339308 23394 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 17:04:52.339311 23394 net.cpp:165] Memory required for data: 1360903020
I0611 17:04:52.339324 23394 layer_factory.hpp:77] Creating layer conv5_1
I0611 17:04:52.339344 23394 net.cpp:106] Creating Layer conv5_1
I0611 17:04:52.339350 23394 net.cpp:454] conv5_1 <- pool4
I0611 17:04:52.339368 23394 net.cpp:411] conv5_1 -> conv5_1
I0611 17:04:52.343566 23394 net.cpp:150] Setting up conv5_1
I0611 17:04:52.343587 23394 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 17:04:52.343591 23394 net.cpp:165] Memory required for data: 1365805932
I0611 17:04:52.343600 23394 layer_factory.hpp:77] Creating layer relu5_1
I0611 17:04:52.343621 23394 net.cpp:106] Creating Layer relu5_1
I0611 17:04:52.343638 23394 net.cpp:454] relu5_1 <- conv5_1
I0611 17:04:52.343655 23394 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0611 17:04:52.343785 23394 net.cpp:150] Setting up relu5_1
I0611 17:04:52.343791 23394 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 17:04:52.343796 23394 net.cpp:165] Memory required for data: 1370708844
I0611 17:04:52.343798 23394 layer_factory.hpp:77] Creating layer conv5_2
I0611 17:04:52.343819 23394 net.cpp:106] Creating Layer conv5_2
I0611 17:04:52.343824 23394 net.cpp:454] conv5_2 <- conv5_1
I0611 17:04:52.343832 23394 net.cpp:411] conv5_2 -> conv5_2
I0611 17:04:52.348014 23394 net.cpp:150] Setting up conv5_2
I0611 17:04:52.348038 23394 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 17:04:52.348042 23394 net.cpp:165] Memory required for data: 1375611756
I0611 17:04:52.348052 23394 layer_factory.hpp:77] Creating layer relu5_2
I0611 17:04:52.348062 23394 net.cpp:106] Creating Layer relu5_2
I0611 17:04:52.348067 23394 net.cpp:454] relu5_2 <- conv5_2
I0611 17:04:52.348073 23394 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0611 17:04:52.348212 23394 net.cpp:150] Setting up relu5_2
I0611 17:04:52.348220 23394 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 17:04:52.348223 23394 net.cpp:165] Memory required for data: 1380514668
I0611 17:04:52.348227 23394 layer_factory.hpp:77] Creating layer conv5_3
I0611 17:04:52.348240 23394 net.cpp:106] Creating Layer conv5_3
I0611 17:04:52.348258 23394 net.cpp:454] conv5_3 <- conv5_2
I0611 17:04:52.348274 23394 net.cpp:411] conv5_3 -> conv5_3
I0611 17:04:52.352558 23394 net.cpp:150] Setting up conv5_3
I0611 17:04:52.352581 23394 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 17:04:52.352584 23394 net.cpp:165] Memory required for data: 1385417580
I0611 17:04:52.352592 23394 layer_factory.hpp:77] Creating layer relu5_3
I0611 17:04:52.352604 23394 net.cpp:106] Creating Layer relu5_3
I0611 17:04:52.352610 23394 net.cpp:454] relu5_3 <- conv5_3
I0611 17:04:52.352618 23394 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0611 17:04:52.352756 23394 net.cpp:150] Setting up relu5_3
I0611 17:04:52.352762 23394 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 17:04:52.352766 23394 net.cpp:165] Memory required for data: 1390320492
I0611 17:04:52.352769 23394 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0611 17:04:52.352775 23394 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0611 17:04:52.352782 23394 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0611 17:04:52.352787 23394 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0611 17:04:52.352797 23394 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0611 17:04:52.352803 23394 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0611 17:04:52.352840 23394 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0611 17:04:52.352846 23394 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 17:04:52.352851 23394 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 17:04:52.352855 23394 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 17:04:52.352860 23394 net.cpp:165] Memory required for data: 1405029228
I0611 17:04:52.352864 23394 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0611 17:04:52.352875 23394 net.cpp:106] Creating Layer rpn_conv/3x3
I0611 17:04:52.352880 23394 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0611 17:04:52.352888 23394 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0611 17:04:52.403290 23394 net.cpp:150] Setting up rpn_conv/3x3
I0611 17:04:52.403311 23394 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 17:04:52.403313 23394 net.cpp:165] Memory required for data: 1409932140
I0611 17:04:52.403322 23394 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0611 17:04:52.403331 23394 net.cpp:106] Creating Layer rpn_relu/3x3
I0611 17:04:52.403348 23394 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0611 17:04:52.403364 23394 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0611 17:04:52.403504 23394 net.cpp:150] Setting up rpn_relu/3x3
I0611 17:04:52.403512 23394 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 17:04:52.403515 23394 net.cpp:165] Memory required for data: 1414835052
I0611 17:04:52.403519 23394 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0611 17:04:52.403525 23394 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0611 17:04:52.403529 23394 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0611 17:04:52.403535 23394 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0611 17:04:52.403553 23394 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0611 17:04:52.403615 23394 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0611 17:04:52.403631 23394 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 17:04:52.403635 23394 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 17:04:52.403638 23394 net.cpp:165] Memory required for data: 1424640876
I0611 17:04:52.403650 23394 layer_factory.hpp:77] Creating layer rpn_cls_score
I0611 17:04:52.403672 23394 net.cpp:106] Creating Layer rpn_cls_score
I0611 17:04:52.403687 23394 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0611 17:04:52.403694 23394 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0611 17:04:52.405563 23394 net.cpp:150] Setting up rpn_cls_score
I0611 17:04:52.405586 23394 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 17:04:52.405591 23394 net.cpp:165] Memory required for data: 1424928156
I0611 17:04:52.405607 23394 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0611 17:04:52.405616 23394 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0611 17:04:52.405619 23394 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0611 17:04:52.405624 23394 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0611 17:04:52.405632 23394 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0611 17:04:52.405679 23394 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0611 17:04:52.405686 23394 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 17:04:52.405700 23394 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 17:04:52.405704 23394 net.cpp:165] Memory required for data: 1425502716
I0611 17:04:52.405707 23394 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0611 17:04:52.405717 23394 net.cpp:106] Creating Layer rpn_bbox_pred
I0611 17:04:52.405726 23394 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0611 17:04:52.405737 23394 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0611 17:04:52.407382 23394 net.cpp:150] Setting up rpn_bbox_pred
I0611 17:04:52.407390 23394 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 17:04:52.407392 23394 net.cpp:165] Memory required for data: 1426077276
I0611 17:04:52.407397 23394 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 17:04:52.407400 23394 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 17:04:52.407403 23394 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0611 17:04:52.407407 23394 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0611 17:04:52.407423 23394 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0611 17:04:52.407459 23394 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 17:04:52.407464 23394 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 17:04:52.407480 23394 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 17:04:52.407481 23394 net.cpp:165] Memory required for data: 1427226396
I0611 17:04:52.407483 23394 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0611 17:04:52.407497 23394 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0611 17:04:52.407500 23394 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0611 17:04:52.407503 23394 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0611 17:04:52.407532 23394 net.cpp:150] Setting up rpn_cls_score_reshape
I0611 17:04:52.407536 23394 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 17:04:52.407548 23394 net.cpp:165] Memory required for data: 1427513676
I0611 17:04:52.407550 23394 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 17:04:52.407553 23394 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 17:04:52.407570 23394 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0611 17:04:52.407573 23394 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0611 17:04:52.407577 23394 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0611 17:04:52.407618 23394 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 17:04:52.407621 23394 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 17:04:52.407634 23394 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 17:04:52.407635 23394 net.cpp:165] Memory required for data: 1428088236
I0611 17:04:52.407637 23394 layer_factory.hpp:77] Creating layer rpn-data
I0611 17:04:52.407979 23394 net.cpp:106] Creating Layer rpn-data
I0611 17:04:52.407987 23394 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0611 17:04:52.407992 23394 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0611 17:04:52.407996 23394 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0611 17:04:52.408010 23394 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0611 17:04:52.408015 23394 net.cpp:411] rpn-data -> rpn_labels
I0611 17:04:52.408025 23394 net.cpp:411] rpn-data -> rpn_bbox_targets
I0611 17:04:52.408033 23394 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0611 17:04:52.408051 23394 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0611 17:04:52.408990 23394 net.cpp:150] Setting up rpn-data
I0611 17:04:52.408999 23394 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0611 17:04:52.409003 23394 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 17:04:52.409004 23394 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 17:04:52.409008 23394 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 17:04:52.409009 23394 net.cpp:165] Memory required for data: 1429955556
I0611 17:04:52.409011 23394 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0611 17:04:52.409018 23394 net.cpp:106] Creating Layer rpn_loss_cls
I0611 17:04:52.409031 23394 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0611 17:04:52.409035 23394 net.cpp:454] rpn_loss_cls <- rpn_labels
I0611 17:04:52.409050 23394 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0611 17:04:52.409059 23394 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0611 17:04:52.409710 23394 net.cpp:150] Setting up rpn_loss_cls
I0611 17:04:52.409719 23394 net.cpp:157] Top shape: (1)
I0611 17:04:52.409721 23394 net.cpp:160]     with loss weight 1
I0611 17:04:52.409740 23394 net.cpp:165] Memory required for data: 1429955560
I0611 17:04:52.409742 23394 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0611 17:04:52.409759 23394 net.cpp:106] Creating Layer rpn_loss_bbox
I0611 17:04:52.409761 23394 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0611 17:04:52.409765 23394 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0611 17:04:52.409768 23394 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0611 17:04:52.409770 23394 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0611 17:04:52.409775 23394 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0611 17:04:52.410881 23394 net.cpp:150] Setting up rpn_loss_bbox
I0611 17:04:52.410890 23394 net.cpp:157] Top shape: (1)
I0611 17:04:52.410893 23394 net.cpp:160]     with loss weight 1
I0611 17:04:52.410897 23394 net.cpp:165] Memory required for data: 1429955564
I0611 17:04:52.410910 23394 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0611 17:04:52.410914 23394 net.cpp:106] Creating Layer rpn_cls_prob
I0611 17:04:52.410917 23394 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0611 17:04:52.410930 23394 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0611 17:04:52.411106 23394 net.cpp:150] Setting up rpn_cls_prob
I0611 17:04:52.411113 23394 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 17:04:52.411114 23394 net.cpp:165] Memory required for data: 1430242844
I0611 17:04:52.411116 23394 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0611 17:04:52.411134 23394 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0611 17:04:52.411136 23394 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0611 17:04:52.411150 23394 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0611 17:04:52.411178 23394 net.cpp:150] Setting up rpn_cls_prob_reshape
I0611 17:04:52.411183 23394 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 17:04:52.411185 23394 net.cpp:165] Memory required for data: 1430530124
I0611 17:04:52.411188 23394 layer_factory.hpp:77] Creating layer proposal
I0611 17:04:52.427963 23394 net.cpp:106] Creating Layer proposal
I0611 17:04:52.427973 23394 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0611 17:04:52.427978 23394 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0611 17:04:52.427981 23394 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0611 17:04:52.427985 23394 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0611 17:04:52.428957 23394 net.cpp:150] Setting up proposal
I0611 17:04:52.428966 23394 net.cpp:157] Top shape: 1 5 (5)
I0611 17:04:52.428969 23394 net.cpp:165] Memory required for data: 1430530144
I0611 17:04:52.428972 23394 layer_factory.hpp:77] Creating layer roi-data
I0611 17:04:52.429199 23394 net.cpp:106] Creating Layer roi-data
I0611 17:04:52.429206 23394 net.cpp:454] roi-data <- rpn_rois
I0611 17:04:52.429210 23394 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0611 17:04:52.429214 23394 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0611 17:04:52.429216 23394 net.cpp:454] roi-data <- seg_mask_inds
I0611 17:04:52.429219 23394 net.cpp:454] roi-data <- flipped
I0611 17:04:52.429224 23394 net.cpp:411] roi-data -> rois
I0611 17:04:52.429239 23394 net.cpp:411] roi-data -> labels
I0611 17:04:52.429244 23394 net.cpp:411] roi-data -> bbox_targets
I0611 17:04:52.429260 23394 net.cpp:411] roi-data -> bbox_inside_weights
I0611 17:04:52.429265 23394 net.cpp:411] roi-data -> bbox_outside_weights
I0611 17:04:52.429270 23394 net.cpp:411] roi-data -> mask_targets
I0611 17:04:52.429275 23394 net.cpp:411] roi-data -> rois_pos
I0611 17:04:52.429280 23394 net.cpp:411] roi-data -> attrArray
I0611 17:04:52.429284 23394 net.cpp:411] roi-data -> attrArrayInd
I0611 17:04:52.429603 23394 net.cpp:150] Setting up roi-data
I0611 17:04:52.429611 23394 net.cpp:157] Top shape: 1 5 (5)
I0611 17:04:52.429615 23394 net.cpp:157] Top shape: 1 1 (1)
I0611 17:04:52.429616 23394 net.cpp:157] Top shape: 1 8 (8)
I0611 17:04:52.429620 23394 net.cpp:157] Top shape: 1 8 (8)
I0611 17:04:52.429621 23394 net.cpp:157] Top shape: 1 8 (8)
I0611 17:04:52.429625 23394 net.cpp:157] Top shape: 1 244 244 (59536)
I0611 17:04:52.429626 23394 net.cpp:157] Top shape: 1 5 (5)
I0611 17:04:52.429639 23394 net.cpp:157] Top shape: 1 7 (7)
I0611 17:04:52.429643 23394 net.cpp:157] Top shape: 1 7 (7)
I0611 17:04:52.429646 23394 net.cpp:165] Memory required for data: 1430768484
I0611 17:04:52.429658 23394 layer_factory.hpp:77] Creating layer roi_pool5
I0611 17:04:52.429664 23394 net.cpp:106] Creating Layer roi_pool5
I0611 17:04:52.429667 23394 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0611 17:04:52.429672 23394 net.cpp:454] roi_pool5 <- rois
I0611 17:04:52.429675 23394 net.cpp:411] roi_pool5 -> pool5
I0611 17:04:52.429682 23394 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0611 17:04:52.429760 23394 net.cpp:150] Setting up roi_pool5
I0611 17:04:52.429764 23394 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 17:04:52.429767 23394 net.cpp:165] Memory required for data: 1430868836
I0611 17:04:52.429770 23394 layer_factory.hpp:77] Creating layer fc6
I0611 17:04:52.429788 23394 net.cpp:106] Creating Layer fc6
I0611 17:04:52.429791 23394 net.cpp:454] fc6 <- pool5
I0611 17:04:52.429795 23394 net.cpp:411] fc6 -> fc6
I0611 17:04:52.569955 23394 net.cpp:150] Setting up fc6
I0611 17:04:52.569991 23394 net.cpp:157] Top shape: 1 4096 (4096)
I0611 17:04:52.569994 23394 net.cpp:165] Memory required for data: 1430885220
I0611 17:04:52.570009 23394 layer_factory.hpp:77] Creating layer relu6
I0611 17:04:52.570020 23394 net.cpp:106] Creating Layer relu6
I0611 17:04:52.570036 23394 net.cpp:454] relu6 <- fc6
I0611 17:04:52.570041 23394 net.cpp:397] relu6 -> fc6 (in-place)
I0611 17:04:52.570252 23394 net.cpp:150] Setting up relu6
I0611 17:04:52.570261 23394 net.cpp:157] Top shape: 1 4096 (4096)
I0611 17:04:52.570272 23394 net.cpp:165] Memory required for data: 1430901604
I0611 17:04:52.570276 23394 layer_factory.hpp:77] Creating layer fc7
I0611 17:04:52.570282 23394 net.cpp:106] Creating Layer fc7
I0611 17:04:52.570286 23394 net.cpp:454] fc7 <- fc6
I0611 17:04:52.570300 23394 net.cpp:411] fc7 -> fc7
I0611 17:04:52.593593 23394 net.cpp:150] Setting up fc7
I0611 17:04:52.593616 23394 net.cpp:157] Top shape: 1 4096 (4096)
I0611 17:04:52.593621 23394 net.cpp:165] Memory required for data: 1430917988
I0611 17:04:52.593628 23394 layer_factory.hpp:77] Creating layer relu7
I0611 17:04:52.593647 23394 net.cpp:106] Creating Layer relu7
I0611 17:04:52.593652 23394 net.cpp:454] relu7 <- fc7
I0611 17:04:52.593657 23394 net.cpp:397] relu7 -> fc7 (in-place)
I0611 17:04:52.593870 23394 net.cpp:150] Setting up relu7
I0611 17:04:52.593879 23394 net.cpp:157] Top shape: 1 4096 (4096)
I0611 17:04:52.593881 23394 net.cpp:165] Memory required for data: 1430934372
I0611 17:04:52.593884 23394 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0611 17:04:52.593889 23394 net.cpp:106] Creating Layer fc7_relu7_0_split
I0611 17:04:52.593892 23394 net.cpp:454] fc7_relu7_0_split <- fc7
I0611 17:04:52.593895 23394 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0611 17:04:52.593900 23394 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0611 17:04:52.593915 23394 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0611 17:04:52.593984 23394 net.cpp:150] Setting up fc7_relu7_0_split
I0611 17:04:52.593988 23394 net.cpp:157] Top shape: 1 4096 (4096)
I0611 17:04:52.593991 23394 net.cpp:157] Top shape: 1 4096 (4096)
I0611 17:04:52.593993 23394 net.cpp:157] Top shape: 1 4096 (4096)
I0611 17:04:52.593996 23394 net.cpp:165] Memory required for data: 1430983524
I0611 17:04:52.593997 23394 layer_factory.hpp:77] Creating layer attr_score
I0611 17:04:52.594003 23394 net.cpp:106] Creating Layer attr_score
I0611 17:04:52.594005 23394 net.cpp:454] attr_score <- fc7_relu7_0_split_0
I0611 17:04:52.594022 23394 net.cpp:411] attr_score -> attr_score
I0611 17:04:52.594696 23394 net.cpp:150] Setting up attr_score
I0611 17:04:52.594700 23394 net.cpp:157] Top shape: 1 7 (7)
I0611 17:04:52.594702 23394 net.cpp:165] Memory required for data: 1430983552
I0611 17:04:52.594707 23394 layer_factory.hpp:77] Creating layer attr_score_pos
I0611 17:04:52.594712 23394 net.cpp:106] Creating Layer attr_score_pos
I0611 17:04:52.594714 23394 net.cpp:454] attr_score_pos <- attr_score
I0611 17:04:52.594717 23394 net.cpp:454] attr_score_pos <- attrArrayInd
I0611 17:04:52.594732 23394 net.cpp:411] attr_score_pos -> attr_score_pos
I0611 17:04:52.594761 23394 net.cpp:150] Setting up attr_score_pos
I0611 17:04:52.594774 23394 net.cpp:157] Top shape: 1 7 (7)
I0611 17:04:52.594776 23394 net.cpp:165] Memory required for data: 1430983580
I0611 17:04:52.594779 23394 layer_factory.hpp:77] Creating layer cls_score
I0611 17:04:52.594791 23394 net.cpp:106] Creating Layer cls_score
I0611 17:04:52.594794 23394 net.cpp:454] cls_score <- fc7_relu7_0_split_1
I0611 17:04:52.594797 23394 net.cpp:411] cls_score -> cls_score
I0611 17:04:52.595039 23394 net.cpp:150] Setting up cls_score
I0611 17:04:52.595043 23394 net.cpp:157] Top shape: 1 2 (2)
I0611 17:04:52.595046 23394 net.cpp:165] Memory required for data: 1430983588
I0611 17:04:52.595048 23394 layer_factory.hpp:77] Creating layer bbox_pred
I0611 17:04:52.595054 23394 net.cpp:106] Creating Layer bbox_pred
I0611 17:04:52.595057 23394 net.cpp:454] bbox_pred <- fc7_relu7_0_split_2
I0611 17:04:52.595062 23394 net.cpp:411] bbox_pred -> bbox_pred
I0611 17:04:52.595789 23394 net.cpp:150] Setting up bbox_pred
I0611 17:04:52.595794 23394 net.cpp:157] Top shape: 1 8 (8)
I0611 17:04:52.595796 23394 net.cpp:165] Memory required for data: 1430983620
I0611 17:04:52.595799 23394 layer_factory.hpp:77] Creating layer loss_attribute
I0611 17:04:52.595993 23394 net.cpp:106] Creating Layer loss_attribute
I0611 17:04:52.595999 23394 net.cpp:454] loss_attribute <- attr_score_pos
I0611 17:04:52.596014 23394 net.cpp:454] loss_attribute <- attrArray
I0611 17:04:52.596017 23394 net.cpp:411] loss_attribute -> loss_attribute
I0611 17:04:52.596146 23394 net.cpp:150] Setting up loss_attribute
I0611 17:04:52.596153 23394 net.cpp:157] Top shape: 1 (1)
I0611 17:04:52.596166 23394 net.cpp:160]     with loss weight 0.5
I0611 17:04:52.596174 23394 net.cpp:165] Memory required for data: 1430983624
I0611 17:04:52.596177 23394 layer_factory.hpp:77] Creating layer loss_cls
I0611 17:04:52.596182 23394 net.cpp:106] Creating Layer loss_cls
I0611 17:04:52.596184 23394 net.cpp:454] loss_cls <- cls_score
I0611 17:04:52.596189 23394 net.cpp:454] loss_cls <- labels
I0611 17:04:52.596194 23394 net.cpp:411] loss_cls -> loss_cls
I0611 17:04:52.596210 23394 layer_factory.hpp:77] Creating layer loss_cls
I0611 17:04:52.597111 23394 net.cpp:150] Setting up loss_cls
I0611 17:04:52.597120 23394 net.cpp:157] Top shape: (1)
I0611 17:04:52.597122 23394 net.cpp:160]     with loss weight 3
I0611 17:04:52.597126 23394 net.cpp:165] Memory required for data: 1430983628
I0611 17:04:52.597129 23394 layer_factory.hpp:77] Creating layer loss_bbox
I0611 17:04:52.597134 23394 net.cpp:106] Creating Layer loss_bbox
I0611 17:04:52.597137 23394 net.cpp:454] loss_bbox <- bbox_pred
I0611 17:04:52.597141 23394 net.cpp:454] loss_bbox <- bbox_targets
I0611 17:04:52.597143 23394 net.cpp:454] loss_bbox <- bbox_inside_weights
I0611 17:04:52.597157 23394 net.cpp:454] loss_bbox <- bbox_outside_weights
I0611 17:04:52.597159 23394 net.cpp:411] loss_bbox -> loss_bbox
I0611 17:04:52.597271 23394 net.cpp:150] Setting up loss_bbox
I0611 17:04:52.597276 23394 net.cpp:157] Top shape: (1)
I0611 17:04:52.597288 23394 net.cpp:160]     with loss weight 2
I0611 17:04:52.597292 23394 net.cpp:165] Memory required for data: 1430983632
I0611 17:04:52.597295 23394 layer_factory.hpp:77] Creating layer roi_pool5_2
I0611 17:04:52.597316 23394 net.cpp:106] Creating Layer roi_pool5_2
I0611 17:04:52.597319 23394 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0611 17:04:52.597323 23394 net.cpp:454] roi_pool5_2 <- rois_pos
I0611 17:04:52.597329 23394 net.cpp:411] roi_pool5_2 -> pool5_2
I0611 17:04:52.597334 23394 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0611 17:04:52.597409 23394 net.cpp:150] Setting up roi_pool5_2
I0611 17:04:52.597422 23394 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 17:04:52.597424 23394 net.cpp:165] Memory required for data: 1431083984
I0611 17:04:52.597427 23394 layer_factory.hpp:77] Creating layer pool5_2_conv
I0611 17:04:52.597445 23394 net.cpp:106] Creating Layer pool5_2_conv
I0611 17:04:52.597450 23394 net.cpp:454] pool5_2_conv <- pool5_2
I0611 17:04:52.597455 23394 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0611 17:04:52.606199 23394 net.cpp:150] Setting up pool5_2_conv
I0611 17:04:52.606218 23394 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 17:04:52.606221 23394 net.cpp:165] Memory required for data: 1431184336
I0611 17:04:52.606230 23394 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0611 17:04:52.606240 23394 net.cpp:106] Creating Layer pool5_2_conv_relu
I0611 17:04:52.606245 23394 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0611 17:04:52.606251 23394 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0611 17:04:52.606415 23394 net.cpp:150] Setting up pool5_2_conv_relu
I0611 17:04:52.606422 23394 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 17:04:52.606425 23394 net.cpp:165] Memory required for data: 1431284688
I0611 17:04:52.606428 23394 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0611 17:04:52.606449 23394 net.cpp:106] Creating Layer pool5_2_conv2
I0611 17:04:52.606452 23394 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0611 17:04:52.606467 23394 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0611 17:04:52.657263 23394 net.cpp:150] Setting up pool5_2_conv2
I0611 17:04:52.657281 23394 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 17:04:52.657284 23394 net.cpp:165] Memory required for data: 1431385040
I0611 17:04:52.657291 23394 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0611 17:04:52.657300 23394 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0611 17:04:52.657305 23394 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0611 17:04:52.657320 23394 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0611 17:04:52.657526 23394 net.cpp:150] Setting up pool5_2_conv2_relu
I0611 17:04:52.657534 23394 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 17:04:52.657546 23394 net.cpp:165] Memory required for data: 1431485392
I0611 17:04:52.657549 23394 layer_factory.hpp:77] Creating layer mask_deconv1
I0611 17:04:52.657557 23394 net.cpp:106] Creating Layer mask_deconv1
I0611 17:04:52.657569 23394 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0611 17:04:52.657574 23394 net.cpp:411] mask_deconv1 -> mask_deconv1
I0611 17:04:52.658892 23394 net.cpp:150] Setting up mask_deconv1
I0611 17:04:52.658902 23394 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0611 17:04:52.658905 23394 net.cpp:165] Memory required for data: 1432406992
I0611 17:04:52.658910 23394 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0611 17:04:52.658919 23394 net.cpp:106] Creating Layer pool5_2_conv3
I0611 17:04:52.658932 23394 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0611 17:04:52.658938 23394 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0611 17:04:52.684988 23394 net.cpp:150] Setting up pool5_2_conv3
I0611 17:04:52.685014 23394 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 17:04:52.685017 23394 net.cpp:165] Memory required for data: 1434250192
I0611 17:04:52.685034 23394 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0611 17:04:52.685045 23394 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0611 17:04:52.685050 23394 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0611 17:04:52.685057 23394 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0611 17:04:52.685218 23394 net.cpp:150] Setting up pool5_2_conv3_relu
I0611 17:04:52.685226 23394 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 17:04:52.685228 23394 net.cpp:165] Memory required for data: 1436093392
I0611 17:04:52.685231 23394 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0611 17:04:52.685240 23394 net.cpp:106] Creating Layer pool5_2_conv4
I0611 17:04:52.685243 23394 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0611 17:04:52.685247 23394 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0611 17:04:52.736069 23394 net.cpp:150] Setting up pool5_2_conv4
I0611 17:04:52.736086 23394 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 17:04:52.736089 23394 net.cpp:165] Memory required for data: 1437936592
I0611 17:04:52.736096 23394 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0611 17:04:52.736115 23394 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0611 17:04:52.736120 23394 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0611 17:04:52.736136 23394 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0611 17:04:52.736287 23394 net.cpp:150] Setting up pool5_2_conv4_relu
I0611 17:04:52.736295 23394 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 17:04:52.736297 23394 net.cpp:165] Memory required for data: 1439779792
I0611 17:04:52.736300 23394 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 17:04:52.736305 23394 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 17:04:52.736307 23394 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0611 17:04:52.736310 23394 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0611 17:04:52.736326 23394 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0611 17:04:52.736331 23394 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0611 17:04:52.736346 23394 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0611 17:04:52.736409 23394 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 17:04:52.736413 23394 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 17:04:52.736415 23394 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 17:04:52.736418 23394 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 17:04:52.736420 23394 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 17:04:52.736423 23394 net.cpp:165] Memory required for data: 1447152592
I0611 17:04:52.736424 23394 layer_factory.hpp:77] Creating layer query_conv
I0611 17:04:52.736433 23394 net.cpp:106] Creating Layer query_conv
I0611 17:04:52.736446 23394 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0611 17:04:52.736451 23394 net.cpp:411] query_conv -> query_conv
I0611 17:04:52.738085 23394 net.cpp:150] Setting up query_conv
I0611 17:04:52.738095 23394 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0611 17:04:52.738106 23394 net.cpp:165] Memory required for data: 1447382992
I0611 17:04:52.738112 23394 layer_factory.hpp:77] Creating layer key_conv
I0611 17:04:52.738132 23394 net.cpp:106] Creating Layer key_conv
I0611 17:04:52.738137 23394 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0611 17:04:52.738140 23394 net.cpp:411] key_conv -> key_conv
I0611 17:04:52.739696 23394 net.cpp:150] Setting up key_conv
I0611 17:04:52.739704 23394 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0611 17:04:52.739717 23394 net.cpp:165] Memory required for data: 1447613392
I0611 17:04:52.739722 23394 layer_factory.hpp:77] Creating layer value_conv
I0611 17:04:52.739729 23394 net.cpp:106] Creating Layer value_conv
I0611 17:04:52.739748 23394 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0611 17:04:52.739754 23394 net.cpp:411] value_conv -> value_conv
I0611 17:04:52.746409 23394 net.cpp:150] Setting up value_conv
I0611 17:04:52.746418 23394 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 17:04:52.746420 23394 net.cpp:165] Memory required for data: 1449456592
I0611 17:04:52.746425 23394 layer_factory.hpp:77] Creating layer query_conv_reshape
I0611 17:04:52.746431 23394 net.cpp:106] Creating Layer query_conv_reshape
I0611 17:04:52.746433 23394 net.cpp:454] query_conv_reshape <- query_conv
I0611 17:04:52.746448 23394 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0611 17:04:52.746490 23394 net.cpp:150] Setting up query_conv_reshape
I0611 17:04:52.746495 23394 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0611 17:04:52.746506 23394 net.cpp:165] Memory required for data: 1449686992
I0611 17:04:52.746508 23394 layer_factory.hpp:77] Creating layer key_conv_reshape
I0611 17:04:52.746511 23394 net.cpp:106] Creating Layer key_conv_reshape
I0611 17:04:52.746524 23394 net.cpp:454] key_conv_reshape <- key_conv
I0611 17:04:52.746528 23394 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0611 17:04:52.746553 23394 net.cpp:150] Setting up key_conv_reshape
I0611 17:04:52.746570 23394 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0611 17:04:52.746572 23394 net.cpp:165] Memory required for data: 1449917392
I0611 17:04:52.746574 23394 layer_factory.hpp:77] Creating layer value_conv_reshape
I0611 17:04:52.746592 23394 net.cpp:106] Creating Layer value_conv_reshape
I0611 17:04:52.746595 23394 net.cpp:454] value_conv_reshape <- value_conv
I0611 17:04:52.746598 23394 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0611 17:04:52.746615 23394 net.cpp:150] Setting up value_conv_reshape
I0611 17:04:52.746628 23394 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0611 17:04:52.746630 23394 net.cpp:165] Memory required for data: 1451760592
I0611 17:04:52.746632 23394 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0611 17:04:52.746650 23394 net.cpp:106] Creating Layer query_conv_reshape_perm
I0611 17:04:52.746664 23394 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0611 17:04:52.746666 23394 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0611 17:04:52.746781 23394 net.cpp:150] Setting up query_conv_reshape_perm
I0611 17:04:52.746785 23394 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0611 17:04:52.746800 23394 net.cpp:165] Memory required for data: 1451990992
I0611 17:04:52.746803 23394 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0611 17:04:52.746806 23394 net.cpp:106] Creating Layer key_conv_reshape_perm
I0611 17:04:52.746809 23394 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0611 17:04:52.746821 23394 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0611 17:04:52.746903 23394 net.cpp:150] Setting up key_conv_reshape_perm
I0611 17:04:52.746907 23394 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0611 17:04:52.746909 23394 net.cpp:165] Memory required for data: 1452221392
I0611 17:04:52.746912 23394 layer_factory.hpp:77] Creating layer energy
I0611 17:04:52.746915 23394 net.cpp:106] Creating Layer energy
I0611 17:04:52.746917 23394 net.cpp:454] energy <- query_conv_reshape_perm
I0611 17:04:52.746920 23394 net.cpp:454] energy <- key_conv_reshape_perm
I0611 17:04:52.746923 23394 net.cpp:411] energy -> energy
I0611 17:04:52.746948 23394 net.cpp:150] Setting up energy
I0611 17:04:52.746965 23394 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 17:04:52.746968 23394 net.cpp:165] Memory required for data: 1455461392
I0611 17:04:52.746969 23394 layer_factory.hpp:77] Creating layer attention
I0611 17:04:52.746982 23394 net.cpp:106] Creating Layer attention
I0611 17:04:52.746984 23394 net.cpp:454] attention <- energy
I0611 17:04:52.746989 23394 net.cpp:411] attention -> attention
I0611 17:04:52.747179 23394 net.cpp:150] Setting up attention
I0611 17:04:52.747185 23394 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 17:04:52.747187 23394 net.cpp:165] Memory required for data: 1458701392
I0611 17:04:52.747189 23394 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0611 17:04:52.747193 23394 net.cpp:106] Creating Layer value_conv_reshape_perm
I0611 17:04:52.747196 23394 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0611 17:04:52.747200 23394 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0611 17:04:52.747292 23394 net.cpp:150] Setting up value_conv_reshape_perm
I0611 17:04:52.747297 23394 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0611 17:04:52.747298 23394 net.cpp:165] Memory required for data: 1460544592
I0611 17:04:52.747300 23394 layer_factory.hpp:77] Creating layer attention_perm
I0611 17:04:52.747304 23394 net.cpp:106] Creating Layer attention_perm
I0611 17:04:52.747306 23394 net.cpp:454] attention_perm <- attention
I0611 17:04:52.747310 23394 net.cpp:411] attention_perm -> attention_perm
I0611 17:04:52.747398 23394 net.cpp:150] Setting up attention_perm
I0611 17:04:52.747402 23394 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 17:04:52.747404 23394 net.cpp:165] Memory required for data: 1463784592
I0611 17:04:52.747416 23394 layer_factory.hpp:77] Creating layer out
I0611 17:04:52.747418 23394 net.cpp:106] Creating Layer out
I0611 17:04:52.747421 23394 net.cpp:454] out <- value_conv_reshape_perm
I0611 17:04:52.747433 23394 net.cpp:454] out <- attention_perm
I0611 17:04:52.747439 23394 net.cpp:411] out -> out
I0611 17:04:52.747465 23394 net.cpp:150] Setting up out
I0611 17:04:52.747468 23394 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0611 17:04:52.747472 23394 net.cpp:165] Memory required for data: 1465627792
I0611 17:04:52.747473 23394 layer_factory.hpp:77] Creating layer out_reshape
I0611 17:04:52.747486 23394 net.cpp:106] Creating Layer out_reshape
I0611 17:04:52.747488 23394 net.cpp:454] out_reshape <- out
I0611 17:04:52.747491 23394 net.cpp:411] out_reshape -> out_reshape
I0611 17:04:52.747525 23394 net.cpp:150] Setting up out_reshape
I0611 17:04:52.747529 23394 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 17:04:52.747531 23394 net.cpp:165] Memory required for data: 1467470992
I0611 17:04:52.747545 23394 layer_factory.hpp:77] Creating layer out_reshape_scale
I0611 17:04:52.747552 23394 net.cpp:106] Creating Layer out_reshape_scale
I0611 17:04:52.747565 23394 net.cpp:454] out_reshape_scale <- out_reshape
I0611 17:04:52.747570 23394 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0611 17:04:52.747642 23394 net.cpp:150] Setting up out_reshape_scale
I0611 17:04:52.747647 23394 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 17:04:52.747648 23394 net.cpp:165] Memory required for data: 1469314192
I0611 17:04:52.747661 23394 layer_factory.hpp:77] Creating layer out_x
I0611 17:04:52.747669 23394 net.cpp:106] Creating Layer out_x
I0611 17:04:52.747681 23394 net.cpp:454] out_x <- out_reshape_scale
I0611 17:04:52.747684 23394 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0611 17:04:52.747690 23394 net.cpp:411] out_x -> out_x
I0611 17:04:52.747709 23394 net.cpp:150] Setting up out_x
I0611 17:04:52.747712 23394 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 17:04:52.747714 23394 net.cpp:165] Memory required for data: 1471157392
I0611 17:04:52.747720 23394 layer_factory.hpp:77] Creating layer mask_deconv2
I0611 17:04:52.747727 23394 net.cpp:106] Creating Layer mask_deconv2
I0611 17:04:52.747731 23394 net.cpp:454] mask_deconv2 <- out_x
I0611 17:04:52.747738 23394 net.cpp:411] mask_deconv2 -> mask_deconv2
I0611 17:04:52.748565 23394 net.cpp:150] Setting up mask_deconv2
I0611 17:04:52.748572 23394 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0611 17:04:52.748575 23394 net.cpp:165] Memory required for data: 1486398608
I0611 17:04:52.748579 23394 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0611 17:04:52.748589 23394 net.cpp:106] Creating Layer pool5_2_conv5
I0611 17:04:52.748591 23394 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0611 17:04:52.748596 23394 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0611 17:04:52.774974 23394 net.cpp:150] Setting up pool5_2_conv5
I0611 17:04:52.774992 23394 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 17:04:52.774996 23394 net.cpp:165] Memory required for data: 1516881040
I0611 17:04:52.775002 23394 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0611 17:04:52.775010 23394 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0611 17:04:52.775027 23394 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0611 17:04:52.775033 23394 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0611 17:04:52.775205 23394 net.cpp:150] Setting up pool5_2_conv5_relu
I0611 17:04:52.775213 23394 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 17:04:52.775214 23394 net.cpp:165] Memory required for data: 1547363472
I0611 17:04:52.775218 23394 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0611 17:04:52.775226 23394 net.cpp:106] Creating Layer pool5_2_conv6
I0611 17:04:52.775228 23394 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0611 17:04:52.775243 23394 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0611 17:04:52.825592 23394 net.cpp:150] Setting up pool5_2_conv6
I0611 17:04:52.825609 23394 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 17:04:52.825611 23394 net.cpp:165] Memory required for data: 1577845904
I0611 17:04:52.825637 23394 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0611 17:04:52.825646 23394 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0611 17:04:52.825664 23394 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0611 17:04:52.825678 23394 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0611 17:04:52.826239 23394 net.cpp:150] Setting up pool5_2_conv6_relu
I0611 17:04:52.826248 23394 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 17:04:52.826251 23394 net.cpp:165] Memory required for data: 1608328336
I0611 17:04:52.826253 23394 layer_factory.hpp:77] Creating layer mask_deconv3
I0611 17:04:52.826262 23394 net.cpp:106] Creating Layer mask_deconv3
I0611 17:04:52.826265 23394 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0611 17:04:52.826280 23394 net.cpp:411] mask_deconv3 -> mask_deconv3
I0611 17:04:52.826647 23394 net.cpp:150] Setting up mask_deconv3
I0611 17:04:52.826653 23394 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0611 17:04:52.826655 23394 net.cpp:165] Memory required for data: 1669293200
I0611 17:04:52.826660 23394 layer_factory.hpp:77] Creating layer mask_score
I0611 17:04:52.826666 23394 net.cpp:106] Creating Layer mask_score
I0611 17:04:52.826669 23394 net.cpp:454] mask_score <- mask_deconv3
I0611 17:04:52.826683 23394 net.cpp:411] mask_score -> mask_score
I0611 17:04:52.827293 23394 net.cpp:150] Setting up mask_score
I0611 17:04:52.827301 23394 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0611 17:04:52.827303 23394 net.cpp:165] Memory required for data: 1671198352
I0611 17:04:52.827307 23394 layer_factory.hpp:77] Creating layer loss_mask
I0611 17:04:52.827313 23394 net.cpp:106] Creating Layer loss_mask
I0611 17:04:52.827316 23394 net.cpp:454] loss_mask <- mask_score
I0611 17:04:52.827329 23394 net.cpp:454] loss_mask <- mask_targets
I0611 17:04:52.827335 23394 net.cpp:411] loss_mask -> loss_mask
I0611 17:04:52.827353 23394 layer_factory.hpp:77] Creating layer loss_mask
I0611 17:04:52.828743 23394 net.cpp:150] Setting up loss_mask
I0611 17:04:52.828752 23394 net.cpp:157] Top shape: (1)
I0611 17:04:52.828764 23394 net.cpp:160]     with loss weight 3
I0611 17:04:52.828783 23394 net.cpp:165] Memory required for data: 1671198356
I0611 17:04:52.828785 23394 net.cpp:226] loss_mask needs backward computation.
I0611 17:04:52.828790 23394 net.cpp:226] mask_score needs backward computation.
I0611 17:04:52.828792 23394 net.cpp:226] mask_deconv3 needs backward computation.
I0611 17:04:52.828794 23394 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0611 17:04:52.828797 23394 net.cpp:226] pool5_2_conv6 needs backward computation.
I0611 17:04:52.828799 23394 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0611 17:04:52.828802 23394 net.cpp:226] pool5_2_conv5 needs backward computation.
I0611 17:04:52.828804 23394 net.cpp:226] mask_deconv2 needs backward computation.
I0611 17:04:52.828807 23394 net.cpp:226] out_x needs backward computation.
I0611 17:04:52.828810 23394 net.cpp:226] out_reshape_scale needs backward computation.
I0611 17:04:52.828814 23394 net.cpp:226] out_reshape needs backward computation.
I0611 17:04:52.828817 23394 net.cpp:226] out needs backward computation.
I0611 17:04:52.828821 23394 net.cpp:226] attention_perm needs backward computation.
I0611 17:04:52.828824 23394 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0611 17:04:52.828827 23394 net.cpp:226] attention needs backward computation.
I0611 17:04:52.828830 23394 net.cpp:226] energy needs backward computation.
I0611 17:04:52.828835 23394 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0611 17:04:52.828837 23394 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0611 17:04:52.828840 23394 net.cpp:226] value_conv_reshape needs backward computation.
I0611 17:04:52.828843 23394 net.cpp:226] key_conv_reshape needs backward computation.
I0611 17:04:52.828846 23394 net.cpp:226] query_conv_reshape needs backward computation.
I0611 17:04:52.828850 23394 net.cpp:226] value_conv needs backward computation.
I0611 17:04:52.828855 23394 net.cpp:226] key_conv needs backward computation.
I0611 17:04:52.828857 23394 net.cpp:226] query_conv needs backward computation.
I0611 17:04:52.828860 23394 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0611 17:04:52.828863 23394 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0611 17:04:52.828866 23394 net.cpp:226] pool5_2_conv4 needs backward computation.
I0611 17:04:52.828869 23394 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0611 17:04:52.828873 23394 net.cpp:226] pool5_2_conv3 needs backward computation.
I0611 17:04:52.828876 23394 net.cpp:226] mask_deconv1 needs backward computation.
I0611 17:04:52.828878 23394 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0611 17:04:52.828881 23394 net.cpp:226] pool5_2_conv2 needs backward computation.
I0611 17:04:52.828882 23394 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0611 17:04:52.828889 23394 net.cpp:226] pool5_2_conv needs backward computation.
I0611 17:04:52.828894 23394 net.cpp:226] roi_pool5_2 needs backward computation.
I0611 17:04:52.828907 23394 net.cpp:226] loss_bbox needs backward computation.
I0611 17:04:52.828913 23394 net.cpp:226] loss_cls needs backward computation.
I0611 17:04:52.828927 23394 net.cpp:226] loss_attribute needs backward computation.
I0611 17:04:52.828933 23394 net.cpp:226] bbox_pred needs backward computation.
I0611 17:04:52.828950 23394 net.cpp:226] cls_score needs backward computation.
I0611 17:04:52.828955 23394 net.cpp:226] attr_score_pos needs backward computation.
I0611 17:04:52.828964 23394 net.cpp:226] attr_score needs backward computation.
I0611 17:04:52.828969 23394 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0611 17:04:52.828976 23394 net.cpp:226] relu7 needs backward computation.
I0611 17:04:52.828985 23394 net.cpp:226] fc7 needs backward computation.
I0611 17:04:52.828989 23394 net.cpp:226] relu6 needs backward computation.
I0611 17:04:52.828994 23394 net.cpp:226] fc6 needs backward computation.
I0611 17:04:52.829007 23394 net.cpp:226] roi_pool5 needs backward computation.
I0611 17:04:52.829012 23394 net.cpp:226] roi-data needs backward computation.
I0611 17:04:52.829021 23394 net.cpp:226] proposal needs backward computation.
I0611 17:04:52.829028 23394 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0611 17:04:52.829033 23394 net.cpp:226] rpn_cls_prob needs backward computation.
I0611 17:04:52.829037 23394 net.cpp:226] rpn_loss_bbox needs backward computation.
I0611 17:04:52.829043 23394 net.cpp:226] rpn_loss_cls needs backward computation.
I0611 17:04:52.829048 23394 net.cpp:226] rpn-data needs backward computation.
I0611 17:04:52.829054 23394 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0611 17:04:52.829061 23394 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0611 17:04:52.829064 23394 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0611 17:04:52.829068 23394 net.cpp:226] rpn_bbox_pred needs backward computation.
I0611 17:04:52.829073 23394 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0611 17:04:52.829078 23394 net.cpp:226] rpn_cls_score needs backward computation.
I0611 17:04:52.829082 23394 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0611 17:04:52.829088 23394 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0611 17:04:52.829094 23394 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0611 17:04:52.829099 23394 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0611 17:04:52.829104 23394 net.cpp:226] relu5_3 needs backward computation.
I0611 17:04:52.829108 23394 net.cpp:226] conv5_3 needs backward computation.
I0611 17:04:52.829114 23394 net.cpp:226] relu5_2 needs backward computation.
I0611 17:04:52.829120 23394 net.cpp:226] conv5_2 needs backward computation.
I0611 17:04:52.829123 23394 net.cpp:226] relu5_1 needs backward computation.
I0611 17:04:52.829128 23394 net.cpp:226] conv5_1 needs backward computation.
I0611 17:04:52.829133 23394 net.cpp:226] pool4 needs backward computation.
I0611 17:04:52.829138 23394 net.cpp:226] relu4_3 needs backward computation.
I0611 17:04:52.829143 23394 net.cpp:226] conv4_3 needs backward computation.
I0611 17:04:52.829149 23394 net.cpp:226] relu4_2 needs backward computation.
I0611 17:04:52.829152 23394 net.cpp:226] conv4_2 needs backward computation.
I0611 17:04:52.829157 23394 net.cpp:226] relu4_1 needs backward computation.
I0611 17:04:52.829164 23394 net.cpp:226] conv4_1 needs backward computation.
I0611 17:04:52.829167 23394 net.cpp:226] pool3 needs backward computation.
I0611 17:04:52.829174 23394 net.cpp:226] relu3_3 needs backward computation.
I0611 17:04:52.829179 23394 net.cpp:226] conv3_3 needs backward computation.
I0611 17:04:52.829182 23394 net.cpp:226] relu3_2 needs backward computation.
I0611 17:04:52.829187 23394 net.cpp:226] conv3_2 needs backward computation.
I0611 17:04:52.829191 23394 net.cpp:226] relu3_1 needs backward computation.
I0611 17:04:52.829195 23394 net.cpp:226] conv3_1 needs backward computation.
I0611 17:04:52.829200 23394 net.cpp:228] pool2 does not need backward computation.
I0611 17:04:52.829205 23394 net.cpp:228] relu2_2 does not need backward computation.
I0611 17:04:52.829210 23394 net.cpp:228] conv2_2 does not need backward computation.
I0611 17:04:52.829216 23394 net.cpp:228] relu2_1 does not need backward computation.
I0611 17:04:52.829221 23394 net.cpp:228] conv2_1 does not need backward computation.
I0611 17:04:52.829226 23394 net.cpp:228] pool1 does not need backward computation.
I0611 17:04:52.829232 23394 net.cpp:228] relu1_2 does not need backward computation.
I0611 17:04:52.829236 23394 net.cpp:228] conv1_2 does not need backward computation.
I0611 17:04:52.829241 23394 net.cpp:228] relu1_1 does not need backward computation.
I0611 17:04:52.829247 23394 net.cpp:228] conv1_1 does not need backward computation.
I0611 17:04:52.829254 23394 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0611 17:04:52.829260 23394 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0611 17:04:52.829264 23394 net.cpp:228] data_input-data_0_split does not need backward computation.
I0611 17:04:52.829272 23394 net.cpp:228] input-data does not need backward computation.
I0611 17:04:52.829275 23394 net.cpp:270] This network produces output loss_attribute
I0611 17:04:52.829279 23394 net.cpp:270] This network produces output loss_bbox
I0611 17:04:52.829285 23394 net.cpp:270] This network produces output loss_cls
I0611 17:04:52.829288 23394 net.cpp:270] This network produces output loss_mask
I0611 17:04:52.829293 23394 net.cpp:270] This network produces output rpn_cls_loss
I0611 17:04:52.829296 23394 net.cpp:270] This network produces output rpn_loss_bbox
I0611 17:04:52.829355 23394 net.cpp:283] Network initialization done.
I0611 17:04:52.829589 23394 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0611 17:04:56.751572 23394 net.cpp:816] Ignoring source layer pool5
I0611 17:04:56.820286 23394 net.cpp:816] Ignoring source layer drop6
I0611 17:04:56.831184 23394 net.cpp:816] Ignoring source layer drop7
I0611 17:04:56.831202 23394 net.cpp:816] Ignoring source layer fc8
I0611 17:04:56.831205 23394 net.cpp:816] Ignoring source layer prob
Solving...
I0611 17:04:57.908876 23394 solver.cpp:229] Iteration 0, loss = 126.301
I0611 17:04:57.908905 23394 solver.cpp:245]     Train net output #0: loss_attribute = 232.971 (* 0.5 = 116.486 loss)
I0611 17:04:57.908910 23394 solver.cpp:245]     Train net output #1: loss_bbox = 0.0916567 (* 2 = 0.183313 loss)
I0611 17:04:57.908915 23394 solver.cpp:245]     Train net output #2: loss_cls = 0.947394 (* 3 = 2.84218 loss)
I0611 17:04:57.908918 23394 solver.cpp:245]     Train net output #3: loss_mask = 2.08166 (* 3 = 6.24497 loss)
I0611 17:04:57.908921 23394 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.73882 (* 1 = 0.73882 loss)
I0611 17:04:57.908926 23394 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0189577 (* 1 = 0.0189577 loss)
I0611 17:04:57.908929 23394 sgd_solver.cpp:106] Iteration 0, lr = 0.001
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:62: RuntimeWarning: overflow encountered in exp
  pred_w = np.exp(dw) * widths[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:62: RuntimeWarning: overflow encountered in multiply
  pred_w = np.exp(dw) * widths[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:63: RuntimeWarning: overflow encountered in exp
  pred_h = np.exp(dh) * heights[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:63: RuntimeWarning: overflow encountered in multiply
  pred_h = np.exp(dh) * heights[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/utils/SigmoidCrossEntropyWeightLossLayer.py:27: RuntimeWarning: overflow encountered in exp
  second_term = -((1-self.cls_weight)*label - 1)*np.log(1+np.exp(-score))
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/utils/SigmoidCrossEntropyWeightLossLayer.py:31: RuntimeWarning: overflow encountered in exp
  sig = 1.0/(1.0+np.exp(-score))
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:83: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:83: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:85: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:85: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:87: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:87: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:89: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:89: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/rpn/proposal_layer.py:187: RuntimeWarning: invalid value encountered in greater_equal
  keep = np.where((ws >= min_size) & (hs >= min_size))[0]
---- WARNING: filter_boxes() remove ALL proposal.
./experiments/scripts/faster_rcnn_end2end.sh: line 65: 23394 Floating point exception/usr/bin/python ./tools/train_net.py --gpu ${GPU_ID} --solver models/${PT_DIR}/${NET}/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb ${TRAIN_IMDB} --iters ${ITERS} --cfg experiments/cfgs/faster_rcnn_end2end.yml ${EXTRA_ARGS}
