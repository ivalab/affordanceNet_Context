+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-05_13-23-59
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-05_13-23-59
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
29646 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 29646 -> 29646
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0605 13:24:09.121132 15110 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0605 13:24:09.121153 15110 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0605 13:24:09.122968 15110 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  top: "rois_attribute"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "query_conv_reshape_ch"
  type: "Reshape"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv_reshape_ch"
  reshape_param {
    shape {
      dim: 1
      dim: 512
      dim: -1
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape_ch"
  type: "Reshape"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv_reshape_ch"
  reshape_param {
    shape {
      dim: 1
      dim: 512
      dim: -1
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape_ch"
  type: "Reshape"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv_reshape_ch"
  reshape_param {
    shape {
      dim: 1
      dim: 512
      dim: -1
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm_ch"
  type: "Permute"
  bottom: "query_conv_reshape_ch"
  top: "query_conv_reshape_perm_ch"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "key_conv_reshape_perm_ch"
  type: "Permute"
  bottom: "key_conv_reshape_ch"
  top: "key_conv_reshape_perm_ch"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "energy_ch"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm_ch"
  bottom: "key_conv_reshape_perm_ch"
  top: "energy_ch"
}
layer {
  name: "energy_ch_pool"
  type: "Pooling"
  bottom: "energy_ch"
  top: "energy_ch_pool"
  pooling_param {
    pool: MAX
    kernel_h: 1
    kernel_w: 512
    stride_h: 1
    stride_w: 512
  }
}
layer {
  name: "energy_ch_max"
  type: "Tile"
  bottom: "energy_ch_pool"
  top: "energy_ch_max"
  tile_param {
    axis: 3
    tiles: 512
  }
}
layer {
  name: "energy_ch_minus"
  type: "Power"
  bottom: "energy_ch"
  top: "energy_ch_minus"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "energy_new"
  type: "Eltwise"
  bottom: "energy_ch_max"
  bottom: "energy_ch_minus"
  top: "energy_new"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "attention_ch"
  type: "Softmax"
  bottom: "energy_new"
  top: "attention_ch"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_ch_perm"
  type: "Permute"
  bottom: "value_conv_reshape_ch"
  top: "value_conv_reshape_ch_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_ch_perm"
  type: "Permute"
  bottom: "attention_ch"
  top: "attention_ch_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out_ch"
  type: "MatrixMultiplication"
  bottom: "attention_ch_perm"
  bottom: "value_conv_reshape_ch_perm"
  top: "out_ch"
}
layer {
  name: "out_ch_reshape"
  type: "Reshape"
  bottom: "out_ch"
  top: "out_ch_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_ch_reshape_scale"
  type: "Scale"
  bottom: "out_ch_reshape"
  top: "out_ch_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_ch_x"
  type: "Eltwise"
  bottom: "out_ch_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_ch_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "out_conv_ch_x"
  type: "Convolution"
  bottom: "out_ch_x"
  top: "out_conv_ch_x"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out_conv_x"
  type: "Convolution"
  bottom: "out_x"
  top: "out_conv_x"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out_x_sum"
  type: "Eltwise"
  bottom: "out_conv_x"
  bottom: "out_conv_ch_x"
  top: "out_x_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x_sum"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_mask"
  type: "SoftmaxWithLoss"
  bottom: "mask_score"
  bottom: "mask_targets"
  top: "loss_mask"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
I0605 13:24:09.123335 15110 layer_factory.hpp:77] Creating layer input-data
I0605 13:24:09.170774 15110 net.cpp:106] Creating Layer input-data
I0605 13:24:09.170795 15110 net.cpp:411] input-data -> data
I0605 13:24:09.170809 15110 net.cpp:411] input-data -> im_info
I0605 13:24:09.170815 15110 net.cpp:411] input-data -> gt_boxes
I0605 13:24:09.170821 15110 net.cpp:411] input-data -> seg_mask_inds
I0605 13:24:09.170827 15110 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0605 13:24:09.204043 15110 net.cpp:150] Setting up input-data
I0605 13:24:09.204064 15110 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0605 13:24:09.204071 15110 net.cpp:157] Top shape: 1 3 (3)
I0605 13:24:09.204074 15110 net.cpp:157] Top shape: 1 4 (4)
I0605 13:24:09.204079 15110 net.cpp:157] Top shape: 1 2 (2)
I0605 13:24:09.204084 15110 net.cpp:157] Top shape: 1 1 (1)
I0605 13:24:09.204087 15110 net.cpp:165] Memory required for data: 7200040
I0605 13:24:09.204093 15110 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0605 13:24:09.204110 15110 net.cpp:106] Creating Layer data_input-data_0_split
I0605 13:24:09.204116 15110 net.cpp:454] data_input-data_0_split <- data
I0605 13:24:09.204123 15110 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0605 13:24:09.204134 15110 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0605 13:24:09.204169 15110 net.cpp:150] Setting up data_input-data_0_split
I0605 13:24:09.204177 15110 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0605 13:24:09.204180 15110 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0605 13:24:09.204182 15110 net.cpp:165] Memory required for data: 21600040
I0605 13:24:09.204185 15110 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0605 13:24:09.204190 15110 net.cpp:106] Creating Layer im_info_input-data_1_split
I0605 13:24:09.204196 15110 net.cpp:454] im_info_input-data_1_split <- im_info
I0605 13:24:09.204201 15110 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0605 13:24:09.204210 15110 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0605 13:24:09.204221 15110 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0605 13:24:09.204259 15110 net.cpp:150] Setting up im_info_input-data_1_split
I0605 13:24:09.204267 15110 net.cpp:157] Top shape: 1 3 (3)
I0605 13:24:09.204270 15110 net.cpp:157] Top shape: 1 3 (3)
I0605 13:24:09.204272 15110 net.cpp:157] Top shape: 1 3 (3)
I0605 13:24:09.204275 15110 net.cpp:165] Memory required for data: 21600076
I0605 13:24:09.204278 15110 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0605 13:24:09.204282 15110 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0605 13:24:09.204286 15110 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0605 13:24:09.204294 15110 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0605 13:24:09.204303 15110 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0605 13:24:09.204334 15110 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0605 13:24:09.204339 15110 net.cpp:157] Top shape: 1 4 (4)
I0605 13:24:09.204341 15110 net.cpp:157] Top shape: 1 4 (4)
I0605 13:24:09.204344 15110 net.cpp:165] Memory required for data: 21600108
I0605 13:24:09.204346 15110 layer_factory.hpp:77] Creating layer conv1_1
I0605 13:24:09.204360 15110 net.cpp:106] Creating Layer conv1_1
I0605 13:24:09.204365 15110 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0605 13:24:09.204373 15110 net.cpp:411] conv1_1 -> conv1_1
I0605 13:24:09.413858 15110 net.cpp:150] Setting up conv1_1
I0605 13:24:09.413893 15110 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0605 13:24:09.413897 15110 net.cpp:165] Memory required for data: 175200108
I0605 13:24:09.413918 15110 layer_factory.hpp:77] Creating layer relu1_1
I0605 13:24:09.413936 15110 net.cpp:106] Creating Layer relu1_1
I0605 13:24:09.413941 15110 net.cpp:454] relu1_1 <- conv1_1
I0605 13:24:09.413946 15110 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0605 13:24:09.414084 15110 net.cpp:150] Setting up relu1_1
I0605 13:24:09.414090 15110 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0605 13:24:09.414093 15110 net.cpp:165] Memory required for data: 328800108
I0605 13:24:09.414095 15110 layer_factory.hpp:77] Creating layer conv1_2
I0605 13:24:09.414103 15110 net.cpp:106] Creating Layer conv1_2
I0605 13:24:09.414105 15110 net.cpp:454] conv1_2 <- conv1_1
I0605 13:24:09.414119 15110 net.cpp:411] conv1_2 -> conv1_2
I0605 13:24:09.416391 15110 net.cpp:150] Setting up conv1_2
I0605 13:24:09.416401 15110 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0605 13:24:09.416404 15110 net.cpp:165] Memory required for data: 482400108
I0605 13:24:09.416411 15110 layer_factory.hpp:77] Creating layer relu1_2
I0605 13:24:09.416416 15110 net.cpp:106] Creating Layer relu1_2
I0605 13:24:09.416419 15110 net.cpp:454] relu1_2 <- conv1_2
I0605 13:24:09.416422 15110 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0605 13:24:09.416530 15110 net.cpp:150] Setting up relu1_2
I0605 13:24:09.416537 15110 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0605 13:24:09.416539 15110 net.cpp:165] Memory required for data: 636000108
I0605 13:24:09.416541 15110 layer_factory.hpp:77] Creating layer pool1
I0605 13:24:09.416548 15110 net.cpp:106] Creating Layer pool1
I0605 13:24:09.416550 15110 net.cpp:454] pool1 <- conv1_2
I0605 13:24:09.416554 15110 net.cpp:411] pool1 -> pool1
I0605 13:24:09.416589 15110 net.cpp:150] Setting up pool1
I0605 13:24:09.416592 15110 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0605 13:24:09.416595 15110 net.cpp:165] Memory required for data: 674400108
I0605 13:24:09.416597 15110 layer_factory.hpp:77] Creating layer conv2_1
I0605 13:24:09.416604 15110 net.cpp:106] Creating Layer conv2_1
I0605 13:24:09.416605 15110 net.cpp:454] conv2_1 <- pool1
I0605 13:24:09.416610 15110 net.cpp:411] conv2_1 -> conv2_1
I0605 13:24:09.418520 15110 net.cpp:150] Setting up conv2_1
I0605 13:24:09.418539 15110 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0605 13:24:09.418541 15110 net.cpp:165] Memory required for data: 751200108
I0605 13:24:09.418558 15110 layer_factory.hpp:77] Creating layer relu2_1
I0605 13:24:09.418573 15110 net.cpp:106] Creating Layer relu2_1
I0605 13:24:09.418576 15110 net.cpp:454] relu2_1 <- conv2_1
I0605 13:24:09.418579 15110 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0605 13:24:09.419054 15110 net.cpp:150] Setting up relu2_1
I0605 13:24:09.419061 15110 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0605 13:24:09.419073 15110 net.cpp:165] Memory required for data: 828000108
I0605 13:24:09.419076 15110 layer_factory.hpp:77] Creating layer conv2_2
I0605 13:24:09.419085 15110 net.cpp:106] Creating Layer conv2_2
I0605 13:24:09.419088 15110 net.cpp:454] conv2_2 <- conv2_1
I0605 13:24:09.419092 15110 net.cpp:411] conv2_2 -> conv2_2
I0605 13:24:09.420574 15110 net.cpp:150] Setting up conv2_2
I0605 13:24:09.420594 15110 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0605 13:24:09.420598 15110 net.cpp:165] Memory required for data: 904800108
I0605 13:24:09.420603 15110 layer_factory.hpp:77] Creating layer relu2_2
I0605 13:24:09.420608 15110 net.cpp:106] Creating Layer relu2_2
I0605 13:24:09.420612 15110 net.cpp:454] relu2_2 <- conv2_2
I0605 13:24:09.420615 15110 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0605 13:24:09.420723 15110 net.cpp:150] Setting up relu2_2
I0605 13:24:09.420728 15110 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0605 13:24:09.420732 15110 net.cpp:165] Memory required for data: 981600108
I0605 13:24:09.420734 15110 layer_factory.hpp:77] Creating layer pool2
I0605 13:24:09.420740 15110 net.cpp:106] Creating Layer pool2
I0605 13:24:09.420744 15110 net.cpp:454] pool2 <- conv2_2
I0605 13:24:09.420748 15110 net.cpp:411] pool2 -> pool2
I0605 13:24:09.420778 15110 net.cpp:150] Setting up pool2
I0605 13:24:09.420783 15110 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0605 13:24:09.420785 15110 net.cpp:165] Memory required for data: 1000800108
I0605 13:24:09.420789 15110 layer_factory.hpp:77] Creating layer conv3_1
I0605 13:24:09.420805 15110 net.cpp:106] Creating Layer conv3_1
I0605 13:24:09.420809 15110 net.cpp:454] conv3_1 <- pool2
I0605 13:24:09.420812 15110 net.cpp:411] conv3_1 -> conv3_1
I0605 13:24:09.422869 15110 net.cpp:150] Setting up conv3_1
I0605 13:24:09.422879 15110 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 13:24:09.422881 15110 net.cpp:165] Memory required for data: 1039200108
I0605 13:24:09.422889 15110 layer_factory.hpp:77] Creating layer relu3_1
I0605 13:24:09.422894 15110 net.cpp:106] Creating Layer relu3_1
I0605 13:24:09.422899 15110 net.cpp:454] relu3_1 <- conv3_1
I0605 13:24:09.422901 15110 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0605 13:24:09.423015 15110 net.cpp:150] Setting up relu3_1
I0605 13:24:09.423022 15110 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 13:24:09.423034 15110 net.cpp:165] Memory required for data: 1077600108
I0605 13:24:09.423036 15110 layer_factory.hpp:77] Creating layer conv3_2
I0605 13:24:09.423043 15110 net.cpp:106] Creating Layer conv3_2
I0605 13:24:09.423045 15110 net.cpp:454] conv3_2 <- conv3_1
I0605 13:24:09.423050 15110 net.cpp:411] conv3_2 -> conv3_2
I0605 13:24:09.425217 15110 net.cpp:150] Setting up conv3_2
I0605 13:24:09.425227 15110 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 13:24:09.425230 15110 net.cpp:165] Memory required for data: 1116000108
I0605 13:24:09.425235 15110 layer_factory.hpp:77] Creating layer relu3_2
I0605 13:24:09.425240 15110 net.cpp:106] Creating Layer relu3_2
I0605 13:24:09.425252 15110 net.cpp:454] relu3_2 <- conv3_2
I0605 13:24:09.425258 15110 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0605 13:24:09.425366 15110 net.cpp:150] Setting up relu3_2
I0605 13:24:09.425372 15110 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 13:24:09.425376 15110 net.cpp:165] Memory required for data: 1154400108
I0605 13:24:09.425379 15110 layer_factory.hpp:77] Creating layer conv3_3
I0605 13:24:09.425385 15110 net.cpp:106] Creating Layer conv3_3
I0605 13:24:09.425390 15110 net.cpp:454] conv3_3 <- conv3_2
I0605 13:24:09.425395 15110 net.cpp:411] conv3_3 -> conv3_3
I0605 13:24:09.427381 15110 net.cpp:150] Setting up conv3_3
I0605 13:24:09.427400 15110 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 13:24:09.427403 15110 net.cpp:165] Memory required for data: 1192800108
I0605 13:24:09.427408 15110 layer_factory.hpp:77] Creating layer relu3_3
I0605 13:24:09.427413 15110 net.cpp:106] Creating Layer relu3_3
I0605 13:24:09.427417 15110 net.cpp:454] relu3_3 <- conv3_3
I0605 13:24:09.427419 15110 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0605 13:24:09.427533 15110 net.cpp:150] Setting up relu3_3
I0605 13:24:09.427538 15110 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 13:24:09.427551 15110 net.cpp:165] Memory required for data: 1231200108
I0605 13:24:09.427553 15110 layer_factory.hpp:77] Creating layer pool3
I0605 13:24:09.427559 15110 net.cpp:106] Creating Layer pool3
I0605 13:24:09.427561 15110 net.cpp:454] pool3 <- conv3_3
I0605 13:24:09.427565 15110 net.cpp:411] pool3 -> pool3
I0605 13:24:09.427603 15110 net.cpp:150] Setting up pool3
I0605 13:24:09.427606 15110 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0605 13:24:09.427619 15110 net.cpp:165] Memory required for data: 1240800108
I0605 13:24:09.427621 15110 layer_factory.hpp:77] Creating layer conv4_1
I0605 13:24:09.427628 15110 net.cpp:106] Creating Layer conv4_1
I0605 13:24:09.427629 15110 net.cpp:454] conv4_1 <- pool3
I0605 13:24:09.427634 15110 net.cpp:411] conv4_1 -> conv4_1
I0605 13:24:09.431340 15110 net.cpp:150] Setting up conv4_1
I0605 13:24:09.431370 15110 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 13:24:09.431373 15110 net.cpp:165] Memory required for data: 1260000108
I0605 13:24:09.431381 15110 layer_factory.hpp:77] Creating layer relu4_1
I0605 13:24:09.431391 15110 net.cpp:106] Creating Layer relu4_1
I0605 13:24:09.431396 15110 net.cpp:454] relu4_1 <- conv4_1
I0605 13:24:09.431401 15110 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0605 13:24:09.431524 15110 net.cpp:150] Setting up relu4_1
I0605 13:24:09.431529 15110 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 13:24:09.431541 15110 net.cpp:165] Memory required for data: 1279200108
I0605 13:24:09.431545 15110 layer_factory.hpp:77] Creating layer conv4_2
I0605 13:24:09.431551 15110 net.cpp:106] Creating Layer conv4_2
I0605 13:24:09.431555 15110 net.cpp:454] conv4_2 <- conv4_1
I0605 13:24:09.431558 15110 net.cpp:411] conv4_2 -> conv4_2
I0605 13:24:09.436103 15110 net.cpp:150] Setting up conv4_2
I0605 13:24:09.436125 15110 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 13:24:09.436127 15110 net.cpp:165] Memory required for data: 1298400108
I0605 13:24:09.436139 15110 layer_factory.hpp:77] Creating layer relu4_2
I0605 13:24:09.436146 15110 net.cpp:106] Creating Layer relu4_2
I0605 13:24:09.436151 15110 net.cpp:454] relu4_2 <- conv4_2
I0605 13:24:09.436166 15110 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0605 13:24:09.436640 15110 net.cpp:150] Setting up relu4_2
I0605 13:24:09.436647 15110 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 13:24:09.436650 15110 net.cpp:165] Memory required for data: 1317600108
I0605 13:24:09.436652 15110 layer_factory.hpp:77] Creating layer conv4_3
I0605 13:24:09.436659 15110 net.cpp:106] Creating Layer conv4_3
I0605 13:24:09.436661 15110 net.cpp:454] conv4_3 <- conv4_2
I0605 13:24:09.436666 15110 net.cpp:411] conv4_3 -> conv4_3
I0605 13:24:09.441382 15110 net.cpp:150] Setting up conv4_3
I0605 13:24:09.441431 15110 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 13:24:09.441435 15110 net.cpp:165] Memory required for data: 1336800108
I0605 13:24:09.441447 15110 layer_factory.hpp:77] Creating layer relu4_3
I0605 13:24:09.441457 15110 net.cpp:106] Creating Layer relu4_3
I0605 13:24:09.441462 15110 net.cpp:454] relu4_3 <- conv4_3
I0605 13:24:09.441468 15110 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0605 13:24:09.441601 15110 net.cpp:150] Setting up relu4_3
I0605 13:24:09.441607 15110 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 13:24:09.441609 15110 net.cpp:165] Memory required for data: 1356000108
I0605 13:24:09.441612 15110 layer_factory.hpp:77] Creating layer pool4
I0605 13:24:09.441617 15110 net.cpp:106] Creating Layer pool4
I0605 13:24:09.441618 15110 net.cpp:454] pool4 <- conv4_3
I0605 13:24:09.441624 15110 net.cpp:411] pool4 -> pool4
I0605 13:24:09.441673 15110 net.cpp:150] Setting up pool4
I0605 13:24:09.441676 15110 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 13:24:09.441689 15110 net.cpp:165] Memory required for data: 1360903020
I0605 13:24:09.441691 15110 layer_factory.hpp:77] Creating layer conv5_1
I0605 13:24:09.441699 15110 net.cpp:106] Creating Layer conv5_1
I0605 13:24:09.441701 15110 net.cpp:454] conv5_1 <- pool4
I0605 13:24:09.441704 15110 net.cpp:411] conv5_1 -> conv5_1
I0605 13:24:09.445951 15110 net.cpp:150] Setting up conv5_1
I0605 13:24:09.445971 15110 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 13:24:09.445973 15110 net.cpp:165] Memory required for data: 1365805932
I0605 13:24:09.445981 15110 layer_factory.hpp:77] Creating layer relu5_1
I0605 13:24:09.445987 15110 net.cpp:106] Creating Layer relu5_1
I0605 13:24:09.445991 15110 net.cpp:454] relu5_1 <- conv5_1
I0605 13:24:09.445996 15110 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0605 13:24:09.446111 15110 net.cpp:150] Setting up relu5_1
I0605 13:24:09.446117 15110 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 13:24:09.446120 15110 net.cpp:165] Memory required for data: 1370708844
I0605 13:24:09.446121 15110 layer_factory.hpp:77] Creating layer conv5_2
I0605 13:24:09.446128 15110 net.cpp:106] Creating Layer conv5_2
I0605 13:24:09.446130 15110 net.cpp:454] conv5_2 <- conv5_1
I0605 13:24:09.446135 15110 net.cpp:411] conv5_2 -> conv5_2
I0605 13:24:09.450392 15110 net.cpp:150] Setting up conv5_2
I0605 13:24:09.450410 15110 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 13:24:09.450412 15110 net.cpp:165] Memory required for data: 1375611756
I0605 13:24:09.450419 15110 layer_factory.hpp:77] Creating layer relu5_2
I0605 13:24:09.450428 15110 net.cpp:106] Creating Layer relu5_2
I0605 13:24:09.450430 15110 net.cpp:454] relu5_2 <- conv5_2
I0605 13:24:09.450436 15110 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0605 13:24:09.450551 15110 net.cpp:150] Setting up relu5_2
I0605 13:24:09.450557 15110 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 13:24:09.450559 15110 net.cpp:165] Memory required for data: 1380514668
I0605 13:24:09.450562 15110 layer_factory.hpp:77] Creating layer conv5_3
I0605 13:24:09.450572 15110 net.cpp:106] Creating Layer conv5_3
I0605 13:24:09.450575 15110 net.cpp:454] conv5_3 <- conv5_2
I0605 13:24:09.450578 15110 net.cpp:411] conv5_3 -> conv5_3
I0605 13:24:09.455006 15110 net.cpp:150] Setting up conv5_3
I0605 13:24:09.455044 15110 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 13:24:09.455047 15110 net.cpp:165] Memory required for data: 1385417580
I0605 13:24:09.455054 15110 layer_factory.hpp:77] Creating layer relu5_3
I0605 13:24:09.455063 15110 net.cpp:106] Creating Layer relu5_3
I0605 13:24:09.455067 15110 net.cpp:454] relu5_3 <- conv5_3
I0605 13:24:09.455072 15110 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0605 13:24:09.455197 15110 net.cpp:150] Setting up relu5_3
I0605 13:24:09.455204 15110 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 13:24:09.455215 15110 net.cpp:165] Memory required for data: 1390320492
I0605 13:24:09.455217 15110 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0605 13:24:09.455222 15110 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0605 13:24:09.455225 15110 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0605 13:24:09.455229 15110 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0605 13:24:09.455233 15110 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0605 13:24:09.455237 15110 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0605 13:24:09.455271 15110 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0605 13:24:09.455274 15110 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 13:24:09.455277 15110 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 13:24:09.455279 15110 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 13:24:09.455281 15110 net.cpp:165] Memory required for data: 1405029228
I0605 13:24:09.455283 15110 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0605 13:24:09.455302 15110 net.cpp:106] Creating Layer rpn_conv/3x3
I0605 13:24:09.455307 15110 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0605 13:24:09.455312 15110 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0605 13:24:09.505976 15110 net.cpp:150] Setting up rpn_conv/3x3
I0605 13:24:09.505996 15110 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 13:24:09.506000 15110 net.cpp:165] Memory required for data: 1409932140
I0605 13:24:09.506007 15110 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0605 13:24:09.506017 15110 net.cpp:106] Creating Layer rpn_relu/3x3
I0605 13:24:09.506031 15110 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0605 13:24:09.506036 15110 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0605 13:24:09.506192 15110 net.cpp:150] Setting up rpn_relu/3x3
I0605 13:24:09.506199 15110 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 13:24:09.506201 15110 net.cpp:165] Memory required for data: 1414835052
I0605 13:24:09.506204 15110 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0605 13:24:09.506209 15110 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0605 13:24:09.506212 15110 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0605 13:24:09.506218 15110 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0605 13:24:09.506233 15110 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0605 13:24:09.506274 15110 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0605 13:24:09.506278 15110 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 13:24:09.506283 15110 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 13:24:09.506284 15110 net.cpp:165] Memory required for data: 1424640876
I0605 13:24:09.506296 15110 layer_factory.hpp:77] Creating layer rpn_cls_score
I0605 13:24:09.506304 15110 net.cpp:106] Creating Layer rpn_cls_score
I0605 13:24:09.506309 15110 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0605 13:24:09.506312 15110 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0605 13:24:09.507963 15110 net.cpp:150] Setting up rpn_cls_score
I0605 13:24:09.507973 15110 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0605 13:24:09.507987 15110 net.cpp:165] Memory required for data: 1424928156
I0605 13:24:09.507992 15110 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0605 13:24:09.507997 15110 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0605 13:24:09.507999 15110 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0605 13:24:09.508004 15110 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0605 13:24:09.508010 15110 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0605 13:24:09.508036 15110 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0605 13:24:09.508041 15110 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0605 13:24:09.508044 15110 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0605 13:24:09.508046 15110 net.cpp:165] Memory required for data: 1425502716
I0605 13:24:09.508049 15110 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0605 13:24:09.508056 15110 net.cpp:106] Creating Layer rpn_bbox_pred
I0605 13:24:09.508059 15110 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0605 13:24:09.508064 15110 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0605 13:24:09.509552 15110 net.cpp:150] Setting up rpn_bbox_pred
I0605 13:24:09.509559 15110 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 13:24:09.509562 15110 net.cpp:165] Memory required for data: 1426077276
I0605 13:24:09.509567 15110 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0605 13:24:09.509570 15110 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0605 13:24:09.509573 15110 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0605 13:24:09.509578 15110 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0605 13:24:09.509593 15110 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0605 13:24:09.509629 15110 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0605 13:24:09.509634 15110 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 13:24:09.509635 15110 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 13:24:09.509637 15110 net.cpp:165] Memory required for data: 1427226396
I0605 13:24:09.509639 15110 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0605 13:24:09.509655 15110 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0605 13:24:09.509658 15110 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0605 13:24:09.509662 15110 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0605 13:24:09.509680 15110 net.cpp:150] Setting up rpn_cls_score_reshape
I0605 13:24:09.509692 15110 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0605 13:24:09.509694 15110 net.cpp:165] Memory required for data: 1427513676
I0605 13:24:09.509696 15110 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0605 13:24:09.509711 15110 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0605 13:24:09.509714 15110 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0605 13:24:09.509718 15110 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0605 13:24:09.509722 15110 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0605 13:24:09.509778 15110 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0605 13:24:09.509781 15110 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0605 13:24:09.509783 15110 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0605 13:24:09.509796 15110 net.cpp:165] Memory required for data: 1428088236
I0605 13:24:09.509799 15110 layer_factory.hpp:77] Creating layer rpn-data
I0605 13:24:09.510123 15110 net.cpp:106] Creating Layer rpn-data
I0605 13:24:09.510130 15110 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0605 13:24:09.510136 15110 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0605 13:24:09.510141 15110 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0605 13:24:09.510144 15110 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0605 13:24:09.510149 15110 net.cpp:411] rpn-data -> rpn_labels
I0605 13:24:09.510154 15110 net.cpp:411] rpn-data -> rpn_bbox_targets
I0605 13:24:09.510159 15110 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0605 13:24:09.510164 15110 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0605 13:24:09.510993 15110 net.cpp:150] Setting up rpn-data
I0605 13:24:09.511000 15110 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0605 13:24:09.511004 15110 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 13:24:09.511008 15110 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 13:24:09.511011 15110 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 13:24:09.511014 15110 net.cpp:165] Memory required for data: 1429955556
I0605 13:24:09.511016 15110 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0605 13:24:09.511023 15110 net.cpp:106] Creating Layer rpn_loss_cls
I0605 13:24:09.511027 15110 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0605 13:24:09.511031 15110 net.cpp:454] rpn_loss_cls <- rpn_labels
I0605 13:24:09.511034 15110 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0605 13:24:09.511046 15110 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0605 13:24:09.511665 15110 net.cpp:150] Setting up rpn_loss_cls
I0605 13:24:09.511673 15110 net.cpp:157] Top shape: (1)
I0605 13:24:09.511677 15110 net.cpp:160]     with loss weight 1
I0605 13:24:09.511685 15110 net.cpp:165] Memory required for data: 1429955560
I0605 13:24:09.511687 15110 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0605 13:24:09.511695 15110 net.cpp:106] Creating Layer rpn_loss_bbox
I0605 13:24:09.511699 15110 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0605 13:24:09.511703 15110 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0605 13:24:09.511706 15110 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0605 13:24:09.511709 15110 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0605 13:24:09.511714 15110 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0605 13:24:09.512814 15110 net.cpp:150] Setting up rpn_loss_bbox
I0605 13:24:09.512821 15110 net.cpp:157] Top shape: (1)
I0605 13:24:09.512825 15110 net.cpp:160]     with loss weight 1
I0605 13:24:09.512830 15110 net.cpp:165] Memory required for data: 1429955564
I0605 13:24:09.512833 15110 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0605 13:24:09.512838 15110 net.cpp:106] Creating Layer rpn_cls_prob
I0605 13:24:09.512843 15110 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0605 13:24:09.512848 15110 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0605 13:24:09.513002 15110 net.cpp:150] Setting up rpn_cls_prob
I0605 13:24:09.513008 15110 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0605 13:24:09.513011 15110 net.cpp:165] Memory required for data: 1430242844
I0605 13:24:09.513013 15110 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0605 13:24:09.513020 15110 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0605 13:24:09.513023 15110 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0605 13:24:09.513028 15110 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0605 13:24:09.513046 15110 net.cpp:150] Setting up rpn_cls_prob_reshape
I0605 13:24:09.513049 15110 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0605 13:24:09.513051 15110 net.cpp:165] Memory required for data: 1430530124
I0605 13:24:09.513053 15110 layer_factory.hpp:77] Creating layer proposal
I0605 13:24:09.514087 15110 net.cpp:106] Creating Layer proposal
I0605 13:24:09.514096 15110 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0605 13:24:09.514099 15110 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0605 13:24:09.514102 15110 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0605 13:24:09.514107 15110 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0605 13:24:09.516178 15110 net.cpp:150] Setting up proposal
I0605 13:24:09.516187 15110 net.cpp:157] Top shape: 1 5 (5)
I0605 13:24:09.516191 15110 net.cpp:165] Memory required for data: 1430530144
I0605 13:24:09.516193 15110 layer_factory.hpp:77] Creating layer roi-data
I0605 13:24:09.518997 15110 net.cpp:106] Creating Layer roi-data
I0605 13:24:09.519006 15110 net.cpp:454] roi-data <- rpn_rois
I0605 13:24:09.519022 15110 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0605 13:24:09.519026 15110 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0605 13:24:09.519029 15110 net.cpp:454] roi-data <- seg_mask_inds
I0605 13:24:09.519042 15110 net.cpp:454] roi-data <- flipped
I0605 13:24:09.519048 15110 net.cpp:411] roi-data -> rois
I0605 13:24:09.519055 15110 net.cpp:411] roi-data -> labels
I0605 13:24:09.519062 15110 net.cpp:411] roi-data -> bbox_targets
I0605 13:24:09.519066 15110 net.cpp:411] roi-data -> bbox_inside_weights
I0605 13:24:09.519071 15110 net.cpp:411] roi-data -> bbox_outside_weights
I0605 13:24:09.519075 15110 net.cpp:411] roi-data -> mask_targets
I0605 13:24:09.519081 15110 net.cpp:411] roi-data -> rois_pos
I0605 13:24:09.519086 15110 net.cpp:411] roi-data -> rois_attribute
I0605 13:24:09.519431 15110 net.cpp:150] Setting up roi-data
I0605 13:24:09.519450 15110 net.cpp:157] Top shape: 1 5 (5)
I0605 13:24:09.519454 15110 net.cpp:157] Top shape: 1 1 (1)
I0605 13:24:09.519457 15110 net.cpp:157] Top shape: 1 8 (8)
I0605 13:24:09.519460 15110 net.cpp:157] Top shape: 1 8 (8)
I0605 13:24:09.519464 15110 net.cpp:157] Top shape: 1 8 (8)
I0605 13:24:09.519481 15110 net.cpp:157] Top shape: 1 244 244 (59536)
I0605 13:24:09.519485 15110 net.cpp:157] Top shape: 1 5 (5)
I0605 13:24:09.519490 15110 net.cpp:157] Top shape: 1 20 (20)
I0605 13:24:09.519495 15110 net.cpp:165] Memory required for data: 1430768508
I0605 13:24:09.519500 15110 layer_factory.hpp:77] Creating layer roi_pool5
I0605 13:24:09.519508 15110 net.cpp:106] Creating Layer roi_pool5
I0605 13:24:09.519512 15110 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0605 13:24:09.519516 15110 net.cpp:454] roi_pool5 <- rois
I0605 13:24:09.519520 15110 net.cpp:411] roi_pool5 -> pool5
I0605 13:24:09.519531 15110 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0605 13:24:09.519623 15110 net.cpp:150] Setting up roi_pool5
I0605 13:24:09.519628 15110 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 13:24:09.519639 15110 net.cpp:165] Memory required for data: 1430868860
I0605 13:24:09.519642 15110 layer_factory.hpp:77] Creating layer fc6
I0605 13:24:09.519659 15110 net.cpp:106] Creating Layer fc6
I0605 13:24:09.519665 15110 net.cpp:454] fc6 <- pool5
I0605 13:24:09.519670 15110 net.cpp:411] fc6 -> fc6
I0605 13:24:09.659149 15110 net.cpp:150] Setting up fc6
I0605 13:24:09.659178 15110 net.cpp:157] Top shape: 1 4096 (4096)
I0605 13:24:09.659180 15110 net.cpp:165] Memory required for data: 1430885244
I0605 13:24:09.659196 15110 layer_factory.hpp:77] Creating layer relu6
I0605 13:24:09.659205 15110 net.cpp:106] Creating Layer relu6
I0605 13:24:09.659210 15110 net.cpp:454] relu6 <- fc6
I0605 13:24:09.659216 15110 net.cpp:397] relu6 -> fc6 (in-place)
I0605 13:24:09.659420 15110 net.cpp:150] Setting up relu6
I0605 13:24:09.659427 15110 net.cpp:157] Top shape: 1 4096 (4096)
I0605 13:24:09.659430 15110 net.cpp:165] Memory required for data: 1430901628
I0605 13:24:09.659432 15110 layer_factory.hpp:77] Creating layer fc7
I0605 13:24:09.659438 15110 net.cpp:106] Creating Layer fc7
I0605 13:24:09.659441 15110 net.cpp:454] fc7 <- fc6
I0605 13:24:09.659446 15110 net.cpp:411] fc7 -> fc7
I0605 13:24:09.683116 15110 net.cpp:150] Setting up fc7
I0605 13:24:09.683141 15110 net.cpp:157] Top shape: 1 4096 (4096)
I0605 13:24:09.683145 15110 net.cpp:165] Memory required for data: 1430918012
I0605 13:24:09.683156 15110 layer_factory.hpp:77] Creating layer relu7
I0605 13:24:09.683164 15110 net.cpp:106] Creating Layer relu7
I0605 13:24:09.683169 15110 net.cpp:454] relu7 <- fc7
I0605 13:24:09.683176 15110 net.cpp:397] relu7 -> fc7 (in-place)
I0605 13:24:09.683388 15110 net.cpp:150] Setting up relu7
I0605 13:24:09.683396 15110 net.cpp:157] Top shape: 1 4096 (4096)
I0605 13:24:09.683399 15110 net.cpp:165] Memory required for data: 1430934396
I0605 13:24:09.683403 15110 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0605 13:24:09.683408 15110 net.cpp:106] Creating Layer fc7_relu7_0_split
I0605 13:24:09.683410 15110 net.cpp:454] fc7_relu7_0_split <- fc7
I0605 13:24:09.683414 15110 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0605 13:24:09.683434 15110 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0605 13:24:09.683497 15110 net.cpp:150] Setting up fc7_relu7_0_split
I0605 13:24:09.683502 15110 net.cpp:157] Top shape: 1 4096 (4096)
I0605 13:24:09.683516 15110 net.cpp:157] Top shape: 1 4096 (4096)
I0605 13:24:09.683517 15110 net.cpp:165] Memory required for data: 1430967164
I0605 13:24:09.683521 15110 layer_factory.hpp:77] Creating layer cls_score
I0605 13:24:09.683537 15110 net.cpp:106] Creating Layer cls_score
I0605 13:24:09.683540 15110 net.cpp:454] cls_score <- fc7_relu7_0_split_0
I0605 13:24:09.683554 15110 net.cpp:411] cls_score -> cls_score
I0605 13:24:09.683815 15110 net.cpp:150] Setting up cls_score
I0605 13:24:09.683820 15110 net.cpp:157] Top shape: 1 2 (2)
I0605 13:24:09.683822 15110 net.cpp:165] Memory required for data: 1430967172
I0605 13:24:09.683826 15110 layer_factory.hpp:77] Creating layer bbox_pred
I0605 13:24:09.683830 15110 net.cpp:106] Creating Layer bbox_pred
I0605 13:24:09.683833 15110 net.cpp:454] bbox_pred <- fc7_relu7_0_split_1
I0605 13:24:09.683836 15110 net.cpp:411] bbox_pred -> bbox_pred
I0605 13:24:09.684597 15110 net.cpp:150] Setting up bbox_pred
I0605 13:24:09.684602 15110 net.cpp:157] Top shape: 1 8 (8)
I0605 13:24:09.684603 15110 net.cpp:165] Memory required for data: 1430967204
I0605 13:24:09.684607 15110 layer_factory.hpp:77] Creating layer loss_cls
I0605 13:24:09.684612 15110 net.cpp:106] Creating Layer loss_cls
I0605 13:24:09.684614 15110 net.cpp:454] loss_cls <- cls_score
I0605 13:24:09.684618 15110 net.cpp:454] loss_cls <- labels
I0605 13:24:09.684631 15110 net.cpp:411] loss_cls -> loss_cls
I0605 13:24:09.684638 15110 layer_factory.hpp:77] Creating layer loss_cls
I0605 13:24:09.685374 15110 net.cpp:150] Setting up loss_cls
I0605 13:24:09.685384 15110 net.cpp:157] Top shape: (1)
I0605 13:24:09.685386 15110 net.cpp:160]     with loss weight 3
I0605 13:24:09.685396 15110 net.cpp:165] Memory required for data: 1430967208
I0605 13:24:09.685408 15110 layer_factory.hpp:77] Creating layer loss_bbox
I0605 13:24:09.685432 15110 net.cpp:106] Creating Layer loss_bbox
I0605 13:24:09.685436 15110 net.cpp:454] loss_bbox <- bbox_pred
I0605 13:24:09.685438 15110 net.cpp:454] loss_bbox <- bbox_targets
I0605 13:24:09.685442 15110 net.cpp:454] loss_bbox <- bbox_inside_weights
I0605 13:24:09.685446 15110 net.cpp:454] loss_bbox <- bbox_outside_weights
I0605 13:24:09.685449 15110 net.cpp:411] loss_bbox -> loss_bbox
I0605 13:24:09.685523 15110 net.cpp:150] Setting up loss_bbox
I0605 13:24:09.685528 15110 net.cpp:157] Top shape: (1)
I0605 13:24:09.685529 15110 net.cpp:160]     with loss weight 2
I0605 13:24:09.685534 15110 net.cpp:165] Memory required for data: 1430967212
I0605 13:24:09.685545 15110 layer_factory.hpp:77] Creating layer roi_pool5_2
I0605 13:24:09.685551 15110 net.cpp:106] Creating Layer roi_pool5_2
I0605 13:24:09.685556 15110 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0605 13:24:09.685560 15110 net.cpp:454] roi_pool5_2 <- rois_pos
I0605 13:24:09.685564 15110 net.cpp:411] roi_pool5_2 -> pool5_2
I0605 13:24:09.685570 15110 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0605 13:24:09.685643 15110 net.cpp:150] Setting up roi_pool5_2
I0605 13:24:09.685650 15110 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 13:24:09.685653 15110 net.cpp:165] Memory required for data: 1431067564
I0605 13:24:09.685667 15110 layer_factory.hpp:77] Creating layer pool5_2_conv
I0605 13:24:09.685675 15110 net.cpp:106] Creating Layer pool5_2_conv
I0605 13:24:09.685678 15110 net.cpp:454] pool5_2_conv <- pool5_2
I0605 13:24:09.685683 15110 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0605 13:24:09.692414 15110 net.cpp:150] Setting up pool5_2_conv
I0605 13:24:09.692425 15110 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 13:24:09.692426 15110 net.cpp:165] Memory required for data: 1431167916
I0605 13:24:09.692443 15110 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0605 13:24:09.692450 15110 net.cpp:106] Creating Layer pool5_2_conv_relu
I0605 13:24:09.692463 15110 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0605 13:24:09.692469 15110 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0605 13:24:09.692625 15110 net.cpp:150] Setting up pool5_2_conv_relu
I0605 13:24:09.692631 15110 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 13:24:09.692633 15110 net.cpp:165] Memory required for data: 1431268268
I0605 13:24:09.692647 15110 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0605 13:24:09.692670 15110 net.cpp:106] Creating Layer pool5_2_conv2
I0605 13:24:09.692674 15110 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0605 13:24:09.692688 15110 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0605 13:24:09.743630 15110 net.cpp:150] Setting up pool5_2_conv2
I0605 13:24:09.743647 15110 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 13:24:09.743650 15110 net.cpp:165] Memory required for data: 1431368620
I0605 13:24:09.743659 15110 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0605 13:24:09.743666 15110 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0605 13:24:09.743681 15110 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0605 13:24:09.743686 15110 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0605 13:24:09.743860 15110 net.cpp:150] Setting up pool5_2_conv2_relu
I0605 13:24:09.743867 15110 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 13:24:09.743870 15110 net.cpp:165] Memory required for data: 1431468972
I0605 13:24:09.743872 15110 layer_factory.hpp:77] Creating layer mask_deconv1
I0605 13:24:09.743880 15110 net.cpp:106] Creating Layer mask_deconv1
I0605 13:24:09.743882 15110 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0605 13:24:09.743886 15110 net.cpp:411] mask_deconv1 -> mask_deconv1
I0605 13:24:09.744693 15110 net.cpp:150] Setting up mask_deconv1
I0605 13:24:09.744699 15110 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0605 13:24:09.744700 15110 net.cpp:165] Memory required for data: 1432390572
I0605 13:24:09.744704 15110 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0605 13:24:09.744711 15110 net.cpp:106] Creating Layer pool5_2_conv3
I0605 13:24:09.744714 15110 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0605 13:24:09.744717 15110 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0605 13:24:09.770841 15110 net.cpp:150] Setting up pool5_2_conv3
I0605 13:24:09.770859 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.770862 15110 net.cpp:165] Memory required for data: 1434233772
I0605 13:24:09.770870 15110 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0605 13:24:09.770879 15110 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0605 13:24:09.770885 15110 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0605 13:24:09.770890 15110 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0605 13:24:09.771035 15110 net.cpp:150] Setting up pool5_2_conv3_relu
I0605 13:24:09.771042 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.771044 15110 net.cpp:165] Memory required for data: 1436076972
I0605 13:24:09.771047 15110 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0605 13:24:09.771057 15110 net.cpp:106] Creating Layer pool5_2_conv4
I0605 13:24:09.771060 15110 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0605 13:24:09.771065 15110 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0605 13:24:09.821625 15110 net.cpp:150] Setting up pool5_2_conv4
I0605 13:24:09.821645 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.821648 15110 net.cpp:165] Memory required for data: 1437920172
I0605 13:24:09.821656 15110 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0605 13:24:09.821676 15110 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0605 13:24:09.821681 15110 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0605 13:24:09.821687 15110 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0605 13:24:09.821837 15110 net.cpp:150] Setting up pool5_2_conv4_relu
I0605 13:24:09.821846 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.821847 15110 net.cpp:165] Memory required for data: 1439763372
I0605 13:24:09.821851 15110 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0605 13:24:09.821857 15110 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0605 13:24:09.821861 15110 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0605 13:24:09.821875 15110 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0605 13:24:09.821880 15110 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0605 13:24:09.821888 15110 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0605 13:24:09.821892 15110 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0605 13:24:09.821897 15110 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_4
I0605 13:24:09.821902 15110 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_5
I0605 13:24:09.821905 15110 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_6
I0605 13:24:09.821909 15110 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_7
I0605 13:24:09.821993 15110 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0605 13:24:09.821998 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.822012 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.822015 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.822017 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.822021 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.822023 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.822026 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.822028 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.822031 15110 net.cpp:165] Memory required for data: 1454508972
I0605 13:24:09.822033 15110 layer_factory.hpp:77] Creating layer query_conv
I0605 13:24:09.822042 15110 net.cpp:106] Creating Layer query_conv
I0605 13:24:09.822046 15110 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0605 13:24:09.822052 15110 net.cpp:411] query_conv -> query_conv
I0605 13:24:09.823685 15110 net.cpp:150] Setting up query_conv
I0605 13:24:09.823705 15110 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0605 13:24:09.823707 15110 net.cpp:165] Memory required for data: 1454739372
I0605 13:24:09.823714 15110 layer_factory.hpp:77] Creating layer key_conv
I0605 13:24:09.823722 15110 net.cpp:106] Creating Layer key_conv
I0605 13:24:09.823726 15110 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0605 13:24:09.823731 15110 net.cpp:411] key_conv -> key_conv
I0605 13:24:09.825314 15110 net.cpp:150] Setting up key_conv
I0605 13:24:09.825323 15110 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0605 13:24:09.825326 15110 net.cpp:165] Memory required for data: 1454969772
I0605 13:24:09.825331 15110 layer_factory.hpp:77] Creating layer value_conv
I0605 13:24:09.825338 15110 net.cpp:106] Creating Layer value_conv
I0605 13:24:09.825341 15110 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0605 13:24:09.825348 15110 net.cpp:411] value_conv -> value_conv
I0605 13:24:09.831984 15110 net.cpp:150] Setting up value_conv
I0605 13:24:09.831993 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.831996 15110 net.cpp:165] Memory required for data: 1456812972
I0605 13:24:09.832011 15110 layer_factory.hpp:77] Creating layer query_conv_reshape
I0605 13:24:09.832020 15110 net.cpp:106] Creating Layer query_conv_reshape
I0605 13:24:09.832023 15110 net.cpp:454] query_conv_reshape <- query_conv
I0605 13:24:09.832028 15110 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0605 13:24:09.832049 15110 net.cpp:150] Setting up query_conv_reshape
I0605 13:24:09.832062 15110 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0605 13:24:09.832064 15110 net.cpp:165] Memory required for data: 1457043372
I0605 13:24:09.832067 15110 layer_factory.hpp:77] Creating layer key_conv_reshape
I0605 13:24:09.832082 15110 net.cpp:106] Creating Layer key_conv_reshape
I0605 13:24:09.832085 15110 net.cpp:454] key_conv_reshape <- key_conv
I0605 13:24:09.832090 15110 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0605 13:24:09.832118 15110 net.cpp:150] Setting up key_conv_reshape
I0605 13:24:09.832121 15110 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0605 13:24:09.832134 15110 net.cpp:165] Memory required for data: 1457273772
I0605 13:24:09.832135 15110 layer_factory.hpp:77] Creating layer value_conv_reshape
I0605 13:24:09.832139 15110 net.cpp:106] Creating Layer value_conv_reshape
I0605 13:24:09.832144 15110 net.cpp:454] value_conv_reshape <- value_conv
I0605 13:24:09.832147 15110 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0605 13:24:09.832162 15110 net.cpp:150] Setting up value_conv_reshape
I0605 13:24:09.832165 15110 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0605 13:24:09.832168 15110 net.cpp:165] Memory required for data: 1459116972
I0605 13:24:09.832170 15110 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0605 13:24:09.832180 15110 net.cpp:106] Creating Layer query_conv_reshape_perm
I0605 13:24:09.832182 15110 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0605 13:24:09.832186 15110 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0605 13:24:09.832253 15110 net.cpp:150] Setting up query_conv_reshape_perm
I0605 13:24:09.832258 15110 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0605 13:24:09.832260 15110 net.cpp:165] Memory required for data: 1459347372
I0605 13:24:09.832262 15110 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0605 13:24:09.832267 15110 net.cpp:106] Creating Layer key_conv_reshape_perm
I0605 13:24:09.832271 15110 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0605 13:24:09.832275 15110 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0605 13:24:09.832360 15110 net.cpp:150] Setting up key_conv_reshape_perm
I0605 13:24:09.832365 15110 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0605 13:24:09.832366 15110 net.cpp:165] Memory required for data: 1459577772
I0605 13:24:09.832368 15110 layer_factory.hpp:77] Creating layer energy
I0605 13:24:09.832372 15110 net.cpp:106] Creating Layer energy
I0605 13:24:09.832376 15110 net.cpp:454] energy <- query_conv_reshape_perm
I0605 13:24:09.832378 15110 net.cpp:454] energy <- key_conv_reshape_perm
I0605 13:24:09.832382 15110 net.cpp:411] energy -> energy
I0605 13:24:09.832397 15110 net.cpp:150] Setting up energy
I0605 13:24:09.832401 15110 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0605 13:24:09.832404 15110 net.cpp:165] Memory required for data: 1462817772
I0605 13:24:09.832406 15110 layer_factory.hpp:77] Creating layer attention
I0605 13:24:09.832410 15110 net.cpp:106] Creating Layer attention
I0605 13:24:09.832413 15110 net.cpp:454] attention <- energy
I0605 13:24:09.832417 15110 net.cpp:411] attention -> attention
I0605 13:24:09.832571 15110 net.cpp:150] Setting up attention
I0605 13:24:09.832577 15110 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0605 13:24:09.832579 15110 net.cpp:165] Memory required for data: 1466057772
I0605 13:24:09.832582 15110 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0605 13:24:09.832597 15110 net.cpp:106] Creating Layer value_conv_reshape_perm
I0605 13:24:09.832599 15110 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0605 13:24:09.832603 15110 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0605 13:24:09.832677 15110 net.cpp:150] Setting up value_conv_reshape_perm
I0605 13:24:09.832682 15110 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0605 13:24:09.832684 15110 net.cpp:165] Memory required for data: 1467900972
I0605 13:24:09.832686 15110 layer_factory.hpp:77] Creating layer attention_perm
I0605 13:24:09.832700 15110 net.cpp:106] Creating Layer attention_perm
I0605 13:24:09.832702 15110 net.cpp:454] attention_perm <- attention
I0605 13:24:09.832705 15110 net.cpp:411] attention_perm -> attention_perm
I0605 13:24:09.832777 15110 net.cpp:150] Setting up attention_perm
I0605 13:24:09.832782 15110 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0605 13:24:09.832783 15110 net.cpp:165] Memory required for data: 1471140972
I0605 13:24:09.832787 15110 layer_factory.hpp:77] Creating layer out
I0605 13:24:09.832790 15110 net.cpp:106] Creating Layer out
I0605 13:24:09.832792 15110 net.cpp:454] out <- value_conv_reshape_perm
I0605 13:24:09.832795 15110 net.cpp:454] out <- attention_perm
I0605 13:24:09.832799 15110 net.cpp:411] out -> out
I0605 13:24:09.832825 15110 net.cpp:150] Setting up out
I0605 13:24:09.832840 15110 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0605 13:24:09.832842 15110 net.cpp:165] Memory required for data: 1472984172
I0605 13:24:09.832844 15110 layer_factory.hpp:77] Creating layer out_reshape
I0605 13:24:09.832856 15110 net.cpp:106] Creating Layer out_reshape
I0605 13:24:09.832859 15110 net.cpp:454] out_reshape <- out
I0605 13:24:09.832862 15110 net.cpp:411] out_reshape -> out_reshape
I0605 13:24:09.832888 15110 net.cpp:150] Setting up out_reshape
I0605 13:24:09.832892 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.832903 15110 net.cpp:165] Memory required for data: 1474827372
I0605 13:24:09.832906 15110 layer_factory.hpp:77] Creating layer out_reshape_scale
I0605 13:24:09.832923 15110 net.cpp:106] Creating Layer out_reshape_scale
I0605 13:24:09.832927 15110 net.cpp:454] out_reshape_scale <- out_reshape
I0605 13:24:09.832931 15110 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0605 13:24:09.833000 15110 net.cpp:150] Setting up out_reshape_scale
I0605 13:24:09.833005 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.833007 15110 net.cpp:165] Memory required for data: 1476670572
I0605 13:24:09.833020 15110 layer_factory.hpp:77] Creating layer out_x
I0605 13:24:09.833026 15110 net.cpp:106] Creating Layer out_x
I0605 13:24:09.833029 15110 net.cpp:454] out_x <- out_reshape_scale
I0605 13:24:09.833031 15110 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0605 13:24:09.833035 15110 net.cpp:411] out_x -> out_x
I0605 13:24:09.833051 15110 net.cpp:150] Setting up out_x
I0605 13:24:09.833055 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.833066 15110 net.cpp:165] Memory required for data: 1478513772
I0605 13:24:09.833068 15110 layer_factory.hpp:77] Creating layer query_conv_reshape_ch
I0605 13:24:09.833073 15110 net.cpp:106] Creating Layer query_conv_reshape_ch
I0605 13:24:09.833086 15110 net.cpp:454] query_conv_reshape_ch <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_4
I0605 13:24:09.833089 15110 net.cpp:411] query_conv_reshape_ch -> query_conv_reshape_ch
I0605 13:24:09.833106 15110 net.cpp:150] Setting up query_conv_reshape_ch
I0605 13:24:09.833120 15110 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0605 13:24:09.833122 15110 net.cpp:165] Memory required for data: 1480356972
I0605 13:24:09.833124 15110 layer_factory.hpp:77] Creating layer key_conv_reshape_ch
I0605 13:24:09.833127 15110 net.cpp:106] Creating Layer key_conv_reshape_ch
I0605 13:24:09.833142 15110 net.cpp:454] key_conv_reshape_ch <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_5
I0605 13:24:09.833144 15110 net.cpp:411] key_conv_reshape_ch -> key_conv_reshape_ch
I0605 13:24:09.833169 15110 net.cpp:150] Setting up key_conv_reshape_ch
I0605 13:24:09.833184 15110 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0605 13:24:09.833185 15110 net.cpp:165] Memory required for data: 1482200172
I0605 13:24:09.833187 15110 layer_factory.hpp:77] Creating layer value_conv_reshape_ch
I0605 13:24:09.833201 15110 net.cpp:106] Creating Layer value_conv_reshape_ch
I0605 13:24:09.833204 15110 net.cpp:454] value_conv_reshape_ch <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_6
I0605 13:24:09.833207 15110 net.cpp:411] value_conv_reshape_ch -> value_conv_reshape_ch
I0605 13:24:09.833221 15110 net.cpp:150] Setting up value_conv_reshape_ch
I0605 13:24:09.833225 15110 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0605 13:24:09.833237 15110 net.cpp:165] Memory required for data: 1484043372
I0605 13:24:09.833240 15110 layer_factory.hpp:77] Creating layer query_conv_reshape_perm_ch
I0605 13:24:09.833242 15110 net.cpp:106] Creating Layer query_conv_reshape_perm_ch
I0605 13:24:09.833256 15110 net.cpp:454] query_conv_reshape_perm_ch <- query_conv_reshape_ch
I0605 13:24:09.833259 15110 net.cpp:411] query_conv_reshape_perm_ch -> query_conv_reshape_perm_ch
I0605 13:24:09.833343 15110 net.cpp:150] Setting up query_conv_reshape_perm_ch
I0605 13:24:09.833348 15110 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0605 13:24:09.833351 15110 net.cpp:165] Memory required for data: 1485886572
I0605 13:24:09.833353 15110 layer_factory.hpp:77] Creating layer key_conv_reshape_perm_ch
I0605 13:24:09.833356 15110 net.cpp:106] Creating Layer key_conv_reshape_perm_ch
I0605 13:24:09.833359 15110 net.cpp:454] key_conv_reshape_perm_ch <- key_conv_reshape_ch
I0605 13:24:09.833364 15110 net.cpp:411] key_conv_reshape_perm_ch -> key_conv_reshape_perm_ch
I0605 13:24:09.833446 15110 net.cpp:150] Setting up key_conv_reshape_perm_ch
I0605 13:24:09.833452 15110 net.cpp:157] Top shape: 1 1 900 512 (460800)
I0605 13:24:09.833454 15110 net.cpp:165] Memory required for data: 1487729772
I0605 13:24:09.833457 15110 layer_factory.hpp:77] Creating layer energy_ch
I0605 13:24:09.833461 15110 net.cpp:106] Creating Layer energy_ch
I0605 13:24:09.833464 15110 net.cpp:454] energy_ch <- query_conv_reshape_perm_ch
I0605 13:24:09.833468 15110 net.cpp:454] energy_ch <- key_conv_reshape_perm_ch
I0605 13:24:09.833473 15110 net.cpp:411] energy_ch -> energy_ch
I0605 13:24:09.833489 15110 net.cpp:150] Setting up energy_ch
I0605 13:24:09.833503 15110 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0605 13:24:09.833505 15110 net.cpp:165] Memory required for data: 1488778348
I0605 13:24:09.833508 15110 layer_factory.hpp:77] Creating layer energy_ch_energy_ch_0_split
I0605 13:24:09.833520 15110 net.cpp:106] Creating Layer energy_ch_energy_ch_0_split
I0605 13:24:09.833523 15110 net.cpp:454] energy_ch_energy_ch_0_split <- energy_ch
I0605 13:24:09.833526 15110 net.cpp:411] energy_ch_energy_ch_0_split -> energy_ch_energy_ch_0_split_0
I0605 13:24:09.833529 15110 net.cpp:411] energy_ch_energy_ch_0_split -> energy_ch_energy_ch_0_split_1
I0605 13:24:09.833554 15110 net.cpp:150] Setting up energy_ch_energy_ch_0_split
I0605 13:24:09.833559 15110 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0605 13:24:09.833562 15110 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0605 13:24:09.833564 15110 net.cpp:165] Memory required for data: 1490875500
I0605 13:24:09.833566 15110 layer_factory.hpp:77] Creating layer energy_ch_pool
I0605 13:24:09.833572 15110 net.cpp:106] Creating Layer energy_ch_pool
I0605 13:24:09.833575 15110 net.cpp:454] energy_ch_pool <- energy_ch_energy_ch_0_split_0
I0605 13:24:09.833580 15110 net.cpp:411] energy_ch_pool -> energy_ch_pool
I0605 13:24:09.833609 15110 net.cpp:150] Setting up energy_ch_pool
I0605 13:24:09.833613 15110 net.cpp:157] Top shape: 1 1 512 1 (512)
I0605 13:24:09.833616 15110 net.cpp:165] Memory required for data: 1490877548
I0605 13:24:09.833618 15110 layer_factory.hpp:77] Creating layer energy_ch_max
I0605 13:24:09.833623 15110 net.cpp:106] Creating Layer energy_ch_max
I0605 13:24:09.833626 15110 net.cpp:454] energy_ch_max <- energy_ch_pool
I0605 13:24:09.833629 15110 net.cpp:411] energy_ch_max -> energy_ch_max
I0605 13:24:09.833647 15110 net.cpp:150] Setting up energy_ch_max
I0605 13:24:09.833650 15110 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0605 13:24:09.833652 15110 net.cpp:165] Memory required for data: 1491926124
I0605 13:24:09.833655 15110 layer_factory.hpp:77] Creating layer energy_ch_minus
I0605 13:24:09.833659 15110 net.cpp:106] Creating Layer energy_ch_minus
I0605 13:24:09.833662 15110 net.cpp:454] energy_ch_minus <- energy_ch_energy_ch_0_split_1
I0605 13:24:09.833667 15110 net.cpp:411] energy_ch_minus -> energy_ch_minus
I0605 13:24:09.833683 15110 net.cpp:150] Setting up energy_ch_minus
I0605 13:24:09.833685 15110 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0605 13:24:09.833688 15110 net.cpp:165] Memory required for data: 1492974700
I0605 13:24:09.833690 15110 layer_factory.hpp:77] Creating layer energy_new
I0605 13:24:09.833695 15110 net.cpp:106] Creating Layer energy_new
I0605 13:24:09.833698 15110 net.cpp:454] energy_new <- energy_ch_max
I0605 13:24:09.833701 15110 net.cpp:454] energy_new <- energy_ch_minus
I0605 13:24:09.833704 15110 net.cpp:411] energy_new -> energy_new
I0605 13:24:09.833719 15110 net.cpp:150] Setting up energy_new
I0605 13:24:09.833722 15110 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0605 13:24:09.833724 15110 net.cpp:165] Memory required for data: 1494023276
I0605 13:24:09.833726 15110 layer_factory.hpp:77] Creating layer attention_ch
I0605 13:24:09.833732 15110 net.cpp:106] Creating Layer attention_ch
I0605 13:24:09.833734 15110 net.cpp:454] attention_ch <- energy_new
I0605 13:24:09.833737 15110 net.cpp:411] attention_ch -> attention_ch
I0605 13:24:09.834302 15110 net.cpp:150] Setting up attention_ch
I0605 13:24:09.834311 15110 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0605 13:24:09.834314 15110 net.cpp:165] Memory required for data: 1495071852
I0605 13:24:09.834316 15110 layer_factory.hpp:77] Creating layer value_conv_reshape_ch_perm
I0605 13:24:09.834322 15110 net.cpp:106] Creating Layer value_conv_reshape_ch_perm
I0605 13:24:09.834326 15110 net.cpp:454] value_conv_reshape_ch_perm <- value_conv_reshape_ch
I0605 13:24:09.834329 15110 net.cpp:411] value_conv_reshape_ch_perm -> value_conv_reshape_ch_perm
I0605 13:24:09.834398 15110 net.cpp:150] Setting up value_conv_reshape_ch_perm
I0605 13:24:09.834403 15110 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0605 13:24:09.834405 15110 net.cpp:165] Memory required for data: 1496915052
I0605 13:24:09.834408 15110 layer_factory.hpp:77] Creating layer attention_ch_perm
I0605 13:24:09.834412 15110 net.cpp:106] Creating Layer attention_ch_perm
I0605 13:24:09.834415 15110 net.cpp:454] attention_ch_perm <- attention_ch
I0605 13:24:09.834419 15110 net.cpp:411] attention_ch_perm -> attention_ch_perm
I0605 13:24:09.834483 15110 net.cpp:150] Setting up attention_ch_perm
I0605 13:24:09.834487 15110 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0605 13:24:09.834489 15110 net.cpp:165] Memory required for data: 1497963628
I0605 13:24:09.834491 15110 layer_factory.hpp:77] Creating layer out_ch
I0605 13:24:09.834496 15110 net.cpp:106] Creating Layer out_ch
I0605 13:24:09.834501 15110 net.cpp:454] out_ch <- attention_ch_perm
I0605 13:24:09.834503 15110 net.cpp:454] out_ch <- value_conv_reshape_ch_perm
I0605 13:24:09.834507 15110 net.cpp:411] out_ch -> out_ch
I0605 13:24:09.834522 15110 net.cpp:150] Setting up out_ch
I0605 13:24:09.834527 15110 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0605 13:24:09.834528 15110 net.cpp:165] Memory required for data: 1499806828
I0605 13:24:09.834532 15110 layer_factory.hpp:77] Creating layer out_ch_reshape
I0605 13:24:09.834535 15110 net.cpp:106] Creating Layer out_ch_reshape
I0605 13:24:09.834538 15110 net.cpp:454] out_ch_reshape <- out_ch
I0605 13:24:09.834542 15110 net.cpp:411] out_ch_reshape -> out_ch_reshape
I0605 13:24:09.834558 15110 net.cpp:150] Setting up out_ch_reshape
I0605 13:24:09.834563 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.834564 15110 net.cpp:165] Memory required for data: 1501650028
I0605 13:24:09.834568 15110 layer_factory.hpp:77] Creating layer out_ch_reshape_scale
I0605 13:24:09.834571 15110 net.cpp:106] Creating Layer out_ch_reshape_scale
I0605 13:24:09.834576 15110 net.cpp:454] out_ch_reshape_scale <- out_ch_reshape
I0605 13:24:09.834579 15110 net.cpp:411] out_ch_reshape_scale -> out_ch_reshape_scale
I0605 13:24:09.834636 15110 net.cpp:150] Setting up out_ch_reshape_scale
I0605 13:24:09.834641 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.834643 15110 net.cpp:165] Memory required for data: 1503493228
I0605 13:24:09.834647 15110 net.cpp:514] Sharing parameters 'scale_conv1_1' owned by layer 'out_reshape_scale', param index 0
I0605 13:24:09.834650 15110 layer_factory.hpp:77] Creating layer out_ch_x
I0605 13:24:09.834658 15110 net.cpp:106] Creating Layer out_ch_x
I0605 13:24:09.834661 15110 net.cpp:454] out_ch_x <- out_ch_reshape_scale
I0605 13:24:09.834666 15110 net.cpp:454] out_ch_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_7
I0605 13:24:09.834669 15110 net.cpp:411] out_ch_x -> out_ch_x
I0605 13:24:09.834687 15110 net.cpp:150] Setting up out_ch_x
I0605 13:24:09.834692 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.834693 15110 net.cpp:165] Memory required for data: 1505336428
I0605 13:24:09.834697 15110 layer_factory.hpp:77] Creating layer out_conv_ch_x
I0605 13:24:09.834704 15110 net.cpp:106] Creating Layer out_conv_ch_x
I0605 13:24:09.834707 15110 net.cpp:454] out_conv_ch_x <- out_ch_x
I0605 13:24:09.834712 15110 net.cpp:411] out_conv_ch_x -> out_conv_ch_x
I0605 13:24:09.840601 15110 net.cpp:150] Setting up out_conv_ch_x
I0605 13:24:09.840610 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.840612 15110 net.cpp:165] Memory required for data: 1507179628
I0605 13:24:09.840618 15110 layer_factory.hpp:77] Creating layer out_conv_x
I0605 13:24:09.840626 15110 net.cpp:106] Creating Layer out_conv_x
I0605 13:24:09.840631 15110 net.cpp:454] out_conv_x <- out_x
I0605 13:24:09.840637 15110 net.cpp:411] out_conv_x -> out_conv_x
I0605 13:24:09.849473 15110 net.cpp:150] Setting up out_conv_x
I0605 13:24:09.849484 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.849488 15110 net.cpp:165] Memory required for data: 1509022828
I0605 13:24:09.849493 15110 layer_factory.hpp:77] Creating layer out_x_sum
I0605 13:24:09.849501 15110 net.cpp:106] Creating Layer out_x_sum
I0605 13:24:09.849505 15110 net.cpp:454] out_x_sum <- out_conv_x
I0605 13:24:09.849511 15110 net.cpp:454] out_x_sum <- out_conv_ch_x
I0605 13:24:09.849517 15110 net.cpp:411] out_x_sum -> out_x_sum
I0605 13:24:09.849541 15110 net.cpp:150] Setting up out_x_sum
I0605 13:24:09.849546 15110 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 13:24:09.849548 15110 net.cpp:165] Memory required for data: 1510866028
I0605 13:24:09.849550 15110 layer_factory.hpp:77] Creating layer mask_deconv2
I0605 13:24:09.849557 15110 net.cpp:106] Creating Layer mask_deconv2
I0605 13:24:09.849562 15110 net.cpp:454] mask_deconv2 <- out_x_sum
I0605 13:24:09.849566 15110 net.cpp:411] mask_deconv2 -> mask_deconv2
I0605 13:24:09.850427 15110 net.cpp:150] Setting up mask_deconv2
I0605 13:24:09.850435 15110 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0605 13:24:09.850446 15110 net.cpp:165] Memory required for data: 1526107244
I0605 13:24:09.850451 15110 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0605 13:24:09.850458 15110 net.cpp:106] Creating Layer pool5_2_conv5
I0605 13:24:09.850462 15110 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0605 13:24:09.850469 15110 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0605 13:24:09.878958 15110 net.cpp:150] Setting up pool5_2_conv5
I0605 13:24:09.878976 15110 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 13:24:09.878979 15110 net.cpp:165] Memory required for data: 1556589676
I0605 13:24:09.879007 15110 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0605 13:24:09.879016 15110 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0605 13:24:09.879034 15110 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0605 13:24:09.879040 15110 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0605 13:24:09.879230 15110 net.cpp:150] Setting up pool5_2_conv5_relu
I0605 13:24:09.879237 15110 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 13:24:09.879240 15110 net.cpp:165] Memory required for data: 1587072108
I0605 13:24:09.879242 15110 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0605 13:24:09.879268 15110 net.cpp:106] Creating Layer pool5_2_conv6
I0605 13:24:09.879272 15110 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0605 13:24:09.879277 15110 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0605 13:24:09.929502 15110 net.cpp:150] Setting up pool5_2_conv6
I0605 13:24:09.929538 15110 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 13:24:09.929543 15110 net.cpp:165] Memory required for data: 1617554540
I0605 13:24:09.929551 15110 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0605 13:24:09.929560 15110 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0605 13:24:09.929565 15110 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0605 13:24:09.929572 15110 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0605 13:24:09.930202 15110 net.cpp:150] Setting up pool5_2_conv6_relu
I0605 13:24:09.930212 15110 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 13:24:09.930214 15110 net.cpp:165] Memory required for data: 1648036972
I0605 13:24:09.930217 15110 layer_factory.hpp:77] Creating layer mask_deconv3
I0605 13:24:09.930225 15110 net.cpp:106] Creating Layer mask_deconv3
I0605 13:24:09.930228 15110 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0605 13:24:09.930234 15110 net.cpp:411] mask_deconv3 -> mask_deconv3
I0605 13:24:09.930610 15110 net.cpp:150] Setting up mask_deconv3
I0605 13:24:09.930616 15110 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0605 13:24:09.930619 15110 net.cpp:165] Memory required for data: 1709001836
I0605 13:24:09.930624 15110 layer_factory.hpp:77] Creating layer mask_score
I0605 13:24:09.930630 15110 net.cpp:106] Creating Layer mask_score
I0605 13:24:09.930634 15110 net.cpp:454] mask_score <- mask_deconv3
I0605 13:24:09.930639 15110 net.cpp:411] mask_score -> mask_score
I0605 13:24:09.931666 15110 net.cpp:150] Setting up mask_score
I0605 13:24:09.931675 15110 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0605 13:24:09.931677 15110 net.cpp:165] Memory required for data: 1710906988
I0605 13:24:09.931682 15110 layer_factory.hpp:77] Creating layer loss_mask
I0605 13:24:09.931689 15110 net.cpp:106] Creating Layer loss_mask
I0605 13:24:09.931692 15110 net.cpp:454] loss_mask <- mask_score
I0605 13:24:09.931695 15110 net.cpp:454] loss_mask <- mask_targets
I0605 13:24:09.931700 15110 net.cpp:411] loss_mask -> loss_mask
I0605 13:24:09.931707 15110 layer_factory.hpp:77] Creating layer loss_mask
I0605 13:24:09.932742 15110 net.cpp:150] Setting up loss_mask
I0605 13:24:09.932750 15110 net.cpp:157] Top shape: (1)
I0605 13:24:09.932752 15110 net.cpp:160]     with loss weight 3
I0605 13:24:09.932760 15110 net.cpp:165] Memory required for data: 1710906992
I0605 13:24:09.932762 15110 net.cpp:226] loss_mask needs backward computation.
I0605 13:24:09.932765 15110 net.cpp:226] mask_score needs backward computation.
I0605 13:24:09.932767 15110 net.cpp:226] mask_deconv3 needs backward computation.
I0605 13:24:09.932770 15110 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0605 13:24:09.932781 15110 net.cpp:226] pool5_2_conv6 needs backward computation.
I0605 13:24:09.932785 15110 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0605 13:24:09.932787 15110 net.cpp:226] pool5_2_conv5 needs backward computation.
I0605 13:24:09.932790 15110 net.cpp:226] mask_deconv2 needs backward computation.
I0605 13:24:09.932793 15110 net.cpp:226] out_x_sum needs backward computation.
I0605 13:24:09.932796 15110 net.cpp:226] out_conv_x needs backward computation.
I0605 13:24:09.932799 15110 net.cpp:226] out_conv_ch_x needs backward computation.
I0605 13:24:09.932812 15110 net.cpp:226] out_ch_x needs backward computation.
I0605 13:24:09.932816 15110 net.cpp:226] out_ch_reshape_scale needs backward computation.
I0605 13:24:09.932821 15110 net.cpp:226] out_ch_reshape needs backward computation.
I0605 13:24:09.932824 15110 net.cpp:226] out_ch needs backward computation.
I0605 13:24:09.932827 15110 net.cpp:226] attention_ch_perm needs backward computation.
I0605 13:24:09.932832 15110 net.cpp:226] value_conv_reshape_ch_perm needs backward computation.
I0605 13:24:09.932843 15110 net.cpp:226] attention_ch needs backward computation.
I0605 13:24:09.932847 15110 net.cpp:226] energy_new needs backward computation.
I0605 13:24:09.932849 15110 net.cpp:226] energy_ch_minus needs backward computation.
I0605 13:24:09.932862 15110 net.cpp:226] energy_ch_max needs backward computation.
I0605 13:24:09.932866 15110 net.cpp:226] energy_ch_pool needs backward computation.
I0605 13:24:09.932870 15110 net.cpp:226] energy_ch_energy_ch_0_split needs backward computation.
I0605 13:24:09.932875 15110 net.cpp:226] energy_ch needs backward computation.
I0605 13:24:09.932878 15110 net.cpp:226] key_conv_reshape_perm_ch needs backward computation.
I0605 13:24:09.932881 15110 net.cpp:226] query_conv_reshape_perm_ch needs backward computation.
I0605 13:24:09.932883 15110 net.cpp:226] value_conv_reshape_ch needs backward computation.
I0605 13:24:09.932895 15110 net.cpp:226] key_conv_reshape_ch needs backward computation.
I0605 13:24:09.932898 15110 net.cpp:226] query_conv_reshape_ch needs backward computation.
I0605 13:24:09.932902 15110 net.cpp:226] out_x needs backward computation.
I0605 13:24:09.932915 15110 net.cpp:226] out_reshape_scale needs backward computation.
I0605 13:24:09.932919 15110 net.cpp:226] out_reshape needs backward computation.
I0605 13:24:09.932921 15110 net.cpp:226] out needs backward computation.
I0605 13:24:09.932924 15110 net.cpp:226] attention_perm needs backward computation.
I0605 13:24:09.932927 15110 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0605 13:24:09.932930 15110 net.cpp:226] attention needs backward computation.
I0605 13:24:09.932934 15110 net.cpp:226] energy needs backward computation.
I0605 13:24:09.932936 15110 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0605 13:24:09.932950 15110 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0605 13:24:09.932952 15110 net.cpp:226] value_conv_reshape needs backward computation.
I0605 13:24:09.932956 15110 net.cpp:226] key_conv_reshape needs backward computation.
I0605 13:24:09.932970 15110 net.cpp:226] query_conv_reshape needs backward computation.
I0605 13:24:09.932972 15110 net.cpp:226] value_conv needs backward computation.
I0605 13:24:09.932977 15110 net.cpp:226] key_conv needs backward computation.
I0605 13:24:09.932979 15110 net.cpp:226] query_conv needs backward computation.
I0605 13:24:09.932982 15110 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0605 13:24:09.932986 15110 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0605 13:24:09.932988 15110 net.cpp:226] pool5_2_conv4 needs backward computation.
I0605 13:24:09.932991 15110 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0605 13:24:09.932994 15110 net.cpp:226] pool5_2_conv3 needs backward computation.
I0605 13:24:09.932997 15110 net.cpp:226] mask_deconv1 needs backward computation.
I0605 13:24:09.933001 15110 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0605 13:24:09.933004 15110 net.cpp:226] pool5_2_conv2 needs backward computation.
I0605 13:24:09.933007 15110 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0605 13:24:09.933012 15110 net.cpp:226] pool5_2_conv needs backward computation.
I0605 13:24:09.933013 15110 net.cpp:226] roi_pool5_2 needs backward computation.
I0605 13:24:09.933018 15110 net.cpp:226] loss_bbox needs backward computation.
I0605 13:24:09.933023 15110 net.cpp:226] loss_cls needs backward computation.
I0605 13:24:09.933027 15110 net.cpp:226] bbox_pred needs backward computation.
I0605 13:24:09.933029 15110 net.cpp:226] cls_score needs backward computation.
I0605 13:24:09.933032 15110 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0605 13:24:09.933037 15110 net.cpp:226] relu7 needs backward computation.
I0605 13:24:09.933039 15110 net.cpp:226] fc7 needs backward computation.
I0605 13:24:09.933043 15110 net.cpp:226] relu6 needs backward computation.
I0605 13:24:09.933046 15110 net.cpp:226] fc6 needs backward computation.
I0605 13:24:09.933049 15110 net.cpp:226] roi_pool5 needs backward computation.
I0605 13:24:09.933053 15110 net.cpp:226] roi-data needs backward computation.
I0605 13:24:09.933059 15110 net.cpp:226] proposal needs backward computation.
I0605 13:24:09.933064 15110 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0605 13:24:09.933069 15110 net.cpp:226] rpn_cls_prob needs backward computation.
I0605 13:24:09.933071 15110 net.cpp:226] rpn_loss_bbox needs backward computation.
I0605 13:24:09.933075 15110 net.cpp:226] rpn_loss_cls needs backward computation.
I0605 13:24:09.933080 15110 net.cpp:226] rpn-data needs backward computation.
I0605 13:24:09.933084 15110 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0605 13:24:09.933089 15110 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0605 13:24:09.933091 15110 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0605 13:24:09.933095 15110 net.cpp:226] rpn_bbox_pred needs backward computation.
I0605 13:24:09.933099 15110 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0605 13:24:09.933101 15110 net.cpp:226] rpn_cls_score needs backward computation.
I0605 13:24:09.933105 15110 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0605 13:24:09.933109 15110 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0605 13:24:09.933110 15110 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0605 13:24:09.933115 15110 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0605 13:24:09.933120 15110 net.cpp:226] relu5_3 needs backward computation.
I0605 13:24:09.933122 15110 net.cpp:226] conv5_3 needs backward computation.
I0605 13:24:09.933125 15110 net.cpp:226] relu5_2 needs backward computation.
I0605 13:24:09.933128 15110 net.cpp:226] conv5_2 needs backward computation.
I0605 13:24:09.933130 15110 net.cpp:226] relu5_1 needs backward computation.
I0605 13:24:09.933135 15110 net.cpp:226] conv5_1 needs backward computation.
I0605 13:24:09.933138 15110 net.cpp:226] pool4 needs backward computation.
I0605 13:24:09.933143 15110 net.cpp:226] relu4_3 needs backward computation.
I0605 13:24:09.933145 15110 net.cpp:226] conv4_3 needs backward computation.
I0605 13:24:09.933148 15110 net.cpp:226] relu4_2 needs backward computation.
I0605 13:24:09.933152 15110 net.cpp:226] conv4_2 needs backward computation.
I0605 13:24:09.933154 15110 net.cpp:226] relu4_1 needs backward computation.
I0605 13:24:09.933157 15110 net.cpp:226] conv4_1 needs backward computation.
I0605 13:24:09.933161 15110 net.cpp:226] pool3 needs backward computation.
I0605 13:24:09.933164 15110 net.cpp:226] relu3_3 needs backward computation.
I0605 13:24:09.933168 15110 net.cpp:226] conv3_3 needs backward computation.
I0605 13:24:09.933171 15110 net.cpp:226] relu3_2 needs backward computation.
I0605 13:24:09.933173 15110 net.cpp:226] conv3_2 needs backward computation.
I0605 13:24:09.933177 15110 net.cpp:226] relu3_1 needs backward computation.
I0605 13:24:09.933179 15110 net.cpp:226] conv3_1 needs backward computation.
I0605 13:24:09.933182 15110 net.cpp:228] pool2 does not need backward computation.
I0605 13:24:09.933187 15110 net.cpp:228] relu2_2 does not need backward computation.
I0605 13:24:09.933189 15110 net.cpp:228] conv2_2 does not need backward computation.
I0605 13:24:09.933192 15110 net.cpp:228] relu2_1 does not need backward computation.
I0605 13:24:09.933197 15110 net.cpp:228] conv2_1 does not need backward computation.
I0605 13:24:09.933200 15110 net.cpp:228] pool1 does not need backward computation.
I0605 13:24:09.933204 15110 net.cpp:228] relu1_2 does not need backward computation.
I0605 13:24:09.933207 15110 net.cpp:228] conv1_2 does not need backward computation.
I0605 13:24:09.933208 15110 net.cpp:228] relu1_1 does not need backward computation.
I0605 13:24:09.933213 15110 net.cpp:228] conv1_1 does not need backward computation.
I0605 13:24:09.933216 15110 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0605 13:24:09.933220 15110 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0605 13:24:09.933224 15110 net.cpp:228] data_input-data_0_split does not need backward computation.
I0605 13:24:09.933229 15110 net.cpp:228] input-data does not need backward computation.
I0605 13:24:09.933231 15110 net.cpp:270] This network produces output loss_bbox
I0605 13:24:09.933235 15110 net.cpp:270] This network produces output loss_cls
I0605 13:24:09.933239 15110 net.cpp:270] This network produces output loss_mask
I0605 13:24:09.933243 15110 net.cpp:270] This network produces output rois_attribute
I0605 13:24:09.933245 15110 net.cpp:270] This network produces output rpn_cls_loss
I0605 13:24:09.933249 15110 net.cpp:270] This network produces output rpn_loss_bbox
I0605 13:24:09.933333 15110 net.cpp:283] Network initialization done.
I0605 13:24:09.933612 15110 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0605 13:24:16.178335 15110 net.cpp:816] Ignoring source layer pool5
I0605 13:24:16.247650 15110 net.cpp:816] Ignoring source layer drop6
I0605 13:24:16.259390 15110 net.cpp:816] Ignoring source layer drop7
I0605 13:24:16.259408 15110 net.cpp:816] Ignoring source layer fc8
I0605 13:24:16.259411 15110 net.cpp:816] Ignoring source layer prob
Solving...
[0 1 4 7]
[0 1 4 7]
[0 1 4 7]
[0 1 4 7]
[0 1 4 7]
[0 1 4 7]
[0 1 4 7]
[1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
(48,)
[0 1 4 7]
[0 1 4 7]
[0 1 4 7]
[0 1 4 7]
[0 1 4 7]
[0 1 4 7]
[1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
(48,)
I0605 13:24:17.987098 15110 solver.cpp:229] Iteration 0, loss = 9.12671
I0605 13:24:17.987128 15110 solver.cpp:245]     Train net output #0: loss_bbox = 0.244229 (* 2 = 0.488458 loss)
I0605 13:24:17.987133 15110 solver.cpp:245]     Train net output #1: loss_cls = 0.52338 (* 3 = 1.57014 loss)
I0605 13:24:17.987138 15110 solver.cpp:245]     Train net output #2: loss_mask = 2.07894 (* 3 = 6.23681 loss)
I0605 13:24:17.987217 15110 solver.cpp:245]     Train net output #3: rois_attribute = 0
I0605 13:24:17.987222 15110 solver.cpp:245]     Train net output #4: rois_attribute = 0
I0605 13:24:17.987224 15110 solver.cpp:245]     Train net output #5: rois_attribute = 0
I0605 13:24:17.987227 15110 solver.cpp:245]     Train net output #6: rois_attribute = 0
I0605 13:24:17.987229 15110 solver.cpp:245]     Train net output #7: rois_attribute = 0
I0605 13:24:17.987232 15110 solver.cpp:245]     Train net output #8: rois_attribute = 0
I0605 13:24:17.987236 15110 solver.cpp:245]     Train net output #9: rois_attribute = 0
I0605 13:24:17.987237 15110 solver.cpp:245]     Train net output #10: rois_attribute = 0
I0605 13:24:17.987239 15110 solver.cpp:245]     Train net output #11: rois_attribute = 0
I0605 13:24:17.987242 15110 solver.cpp:245]     Train net output #12: rois_attribute = 0
I0605 13:24:17.987244 15110 solver.cpp:245]     Train net output #13: rois_attribute = 0
I0605 13:24:17.987247 15110 solver.cpp:245]     Train net output #14: rois_attribute = 0
I0605 13:24:17.987251 15110 solver.cpp:245]     Train net output #15: rois_attribute = 0
I0605 13:24:17.987253 15110 solver.cpp:245]     Train net output #16: rois_attribute = 0
I0605 13:24:17.987257 15110 solver.cpp:245]     Train net output #17: rois_attribute = 0
I0605 13:24:17.987268 15110 solver.cpp:245]     Train net output #18: rois_attribute = 0
I0605 13:24:17.987272 15110 solver.cpp:245]     Train net output #19: rois_attribute = 0
I0605 13:24:17.987280 15110 solver.cpp:245]     Train net output #20: rois_attribute = 0
I0605 13:24:17.987283 15110 solver.cpp:245]     Train net output #21: rois_attribute = 0
I0605 13:24:17.987296 15110 solver.cpp:245]     Train net output #22: rois_attribute = 0
I0605 13:24:17.987300 15110 solver.cpp:245]     Train net output #23: rpn_cls_loss = 0.728647 (* 1 = 0.728647 loss)
I0605 13:24:17.987304 15110 solver.cpp:245]     Train net output #24: rpn_loss_bbox = 0.0193384 (* 1 = 0.0193384 loss)
I0605 13:24:17.987320 15110 sgd_solver.cpp:106] Iteration 0, lr = 0.001
[0 1 3]
[0 1 3]
[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
(48,)
[0 1 2]
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
(48,)
[0 4]
[0 4]
[0 4]
[0 4]
[0 4]
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
(48,)
