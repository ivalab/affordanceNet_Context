+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-05_18-45-06
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-05_18-45-06
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0605 18:45:13.590626 12718 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0605 18:45:13.590646 12718 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0605 18:45:13.591925 12718 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "pool5_2_conv4_relu"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv6_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv6_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv6_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 14884
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 14884
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 14884
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 122
      dim: 122
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv6_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_mask"
  type: "SoftmaxWithLoss"
  bottom: "mask_score"
  bottom: "mask_targets"
  top: "loss_mask"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
I0605 18:45:13.592255 12718 layer_factory.hpp:77] Creating layer input-data
I0605 18:45:13.605332 12718 net.cpp:106] Creating Layer input-data
I0605 18:45:13.605347 12718 net.cpp:411] input-data -> data
I0605 18:45:13.605356 12718 net.cpp:411] input-data -> im_info
I0605 18:45:13.605361 12718 net.cpp:411] input-data -> gt_boxes
I0605 18:45:13.605366 12718 net.cpp:411] input-data -> seg_mask_inds
I0605 18:45:13.605370 12718 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0605 18:45:13.616281 12718 net.cpp:150] Setting up input-data
I0605 18:45:13.616305 12718 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0605 18:45:13.616318 12718 net.cpp:157] Top shape: 1 3 (3)
I0605 18:45:13.616322 12718 net.cpp:157] Top shape: 1 4 (4)
I0605 18:45:13.616323 12718 net.cpp:157] Top shape: 1 2 (2)
I0605 18:45:13.616336 12718 net.cpp:157] Top shape: 1 1 (1)
I0605 18:45:13.616338 12718 net.cpp:165] Memory required for data: 7200040
I0605 18:45:13.616343 12718 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0605 18:45:13.616356 12718 net.cpp:106] Creating Layer data_input-data_0_split
I0605 18:45:13.616361 12718 net.cpp:454] data_input-data_0_split <- data
I0605 18:45:13.616365 12718 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0605 18:45:13.616372 12718 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0605 18:45:13.616405 12718 net.cpp:150] Setting up data_input-data_0_split
I0605 18:45:13.616410 12718 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0605 18:45:13.616422 12718 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0605 18:45:13.616425 12718 net.cpp:165] Memory required for data: 21600040
I0605 18:45:13.616426 12718 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0605 18:45:13.616431 12718 net.cpp:106] Creating Layer im_info_input-data_1_split
I0605 18:45:13.616442 12718 net.cpp:454] im_info_input-data_1_split <- im_info
I0605 18:45:13.616446 12718 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0605 18:45:13.616449 12718 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0605 18:45:13.616466 12718 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0605 18:45:13.616513 12718 net.cpp:150] Setting up im_info_input-data_1_split
I0605 18:45:13.616525 12718 net.cpp:157] Top shape: 1 3 (3)
I0605 18:45:13.616528 12718 net.cpp:157] Top shape: 1 3 (3)
I0605 18:45:13.616530 12718 net.cpp:157] Top shape: 1 3 (3)
I0605 18:45:13.616533 12718 net.cpp:165] Memory required for data: 21600076
I0605 18:45:13.616545 12718 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0605 18:45:13.616549 12718 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0605 18:45:13.616550 12718 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0605 18:45:13.616554 12718 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0605 18:45:13.616567 12718 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0605 18:45:13.616598 12718 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0605 18:45:13.616618 12718 net.cpp:157] Top shape: 1 4 (4)
I0605 18:45:13.616621 12718 net.cpp:157] Top shape: 1 4 (4)
I0605 18:45:13.616622 12718 net.cpp:165] Memory required for data: 21600108
I0605 18:45:13.616624 12718 layer_factory.hpp:77] Creating layer conv1_1
I0605 18:45:13.616643 12718 net.cpp:106] Creating Layer conv1_1
I0605 18:45:13.616645 12718 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0605 18:45:13.616648 12718 net.cpp:411] conv1_1 -> conv1_1
I0605 18:45:13.782722 12718 net.cpp:150] Setting up conv1_1
I0605 18:45:13.782740 12718 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0605 18:45:13.782743 12718 net.cpp:165] Memory required for data: 175200108
I0605 18:45:13.782754 12718 layer_factory.hpp:77] Creating layer relu1_1
I0605 18:45:13.782773 12718 net.cpp:106] Creating Layer relu1_1
I0605 18:45:13.782776 12718 net.cpp:454] relu1_1 <- conv1_1
I0605 18:45:13.782780 12718 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0605 18:45:13.782922 12718 net.cpp:150] Setting up relu1_1
I0605 18:45:13.782928 12718 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0605 18:45:13.782930 12718 net.cpp:165] Memory required for data: 328800108
I0605 18:45:13.782932 12718 layer_factory.hpp:77] Creating layer conv1_2
I0605 18:45:13.782939 12718 net.cpp:106] Creating Layer conv1_2
I0605 18:45:13.782941 12718 net.cpp:454] conv1_2 <- conv1_1
I0605 18:45:13.782945 12718 net.cpp:411] conv1_2 -> conv1_2
I0605 18:45:13.784991 12718 net.cpp:150] Setting up conv1_2
I0605 18:45:13.785001 12718 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0605 18:45:13.785004 12718 net.cpp:165] Memory required for data: 482400108
I0605 18:45:13.785012 12718 layer_factory.hpp:77] Creating layer relu1_2
I0605 18:45:13.785017 12718 net.cpp:106] Creating Layer relu1_2
I0605 18:45:13.785019 12718 net.cpp:454] relu1_2 <- conv1_2
I0605 18:45:13.785033 12718 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0605 18:45:13.785166 12718 net.cpp:150] Setting up relu1_2
I0605 18:45:13.785172 12718 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0605 18:45:13.785174 12718 net.cpp:165] Memory required for data: 636000108
I0605 18:45:13.785176 12718 layer_factory.hpp:77] Creating layer pool1
I0605 18:45:13.785182 12718 net.cpp:106] Creating Layer pool1
I0605 18:45:13.785185 12718 net.cpp:454] pool1 <- conv1_2
I0605 18:45:13.785198 12718 net.cpp:411] pool1 -> pool1
I0605 18:45:13.785260 12718 net.cpp:150] Setting up pool1
I0605 18:45:13.785265 12718 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0605 18:45:13.785277 12718 net.cpp:165] Memory required for data: 674400108
I0605 18:45:13.785279 12718 layer_factory.hpp:77] Creating layer conv2_1
I0605 18:45:13.785285 12718 net.cpp:106] Creating Layer conv2_1
I0605 18:45:13.785297 12718 net.cpp:454] conv2_1 <- pool1
I0605 18:45:13.785301 12718 net.cpp:411] conv2_1 -> conv2_1
I0605 18:45:13.787046 12718 net.cpp:150] Setting up conv2_1
I0605 18:45:13.787056 12718 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0605 18:45:13.787058 12718 net.cpp:165] Memory required for data: 751200108
I0605 18:45:13.787065 12718 layer_factory.hpp:77] Creating layer relu2_1
I0605 18:45:13.787070 12718 net.cpp:106] Creating Layer relu2_1
I0605 18:45:13.787071 12718 net.cpp:454] relu2_1 <- conv2_1
I0605 18:45:13.787086 12718 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0605 18:45:13.787561 12718 net.cpp:150] Setting up relu2_1
I0605 18:45:13.787569 12718 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0605 18:45:13.787571 12718 net.cpp:165] Memory required for data: 828000108
I0605 18:45:13.787573 12718 layer_factory.hpp:77] Creating layer conv2_2
I0605 18:45:13.787580 12718 net.cpp:106] Creating Layer conv2_2
I0605 18:45:13.787581 12718 net.cpp:454] conv2_2 <- conv2_1
I0605 18:45:13.787585 12718 net.cpp:411] conv2_2 -> conv2_2
I0605 18:45:13.788852 12718 net.cpp:150] Setting up conv2_2
I0605 18:45:13.788872 12718 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0605 18:45:13.788874 12718 net.cpp:165] Memory required for data: 904800108
I0605 18:45:13.788879 12718 layer_factory.hpp:77] Creating layer relu2_2
I0605 18:45:13.788893 12718 net.cpp:106] Creating Layer relu2_2
I0605 18:45:13.788898 12718 net.cpp:454] relu2_2 <- conv2_2
I0605 18:45:13.788902 12718 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0605 18:45:13.789026 12718 net.cpp:150] Setting up relu2_2
I0605 18:45:13.789031 12718 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0605 18:45:13.789043 12718 net.cpp:165] Memory required for data: 981600108
I0605 18:45:13.789045 12718 layer_factory.hpp:77] Creating layer pool2
I0605 18:45:13.789049 12718 net.cpp:106] Creating Layer pool2
I0605 18:45:13.789062 12718 net.cpp:454] pool2 <- conv2_2
I0605 18:45:13.789067 12718 net.cpp:411] pool2 -> pool2
I0605 18:45:13.789103 12718 net.cpp:150] Setting up pool2
I0605 18:45:13.789117 12718 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0605 18:45:13.789119 12718 net.cpp:165] Memory required for data: 1000800108
I0605 18:45:13.789121 12718 layer_factory.hpp:77] Creating layer conv3_1
I0605 18:45:13.789135 12718 net.cpp:106] Creating Layer conv3_1
I0605 18:45:13.789137 12718 net.cpp:454] conv3_1 <- pool2
I0605 18:45:13.789153 12718 net.cpp:411] conv3_1 -> conv3_1
I0605 18:45:13.791143 12718 net.cpp:150] Setting up conv3_1
I0605 18:45:13.791153 12718 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 18:45:13.791155 12718 net.cpp:165] Memory required for data: 1039200108
I0605 18:45:13.791164 12718 layer_factory.hpp:77] Creating layer relu3_1
I0605 18:45:13.791169 12718 net.cpp:106] Creating Layer relu3_1
I0605 18:45:13.791172 12718 net.cpp:454] relu3_1 <- conv3_1
I0605 18:45:13.791187 12718 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0605 18:45:13.791304 12718 net.cpp:150] Setting up relu3_1
I0605 18:45:13.791311 12718 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 18:45:13.791312 12718 net.cpp:165] Memory required for data: 1077600108
I0605 18:45:13.791314 12718 layer_factory.hpp:77] Creating layer conv3_2
I0605 18:45:13.791332 12718 net.cpp:106] Creating Layer conv3_2
I0605 18:45:13.791337 12718 net.cpp:454] conv3_2 <- conv3_1
I0605 18:45:13.791340 12718 net.cpp:411] conv3_2 -> conv3_2
I0605 18:45:13.793320 12718 net.cpp:150] Setting up conv3_2
I0605 18:45:13.793329 12718 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 18:45:13.793332 12718 net.cpp:165] Memory required for data: 1116000108
I0605 18:45:13.793336 12718 layer_factory.hpp:77] Creating layer relu3_2
I0605 18:45:13.793341 12718 net.cpp:106] Creating Layer relu3_2
I0605 18:45:13.793344 12718 net.cpp:454] relu3_2 <- conv3_2
I0605 18:45:13.793347 12718 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0605 18:45:13.793519 12718 net.cpp:150] Setting up relu3_2
I0605 18:45:13.793525 12718 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 18:45:13.793527 12718 net.cpp:165] Memory required for data: 1154400108
I0605 18:45:13.793529 12718 layer_factory.hpp:77] Creating layer conv3_3
I0605 18:45:13.793535 12718 net.cpp:106] Creating Layer conv3_3
I0605 18:45:13.793537 12718 net.cpp:454] conv3_3 <- conv3_2
I0605 18:45:13.793541 12718 net.cpp:411] conv3_3 -> conv3_3
I0605 18:45:13.795552 12718 net.cpp:150] Setting up conv3_3
I0605 18:45:13.795562 12718 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 18:45:13.795563 12718 net.cpp:165] Memory required for data: 1192800108
I0605 18:45:13.795568 12718 layer_factory.hpp:77] Creating layer relu3_3
I0605 18:45:13.795573 12718 net.cpp:106] Creating Layer relu3_3
I0605 18:45:13.795576 12718 net.cpp:454] relu3_3 <- conv3_3
I0605 18:45:13.795590 12718 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0605 18:45:13.795730 12718 net.cpp:150] Setting up relu3_3
I0605 18:45:13.795737 12718 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0605 18:45:13.795738 12718 net.cpp:165] Memory required for data: 1231200108
I0605 18:45:13.795740 12718 layer_factory.hpp:77] Creating layer pool3
I0605 18:45:13.795747 12718 net.cpp:106] Creating Layer pool3
I0605 18:45:13.795748 12718 net.cpp:454] pool3 <- conv3_3
I0605 18:45:13.795753 12718 net.cpp:411] pool3 -> pool3
I0605 18:45:13.795814 12718 net.cpp:150] Setting up pool3
I0605 18:45:13.795819 12718 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0605 18:45:13.795830 12718 net.cpp:165] Memory required for data: 1240800108
I0605 18:45:13.795832 12718 layer_factory.hpp:77] Creating layer conv4_1
I0605 18:45:13.795838 12718 net.cpp:106] Creating Layer conv4_1
I0605 18:45:13.795840 12718 net.cpp:454] conv4_1 <- pool3
I0605 18:45:13.795853 12718 net.cpp:411] conv4_1 -> conv4_1
I0605 18:45:13.799906 12718 net.cpp:150] Setting up conv4_1
I0605 18:45:13.799926 12718 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 18:45:13.799927 12718 net.cpp:165] Memory required for data: 1260000108
I0605 18:45:13.799935 12718 layer_factory.hpp:77] Creating layer relu4_1
I0605 18:45:13.799943 12718 net.cpp:106] Creating Layer relu4_1
I0605 18:45:13.799958 12718 net.cpp:454] relu4_1 <- conv4_1
I0605 18:45:13.799963 12718 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0605 18:45:13.800110 12718 net.cpp:150] Setting up relu4_1
I0605 18:45:13.800115 12718 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 18:45:13.800118 12718 net.cpp:165] Memory required for data: 1279200108
I0605 18:45:13.800120 12718 layer_factory.hpp:77] Creating layer conv4_2
I0605 18:45:13.800127 12718 net.cpp:106] Creating Layer conv4_2
I0605 18:45:13.800129 12718 net.cpp:454] conv4_2 <- conv4_1
I0605 18:45:13.800133 12718 net.cpp:411] conv4_2 -> conv4_2
I0605 18:45:13.804797 12718 net.cpp:150] Setting up conv4_2
I0605 18:45:13.804818 12718 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 18:45:13.804822 12718 net.cpp:165] Memory required for data: 1298400108
I0605 18:45:13.804834 12718 layer_factory.hpp:77] Creating layer relu4_2
I0605 18:45:13.804853 12718 net.cpp:106] Creating Layer relu4_2
I0605 18:45:13.804858 12718 net.cpp:454] relu4_2 <- conv4_2
I0605 18:45:13.804863 12718 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0605 18:45:13.805390 12718 net.cpp:150] Setting up relu4_2
I0605 18:45:13.805400 12718 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 18:45:13.805403 12718 net.cpp:165] Memory required for data: 1317600108
I0605 18:45:13.805407 12718 layer_factory.hpp:77] Creating layer conv4_3
I0605 18:45:13.805508 12718 net.cpp:106] Creating Layer conv4_3
I0605 18:45:13.805522 12718 net.cpp:454] conv4_3 <- conv4_2
I0605 18:45:13.805528 12718 net.cpp:411] conv4_3 -> conv4_3
I0605 18:45:13.810412 12718 net.cpp:150] Setting up conv4_3
I0605 18:45:13.810429 12718 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 18:45:13.810433 12718 net.cpp:165] Memory required for data: 1336800108
I0605 18:45:13.810441 12718 layer_factory.hpp:77] Creating layer relu4_3
I0605 18:45:13.810448 12718 net.cpp:106] Creating Layer relu4_3
I0605 18:45:13.810463 12718 net.cpp:454] relu4_3 <- conv4_3
I0605 18:45:13.810470 12718 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0605 18:45:13.810617 12718 net.cpp:150] Setting up relu4_3
I0605 18:45:13.810624 12718 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0605 18:45:13.810626 12718 net.cpp:165] Memory required for data: 1356000108
I0605 18:45:13.810629 12718 layer_factory.hpp:77] Creating layer pool4
I0605 18:45:13.810636 12718 net.cpp:106] Creating Layer pool4
I0605 18:45:13.810638 12718 net.cpp:454] pool4 <- conv4_3
I0605 18:45:13.810642 12718 net.cpp:411] pool4 -> pool4
I0605 18:45:13.810714 12718 net.cpp:150] Setting up pool4
I0605 18:45:13.810717 12718 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:45:13.810719 12718 net.cpp:165] Memory required for data: 1360903020
I0605 18:45:13.810732 12718 layer_factory.hpp:77] Creating layer conv5_1
I0605 18:45:13.810739 12718 net.cpp:106] Creating Layer conv5_1
I0605 18:45:13.810740 12718 net.cpp:454] conv5_1 <- pool4
I0605 18:45:13.810755 12718 net.cpp:411] conv5_1 -> conv5_1
I0605 18:45:13.815280 12718 net.cpp:150] Setting up conv5_1
I0605 18:45:13.815310 12718 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:45:13.815315 12718 net.cpp:165] Memory required for data: 1365805932
I0605 18:45:13.815323 12718 layer_factory.hpp:77] Creating layer relu5_1
I0605 18:45:13.815333 12718 net.cpp:106] Creating Layer relu5_1
I0605 18:45:13.815338 12718 net.cpp:454] relu5_1 <- conv5_1
I0605 18:45:13.815343 12718 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0605 18:45:13.815495 12718 net.cpp:150] Setting up relu5_1
I0605 18:45:13.815505 12718 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:45:13.815508 12718 net.cpp:165] Memory required for data: 1370708844
I0605 18:45:13.815522 12718 layer_factory.hpp:77] Creating layer conv5_2
I0605 18:45:13.815534 12718 net.cpp:106] Creating Layer conv5_2
I0605 18:45:13.815539 12718 net.cpp:454] conv5_2 <- conv5_1
I0605 18:45:13.815546 12718 net.cpp:411] conv5_2 -> conv5_2
I0605 18:45:13.820497 12718 net.cpp:150] Setting up conv5_2
I0605 18:45:13.820519 12718 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:45:13.820523 12718 net.cpp:165] Memory required for data: 1375611756
I0605 18:45:13.820544 12718 layer_factory.hpp:77] Creating layer relu5_2
I0605 18:45:13.820554 12718 net.cpp:106] Creating Layer relu5_2
I0605 18:45:13.820561 12718 net.cpp:454] relu5_2 <- conv5_2
I0605 18:45:13.820574 12718 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0605 18:45:13.820744 12718 net.cpp:150] Setting up relu5_2
I0605 18:45:13.820753 12718 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:45:13.820756 12718 net.cpp:165] Memory required for data: 1380514668
I0605 18:45:13.820770 12718 layer_factory.hpp:77] Creating layer conv5_3
I0605 18:45:13.820788 12718 net.cpp:106] Creating Layer conv5_3
I0605 18:45:13.820792 12718 net.cpp:454] conv5_3 <- conv5_2
I0605 18:45:13.820808 12718 net.cpp:411] conv5_3 -> conv5_3
I0605 18:45:13.825196 12718 net.cpp:150] Setting up conv5_3
I0605 18:45:13.825218 12718 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:45:13.825223 12718 net.cpp:165] Memory required for data: 1385417580
I0605 18:45:13.825243 12718 layer_factory.hpp:77] Creating layer relu5_3
I0605 18:45:13.825254 12718 net.cpp:106] Creating Layer relu5_3
I0605 18:45:13.825273 12718 net.cpp:454] relu5_3 <- conv5_3
I0605 18:45:13.825290 12718 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0605 18:45:13.825448 12718 net.cpp:150] Setting up relu5_3
I0605 18:45:13.825466 12718 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:45:13.825469 12718 net.cpp:165] Memory required for data: 1390320492
I0605 18:45:13.825484 12718 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0605 18:45:13.825492 12718 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0605 18:45:13.825508 12718 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0605 18:45:13.825516 12718 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0605 18:45:13.825525 12718 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0605 18:45:13.825541 12718 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0605 18:45:13.825605 12718 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0605 18:45:13.825611 12718 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:45:13.825615 12718 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:45:13.825629 12718 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:45:13.825634 12718 net.cpp:165] Memory required for data: 1405029228
I0605 18:45:13.825647 12718 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0605 18:45:13.825660 12718 net.cpp:106] Creating Layer rpn_conv/3x3
I0605 18:45:13.825665 12718 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0605 18:45:13.825675 12718 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0605 18:45:13.878268 12718 net.cpp:150] Setting up rpn_conv/3x3
I0605 18:45:13.878288 12718 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:45:13.878293 12718 net.cpp:165] Memory required for data: 1409932140
I0605 18:45:13.878314 12718 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0605 18:45:13.878329 12718 net.cpp:106] Creating Layer rpn_relu/3x3
I0605 18:45:13.878335 12718 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0605 18:45:13.878342 12718 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0605 18:45:13.878500 12718 net.cpp:150] Setting up rpn_relu/3x3
I0605 18:45:13.878509 12718 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:45:13.878512 12718 net.cpp:165] Memory required for data: 1414835052
I0605 18:45:13.878527 12718 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0605 18:45:13.878535 12718 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0605 18:45:13.878549 12718 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0605 18:45:13.878556 12718 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0605 18:45:13.878566 12718 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0605 18:45:13.878617 12718 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0605 18:45:13.878623 12718 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:45:13.878626 12718 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0605 18:45:13.878639 12718 net.cpp:165] Memory required for data: 1424640876
I0605 18:45:13.878643 12718 layer_factory.hpp:77] Creating layer rpn_cls_score
I0605 18:45:13.878665 12718 net.cpp:106] Creating Layer rpn_cls_score
I0605 18:45:13.878681 12718 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0605 18:45:13.878697 12718 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0605 18:45:13.880368 12718 net.cpp:150] Setting up rpn_cls_score
I0605 18:45:13.880378 12718 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0605 18:45:13.880381 12718 net.cpp:165] Memory required for data: 1424928156
I0605 18:45:13.880398 12718 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0605 18:45:13.880407 12718 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0605 18:45:13.880411 12718 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0605 18:45:13.880417 12718 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0605 18:45:13.880439 12718 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0605 18:45:13.880482 12718 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0605 18:45:13.880488 12718 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0605 18:45:13.880493 12718 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0605 18:45:13.880496 12718 net.cpp:165] Memory required for data: 1425502716
I0605 18:45:13.880501 12718 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0605 18:45:13.880523 12718 net.cpp:106] Creating Layer rpn_bbox_pred
I0605 18:45:13.880527 12718 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0605 18:45:13.880543 12718 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0605 18:45:13.882212 12718 net.cpp:150] Setting up rpn_bbox_pred
I0605 18:45:13.882222 12718 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 18:45:13.882226 12718 net.cpp:165] Memory required for data: 1426077276
I0605 18:45:13.882233 12718 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0605 18:45:13.882241 12718 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0605 18:45:13.882247 12718 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0605 18:45:13.882253 12718 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0605 18:45:13.882262 12718 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0605 18:45:13.882297 12718 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0605 18:45:13.882313 12718 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 18:45:13.882318 12718 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 18:45:13.882333 12718 net.cpp:165] Memory required for data: 1427226396
I0605 18:45:13.882338 12718 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0605 18:45:13.882349 12718 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0605 18:45:13.882354 12718 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0605 18:45:13.882361 12718 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0605 18:45:13.882385 12718 net.cpp:150] Setting up rpn_cls_score_reshape
I0605 18:45:13.882392 12718 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0605 18:45:13.882396 12718 net.cpp:165] Memory required for data: 1427513676
I0605 18:45:13.882400 12718 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0605 18:45:13.882407 12718 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0605 18:45:13.882413 12718 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0605 18:45:13.882418 12718 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0605 18:45:13.882426 12718 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0605 18:45:13.882454 12718 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0605 18:45:13.882460 12718 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0605 18:45:13.882464 12718 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0605 18:45:13.882468 12718 net.cpp:165] Memory required for data: 1428088236
I0605 18:45:13.882473 12718 layer_factory.hpp:77] Creating layer rpn-data
I0605 18:45:13.882838 12718 net.cpp:106] Creating Layer rpn-data
I0605 18:45:13.882846 12718 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0605 18:45:13.882853 12718 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0605 18:45:13.882858 12718 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0605 18:45:13.882863 12718 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0605 18:45:13.882871 12718 net.cpp:411] rpn-data -> rpn_labels
I0605 18:45:13.882882 12718 net.cpp:411] rpn-data -> rpn_bbox_targets
I0605 18:45:13.882891 12718 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0605 18:45:13.882900 12718 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0605 18:45:13.883870 12718 net.cpp:150] Setting up rpn-data
I0605 18:45:13.883880 12718 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0605 18:45:13.883884 12718 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 18:45:13.883889 12718 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 18:45:13.883894 12718 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0605 18:45:13.883898 12718 net.cpp:165] Memory required for data: 1429955556
I0605 18:45:13.883916 12718 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0605 18:45:13.883924 12718 net.cpp:106] Creating Layer rpn_loss_cls
I0605 18:45:13.883931 12718 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0605 18:45:13.883937 12718 net.cpp:454] rpn_loss_cls <- rpn_labels
I0605 18:45:13.883952 12718 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0605 18:45:13.883975 12718 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0605 18:45:13.884668 12718 net.cpp:150] Setting up rpn_loss_cls
I0605 18:45:13.884677 12718 net.cpp:157] Top shape: (1)
I0605 18:45:13.884680 12718 net.cpp:160]     with loss weight 1
I0605 18:45:13.884701 12718 net.cpp:165] Memory required for data: 1429955560
I0605 18:45:13.884706 12718 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0605 18:45:13.884716 12718 net.cpp:106] Creating Layer rpn_loss_bbox
I0605 18:45:13.884722 12718 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0605 18:45:13.884728 12718 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0605 18:45:13.884734 12718 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0605 18:45:13.884738 12718 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0605 18:45:13.884747 12718 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0605 18:45:13.885908 12718 net.cpp:150] Setting up rpn_loss_bbox
I0605 18:45:13.885917 12718 net.cpp:157] Top shape: (1)
I0605 18:45:13.885921 12718 net.cpp:160]     with loss weight 1
I0605 18:45:13.885927 12718 net.cpp:165] Memory required for data: 1429955564
I0605 18:45:13.885931 12718 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0605 18:45:13.885939 12718 net.cpp:106] Creating Layer rpn_cls_prob
I0605 18:45:13.885946 12718 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0605 18:45:13.885962 12718 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0605 18:45:13.886153 12718 net.cpp:150] Setting up rpn_cls_prob
I0605 18:45:13.886160 12718 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0605 18:45:13.886163 12718 net.cpp:165] Memory required for data: 1430242844
I0605 18:45:13.886178 12718 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0605 18:45:13.886188 12718 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0605 18:45:13.886193 12718 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0605 18:45:13.886209 12718 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0605 18:45:13.886252 12718 net.cpp:150] Setting up rpn_cls_prob_reshape
I0605 18:45:13.886257 12718 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0605 18:45:13.886260 12718 net.cpp:165] Memory required for data: 1430530124
I0605 18:45:13.886263 12718 layer_factory.hpp:77] Creating layer proposal
I0605 18:45:13.886792 12718 net.cpp:106] Creating Layer proposal
I0605 18:45:13.886801 12718 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0605 18:45:13.886806 12718 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0605 18:45:13.886821 12718 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0605 18:45:13.886837 12718 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0605 18:45:13.887789 12718 net.cpp:150] Setting up proposal
I0605 18:45:13.887797 12718 net.cpp:157] Top shape: 1 5 (5)
I0605 18:45:13.887801 12718 net.cpp:165] Memory required for data: 1430530144
I0605 18:45:13.887815 12718 layer_factory.hpp:77] Creating layer roi-data
I0605 18:45:13.888048 12718 net.cpp:106] Creating Layer roi-data
I0605 18:45:13.888056 12718 net.cpp:454] roi-data <- rpn_rois
I0605 18:45:13.888062 12718 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0605 18:45:13.888075 12718 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0605 18:45:13.888082 12718 net.cpp:454] roi-data <- seg_mask_inds
I0605 18:45:13.888097 12718 net.cpp:454] roi-data <- flipped
I0605 18:45:13.888103 12718 net.cpp:411] roi-data -> rois
I0605 18:45:13.888121 12718 net.cpp:411] roi-data -> labels
I0605 18:45:13.888131 12718 net.cpp:411] roi-data -> bbox_targets
I0605 18:45:13.888139 12718 net.cpp:411] roi-data -> bbox_inside_weights
I0605 18:45:13.888147 12718 net.cpp:411] roi-data -> bbox_outside_weights
I0605 18:45:13.888156 12718 net.cpp:411] roi-data -> mask_targets
I0605 18:45:13.888164 12718 net.cpp:411] roi-data -> rois_pos
I0605 18:45:13.888450 12718 net.cpp:150] Setting up roi-data
I0605 18:45:13.888458 12718 net.cpp:157] Top shape: 1 5 (5)
I0605 18:45:13.888463 12718 net.cpp:157] Top shape: 1 1 (1)
I0605 18:45:13.888468 12718 net.cpp:157] Top shape: 1 8 (8)
I0605 18:45:13.888471 12718 net.cpp:157] Top shape: 1 8 (8)
I0605 18:45:13.888476 12718 net.cpp:157] Top shape: 1 8 (8)
I0605 18:45:13.888491 12718 net.cpp:157] Top shape: 1 244 244 (59536)
I0605 18:45:13.888496 12718 net.cpp:157] Top shape: 1 5 (5)
I0605 18:45:13.888500 12718 net.cpp:165] Memory required for data: 1430768428
I0605 18:45:13.888514 12718 layer_factory.hpp:77] Creating layer roi_pool5
I0605 18:45:13.888522 12718 net.cpp:106] Creating Layer roi_pool5
I0605 18:45:13.888530 12718 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0605 18:45:13.888535 12718 net.cpp:454] roi_pool5 <- rois
I0605 18:45:13.888541 12718 net.cpp:411] roi_pool5 -> pool5
I0605 18:45:13.888556 12718 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0605 18:45:13.888626 12718 net.cpp:150] Setting up roi_pool5
I0605 18:45:13.888633 12718 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 18:45:13.888636 12718 net.cpp:165] Memory required for data: 1430868780
I0605 18:45:13.888641 12718 layer_factory.hpp:77] Creating layer fc6
I0605 18:45:13.888649 12718 net.cpp:106] Creating Layer fc6
I0605 18:45:13.888655 12718 net.cpp:454] fc6 <- pool5
I0605 18:45:13.888664 12718 net.cpp:411] fc6 -> fc6
I0605 18:45:14.029891 12718 net.cpp:150] Setting up fc6
I0605 18:45:14.029917 12718 net.cpp:157] Top shape: 1 4096 (4096)
I0605 18:45:14.029922 12718 net.cpp:165] Memory required for data: 1430885164
I0605 18:45:14.029951 12718 layer_factory.hpp:77] Creating layer relu6
I0605 18:45:14.029975 12718 net.cpp:106] Creating Layer relu6
I0605 18:45:14.029992 12718 net.cpp:454] relu6 <- fc6
I0605 18:45:14.029999 12718 net.cpp:397] relu6 -> fc6 (in-place)
I0605 18:45:14.030230 12718 net.cpp:150] Setting up relu6
I0605 18:45:14.030239 12718 net.cpp:157] Top shape: 1 4096 (4096)
I0605 18:45:14.030242 12718 net.cpp:165] Memory required for data: 1430901548
I0605 18:45:14.030256 12718 layer_factory.hpp:77] Creating layer fc7
I0605 18:45:14.030267 12718 net.cpp:106] Creating Layer fc7
I0605 18:45:14.030272 12718 net.cpp:454] fc7 <- fc6
I0605 18:45:14.030280 12718 net.cpp:411] fc7 -> fc7
I0605 18:45:14.054030 12718 net.cpp:150] Setting up fc7
I0605 18:45:14.054056 12718 net.cpp:157] Top shape: 1 4096 (4096)
I0605 18:45:14.054060 12718 net.cpp:165] Memory required for data: 1430917932
I0605 18:45:14.054082 12718 layer_factory.hpp:77] Creating layer relu7
I0605 18:45:14.054103 12718 net.cpp:106] Creating Layer relu7
I0605 18:45:14.054111 12718 net.cpp:454] relu7 <- fc7
I0605 18:45:14.054122 12718 net.cpp:397] relu7 -> fc7 (in-place)
I0605 18:45:14.054342 12718 net.cpp:150] Setting up relu7
I0605 18:45:14.054350 12718 net.cpp:157] Top shape: 1 4096 (4096)
I0605 18:45:14.054354 12718 net.cpp:165] Memory required for data: 1430934316
I0605 18:45:14.054368 12718 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0605 18:45:14.054376 12718 net.cpp:106] Creating Layer fc7_relu7_0_split
I0605 18:45:14.054391 12718 net.cpp:454] fc7_relu7_0_split <- fc7
I0605 18:45:14.054400 12718 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0605 18:45:14.054407 12718 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0605 18:45:14.054498 12718 net.cpp:150] Setting up fc7_relu7_0_split
I0605 18:45:14.054505 12718 net.cpp:157] Top shape: 1 4096 (4096)
I0605 18:45:14.054522 12718 net.cpp:157] Top shape: 1 4096 (4096)
I0605 18:45:14.054527 12718 net.cpp:165] Memory required for data: 1430967084
I0605 18:45:14.054530 12718 layer_factory.hpp:77] Creating layer cls_score
I0605 18:45:14.054538 12718 net.cpp:106] Creating Layer cls_score
I0605 18:45:14.054543 12718 net.cpp:454] cls_score <- fc7_relu7_0_split_0
I0605 18:45:14.054549 12718 net.cpp:411] cls_score -> cls_score
I0605 18:45:14.054805 12718 net.cpp:150] Setting up cls_score
I0605 18:45:14.054811 12718 net.cpp:157] Top shape: 1 2 (2)
I0605 18:45:14.054814 12718 net.cpp:165] Memory required for data: 1430967092
I0605 18:45:14.054831 12718 layer_factory.hpp:77] Creating layer bbox_pred
I0605 18:45:14.054839 12718 net.cpp:106] Creating Layer bbox_pred
I0605 18:45:14.054846 12718 net.cpp:454] bbox_pred <- fc7_relu7_0_split_1
I0605 18:45:14.054852 12718 net.cpp:411] bbox_pred -> bbox_pred
I0605 18:45:14.055600 12718 net.cpp:150] Setting up bbox_pred
I0605 18:45:14.055606 12718 net.cpp:157] Top shape: 1 8 (8)
I0605 18:45:14.055609 12718 net.cpp:165] Memory required for data: 1430967124
I0605 18:45:14.055615 12718 layer_factory.hpp:77] Creating layer loss_cls
I0605 18:45:14.055634 12718 net.cpp:106] Creating Layer loss_cls
I0605 18:45:14.055639 12718 net.cpp:454] loss_cls <- cls_score
I0605 18:45:14.055644 12718 net.cpp:454] loss_cls <- labels
I0605 18:45:14.055649 12718 net.cpp:411] loss_cls -> loss_cls
I0605 18:45:14.055660 12718 layer_factory.hpp:77] Creating layer loss_cls
I0605 18:45:14.056340 12718 net.cpp:150] Setting up loss_cls
I0605 18:45:14.056349 12718 net.cpp:157] Top shape: (1)
I0605 18:45:14.056352 12718 net.cpp:160]     with loss weight 3
I0605 18:45:14.056375 12718 net.cpp:165] Memory required for data: 1430967128
I0605 18:45:14.056380 12718 layer_factory.hpp:77] Creating layer loss_bbox
I0605 18:45:14.056388 12718 net.cpp:106] Creating Layer loss_bbox
I0605 18:45:14.056394 12718 net.cpp:454] loss_bbox <- bbox_pred
I0605 18:45:14.056399 12718 net.cpp:454] loss_bbox <- bbox_targets
I0605 18:45:14.056404 12718 net.cpp:454] loss_bbox <- bbox_inside_weights
I0605 18:45:14.056409 12718 net.cpp:454] loss_bbox <- bbox_outside_weights
I0605 18:45:14.056417 12718 net.cpp:411] loss_bbox -> loss_bbox
I0605 18:45:14.056496 12718 net.cpp:150] Setting up loss_bbox
I0605 18:45:14.056502 12718 net.cpp:157] Top shape: (1)
I0605 18:45:14.056505 12718 net.cpp:160]     with loss weight 2
I0605 18:45:14.056510 12718 net.cpp:165] Memory required for data: 1430967132
I0605 18:45:14.056524 12718 layer_factory.hpp:77] Creating layer roi_pool5_2
I0605 18:45:14.056533 12718 net.cpp:106] Creating Layer roi_pool5_2
I0605 18:45:14.056537 12718 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0605 18:45:14.056551 12718 net.cpp:454] roi_pool5_2 <- rois_pos
I0605 18:45:14.056556 12718 net.cpp:411] roi_pool5_2 -> pool5_2
I0605 18:45:14.056578 12718 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0605 18:45:14.056679 12718 net.cpp:150] Setting up roi_pool5_2
I0605 18:45:14.056684 12718 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 18:45:14.056687 12718 net.cpp:165] Memory required for data: 1431067484
I0605 18:45:14.056691 12718 layer_factory.hpp:77] Creating layer pool5_2_conv
I0605 18:45:14.056704 12718 net.cpp:106] Creating Layer pool5_2_conv
I0605 18:45:14.056708 12718 net.cpp:454] pool5_2_conv <- pool5_2
I0605 18:45:14.056715 12718 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0605 18:45:14.063616 12718 net.cpp:150] Setting up pool5_2_conv
I0605 18:45:14.063627 12718 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 18:45:14.063629 12718 net.cpp:165] Memory required for data: 1431167836
I0605 18:45:14.063647 12718 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0605 18:45:14.063657 12718 net.cpp:106] Creating Layer pool5_2_conv_relu
I0605 18:45:14.063661 12718 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0605 18:45:14.063668 12718 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0605 18:45:14.063822 12718 net.cpp:150] Setting up pool5_2_conv_relu
I0605 18:45:14.063830 12718 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 18:45:14.063833 12718 net.cpp:165] Memory required for data: 1431268188
I0605 18:45:14.063848 12718 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0605 18:45:14.063864 12718 net.cpp:106] Creating Layer pool5_2_conv2
I0605 18:45:14.063879 12718 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0605 18:45:14.063884 12718 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0605 18:45:14.116470 12718 net.cpp:150] Setting up pool5_2_conv2
I0605 18:45:14.116490 12718 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 18:45:14.116494 12718 net.cpp:165] Memory required for data: 1431368540
I0605 18:45:14.116516 12718 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0605 18:45:14.116538 12718 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0605 18:45:14.116544 12718 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0605 18:45:14.116562 12718 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0605 18:45:14.116760 12718 net.cpp:150] Setting up pool5_2_conv2_relu
I0605 18:45:14.116767 12718 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0605 18:45:14.116770 12718 net.cpp:165] Memory required for data: 1431468892
I0605 18:45:14.116786 12718 layer_factory.hpp:77] Creating layer mask_deconv1
I0605 18:45:14.116809 12718 net.cpp:106] Creating Layer mask_deconv1
I0605 18:45:14.116814 12718 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0605 18:45:14.116832 12718 net.cpp:411] mask_deconv1 -> mask_deconv1
I0605 18:45:14.117692 12718 net.cpp:150] Setting up mask_deconv1
I0605 18:45:14.117699 12718 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0605 18:45:14.117702 12718 net.cpp:165] Memory required for data: 1432390492
I0605 18:45:14.117719 12718 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0605 18:45:14.117739 12718 net.cpp:106] Creating Layer pool5_2_conv3
I0605 18:45:14.117746 12718 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0605 18:45:14.117758 12718 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0605 18:45:14.144894 12718 net.cpp:150] Setting up pool5_2_conv3
I0605 18:45:14.144913 12718 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 18:45:14.144917 12718 net.cpp:165] Memory required for data: 1434233692
I0605 18:45:14.144939 12718 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0605 18:45:14.144961 12718 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0605 18:45:14.144969 12718 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0605 18:45:14.144986 12718 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0605 18:45:14.145184 12718 net.cpp:150] Setting up pool5_2_conv3_relu
I0605 18:45:14.145191 12718 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 18:45:14.145195 12718 net.cpp:165] Memory required for data: 1436076892
I0605 18:45:14.145208 12718 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0605 18:45:14.145233 12718 net.cpp:106] Creating Layer pool5_2_conv4
I0605 18:45:14.145238 12718 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0605 18:45:14.145254 12718 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0605 18:45:14.200037 12718 net.cpp:150] Setting up pool5_2_conv4
I0605 18:45:14.200059 12718 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 18:45:14.200064 12718 net.cpp:165] Memory required for data: 1437920092
I0605 18:45:14.200086 12718 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0605 18:45:14.200099 12718 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0605 18:45:14.200109 12718 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0605 18:45:14.200117 12718 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0605 18:45:14.200290 12718 net.cpp:150] Setting up pool5_2_conv4_relu
I0605 18:45:14.200300 12718 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0605 18:45:14.200304 12718 net.cpp:165] Memory required for data: 1439763292
I0605 18:45:14.200318 12718 layer_factory.hpp:77] Creating layer mask_deconv2
I0605 18:45:14.200332 12718 net.cpp:106] Creating Layer mask_deconv2
I0605 18:45:14.200337 12718 net.cpp:454] mask_deconv2 <- pool5_2_conv4_relu
I0605 18:45:14.200345 12718 net.cpp:411] mask_deconv2 -> mask_deconv2
I0605 18:45:14.201169 12718 net.cpp:150] Setting up mask_deconv2
I0605 18:45:14.201177 12718 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0605 18:45:14.201181 12718 net.cpp:165] Memory required for data: 1455004508
I0605 18:45:14.201198 12718 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0605 18:45:14.201215 12718 net.cpp:106] Creating Layer pool5_2_conv5
I0605 18:45:14.201221 12718 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0605 18:45:14.201228 12718 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0605 18:45:14.229771 12718 net.cpp:150] Setting up pool5_2_conv5
I0605 18:45:14.229792 12718 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:45:14.229797 12718 net.cpp:165] Memory required for data: 1485486940
I0605 18:45:14.229818 12718 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0605 18:45:14.229830 12718 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0605 18:45:14.229836 12718 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0605 18:45:14.229847 12718 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0605 18:45:14.230005 12718 net.cpp:150] Setting up pool5_2_conv5_relu
I0605 18:45:14.230016 12718 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:45:14.230020 12718 net.cpp:165] Memory required for data: 1515969372
I0605 18:45:14.230024 12718 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0605 18:45:14.230038 12718 net.cpp:106] Creating Layer pool5_2_conv6
I0605 18:45:14.230048 12718 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0605 18:45:14.230057 12718 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0605 18:45:14.281810 12718 net.cpp:150] Setting up pool5_2_conv6
I0605 18:45:14.281829 12718 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:45:14.281833 12718 net.cpp:165] Memory required for data: 1546451804
I0605 18:45:14.281854 12718 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0605 18:45:14.281878 12718 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0605 18:45:14.281895 12718 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0605 18:45:14.281913 12718 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0605 18:45:14.282501 12718 net.cpp:150] Setting up pool5_2_conv6_relu
I0605 18:45:14.282512 12718 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:45:14.282516 12718 net.cpp:165] Memory required for data: 1576934236
I0605 18:45:14.282531 12718 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu_pool5_2_conv6_relu_0_split
I0605 18:45:14.282552 12718 net.cpp:106] Creating Layer pool5_2_conv6_relu_pool5_2_conv6_relu_0_split
I0605 18:45:14.282558 12718 net.cpp:454] pool5_2_conv6_relu_pool5_2_conv6_relu_0_split <- pool5_2_conv6_relu
I0605 18:45:14.282573 12718 net.cpp:411] pool5_2_conv6_relu_pool5_2_conv6_relu_0_split -> pool5_2_conv6_relu_pool5_2_conv6_relu_0_split_0
I0605 18:45:14.282582 12718 net.cpp:411] pool5_2_conv6_relu_pool5_2_conv6_relu_0_split -> pool5_2_conv6_relu_pool5_2_conv6_relu_0_split_1
I0605 18:45:14.282601 12718 net.cpp:411] pool5_2_conv6_relu_pool5_2_conv6_relu_0_split -> pool5_2_conv6_relu_pool5_2_conv6_relu_0_split_2
I0605 18:45:14.282618 12718 net.cpp:411] pool5_2_conv6_relu_pool5_2_conv6_relu_0_split -> pool5_2_conv6_relu_pool5_2_conv6_relu_0_split_3
I0605 18:45:14.282691 12718 net.cpp:150] Setting up pool5_2_conv6_relu_pool5_2_conv6_relu_0_split
I0605 18:45:14.282704 12718 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:45:14.282709 12718 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:45:14.282723 12718 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:45:14.282728 12718 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:45:14.282732 12718 net.cpp:165] Memory required for data: 1698863964
I0605 18:45:14.282747 12718 layer_factory.hpp:77] Creating layer query_conv
I0605 18:45:14.282757 12718 net.cpp:106] Creating Layer query_conv
I0605 18:45:14.282763 12718 net.cpp:454] query_conv <- pool5_2_conv6_relu_pool5_2_conv6_relu_0_split_0
I0605 18:45:14.282770 12718 net.cpp:411] query_conv -> query_conv
I0605 18:45:14.284399 12718 net.cpp:150] Setting up query_conv
I0605 18:45:14.284407 12718 net.cpp:157] Top shape: 1 64 122 122 (952576)
I0605 18:45:14.284410 12718 net.cpp:165] Memory required for data: 1702674268
I0605 18:45:14.284428 12718 layer_factory.hpp:77] Creating layer key_conv
I0605 18:45:14.284452 12718 net.cpp:106] Creating Layer key_conv
I0605 18:45:14.284461 12718 net.cpp:454] key_conv <- pool5_2_conv6_relu_pool5_2_conv6_relu_0_split_1
I0605 18:45:14.284471 12718 net.cpp:411] key_conv -> key_conv
I0605 18:45:14.285706 12718 net.cpp:150] Setting up key_conv
I0605 18:45:14.285714 12718 net.cpp:157] Top shape: 1 64 122 122 (952576)
I0605 18:45:14.285718 12718 net.cpp:165] Memory required for data: 1706484572
I0605 18:45:14.285735 12718 layer_factory.hpp:77] Creating layer value_conv
I0605 18:45:14.285758 12718 net.cpp:106] Creating Layer value_conv
I0605 18:45:14.285761 12718 net.cpp:454] value_conv <- pool5_2_conv6_relu_pool5_2_conv6_relu_0_split_2
I0605 18:45:14.285768 12718 net.cpp:411] value_conv -> value_conv
I0605 18:45:14.292733 12718 net.cpp:150] Setting up value_conv
I0605 18:45:14.292743 12718 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:45:14.292747 12718 net.cpp:165] Memory required for data: 1736967004
I0605 18:45:14.292764 12718 layer_factory.hpp:77] Creating layer query_conv_reshape
I0605 18:45:14.292788 12718 net.cpp:106] Creating Layer query_conv_reshape
I0605 18:45:14.292793 12718 net.cpp:454] query_conv_reshape <- query_conv
I0605 18:45:14.292809 12718 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0605 18:45:14.292867 12718 net.cpp:150] Setting up query_conv_reshape
I0605 18:45:14.292872 12718 net.cpp:157] Top shape: 1 64 14884 1 (952576)
I0605 18:45:14.292884 12718 net.cpp:165] Memory required for data: 1740777308
I0605 18:45:14.292888 12718 layer_factory.hpp:77] Creating layer key_conv_reshape
I0605 18:45:14.292908 12718 net.cpp:106] Creating Layer key_conv_reshape
I0605 18:45:14.292913 12718 net.cpp:454] key_conv_reshape <- key_conv
I0605 18:45:14.292919 12718 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0605 18:45:14.292955 12718 net.cpp:150] Setting up key_conv_reshape
I0605 18:45:14.292961 12718 net.cpp:157] Top shape: 1 64 14884 1 (952576)
I0605 18:45:14.292964 12718 net.cpp:165] Memory required for data: 1744587612
I0605 18:45:14.292979 12718 layer_factory.hpp:77] Creating layer value_conv_reshape
I0605 18:45:14.292985 12718 net.cpp:106] Creating Layer value_conv_reshape
I0605 18:45:14.293002 12718 net.cpp:454] value_conv_reshape <- value_conv
I0605 18:45:14.293020 12718 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0605 18:45:14.293062 12718 net.cpp:150] Setting up value_conv_reshape
I0605 18:45:14.293068 12718 net.cpp:157] Top shape: 1 512 14884 1 (7620608)
I0605 18:45:14.293083 12718 net.cpp:165] Memory required for data: 1775070044
I0605 18:45:14.293087 12718 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0605 18:45:14.293103 12718 net.cpp:106] Creating Layer query_conv_reshape_perm
I0605 18:45:14.293108 12718 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0605 18:45:14.293114 12718 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0605 18:45:14.293207 12718 net.cpp:150] Setting up query_conv_reshape_perm
I0605 18:45:14.293213 12718 net.cpp:157] Top shape: 1 1 14884 64 (952576)
I0605 18:45:14.293217 12718 net.cpp:165] Memory required for data: 1778880348
I0605 18:45:14.293221 12718 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0605 18:45:14.293229 12718 net.cpp:106] Creating Layer key_conv_reshape_perm
I0605 18:45:14.293234 12718 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0605 18:45:14.293239 12718 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0605 18:45:14.293311 12718 net.cpp:150] Setting up key_conv_reshape_perm
I0605 18:45:14.293318 12718 net.cpp:157] Top shape: 1 1 64 14884 (952576)
I0605 18:45:14.293323 12718 net.cpp:165] Memory required for data: 1782690652
I0605 18:45:14.293328 12718 layer_factory.hpp:77] Creating layer energy
I0605 18:45:14.293335 12718 net.cpp:106] Creating Layer energy
I0605 18:45:14.293341 12718 net.cpp:454] energy <- query_conv_reshape_perm
I0605 18:45:14.293347 12718 net.cpp:454] energy <- key_conv_reshape_perm
I0605 18:45:14.293354 12718 net.cpp:411] energy -> energy
I0605 18:45:14.293375 12718 net.cpp:150] Setting up energy
I0605 18:45:14.293381 12718 net.cpp:157] Top shape: 1 1 14884 14884 (221533456)
I0605 18:45:14.293385 12718 net.cpp:165] Memory required for data: 2668824476
I0605 18:45:14.293390 12718 layer_factory.hpp:77] Creating layer attention
I0605 18:45:14.293397 12718 net.cpp:106] Creating Layer attention
I0605 18:45:14.293403 12718 net.cpp:454] attention <- energy
I0605 18:45:14.293431 12718 net.cpp:411] attention -> attention
I0605 18:45:14.294031 12718 net.cpp:150] Setting up attention
I0605 18:45:14.294040 12718 net.cpp:157] Top shape: 1 1 14884 14884 (221533456)
I0605 18:45:14.294045 12718 net.cpp:165] Memory required for data: 3554958300
I0605 18:45:14.294049 12718 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0605 18:45:14.294066 12718 net.cpp:106] Creating Layer value_conv_reshape_perm
I0605 18:45:14.294072 12718 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0605 18:45:14.294078 12718 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0605 18:45:14.294165 12718 net.cpp:150] Setting up value_conv_reshape_perm
I0605 18:45:14.294172 12718 net.cpp:157] Top shape: 1 1 512 14884 (7620608)
I0605 18:45:14.294175 12718 net.cpp:165] Memory required for data: 3585440732
I0605 18:45:14.294178 12718 layer_factory.hpp:77] Creating layer attention_perm
I0605 18:45:14.294185 12718 net.cpp:106] Creating Layer attention_perm
I0605 18:45:14.294189 12718 net.cpp:454] attention_perm <- attention
I0605 18:45:14.294196 12718 net.cpp:411] attention_perm -> attention_perm
I0605 18:45:14.294282 12718 net.cpp:150] Setting up attention_perm
I0605 18:45:14.294288 12718 net.cpp:157] Top shape: 1 1 14884 14884 (221533456)
I0605 18:45:14.294292 12718 net.cpp:165] Memory required for data: 4471574556
I0605 18:45:14.294296 12718 layer_factory.hpp:77] Creating layer out
I0605 18:45:14.294301 12718 net.cpp:106] Creating Layer out
I0605 18:45:14.294306 12718 net.cpp:454] out <- value_conv_reshape_perm
I0605 18:45:14.294311 12718 net.cpp:454] out <- attention_perm
I0605 18:45:14.294327 12718 net.cpp:411] out -> out
I0605 18:45:14.294348 12718 net.cpp:150] Setting up out
I0605 18:45:14.294353 12718 net.cpp:157] Top shape: 1 1 512 14884 (7620608)
I0605 18:45:14.294355 12718 net.cpp:165] Memory required for data: 4502056988
I0605 18:45:14.294359 12718 layer_factory.hpp:77] Creating layer out_reshape
I0605 18:45:14.294368 12718 net.cpp:106] Creating Layer out_reshape
I0605 18:45:14.294373 12718 net.cpp:454] out_reshape <- out
I0605 18:45:14.294378 12718 net.cpp:411] out_reshape -> out_reshape
I0605 18:45:14.294401 12718 net.cpp:150] Setting up out_reshape
I0605 18:45:14.294406 12718 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:45:14.294409 12718 net.cpp:165] Memory required for data: 4532539420
I0605 18:45:14.294412 12718 layer_factory.hpp:77] Creating layer out_reshape_scale
I0605 18:45:14.294420 12718 net.cpp:106] Creating Layer out_reshape_scale
I0605 18:45:14.294425 12718 net.cpp:454] out_reshape_scale <- out_reshape
I0605 18:45:14.294430 12718 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0605 18:45:14.294534 12718 net.cpp:150] Setting up out_reshape_scale
I0605 18:45:14.294541 12718 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:45:14.294544 12718 net.cpp:165] Memory required for data: 4563021852
I0605 18:45:14.294559 12718 layer_factory.hpp:77] Creating layer out_x
I0605 18:45:14.294569 12718 net.cpp:106] Creating Layer out_x
I0605 18:45:14.294574 12718 net.cpp:454] out_x <- out_reshape_scale
I0605 18:45:14.294580 12718 net.cpp:454] out_x <- pool5_2_conv6_relu_pool5_2_conv6_relu_0_split_3
I0605 18:45:14.294587 12718 net.cpp:411] out_x -> out_x
I0605 18:45:14.294615 12718 net.cpp:150] Setting up out_x
I0605 18:45:14.294631 12718 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0605 18:45:14.294633 12718 net.cpp:165] Memory required for data: 4593504284
I0605 18:45:14.294646 12718 layer_factory.hpp:77] Creating layer mask_deconv3
I0605 18:45:14.294657 12718 net.cpp:106] Creating Layer mask_deconv3
I0605 18:45:14.294661 12718 net.cpp:454] mask_deconv3 <- out_x
I0605 18:45:14.294669 12718 net.cpp:411] mask_deconv3 -> mask_deconv3
I0605 18:45:14.295037 12718 net.cpp:150] Setting up mask_deconv3
I0605 18:45:14.295043 12718 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0605 18:45:14.295047 12718 net.cpp:165] Memory required for data: 4654469148
I0605 18:45:14.295063 12718 layer_factory.hpp:77] Creating layer mask_score
I0605 18:45:14.295075 12718 net.cpp:106] Creating Layer mask_score
I0605 18:45:14.295080 12718 net.cpp:454] mask_score <- mask_deconv3
I0605 18:45:14.295086 12718 net.cpp:411] mask_score -> mask_score
I0605 18:45:14.296095 12718 net.cpp:150] Setting up mask_score
I0605 18:45:14.296105 12718 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0605 18:45:14.296109 12718 net.cpp:165] Memory required for data: 4656374300
I0605 18:45:14.296116 12718 layer_factory.hpp:77] Creating layer loss_mask
I0605 18:45:14.296125 12718 net.cpp:106] Creating Layer loss_mask
I0605 18:45:14.296130 12718 net.cpp:454] loss_mask <- mask_score
I0605 18:45:14.296136 12718 net.cpp:454] loss_mask <- mask_targets
I0605 18:45:14.296144 12718 net.cpp:411] loss_mask -> loss_mask
I0605 18:45:14.296155 12718 layer_factory.hpp:77] Creating layer loss_mask
I0605 18:45:14.297561 12718 net.cpp:150] Setting up loss_mask
I0605 18:45:14.297570 12718 net.cpp:157] Top shape: (1)
I0605 18:45:14.297574 12718 net.cpp:160]     with loss weight 3
I0605 18:45:14.297585 12718 net.cpp:165] Memory required for data: 4656374304
I0605 18:45:14.297590 12718 net.cpp:226] loss_mask needs backward computation.
I0605 18:45:14.297593 12718 net.cpp:226] mask_score needs backward computation.
I0605 18:45:14.297598 12718 net.cpp:226] mask_deconv3 needs backward computation.
I0605 18:45:14.297601 12718 net.cpp:226] out_x needs backward computation.
I0605 18:45:14.297606 12718 net.cpp:226] out_reshape_scale needs backward computation.
I0605 18:45:14.297610 12718 net.cpp:226] out_reshape needs backward computation.
I0605 18:45:14.297614 12718 net.cpp:226] out needs backward computation.
I0605 18:45:14.297617 12718 net.cpp:226] attention_perm needs backward computation.
I0605 18:45:14.297623 12718 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0605 18:45:14.297627 12718 net.cpp:226] attention needs backward computation.
I0605 18:45:14.297631 12718 net.cpp:226] energy needs backward computation.
I0605 18:45:14.297636 12718 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0605 18:45:14.297639 12718 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0605 18:45:14.297643 12718 net.cpp:226] value_conv_reshape needs backward computation.
I0605 18:45:14.297647 12718 net.cpp:226] key_conv_reshape needs backward computation.
I0605 18:45:14.297654 12718 net.cpp:226] query_conv_reshape needs backward computation.
I0605 18:45:14.297659 12718 net.cpp:226] value_conv needs backward computation.
I0605 18:45:14.297663 12718 net.cpp:226] key_conv needs backward computation.
I0605 18:45:14.297667 12718 net.cpp:226] query_conv needs backward computation.
I0605 18:45:14.297672 12718 net.cpp:226] pool5_2_conv6_relu_pool5_2_conv6_relu_0_split needs backward computation.
I0605 18:45:14.297677 12718 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0605 18:45:14.297679 12718 net.cpp:226] pool5_2_conv6 needs backward computation.
I0605 18:45:14.297684 12718 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0605 18:45:14.297688 12718 net.cpp:226] pool5_2_conv5 needs backward computation.
I0605 18:45:14.297693 12718 net.cpp:226] mask_deconv2 needs backward computation.
I0605 18:45:14.297698 12718 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0605 18:45:14.297701 12718 net.cpp:226] pool5_2_conv4 needs backward computation.
I0605 18:45:14.297705 12718 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0605 18:45:14.297708 12718 net.cpp:226] pool5_2_conv3 needs backward computation.
I0605 18:45:14.297713 12718 net.cpp:226] mask_deconv1 needs backward computation.
I0605 18:45:14.297718 12718 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0605 18:45:14.297722 12718 net.cpp:226] pool5_2_conv2 needs backward computation.
I0605 18:45:14.297726 12718 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0605 18:45:14.297730 12718 net.cpp:226] pool5_2_conv needs backward computation.
I0605 18:45:14.297735 12718 net.cpp:226] roi_pool5_2 needs backward computation.
I0605 18:45:14.297741 12718 net.cpp:226] loss_bbox needs backward computation.
I0605 18:45:14.297747 12718 net.cpp:226] loss_cls needs backward computation.
I0605 18:45:14.297752 12718 net.cpp:226] bbox_pred needs backward computation.
I0605 18:45:14.297755 12718 net.cpp:226] cls_score needs backward computation.
I0605 18:45:14.297760 12718 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0605 18:45:14.297763 12718 net.cpp:226] relu7 needs backward computation.
I0605 18:45:14.297768 12718 net.cpp:226] fc7 needs backward computation.
I0605 18:45:14.297772 12718 net.cpp:226] relu6 needs backward computation.
I0605 18:45:14.297776 12718 net.cpp:226] fc6 needs backward computation.
I0605 18:45:14.297780 12718 net.cpp:226] roi_pool5 needs backward computation.
I0605 18:45:14.297785 12718 net.cpp:226] roi-data needs backward computation.
I0605 18:45:14.297794 12718 net.cpp:226] proposal needs backward computation.
I0605 18:45:14.297801 12718 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0605 18:45:14.297804 12718 net.cpp:226] rpn_cls_prob needs backward computation.
I0605 18:45:14.297808 12718 net.cpp:226] rpn_loss_bbox needs backward computation.
I0605 18:45:14.297814 12718 net.cpp:226] rpn_loss_cls needs backward computation.
I0605 18:45:14.297819 12718 net.cpp:226] rpn-data needs backward computation.
I0605 18:45:14.297827 12718 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0605 18:45:14.297832 12718 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0605 18:45:14.297835 12718 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0605 18:45:14.297839 12718 net.cpp:226] rpn_bbox_pred needs backward computation.
I0605 18:45:14.297843 12718 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0605 18:45:14.297848 12718 net.cpp:226] rpn_cls_score needs backward computation.
I0605 18:45:14.297853 12718 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0605 18:45:14.297859 12718 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0605 18:45:14.297863 12718 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0605 18:45:14.297868 12718 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0605 18:45:14.297873 12718 net.cpp:226] relu5_3 needs backward computation.
I0605 18:45:14.297876 12718 net.cpp:226] conv5_3 needs backward computation.
I0605 18:45:14.297880 12718 net.cpp:226] relu5_2 needs backward computation.
I0605 18:45:14.297884 12718 net.cpp:226] conv5_2 needs backward computation.
I0605 18:45:14.297888 12718 net.cpp:226] relu5_1 needs backward computation.
I0605 18:45:14.297894 12718 net.cpp:226] conv5_1 needs backward computation.
I0605 18:45:14.297897 12718 net.cpp:226] pool4 needs backward computation.
I0605 18:45:14.297902 12718 net.cpp:226] relu4_3 needs backward computation.
I0605 18:45:14.297906 12718 net.cpp:226] conv4_3 needs backward computation.
I0605 18:45:14.297910 12718 net.cpp:226] relu4_2 needs backward computation.
I0605 18:45:14.297914 12718 net.cpp:226] conv4_2 needs backward computation.
I0605 18:45:14.297919 12718 net.cpp:226] relu4_1 needs backward computation.
I0605 18:45:14.297922 12718 net.cpp:226] conv4_1 needs backward computation.
I0605 18:45:14.297927 12718 net.cpp:226] pool3 needs backward computation.
I0605 18:45:14.297933 12718 net.cpp:226] relu3_3 needs backward computation.
I0605 18:45:14.297936 12718 net.cpp:226] conv3_3 needs backward computation.
I0605 18:45:14.297940 12718 net.cpp:226] relu3_2 needs backward computation.
I0605 18:45:14.297945 12718 net.cpp:226] conv3_2 needs backward computation.
I0605 18:45:14.297950 12718 net.cpp:226] relu3_1 needs backward computation.
I0605 18:45:14.297955 12718 net.cpp:226] conv3_1 needs backward computation.
I0605 18:45:14.297958 12718 net.cpp:228] pool2 does not need backward computation.
I0605 18:45:14.297964 12718 net.cpp:228] relu2_2 does not need backward computation.
I0605 18:45:14.297969 12718 net.cpp:228] conv2_2 does not need backward computation.
I0605 18:45:14.297973 12718 net.cpp:228] relu2_1 does not need backward computation.
I0605 18:45:14.297977 12718 net.cpp:228] conv2_1 does not need backward computation.
I0605 18:45:14.297981 12718 net.cpp:228] pool1 does not need backward computation.
I0605 18:45:14.297986 12718 net.cpp:228] relu1_2 does not need backward computation.
I0605 18:45:14.297989 12718 net.cpp:228] conv1_2 does not need backward computation.
I0605 18:45:14.297993 12718 net.cpp:228] relu1_1 does not need backward computation.
I0605 18:45:14.297998 12718 net.cpp:228] conv1_1 does not need backward computation.
I0605 18:45:14.298003 12718 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0605 18:45:14.298009 12718 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0605 18:45:14.298013 12718 net.cpp:228] data_input-data_0_split does not need backward computation.
I0605 18:45:14.298019 12718 net.cpp:228] input-data does not need backward computation.
I0605 18:45:14.298024 12718 net.cpp:270] This network produces output loss_bbox
I0605 18:45:14.298028 12718 net.cpp:270] This network produces output loss_cls
I0605 18:45:14.298033 12718 net.cpp:270] This network produces output loss_mask
I0605 18:45:14.298038 12718 net.cpp:270] This network produces output rpn_cls_loss
I0605 18:45:14.298043 12718 net.cpp:270] This network produces output rpn_loss_bbox
I0605 18:45:14.298095 12718 net.cpp:283] Network initialization done.
I0605 18:45:14.298274 12718 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0605 18:45:25.130256 12718 net.cpp:816] Ignoring source layer pool5
I0605 18:45:25.203694 12718 net.cpp:816] Ignoring source layer drop6
I0605 18:45:25.216148 12718 net.cpp:816] Ignoring source layer drop7
I0605 18:45:25.216164 12718 net.cpp:816] Ignoring source layer fc8
I0605 18:45:25.216167 12718 net.cpp:816] Ignoring source layer prob
Solving...
F0605 18:45:25.657639 12718 syncedmem.cpp:56] Check failed: error == cudaSuccess (2 vs. 0)  out of memory
*** Check failure stack trace: ***
./experiments/scripts/faster_rcnn_end2end.sh: line 65: 12718 Aborted                 /usr/bin/python ./tools/train_net.py --gpu ${GPU_ID} --solver models/${PT_DIR}/${NET}/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb ${TRAIN_IMDB} --iters ${ITERS} --cfg experiments/cfgs/faster_rcnn_end2end.yml ${EXTRA_ARGS}
