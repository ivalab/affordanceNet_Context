+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-11_14-11-36
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-11_14-11-36
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0611 14:11:44.832240 21677 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0611 14:11:44.832332 21677 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0611 14:11:44.834077 21677 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_mask"
  type: "SoftmaxWithLoss"
  bottom: "mask_score"
  bottom: "mask_targets"
  top: "loss_mask"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
I0611 14:11:44.834466 21677 layer_factory.hpp:77] Creating layer input-data
I0611 14:11:44.938316 21677 net.cpp:106] Creating Layer input-data
I0611 14:11:44.938331 21677 net.cpp:411] input-data -> data
I0611 14:11:44.938339 21677 net.cpp:411] input-data -> im_info
I0611 14:11:44.938344 21677 net.cpp:411] input-data -> gt_boxes
I0611 14:11:44.938349 21677 net.cpp:411] input-data -> seg_mask_inds
I0611 14:11:44.938354 21677 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0611 14:11:44.980285 21677 net.cpp:150] Setting up input-data
I0611 14:11:44.980302 21677 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 14:11:44.980307 21677 net.cpp:157] Top shape: 1 3 (3)
I0611 14:11:44.980311 21677 net.cpp:157] Top shape: 1 4 (4)
I0611 14:11:44.980314 21677 net.cpp:157] Top shape: 1 2 (2)
I0611 14:11:44.980317 21677 net.cpp:157] Top shape: 1 1 (1)
I0611 14:11:44.980320 21677 net.cpp:165] Memory required for data: 7200040
I0611 14:11:44.980325 21677 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0611 14:11:44.980815 21677 net.cpp:106] Creating Layer data_input-data_0_split
I0611 14:11:44.980823 21677 net.cpp:454] data_input-data_0_split <- data
I0611 14:11:44.980829 21677 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0611 14:11:44.980836 21677 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0611 14:11:44.980861 21677 net.cpp:150] Setting up data_input-data_0_split
I0611 14:11:44.980870 21677 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 14:11:44.980875 21677 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 14:11:44.980876 21677 net.cpp:165] Memory required for data: 21600040
I0611 14:11:44.980881 21677 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0611 14:11:44.980890 21677 net.cpp:106] Creating Layer im_info_input-data_1_split
I0611 14:11:44.980893 21677 net.cpp:454] im_info_input-data_1_split <- im_info
I0611 14:11:44.980897 21677 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0611 14:11:44.980904 21677 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0611 14:11:44.980912 21677 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0611 14:11:44.980938 21677 net.cpp:150] Setting up im_info_input-data_1_split
I0611 14:11:44.980945 21677 net.cpp:157] Top shape: 1 3 (3)
I0611 14:11:44.980952 21677 net.cpp:157] Top shape: 1 3 (3)
I0611 14:11:44.980957 21677 net.cpp:157] Top shape: 1 3 (3)
I0611 14:11:44.980965 21677 net.cpp:165] Memory required for data: 21600076
I0611 14:11:44.980968 21677 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0611 14:11:44.980971 21677 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0611 14:11:44.980975 21677 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0611 14:11:44.980980 21677 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0611 14:11:44.980985 21677 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0611 14:11:44.981006 21677 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0611 14:11:44.981010 21677 net.cpp:157] Top shape: 1 4 (4)
I0611 14:11:44.981012 21677 net.cpp:157] Top shape: 1 4 (4)
I0611 14:11:44.981015 21677 net.cpp:165] Memory required for data: 21600108
I0611 14:11:44.981019 21677 layer_factory.hpp:77] Creating layer conv1_1
I0611 14:11:44.981030 21677 net.cpp:106] Creating Layer conv1_1
I0611 14:11:44.981034 21677 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0611 14:11:44.981037 21677 net.cpp:411] conv1_1 -> conv1_1
I0611 14:11:45.439230 21677 net.cpp:150] Setting up conv1_1
I0611 14:11:45.439251 21677 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 14:11:45.439255 21677 net.cpp:165] Memory required for data: 175200108
I0611 14:11:45.439267 21677 layer_factory.hpp:77] Creating layer relu1_1
I0611 14:11:45.439287 21677 net.cpp:106] Creating Layer relu1_1
I0611 14:11:45.439291 21677 net.cpp:454] relu1_1 <- conv1_1
I0611 14:11:45.439297 21677 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0611 14:11:45.439476 21677 net.cpp:150] Setting up relu1_1
I0611 14:11:45.439481 21677 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 14:11:45.439484 21677 net.cpp:165] Memory required for data: 328800108
I0611 14:11:45.439486 21677 layer_factory.hpp:77] Creating layer conv1_2
I0611 14:11:45.439493 21677 net.cpp:106] Creating Layer conv1_2
I0611 14:11:45.439496 21677 net.cpp:454] conv1_2 <- conv1_1
I0611 14:11:45.439499 21677 net.cpp:411] conv1_2 -> conv1_2
I0611 14:11:45.441617 21677 net.cpp:150] Setting up conv1_2
I0611 14:11:45.441637 21677 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 14:11:45.441640 21677 net.cpp:165] Memory required for data: 482400108
I0611 14:11:45.441648 21677 layer_factory.hpp:77] Creating layer relu1_2
I0611 14:11:45.441663 21677 net.cpp:106] Creating Layer relu1_2
I0611 14:11:45.441665 21677 net.cpp:454] relu1_2 <- conv1_2
I0611 14:11:45.441670 21677 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0611 14:11:45.441803 21677 net.cpp:150] Setting up relu1_2
I0611 14:11:45.441810 21677 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 14:11:45.441823 21677 net.cpp:165] Memory required for data: 636000108
I0611 14:11:45.441826 21677 layer_factory.hpp:77] Creating layer pool1
I0611 14:11:45.441833 21677 net.cpp:106] Creating Layer pool1
I0611 14:11:45.441846 21677 net.cpp:454] pool1 <- conv1_2
I0611 14:11:45.441850 21677 net.cpp:411] pool1 -> pool1
I0611 14:11:45.442456 21677 net.cpp:150] Setting up pool1
I0611 14:11:45.442462 21677 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0611 14:11:45.442466 21677 net.cpp:165] Memory required for data: 674400108
I0611 14:11:45.442467 21677 layer_factory.hpp:77] Creating layer conv2_1
I0611 14:11:45.442474 21677 net.cpp:106] Creating Layer conv2_1
I0611 14:11:45.442478 21677 net.cpp:454] conv2_1 <- pool1
I0611 14:11:45.442482 21677 net.cpp:411] conv2_1 -> conv2_1
I0611 14:11:45.444332 21677 net.cpp:150] Setting up conv2_1
I0611 14:11:45.444342 21677 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 14:11:45.444345 21677 net.cpp:165] Memory required for data: 751200108
I0611 14:11:45.444362 21677 layer_factory.hpp:77] Creating layer relu2_1
I0611 14:11:45.444368 21677 net.cpp:106] Creating Layer relu2_1
I0611 14:11:45.444372 21677 net.cpp:454] relu2_1 <- conv2_1
I0611 14:11:45.444377 21677 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0611 14:11:45.444943 21677 net.cpp:150] Setting up relu2_1
I0611 14:11:45.444973 21677 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 14:11:45.444977 21677 net.cpp:165] Memory required for data: 828000108
I0611 14:11:45.444980 21677 layer_factory.hpp:77] Creating layer conv2_2
I0611 14:11:45.444999 21677 net.cpp:106] Creating Layer conv2_2
I0611 14:11:45.445019 21677 net.cpp:454] conv2_2 <- conv2_1
I0611 14:11:45.445025 21677 net.cpp:411] conv2_2 -> conv2_2
I0611 14:11:45.446811 21677 net.cpp:150] Setting up conv2_2
I0611 14:11:45.446821 21677 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 14:11:45.446823 21677 net.cpp:165] Memory required for data: 904800108
I0611 14:11:45.446830 21677 layer_factory.hpp:77] Creating layer relu2_2
I0611 14:11:45.446835 21677 net.cpp:106] Creating Layer relu2_2
I0611 14:11:45.446838 21677 net.cpp:454] relu2_2 <- conv2_2
I0611 14:11:45.446851 21677 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0611 14:11:45.447003 21677 net.cpp:150] Setting up relu2_2
I0611 14:11:45.447010 21677 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 14:11:45.447023 21677 net.cpp:165] Memory required for data: 981600108
I0611 14:11:45.447026 21677 layer_factory.hpp:77] Creating layer pool2
I0611 14:11:45.447041 21677 net.cpp:106] Creating Layer pool2
I0611 14:11:45.447044 21677 net.cpp:454] pool2 <- conv2_2
I0611 14:11:45.447049 21677 net.cpp:411] pool2 -> pool2
I0611 14:11:45.447100 21677 net.cpp:150] Setting up pool2
I0611 14:11:45.447118 21677 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0611 14:11:45.447119 21677 net.cpp:165] Memory required for data: 1000800108
I0611 14:11:45.447121 21677 layer_factory.hpp:77] Creating layer conv3_1
I0611 14:11:45.447137 21677 net.cpp:106] Creating Layer conv3_1
I0611 14:11:45.447140 21677 net.cpp:454] conv3_1 <- pool2
I0611 14:11:45.447145 21677 net.cpp:411] conv3_1 -> conv3_1
I0611 14:11:45.449087 21677 net.cpp:150] Setting up conv3_1
I0611 14:11:45.449103 21677 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:11:45.449107 21677 net.cpp:165] Memory required for data: 1039200108
I0611 14:11:45.449127 21677 layer_factory.hpp:77] Creating layer relu3_1
I0611 14:11:45.449149 21677 net.cpp:106] Creating Layer relu3_1
I0611 14:11:45.449153 21677 net.cpp:454] relu3_1 <- conv3_1
I0611 14:11:45.449167 21677 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0611 14:11:45.449290 21677 net.cpp:150] Setting up relu3_1
I0611 14:11:45.449295 21677 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:11:45.449296 21677 net.cpp:165] Memory required for data: 1077600108
I0611 14:11:45.449299 21677 layer_factory.hpp:77] Creating layer conv3_2
I0611 14:11:45.449306 21677 net.cpp:106] Creating Layer conv3_2
I0611 14:11:45.449309 21677 net.cpp:454] conv3_2 <- conv3_1
I0611 14:11:45.449313 21677 net.cpp:411] conv3_2 -> conv3_2
I0611 14:11:45.451434 21677 net.cpp:150] Setting up conv3_2
I0611 14:11:45.451457 21677 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:11:45.451460 21677 net.cpp:165] Memory required for data: 1116000108
I0611 14:11:45.451465 21677 layer_factory.hpp:77] Creating layer relu3_2
I0611 14:11:45.451483 21677 net.cpp:106] Creating Layer relu3_2
I0611 14:11:45.451485 21677 net.cpp:454] relu3_2 <- conv3_2
I0611 14:11:45.451490 21677 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0611 14:11:45.451670 21677 net.cpp:150] Setting up relu3_2
I0611 14:11:45.451676 21677 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:11:45.451678 21677 net.cpp:165] Memory required for data: 1154400108
I0611 14:11:45.451681 21677 layer_factory.hpp:77] Creating layer conv3_3
I0611 14:11:45.451697 21677 net.cpp:106] Creating Layer conv3_3
I0611 14:11:45.451701 21677 net.cpp:454] conv3_3 <- conv3_2
I0611 14:11:45.451714 21677 net.cpp:411] conv3_3 -> conv3_3
I0611 14:11:45.453862 21677 net.cpp:150] Setting up conv3_3
I0611 14:11:45.453884 21677 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:11:45.453886 21677 net.cpp:165] Memory required for data: 1192800108
I0611 14:11:45.453893 21677 layer_factory.hpp:77] Creating layer relu3_3
I0611 14:11:45.453908 21677 net.cpp:106] Creating Layer relu3_3
I0611 14:11:45.453912 21677 net.cpp:454] relu3_3 <- conv3_3
I0611 14:11:45.453917 21677 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0611 14:11:45.454068 21677 net.cpp:150] Setting up relu3_3
I0611 14:11:45.454074 21677 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:11:45.454077 21677 net.cpp:165] Memory required for data: 1231200108
I0611 14:11:45.454078 21677 layer_factory.hpp:77] Creating layer pool3
I0611 14:11:45.454084 21677 net.cpp:106] Creating Layer pool3
I0611 14:11:45.454087 21677 net.cpp:454] pool3 <- conv3_3
I0611 14:11:45.454090 21677 net.cpp:411] pool3 -> pool3
I0611 14:11:45.454139 21677 net.cpp:150] Setting up pool3
I0611 14:11:45.454144 21677 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0611 14:11:45.454155 21677 net.cpp:165] Memory required for data: 1240800108
I0611 14:11:45.454159 21677 layer_factory.hpp:77] Creating layer conv4_1
I0611 14:11:45.454164 21677 net.cpp:106] Creating Layer conv4_1
I0611 14:11:45.454167 21677 net.cpp:454] conv4_1 <- pool3
I0611 14:11:45.454180 21677 net.cpp:411] conv4_1 -> conv4_1
I0611 14:11:45.458644 21677 net.cpp:150] Setting up conv4_1
I0611 14:11:45.458663 21677 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:11:45.458667 21677 net.cpp:165] Memory required for data: 1260000108
I0611 14:11:45.458675 21677 layer_factory.hpp:77] Creating layer relu4_1
I0611 14:11:45.458685 21677 net.cpp:106] Creating Layer relu4_1
I0611 14:11:45.458690 21677 net.cpp:454] relu4_1 <- conv4_1
I0611 14:11:45.458695 21677 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0611 14:11:45.458823 21677 net.cpp:150] Setting up relu4_1
I0611 14:11:45.458829 21677 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:11:45.458832 21677 net.cpp:165] Memory required for data: 1279200108
I0611 14:11:45.458834 21677 layer_factory.hpp:77] Creating layer conv4_2
I0611 14:11:45.458842 21677 net.cpp:106] Creating Layer conv4_2
I0611 14:11:45.458843 21677 net.cpp:454] conv4_2 <- conv4_1
I0611 14:11:45.458848 21677 net.cpp:411] conv4_2 -> conv4_2
I0611 14:11:45.464746 21677 net.cpp:150] Setting up conv4_2
I0611 14:11:45.464773 21677 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:11:45.464776 21677 net.cpp:165] Memory required for data: 1298400108
I0611 14:11:45.464787 21677 layer_factory.hpp:77] Creating layer relu4_2
I0611 14:11:45.464797 21677 net.cpp:106] Creating Layer relu4_2
I0611 14:11:45.464800 21677 net.cpp:454] relu4_2 <- conv4_2
I0611 14:11:45.464804 21677 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0611 14:11:45.465319 21677 net.cpp:150] Setting up relu4_2
I0611 14:11:45.465327 21677 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:11:45.465339 21677 net.cpp:165] Memory required for data: 1317600108
I0611 14:11:45.465342 21677 layer_factory.hpp:77] Creating layer conv4_3
I0611 14:11:45.465351 21677 net.cpp:106] Creating Layer conv4_3
I0611 14:11:45.465356 21677 net.cpp:454] conv4_3 <- conv4_2
I0611 14:11:45.465360 21677 net.cpp:411] conv4_3 -> conv4_3
I0611 14:11:45.470578 21677 net.cpp:150] Setting up conv4_3
I0611 14:11:45.470598 21677 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:11:45.470603 21677 net.cpp:165] Memory required for data: 1336800108
I0611 14:11:45.470623 21677 layer_factory.hpp:77] Creating layer relu4_3
I0611 14:11:45.470634 21677 net.cpp:106] Creating Layer relu4_3
I0611 14:11:45.470640 21677 net.cpp:454] relu4_3 <- conv4_3
I0611 14:11:45.470650 21677 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0611 14:11:45.470795 21677 net.cpp:150] Setting up relu4_3
I0611 14:11:45.470803 21677 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:11:45.470808 21677 net.cpp:165] Memory required for data: 1356000108
I0611 14:11:45.470821 21677 layer_factory.hpp:77] Creating layer pool4
I0611 14:11:45.470832 21677 net.cpp:106] Creating Layer pool4
I0611 14:11:45.470837 21677 net.cpp:454] pool4 <- conv4_3
I0611 14:11:45.470844 21677 net.cpp:411] pool4 -> pool4
I0611 14:11:45.470881 21677 net.cpp:150] Setting up pool4
I0611 14:11:45.470887 21677 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:45.470891 21677 net.cpp:165] Memory required for data: 1360903020
I0611 14:11:45.470894 21677 layer_factory.hpp:77] Creating layer conv5_1
I0611 14:11:45.470908 21677 net.cpp:106] Creating Layer conv5_1
I0611 14:11:45.470912 21677 net.cpp:454] conv5_1 <- pool4
I0611 14:11:45.470919 21677 net.cpp:411] conv5_1 -> conv5_1
I0611 14:11:45.475302 21677 net.cpp:150] Setting up conv5_1
I0611 14:11:45.475320 21677 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:45.475324 21677 net.cpp:165] Memory required for data: 1365805932
I0611 14:11:45.475334 21677 layer_factory.hpp:77] Creating layer relu5_1
I0611 14:11:45.475353 21677 net.cpp:106] Creating Layer relu5_1
I0611 14:11:45.475359 21677 net.cpp:454] relu5_1 <- conv5_1
I0611 14:11:45.475378 21677 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0611 14:11:45.475530 21677 net.cpp:150] Setting up relu5_1
I0611 14:11:45.475538 21677 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:45.475543 21677 net.cpp:165] Memory required for data: 1370708844
I0611 14:11:45.475548 21677 layer_factory.hpp:77] Creating layer conv5_2
I0611 14:11:45.475561 21677 net.cpp:106] Creating Layer conv5_2
I0611 14:11:45.475567 21677 net.cpp:454] conv5_2 <- conv5_1
I0611 14:11:45.475579 21677 net.cpp:411] conv5_2 -> conv5_2
I0611 14:11:45.480623 21677 net.cpp:150] Setting up conv5_2
I0611 14:11:45.480641 21677 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:45.480645 21677 net.cpp:165] Memory required for data: 1375611756
I0611 14:11:45.480655 21677 layer_factory.hpp:77] Creating layer relu5_2
I0611 14:11:45.480679 21677 net.cpp:106] Creating Layer relu5_2
I0611 14:11:45.480685 21677 net.cpp:454] relu5_2 <- conv5_2
I0611 14:11:45.480700 21677 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0611 14:11:45.480844 21677 net.cpp:150] Setting up relu5_2
I0611 14:11:45.480851 21677 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:45.480856 21677 net.cpp:165] Memory required for data: 1380514668
I0611 14:11:45.480861 21677 layer_factory.hpp:77] Creating layer conv5_3
I0611 14:11:45.480883 21677 net.cpp:106] Creating Layer conv5_3
I0611 14:11:45.480887 21677 net.cpp:454] conv5_3 <- conv5_2
I0611 14:11:45.480903 21677 net.cpp:411] conv5_3 -> conv5_3
I0611 14:11:45.485394 21677 net.cpp:150] Setting up conv5_3
I0611 14:11:45.485437 21677 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:45.485442 21677 net.cpp:165] Memory required for data: 1385417580
I0611 14:11:45.485462 21677 layer_factory.hpp:77] Creating layer relu5_3
I0611 14:11:45.485482 21677 net.cpp:106] Creating Layer relu5_3
I0611 14:11:45.485489 21677 net.cpp:454] relu5_3 <- conv5_3
I0611 14:11:45.485508 21677 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0611 14:11:45.485687 21677 net.cpp:150] Setting up relu5_3
I0611 14:11:45.485695 21677 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:45.485699 21677 net.cpp:165] Memory required for data: 1390320492
I0611 14:11:45.485703 21677 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0611 14:11:45.485713 21677 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0611 14:11:45.485718 21677 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0611 14:11:45.485733 21677 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0611 14:11:45.485740 21677 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0611 14:11:45.485747 21677 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0611 14:11:45.485802 21677 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0611 14:11:45.485808 21677 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:45.485812 21677 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:45.485816 21677 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:45.485821 21677 net.cpp:165] Memory required for data: 1405029228
I0611 14:11:45.485824 21677 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0611 14:11:45.485847 21677 net.cpp:106] Creating Layer rpn_conv/3x3
I0611 14:11:45.485852 21677 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0611 14:11:45.485858 21677 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0611 14:11:45.537927 21677 net.cpp:150] Setting up rpn_conv/3x3
I0611 14:11:45.537946 21677 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:45.537950 21677 net.cpp:165] Memory required for data: 1409932140
I0611 14:11:45.537961 21677 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0611 14:11:45.537984 21677 net.cpp:106] Creating Layer rpn_relu/3x3
I0611 14:11:45.537997 21677 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0611 14:11:45.538008 21677 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0611 14:11:45.538156 21677 net.cpp:150] Setting up rpn_relu/3x3
I0611 14:11:45.538164 21677 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:45.538168 21677 net.cpp:165] Memory required for data: 1414835052
I0611 14:11:45.538173 21677 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0611 14:11:45.538182 21677 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0611 14:11:45.538188 21677 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0611 14:11:45.538209 21677 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0611 14:11:45.538220 21677 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0611 14:11:45.538309 21677 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0611 14:11:45.538317 21677 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:45.538322 21677 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:11:45.538337 21677 net.cpp:165] Memory required for data: 1424640876
I0611 14:11:45.538342 21677 layer_factory.hpp:77] Creating layer rpn_cls_score
I0611 14:11:45.538378 21677 net.cpp:106] Creating Layer rpn_cls_score
I0611 14:11:45.538384 21677 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0611 14:11:45.538390 21677 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0611 14:11:45.542834 21677 net.cpp:150] Setting up rpn_cls_score
I0611 14:11:45.542845 21677 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 14:11:45.542848 21677 net.cpp:165] Memory required for data: 1424928156
I0611 14:11:45.542856 21677 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0611 14:11:45.542888 21677 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0611 14:11:45.542894 21677 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0611 14:11:45.542902 21677 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0611 14:11:45.542922 21677 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0611 14:11:45.542961 21677 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0611 14:11:45.542971 21677 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 14:11:45.542976 21677 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 14:11:45.542979 21677 net.cpp:165] Memory required for data: 1425502716
I0611 14:11:45.542985 21677 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0611 14:11:45.542996 21677 net.cpp:106] Creating Layer rpn_bbox_pred
I0611 14:11:45.543002 21677 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0611 14:11:45.543010 21677 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0611 14:11:45.546716 21677 net.cpp:150] Setting up rpn_bbox_pred
I0611 14:11:45.546741 21677 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:11:45.546743 21677 net.cpp:165] Memory required for data: 1426077276
I0611 14:11:45.546751 21677 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 14:11:45.546767 21677 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 14:11:45.546772 21677 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0611 14:11:45.546775 21677 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0611 14:11:45.546783 21677 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0611 14:11:45.546823 21677 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 14:11:45.546828 21677 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:11:45.546840 21677 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:11:45.546842 21677 net.cpp:165] Memory required for data: 1427226396
I0611 14:11:45.546844 21677 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0611 14:11:45.546857 21677 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0611 14:11:45.546861 21677 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0611 14:11:45.546875 21677 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0611 14:11:45.546905 21677 net.cpp:150] Setting up rpn_cls_score_reshape
I0611 14:11:45.546919 21677 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 14:11:45.546921 21677 net.cpp:165] Memory required for data: 1427513676
I0611 14:11:45.546923 21677 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 14:11:45.546937 21677 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 14:11:45.546941 21677 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0611 14:11:45.546944 21677 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0611 14:11:45.546953 21677 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0611 14:11:45.546977 21677 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 14:11:45.546980 21677 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 14:11:45.546983 21677 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 14:11:45.546986 21677 net.cpp:165] Memory required for data: 1428088236
I0611 14:11:45.546988 21677 layer_factory.hpp:77] Creating layer rpn-data
I0611 14:11:45.547979 21677 net.cpp:106] Creating Layer rpn-data
I0611 14:11:45.547987 21677 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0611 14:11:45.547992 21677 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0611 14:11:45.547996 21677 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0611 14:11:45.548000 21677 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0611 14:11:45.548005 21677 net.cpp:411] rpn-data -> rpn_labels
I0611 14:11:45.548010 21677 net.cpp:411] rpn-data -> rpn_bbox_targets
I0611 14:11:45.548017 21677 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0611 14:11:45.548020 21677 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0611 14:11:45.548887 21677 net.cpp:150] Setting up rpn-data
I0611 14:11:45.548897 21677 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0611 14:11:45.548900 21677 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:11:45.548904 21677 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:11:45.548908 21677 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:11:45.548913 21677 net.cpp:165] Memory required for data: 1429955556
I0611 14:11:45.548915 21677 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0611 14:11:45.548924 21677 net.cpp:106] Creating Layer rpn_loss_cls
I0611 14:11:45.548930 21677 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0611 14:11:45.548934 21677 net.cpp:454] rpn_loss_cls <- rpn_labels
I0611 14:11:45.548938 21677 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0611 14:11:45.548949 21677 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0611 14:11:45.550223 21677 net.cpp:150] Setting up rpn_loss_cls
I0611 14:11:45.550232 21677 net.cpp:157] Top shape: (1)
I0611 14:11:45.550235 21677 net.cpp:160]     with loss weight 1
I0611 14:11:45.550242 21677 net.cpp:165] Memory required for data: 1429955560
I0611 14:11:45.550246 21677 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0611 14:11:45.550251 21677 net.cpp:106] Creating Layer rpn_loss_bbox
I0611 14:11:45.550256 21677 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0611 14:11:45.550261 21677 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0611 14:11:45.550266 21677 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0611 14:11:45.550268 21677 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0611 14:11:45.550272 21677 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0611 14:11:45.551457 21677 net.cpp:150] Setting up rpn_loss_bbox
I0611 14:11:45.551465 21677 net.cpp:157] Top shape: (1)
I0611 14:11:45.551479 21677 net.cpp:160]     with loss weight 1
I0611 14:11:45.551483 21677 net.cpp:165] Memory required for data: 1429955564
I0611 14:11:45.551486 21677 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0611 14:11:45.551501 21677 net.cpp:106] Creating Layer rpn_cls_prob
I0611 14:11:45.551507 21677 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0611 14:11:45.551510 21677 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0611 14:11:45.551690 21677 net.cpp:150] Setting up rpn_cls_prob
I0611 14:11:45.551695 21677 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 14:11:45.551707 21677 net.cpp:165] Memory required for data: 1430242844
I0611 14:11:45.551710 21677 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0611 14:11:45.551715 21677 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0611 14:11:45.551728 21677 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0611 14:11:45.551733 21677 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0611 14:11:45.551764 21677 net.cpp:150] Setting up rpn_cls_prob_reshape
I0611 14:11:45.551767 21677 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 14:11:45.551769 21677 net.cpp:165] Memory required for data: 1430530124
I0611 14:11:45.551781 21677 layer_factory.hpp:77] Creating layer proposal
I0611 14:11:45.554255 21677 net.cpp:106] Creating Layer proposal
I0611 14:11:45.554263 21677 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0611 14:11:45.554267 21677 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0611 14:11:45.554271 21677 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0611 14:11:45.554275 21677 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0611 14:11:45.555425 21677 net.cpp:150] Setting up proposal
I0611 14:11:45.555435 21677 net.cpp:157] Top shape: 1 5 (5)
I0611 14:11:45.555438 21677 net.cpp:165] Memory required for data: 1430530144
I0611 14:11:45.555440 21677 layer_factory.hpp:77] Creating layer roi-data
I0611 14:11:45.557874 21677 net.cpp:106] Creating Layer roi-data
I0611 14:11:45.557883 21677 net.cpp:454] roi-data <- rpn_rois
I0611 14:11:45.557886 21677 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0611 14:11:45.557890 21677 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0611 14:11:45.557893 21677 net.cpp:454] roi-data <- seg_mask_inds
I0611 14:11:45.557895 21677 net.cpp:454] roi-data <- flipped
I0611 14:11:45.557899 21677 net.cpp:411] roi-data -> rois
I0611 14:11:45.557915 21677 net.cpp:411] roi-data -> labels
I0611 14:11:45.557921 21677 net.cpp:411] roi-data -> bbox_targets
I0611 14:11:45.557925 21677 net.cpp:411] roi-data -> bbox_inside_weights
I0611 14:11:45.557930 21677 net.cpp:411] roi-data -> bbox_outside_weights
I0611 14:11:45.557934 21677 net.cpp:411] roi-data -> mask_targets
I0611 14:11:45.557940 21677 net.cpp:411] roi-data -> rois_pos
I0611 14:11:45.558228 21677 net.cpp:150] Setting up roi-data
I0611 14:11:45.558236 21677 net.cpp:157] Top shape: 1 5 (5)
I0611 14:11:45.558239 21677 net.cpp:157] Top shape: 1 1 (1)
I0611 14:11:45.558243 21677 net.cpp:157] Top shape: 1 8 (8)
I0611 14:11:45.558244 21677 net.cpp:157] Top shape: 1 8 (8)
I0611 14:11:45.558246 21677 net.cpp:157] Top shape: 1 8 (8)
I0611 14:11:45.558249 21677 net.cpp:157] Top shape: 1 244 244 (59536)
I0611 14:11:45.558251 21677 net.cpp:157] Top shape: 1 5 (5)
I0611 14:11:45.558254 21677 net.cpp:165] Memory required for data: 1430768428
I0611 14:11:45.558266 21677 layer_factory.hpp:77] Creating layer roi_pool5
I0611 14:11:45.558271 21677 net.cpp:106] Creating Layer roi_pool5
I0611 14:11:45.558275 21677 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0611 14:11:45.558279 21677 net.cpp:454] roi_pool5 <- rois
I0611 14:11:45.558284 21677 net.cpp:411] roi_pool5 -> pool5
I0611 14:11:45.558295 21677 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0611 14:11:45.558387 21677 net.cpp:150] Setting up roi_pool5
I0611 14:11:45.558390 21677 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 14:11:45.558403 21677 net.cpp:165] Memory required for data: 1430868780
I0611 14:11:45.558405 21677 layer_factory.hpp:77] Creating layer fc6
I0611 14:11:45.558410 21677 net.cpp:106] Creating Layer fc6
I0611 14:11:45.558413 21677 net.cpp:454] fc6 <- pool5
I0611 14:11:45.558418 21677 net.cpp:411] fc6 -> fc6
I0611 14:11:45.736778 21677 net.cpp:150] Setting up fc6
I0611 14:11:45.736812 21677 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:11:45.736817 21677 net.cpp:165] Memory required for data: 1430885164
I0611 14:11:45.736836 21677 layer_factory.hpp:77] Creating layer relu6
I0611 14:11:45.736848 21677 net.cpp:106] Creating Layer relu6
I0611 14:11:45.736853 21677 net.cpp:454] relu6 <- fc6
I0611 14:11:45.736860 21677 net.cpp:397] relu6 -> fc6 (in-place)
I0611 14:11:45.737072 21677 net.cpp:150] Setting up relu6
I0611 14:11:45.737082 21677 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:11:45.737094 21677 net.cpp:165] Memory required for data: 1430901548
I0611 14:11:45.737097 21677 layer_factory.hpp:77] Creating layer fc7
I0611 14:11:45.737103 21677 net.cpp:106] Creating Layer fc7
I0611 14:11:45.737107 21677 net.cpp:454] fc7 <- fc6
I0611 14:11:45.737112 21677 net.cpp:411] fc7 -> fc7
I0611 14:11:45.764458 21677 net.cpp:150] Setting up fc7
I0611 14:11:45.764490 21677 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:11:45.764494 21677 net.cpp:165] Memory required for data: 1430917932
I0611 14:11:45.764503 21677 layer_factory.hpp:77] Creating layer relu7
I0611 14:11:45.764513 21677 net.cpp:106] Creating Layer relu7
I0611 14:11:45.764528 21677 net.cpp:454] relu7 <- fc7
I0611 14:11:45.764533 21677 net.cpp:397] relu7 -> fc7 (in-place)
I0611 14:11:45.764737 21677 net.cpp:150] Setting up relu7
I0611 14:11:45.764745 21677 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:11:45.764757 21677 net.cpp:165] Memory required for data: 1430934316
I0611 14:11:45.764760 21677 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0611 14:11:45.764765 21677 net.cpp:106] Creating Layer fc7_relu7_0_split
I0611 14:11:45.764780 21677 net.cpp:454] fc7_relu7_0_split <- fc7
I0611 14:11:45.764786 21677 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0611 14:11:45.764793 21677 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0611 14:11:45.764837 21677 net.cpp:150] Setting up fc7_relu7_0_split
I0611 14:11:45.764850 21677 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:11:45.764854 21677 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:11:45.764856 21677 net.cpp:165] Memory required for data: 1430967084
I0611 14:11:45.764859 21677 layer_factory.hpp:77] Creating layer cls_score
I0611 14:11:45.764874 21677 net.cpp:106] Creating Layer cls_score
I0611 14:11:45.764878 21677 net.cpp:454] cls_score <- fc7_relu7_0_split_0
I0611 14:11:45.764881 21677 net.cpp:411] cls_score -> cls_score
I0611 14:11:45.765137 21677 net.cpp:150] Setting up cls_score
I0611 14:11:45.765141 21677 net.cpp:157] Top shape: 1 2 (2)
I0611 14:11:45.765144 21677 net.cpp:165] Memory required for data: 1430967092
I0611 14:11:45.765159 21677 layer_factory.hpp:77] Creating layer bbox_pred
I0611 14:11:45.765163 21677 net.cpp:106] Creating Layer bbox_pred
I0611 14:11:45.765168 21677 net.cpp:454] bbox_pred <- fc7_relu7_0_split_1
I0611 14:11:45.765172 21677 net.cpp:411] bbox_pred -> bbox_pred
I0611 14:11:45.765969 21677 net.cpp:150] Setting up bbox_pred
I0611 14:11:45.765976 21677 net.cpp:157] Top shape: 1 8 (8)
I0611 14:11:45.765980 21677 net.cpp:165] Memory required for data: 1430967124
I0611 14:11:45.765995 21677 layer_factory.hpp:77] Creating layer loss_cls
I0611 14:11:45.766003 21677 net.cpp:106] Creating Layer loss_cls
I0611 14:11:45.766010 21677 net.cpp:454] loss_cls <- cls_score
I0611 14:11:45.766014 21677 net.cpp:454] loss_cls <- labels
I0611 14:11:45.766021 21677 net.cpp:411] loss_cls -> loss_cls
I0611 14:11:45.766031 21677 layer_factory.hpp:77] Creating layer loss_cls
I0611 14:11:45.767931 21677 net.cpp:150] Setting up loss_cls
I0611 14:11:45.767941 21677 net.cpp:157] Top shape: (1)
I0611 14:11:45.767956 21677 net.cpp:160]     with loss weight 3
I0611 14:11:45.767963 21677 net.cpp:165] Memory required for data: 1430967128
I0611 14:11:45.767966 21677 layer_factory.hpp:77] Creating layer loss_bbox
I0611 14:11:45.767971 21677 net.cpp:106] Creating Layer loss_bbox
I0611 14:11:45.767974 21677 net.cpp:454] loss_bbox <- bbox_pred
I0611 14:11:45.767979 21677 net.cpp:454] loss_bbox <- bbox_targets
I0611 14:11:45.767984 21677 net.cpp:454] loss_bbox <- bbox_inside_weights
I0611 14:11:45.767987 21677 net.cpp:454] loss_bbox <- bbox_outside_weights
I0611 14:11:45.767992 21677 net.cpp:411] loss_bbox -> loss_bbox
I0611 14:11:45.768064 21677 net.cpp:150] Setting up loss_bbox
I0611 14:11:45.768069 21677 net.cpp:157] Top shape: (1)
I0611 14:11:45.768081 21677 net.cpp:160]     with loss weight 2
I0611 14:11:45.768085 21677 net.cpp:165] Memory required for data: 1430967132
I0611 14:11:45.768087 21677 layer_factory.hpp:77] Creating layer roi_pool5_2
I0611 14:11:45.768093 21677 net.cpp:106] Creating Layer roi_pool5_2
I0611 14:11:45.768096 21677 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0611 14:11:45.768101 21677 net.cpp:454] roi_pool5_2 <- rois_pos
I0611 14:11:45.768106 21677 net.cpp:411] roi_pool5_2 -> pool5_2
I0611 14:11:45.768115 21677 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0611 14:11:45.768189 21677 net.cpp:150] Setting up roi_pool5_2
I0611 14:11:45.768193 21677 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 14:11:45.768196 21677 net.cpp:165] Memory required for data: 1431067484
I0611 14:11:45.768208 21677 layer_factory.hpp:77] Creating layer pool5_2_conv
I0611 14:11:45.768216 21677 net.cpp:106] Creating Layer pool5_2_conv
I0611 14:11:45.768219 21677 net.cpp:454] pool5_2_conv <- pool5_2
I0611 14:11:45.768224 21677 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0611 14:11:45.775331 21677 net.cpp:150] Setting up pool5_2_conv
I0611 14:11:45.775357 21677 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 14:11:45.775358 21677 net.cpp:165] Memory required for data: 1431167836
I0611 14:11:45.775365 21677 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0611 14:11:45.775372 21677 net.cpp:106] Creating Layer pool5_2_conv_relu
I0611 14:11:45.775377 21677 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0611 14:11:45.775383 21677 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0611 14:11:45.775552 21677 net.cpp:150] Setting up pool5_2_conv_relu
I0611 14:11:45.775559 21677 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 14:11:45.775562 21677 net.cpp:165] Memory required for data: 1431268188
I0611 14:11:45.775564 21677 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0611 14:11:45.775581 21677 net.cpp:106] Creating Layer pool5_2_conv2
I0611 14:11:45.775585 21677 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0611 14:11:45.775591 21677 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0611 14:11:45.828363 21677 net.cpp:150] Setting up pool5_2_conv2
I0611 14:11:45.828395 21677 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 14:11:45.828400 21677 net.cpp:165] Memory required for data: 1431368540
I0611 14:11:45.828413 21677 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0611 14:11:45.828424 21677 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0611 14:11:45.828434 21677 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0611 14:11:45.828440 21677 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0611 14:11:45.828655 21677 net.cpp:150] Setting up pool5_2_conv2_relu
I0611 14:11:45.828665 21677 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 14:11:45.828670 21677 net.cpp:165] Memory required for data: 1431468892
I0611 14:11:45.828673 21677 layer_factory.hpp:77] Creating layer mask_deconv1
I0611 14:11:45.828683 21677 net.cpp:106] Creating Layer mask_deconv1
I0611 14:11:45.828696 21677 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0611 14:11:45.828702 21677 net.cpp:411] mask_deconv1 -> mask_deconv1
I0611 14:11:45.829653 21677 net.cpp:150] Setting up mask_deconv1
I0611 14:11:45.829660 21677 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0611 14:11:45.829663 21677 net.cpp:165] Memory required for data: 1432390492
I0611 14:11:45.829668 21677 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0611 14:11:45.829687 21677 net.cpp:106] Creating Layer pool5_2_conv3
I0611 14:11:45.829691 21677 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0611 14:11:45.829697 21677 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0611 14:11:45.856853 21677 net.cpp:150] Setting up pool5_2_conv3
I0611 14:11:45.856870 21677 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:45.856873 21677 net.cpp:165] Memory required for data: 1434233692
I0611 14:11:45.856884 21677 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0611 14:11:45.856895 21677 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0611 14:11:45.856900 21677 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0611 14:11:45.856906 21677 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0611 14:11:45.857059 21677 net.cpp:150] Setting up pool5_2_conv3_relu
I0611 14:11:45.857066 21677 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:45.857069 21677 net.cpp:165] Memory required for data: 1436076892
I0611 14:11:45.857071 21677 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0611 14:11:45.857082 21677 net.cpp:106] Creating Layer pool5_2_conv4
I0611 14:11:45.857086 21677 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0611 14:11:45.857091 21677 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0611 14:11:45.909158 21677 net.cpp:150] Setting up pool5_2_conv4
I0611 14:11:45.909175 21677 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:45.909178 21677 net.cpp:165] Memory required for data: 1437920092
I0611 14:11:45.909184 21677 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0611 14:11:45.909193 21677 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0611 14:11:45.909198 21677 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0611 14:11:45.909201 21677 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0611 14:11:45.909328 21677 net.cpp:150] Setting up pool5_2_conv4_relu
I0611 14:11:45.909334 21677 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:45.909337 21677 net.cpp:165] Memory required for data: 1439763292
I0611 14:11:45.909338 21677 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 14:11:45.909343 21677 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 14:11:45.909345 21677 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0611 14:11:45.909348 21677 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0611 14:11:45.909354 21677 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0611 14:11:45.909359 21677 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0611 14:11:45.909363 21677 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0611 14:11:45.909405 21677 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 14:11:45.909409 21677 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:45.909442 21677 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:45.909447 21677 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:45.909451 21677 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:45.909453 21677 net.cpp:165] Memory required for data: 1447136092
I0611 14:11:45.909456 21677 layer_factory.hpp:77] Creating layer query_conv
I0611 14:11:45.909466 21677 net.cpp:106] Creating Layer query_conv
I0611 14:11:45.909471 21677 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0611 14:11:45.909477 21677 net.cpp:411] query_conv -> query_conv
I0611 14:11:45.911475 21677 net.cpp:150] Setting up query_conv
I0611 14:11:45.911485 21677 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0611 14:11:45.911487 21677 net.cpp:165] Memory required for data: 1447366492
I0611 14:11:45.911494 21677 layer_factory.hpp:77] Creating layer key_conv
I0611 14:11:45.911514 21677 net.cpp:106] Creating Layer key_conv
I0611 14:11:45.911518 21677 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0611 14:11:45.911523 21677 net.cpp:411] key_conv -> key_conv
I0611 14:11:45.913115 21677 net.cpp:150] Setting up key_conv
I0611 14:11:45.913122 21677 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0611 14:11:45.913125 21677 net.cpp:165] Memory required for data: 1447596892
I0611 14:11:45.913130 21677 layer_factory.hpp:77] Creating layer value_conv
I0611 14:11:45.913137 21677 net.cpp:106] Creating Layer value_conv
I0611 14:11:45.913141 21677 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0611 14:11:45.913146 21677 net.cpp:411] value_conv -> value_conv
I0611 14:11:45.920224 21677 net.cpp:150] Setting up value_conv
I0611 14:11:45.920238 21677 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:45.920240 21677 net.cpp:165] Memory required for data: 1449440092
I0611 14:11:45.920246 21677 layer_factory.hpp:77] Creating layer query_conv_reshape
I0611 14:11:45.920254 21677 net.cpp:106] Creating Layer query_conv_reshape
I0611 14:11:45.920258 21677 net.cpp:454] query_conv_reshape <- query_conv
I0611 14:11:45.920272 21677 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0611 14:11:45.920294 21677 net.cpp:150] Setting up query_conv_reshape
I0611 14:11:45.920298 21677 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0611 14:11:45.920300 21677 net.cpp:165] Memory required for data: 1449670492
I0611 14:11:45.920303 21677 layer_factory.hpp:77] Creating layer key_conv_reshape
I0611 14:11:45.920307 21677 net.cpp:106] Creating Layer key_conv_reshape
I0611 14:11:45.920322 21677 net.cpp:454] key_conv_reshape <- key_conv
I0611 14:11:45.920326 21677 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0611 14:11:45.920346 21677 net.cpp:150] Setting up key_conv_reshape
I0611 14:11:45.920351 21677 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0611 14:11:45.920353 21677 net.cpp:165] Memory required for data: 1449900892
I0611 14:11:45.920356 21677 layer_factory.hpp:77] Creating layer value_conv_reshape
I0611 14:11:45.920361 21677 net.cpp:106] Creating Layer value_conv_reshape
I0611 14:11:45.920367 21677 net.cpp:454] value_conv_reshape <- value_conv
I0611 14:11:45.920370 21677 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0611 14:11:45.920388 21677 net.cpp:150] Setting up value_conv_reshape
I0611 14:11:45.920393 21677 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0611 14:11:45.920395 21677 net.cpp:165] Memory required for data: 1451744092
I0611 14:11:45.920397 21677 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0611 14:11:45.936188 21677 net.cpp:106] Creating Layer query_conv_reshape_perm
I0611 14:11:45.936204 21677 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0611 14:11:45.936213 21677 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0611 14:11:45.936365 21677 net.cpp:150] Setting up query_conv_reshape_perm
I0611 14:11:45.936373 21677 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0611 14:11:45.936378 21677 net.cpp:165] Memory required for data: 1451974492
I0611 14:11:45.936390 21677 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0611 14:11:45.936395 21677 net.cpp:106] Creating Layer key_conv_reshape_perm
I0611 14:11:45.936398 21677 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0611 14:11:45.936411 21677 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0611 14:11:45.936496 21677 net.cpp:150] Setting up key_conv_reshape_perm
I0611 14:11:45.936501 21677 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0611 14:11:45.936502 21677 net.cpp:165] Memory required for data: 1452204892
I0611 14:11:45.936506 21677 layer_factory.hpp:77] Creating layer energy
I0611 14:11:45.936520 21677 net.cpp:106] Creating Layer energy
I0611 14:11:45.936524 21677 net.cpp:454] energy <- query_conv_reshape_perm
I0611 14:11:45.936527 21677 net.cpp:454] energy <- key_conv_reshape_perm
I0611 14:11:45.936532 21677 net.cpp:411] energy -> energy
I0611 14:11:45.936553 21677 net.cpp:150] Setting up energy
I0611 14:11:45.936568 21677 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 14:11:45.936570 21677 net.cpp:165] Memory required for data: 1455444892
I0611 14:11:45.936573 21677 layer_factory.hpp:77] Creating layer attention
I0611 14:11:45.936589 21677 net.cpp:106] Creating Layer attention
I0611 14:11:45.936594 21677 net.cpp:454] attention <- energy
I0611 14:11:45.936597 21677 net.cpp:411] attention -> attention
I0611 14:11:45.936821 21677 net.cpp:150] Setting up attention
I0611 14:11:45.936830 21677 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 14:11:45.936832 21677 net.cpp:165] Memory required for data: 1458684892
I0611 14:11:45.936836 21677 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0611 14:11:45.936841 21677 net.cpp:106] Creating Layer value_conv_reshape_perm
I0611 14:11:45.936846 21677 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0611 14:11:45.936849 21677 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0611 14:11:45.936919 21677 net.cpp:150] Setting up value_conv_reshape_perm
I0611 14:11:45.936924 21677 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0611 14:11:45.936926 21677 net.cpp:165] Memory required for data: 1460528092
I0611 14:11:45.936929 21677 layer_factory.hpp:77] Creating layer attention_perm
I0611 14:11:45.936933 21677 net.cpp:106] Creating Layer attention_perm
I0611 14:11:45.936938 21677 net.cpp:454] attention_perm <- attention
I0611 14:11:45.936940 21677 net.cpp:411] attention_perm -> attention_perm
I0611 14:11:45.937002 21677 net.cpp:150] Setting up attention_perm
I0611 14:11:45.937006 21677 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 14:11:45.937008 21677 net.cpp:165] Memory required for data: 1463768092
I0611 14:11:45.937012 21677 layer_factory.hpp:77] Creating layer out
I0611 14:11:45.937016 21677 net.cpp:106] Creating Layer out
I0611 14:11:45.937019 21677 net.cpp:454] out <- value_conv_reshape_perm
I0611 14:11:45.937022 21677 net.cpp:454] out <- attention_perm
I0611 14:11:45.937027 21677 net.cpp:411] out -> out
I0611 14:11:45.937043 21677 net.cpp:150] Setting up out
I0611 14:11:45.937047 21677 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0611 14:11:45.937050 21677 net.cpp:165] Memory required for data: 1465611292
I0611 14:11:45.937053 21677 layer_factory.hpp:77] Creating layer out_reshape
I0611 14:11:45.937059 21677 net.cpp:106] Creating Layer out_reshape
I0611 14:11:45.937062 21677 net.cpp:454] out_reshape <- out
I0611 14:11:45.937065 21677 net.cpp:411] out_reshape -> out_reshape
I0611 14:11:45.937083 21677 net.cpp:150] Setting up out_reshape
I0611 14:11:45.937088 21677 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:45.937090 21677 net.cpp:165] Memory required for data: 1467454492
I0611 14:11:45.937093 21677 layer_factory.hpp:77] Creating layer out_reshape_scale
I0611 14:11:45.937099 21677 net.cpp:106] Creating Layer out_reshape_scale
I0611 14:11:45.937103 21677 net.cpp:454] out_reshape_scale <- out_reshape
I0611 14:11:45.937106 21677 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0611 14:11:45.937175 21677 net.cpp:150] Setting up out_reshape_scale
I0611 14:11:45.937180 21677 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:45.937181 21677 net.cpp:165] Memory required for data: 1469297692
I0611 14:11:45.937186 21677 layer_factory.hpp:77] Creating layer out_x
I0611 14:11:45.937191 21677 net.cpp:106] Creating Layer out_x
I0611 14:11:45.937196 21677 net.cpp:454] out_x <- out_reshape_scale
I0611 14:11:45.937199 21677 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0611 14:11:45.937206 21677 net.cpp:411] out_x -> out_x
I0611 14:11:45.937223 21677 net.cpp:150] Setting up out_x
I0611 14:11:45.937227 21677 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 14:11:45.937229 21677 net.cpp:165] Memory required for data: 1471140892
I0611 14:11:45.937232 21677 layer_factory.hpp:77] Creating layer mask_deconv2
I0611 14:11:45.937243 21677 net.cpp:106] Creating Layer mask_deconv2
I0611 14:11:45.937247 21677 net.cpp:454] mask_deconv2 <- out_x
I0611 14:11:45.937250 21677 net.cpp:411] mask_deconv2 -> mask_deconv2
I0611 14:11:45.938122 21677 net.cpp:150] Setting up mask_deconv2
I0611 14:11:45.938128 21677 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0611 14:11:45.938132 21677 net.cpp:165] Memory required for data: 1486382108
I0611 14:11:45.938136 21677 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0611 14:11:45.938158 21677 net.cpp:106] Creating Layer pool5_2_conv5
I0611 14:11:45.938161 21677 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0611 14:11:45.938165 21677 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0611 14:11:45.965895 21677 net.cpp:150] Setting up pool5_2_conv5
I0611 14:11:45.965915 21677 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 14:11:45.965919 21677 net.cpp:165] Memory required for data: 1516864540
I0611 14:11:45.965927 21677 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0611 14:11:45.965936 21677 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0611 14:11:45.965942 21677 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0611 14:11:45.965951 21677 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0611 14:11:45.966116 21677 net.cpp:150] Setting up pool5_2_conv5_relu
I0611 14:11:45.966125 21677 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 14:11:45.966126 21677 net.cpp:165] Memory required for data: 1547346972
I0611 14:11:45.966130 21677 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0611 14:11:45.966150 21677 net.cpp:106] Creating Layer pool5_2_conv6
I0611 14:11:45.966152 21677 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0611 14:11:45.966158 21677 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0611 14:11:46.038969 21677 net.cpp:150] Setting up pool5_2_conv6
I0611 14:11:46.039005 21677 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 14:11:46.039010 21677 net.cpp:165] Memory required for data: 1577829404
I0611 14:11:46.039032 21677 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0611 14:11:46.039043 21677 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0611 14:11:46.039050 21677 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0611 14:11:46.039062 21677 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0611 14:11:46.039865 21677 net.cpp:150] Setting up pool5_2_conv6_relu
I0611 14:11:46.039885 21677 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 14:11:46.039888 21677 net.cpp:165] Memory required for data: 1608311836
I0611 14:11:46.039893 21677 layer_factory.hpp:77] Creating layer mask_deconv3
I0611 14:11:46.039918 21677 net.cpp:106] Creating Layer mask_deconv3
I0611 14:11:46.039924 21677 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0611 14:11:46.039942 21677 net.cpp:411] mask_deconv3 -> mask_deconv3
I0611 14:11:46.040482 21677 net.cpp:150] Setting up mask_deconv3
I0611 14:11:46.040501 21677 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0611 14:11:46.040505 21677 net.cpp:165] Memory required for data: 1669276700
I0611 14:11:46.040526 21677 layer_factory.hpp:77] Creating layer mask_score
I0611 14:11:46.040539 21677 net.cpp:106] Creating Layer mask_score
I0611 14:11:46.040544 21677 net.cpp:454] mask_score <- mask_deconv3
I0611 14:11:46.040552 21677 net.cpp:411] mask_score -> mask_score
I0611 14:11:46.041890 21677 net.cpp:150] Setting up mask_score
I0611 14:11:46.041914 21677 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0611 14:11:46.041918 21677 net.cpp:165] Memory required for data: 1671181852
I0611 14:11:46.041939 21677 layer_factory.hpp:77] Creating layer loss_mask
I0611 14:11:46.041952 21677 net.cpp:106] Creating Layer loss_mask
I0611 14:11:46.041960 21677 net.cpp:454] loss_mask <- mask_score
I0611 14:11:46.041965 21677 net.cpp:454] loss_mask <- mask_targets
I0611 14:11:46.041972 21677 net.cpp:411] loss_mask -> loss_mask
I0611 14:11:46.041983 21677 layer_factory.hpp:77] Creating layer loss_mask
I0611 14:11:46.044728 21677 net.cpp:150] Setting up loss_mask
I0611 14:11:46.044765 21677 net.cpp:157] Top shape: (1)
I0611 14:11:46.044775 21677 net.cpp:160]     with loss weight 3
I0611 14:11:46.044804 21677 net.cpp:165] Memory required for data: 1671181856
I0611 14:11:46.044821 21677 net.cpp:226] loss_mask needs backward computation.
I0611 14:11:46.044858 21677 net.cpp:226] mask_score needs backward computation.
I0611 14:11:46.044870 21677 net.cpp:226] mask_deconv3 needs backward computation.
I0611 14:11:46.044879 21677 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0611 14:11:46.044894 21677 net.cpp:226] pool5_2_conv6 needs backward computation.
I0611 14:11:46.044908 21677 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0611 14:11:46.044922 21677 net.cpp:226] pool5_2_conv5 needs backward computation.
I0611 14:11:46.044939 21677 net.cpp:226] mask_deconv2 needs backward computation.
I0611 14:11:46.044955 21677 net.cpp:226] out_x needs backward computation.
I0611 14:11:46.044984 21677 net.cpp:226] out_reshape_scale needs backward computation.
I0611 14:11:46.045009 21677 net.cpp:226] out_reshape needs backward computation.
I0611 14:11:46.045034 21677 net.cpp:226] out needs backward computation.
I0611 14:11:46.045055 21677 net.cpp:226] attention_perm needs backward computation.
I0611 14:11:46.045075 21677 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0611 14:11:46.045092 21677 net.cpp:226] attention needs backward computation.
I0611 14:11:46.045114 21677 net.cpp:226] energy needs backward computation.
I0611 14:11:46.045135 21677 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0611 14:11:46.045156 21677 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0611 14:11:46.045181 21677 net.cpp:226] value_conv_reshape needs backward computation.
I0611 14:11:46.045200 21677 net.cpp:226] key_conv_reshape needs backward computation.
I0611 14:11:46.045222 21677 net.cpp:226] query_conv_reshape needs backward computation.
I0611 14:11:46.045239 21677 net.cpp:226] value_conv needs backward computation.
I0611 14:11:46.045250 21677 net.cpp:226] key_conv needs backward computation.
I0611 14:11:46.045258 21677 net.cpp:226] query_conv needs backward computation.
I0611 14:11:46.045269 21677 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0611 14:11:46.045277 21677 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0611 14:11:46.045286 21677 net.cpp:226] pool5_2_conv4 needs backward computation.
I0611 14:11:46.045297 21677 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0611 14:11:46.045303 21677 net.cpp:226] pool5_2_conv3 needs backward computation.
I0611 14:11:46.045307 21677 net.cpp:226] mask_deconv1 needs backward computation.
I0611 14:11:46.045312 21677 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0611 14:11:46.045316 21677 net.cpp:226] pool5_2_conv2 needs backward computation.
I0611 14:11:46.045321 21677 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0611 14:11:46.045326 21677 net.cpp:226] pool5_2_conv needs backward computation.
I0611 14:11:46.045332 21677 net.cpp:226] roi_pool5_2 needs backward computation.
I0611 14:11:46.045336 21677 net.cpp:226] loss_bbox needs backward computation.
I0611 14:11:46.045346 21677 net.cpp:226] loss_cls needs backward computation.
I0611 14:11:46.045351 21677 net.cpp:226] bbox_pred needs backward computation.
I0611 14:11:46.045354 21677 net.cpp:226] cls_score needs backward computation.
I0611 14:11:46.045357 21677 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0611 14:11:46.045361 21677 net.cpp:226] relu7 needs backward computation.
I0611 14:11:46.045364 21677 net.cpp:226] fc7 needs backward computation.
I0611 14:11:46.045368 21677 net.cpp:226] relu6 needs backward computation.
I0611 14:11:46.045370 21677 net.cpp:226] fc6 needs backward computation.
I0611 14:11:46.045374 21677 net.cpp:226] roi_pool5 needs backward computation.
I0611 14:11:46.045378 21677 net.cpp:226] roi-data needs backward computation.
I0611 14:11:46.045387 21677 net.cpp:226] proposal needs backward computation.
I0611 14:11:46.045392 21677 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0611 14:11:46.045398 21677 net.cpp:226] rpn_cls_prob needs backward computation.
I0611 14:11:46.045401 21677 net.cpp:226] rpn_loss_bbox needs backward computation.
I0611 14:11:46.045405 21677 net.cpp:226] rpn_loss_cls needs backward computation.
I0611 14:11:46.045409 21677 net.cpp:226] rpn-data needs backward computation.
I0611 14:11:46.045439 21677 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0611 14:11:46.045442 21677 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0611 14:11:46.045446 21677 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0611 14:11:46.045449 21677 net.cpp:226] rpn_bbox_pred needs backward computation.
I0611 14:11:46.045451 21677 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0611 14:11:46.045454 21677 net.cpp:226] rpn_cls_score needs backward computation.
I0611 14:11:46.045467 21677 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0611 14:11:46.045471 21677 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0611 14:11:46.045475 21677 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0611 14:11:46.045478 21677 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0611 14:11:46.045481 21677 net.cpp:226] relu5_3 needs backward computation.
I0611 14:11:46.045485 21677 net.cpp:226] conv5_3 needs backward computation.
I0611 14:11:46.045487 21677 net.cpp:226] relu5_2 needs backward computation.
I0611 14:11:46.045490 21677 net.cpp:226] conv5_2 needs backward computation.
I0611 14:11:46.045505 21677 net.cpp:226] relu5_1 needs backward computation.
I0611 14:11:46.045511 21677 net.cpp:226] conv5_1 needs backward computation.
I0611 14:11:46.045516 21677 net.cpp:226] pool4 needs backward computation.
I0611 14:11:46.045521 21677 net.cpp:226] relu4_3 needs backward computation.
I0611 14:11:46.045523 21677 net.cpp:226] conv4_3 needs backward computation.
I0611 14:11:46.045527 21677 net.cpp:226] relu4_2 needs backward computation.
I0611 14:11:46.045532 21677 net.cpp:226] conv4_2 needs backward computation.
I0611 14:11:46.045537 21677 net.cpp:226] relu4_1 needs backward computation.
I0611 14:11:46.045542 21677 net.cpp:226] conv4_1 needs backward computation.
I0611 14:11:46.045544 21677 net.cpp:226] pool3 needs backward computation.
I0611 14:11:46.045549 21677 net.cpp:226] relu3_3 needs backward computation.
I0611 14:11:46.045552 21677 net.cpp:226] conv3_3 needs backward computation.
I0611 14:11:46.045557 21677 net.cpp:226] relu3_2 needs backward computation.
I0611 14:11:46.045560 21677 net.cpp:226] conv3_2 needs backward computation.
I0611 14:11:46.045564 21677 net.cpp:226] relu3_1 needs backward computation.
I0611 14:11:46.045567 21677 net.cpp:226] conv3_1 needs backward computation.
I0611 14:11:46.045572 21677 net.cpp:228] pool2 does not need backward computation.
I0611 14:11:46.045578 21677 net.cpp:228] relu2_2 does not need backward computation.
I0611 14:11:46.045581 21677 net.cpp:228] conv2_2 does not need backward computation.
I0611 14:11:46.045584 21677 net.cpp:228] relu2_1 does not need backward computation.
I0611 14:11:46.045588 21677 net.cpp:228] conv2_1 does not need backward computation.
I0611 14:11:46.045591 21677 net.cpp:228] pool1 does not need backward computation.
I0611 14:11:46.045596 21677 net.cpp:228] relu1_2 does not need backward computation.
I0611 14:11:46.045600 21677 net.cpp:228] conv1_2 does not need backward computation.
I0611 14:11:46.045604 21677 net.cpp:228] relu1_1 does not need backward computation.
I0611 14:11:46.045608 21677 net.cpp:228] conv1_1 does not need backward computation.
I0611 14:11:46.045614 21677 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0611 14:11:46.045619 21677 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0611 14:11:46.045624 21677 net.cpp:228] data_input-data_0_split does not need backward computation.
I0611 14:11:46.045631 21677 net.cpp:228] input-data does not need backward computation.
I0611 14:11:46.045636 21677 net.cpp:270] This network produces output loss_bbox
I0611 14:11:46.045642 21677 net.cpp:270] This network produces output loss_cls
I0611 14:11:46.045647 21677 net.cpp:270] This network produces output loss_mask
I0611 14:11:46.045652 21677 net.cpp:270] This network produces output rpn_cls_loss
I0611 14:11:46.045656 21677 net.cpp:270] This network produces output rpn_loss_bbox
I0611 14:11:46.045725 21677 net.cpp:283] Network initialization done.
I0611 14:11:46.046079 21677 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0611 14:11:48.710573 21677 net.cpp:816] Ignoring source layer pool5
I0611 14:11:48.785480 21677 net.cpp:816] Ignoring source layer drop6
I0611 14:11:48.796533 21677 net.cpp:816] Ignoring source layer drop7
I0611 14:11:48.796553 21677 net.cpp:816] Ignoring source layer fc8
I0611 14:11:48.796556 21677 net.cpp:816] Ignoring source layer prob
Solving...
[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
18529
(48, 10)
[1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
10901
(48, 10)
I0611 14:11:50.052565 21677 solver.cpp:229] Iteration 0, loss = 8.82055
I0611 14:11:50.052592 21677 solver.cpp:245]     Train net output #0: loss_bbox = 0.0930647 (* 2 = 0.186129 loss)
I0611 14:11:50.052598 21677 solver.cpp:245]     Train net output #1: loss_cls = 0.569136 (* 3 = 1.70741 loss)
I0611 14:11:50.052603 21677 solver.cpp:245]     Train net output #2: loss_mask = 2.08154 (* 3 = 6.24461 loss)
I0611 14:11:50.052608 21677 solver.cpp:245]     Train net output #3: rpn_cls_loss = 0.73882 (* 1 = 0.73882 loss)
I0611 14:11:50.052611 21677 solver.cpp:245]     Train net output #4: rpn_loss_bbox = 0.0189577 (* 1 = 0.0189577 loss)
I0611 14:11:50.052626 21677 sgd_solver.cpp:106] Iteration 0, lr = 0.001
[1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
15508
(48, 10)
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
5831
(48, 10)
[1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
28533
(48, 10)
