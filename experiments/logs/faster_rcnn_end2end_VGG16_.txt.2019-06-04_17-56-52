+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-04_17-56-52
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-04_17-56-52
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
29646 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 29646 -> 29646
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0604 17:56:58.650521 27908 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0604 17:56:58.650552 27908 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0604 17:56:58.652189 27908 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "query_conv_reshape_ch"
  type: "Reshape"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv_reshape_ch"
  reshape_param {
    shape {
      dim: 1
      dim: 512
      dim: -1
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape_ch"
  type: "Reshape"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv_reshape_ch"
  reshape_param {
    shape {
      dim: 1
      dim: 512
      dim: -1
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape_ch"
  type: "Reshape"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv_reshape_ch"
  reshape_param {
    shape {
      dim: 1
      dim: 512
      dim: -1
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm_ch"
  type: "Permute"
  bottom: "query_conv_reshape_ch"
  top: "query_conv_reshape_perm_ch"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "key_conv_reshape_perm_ch"
  type: "Permute"
  bottom: "key_conv_reshape_ch"
  top: "key_conv_reshape_perm_ch"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "energy_ch"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm_ch"
  bottom: "key_conv_reshape_perm_ch"
  top: "energy_ch"
}
layer {
  name: "energy_ch_perm"
  type: "Permute"
  bottom: "energy_ch"
  top: "energy_ch_perm"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "energy_ch_pool"
  type: "Pooling"
  bottom: "energy_ch_perm"
  top: "energy_ch_pool"
  pooling_param {
    pool: MAX
    kernel_h: 1
    kernel_w: 512
    stride_h: 1
    stride_w: 512
  }
}
layer {
  name: "energy_ch_reperm"
  type: "Permute"
  bottom: "energy_ch_pool"
  top: "energy_ch_reperm"
  permute_param {
    order: 0
    order: 2
    order: 1
    order: 3
  }
}
layer {
  name: "energy_ch_max"
  type: "Tile"
  bottom: "energy_ch_reperm"
  top: "energy_ch_max"
  tile_param {
    axis: 3
    tiles: 512
  }
}
layer {
  name: "energy_ch_minus"
  type: "Power"
  bottom: "energy_ch"
  top: "energy_ch_minus"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "energy_new"
  type: "Eltwise"
  bottom: "energy_ch_max"
  bottom: "energy_ch_minus"
  top: "energy_new"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "attention_ch"
  type: "Softmax"
  bottom: "energy_new"
  top: "attention_ch"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_ch_perm"
  type: "Permute"
  bottom: "value_conv_reshape_ch"
  top: "value_conv_reshape_ch_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_ch_perm"
  type: "Permute"
  bottom: "attention_ch"
  top: "attention_ch_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out_ch"
  type: "MatrixMultiplication"
  bottom: "attention_ch_perm"
  bottom: "value_conv_reshape_ch_perm"
  top: "out_ch"
}
layer {
  name: "out_ch_reshape"
  type: "Reshape"
  bottom: "out_ch"
  top: "out_ch_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_ch_reshape_scale"
  type: "Scale"
  bottom: "out_ch_reshape"
  top: "out_ch_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_ch_x"
  type: "Eltwise"
  bottom: "out_ch_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_ch_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "out_conv_ch_x"
  type: "Convolution"
  bottom: "out_ch_x"
  top: "out_conv_ch_x"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out_conv_x"
  type: "Convolution"
  bottom: "out_x"
  top: "out_conv_x"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out_x_sum"
  type: "Eltwise"
  bottom: "out_conv_x"
  bottom: "out_conv_ch_x"
  top: "out_x_sum"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x_sum"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_mask"
  type: "SoftmaxWithLoss"
  bottom: "mask_score"
  bottom: "mask_targets"
  top: "loss_mask"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
I0604 17:56:58.652516 27908 layer_factory.hpp:77] Creating layer input-data
I0604 17:56:58.698293 27908 net.cpp:106] Creating Layer input-data
I0604 17:56:58.698310 27908 net.cpp:411] input-data -> data
I0604 17:56:58.698319 27908 net.cpp:411] input-data -> im_info
I0604 17:56:58.698324 27908 net.cpp:411] input-data -> gt_boxes
I0604 17:56:58.698328 27908 net.cpp:411] input-data -> seg_mask_inds
I0604 17:56:58.698331 27908 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0604 17:56:58.709376 27908 net.cpp:150] Setting up input-data
I0604 17:56:58.709393 27908 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0604 17:56:58.709399 27908 net.cpp:157] Top shape: 1 3 (3)
I0604 17:56:58.709403 27908 net.cpp:157] Top shape: 1 4 (4)
I0604 17:56:58.709406 27908 net.cpp:157] Top shape: 1 2 (2)
I0604 17:56:58.709426 27908 net.cpp:157] Top shape: 1 1 (1)
I0604 17:56:58.709429 27908 net.cpp:165] Memory required for data: 7200040
I0604 17:56:58.709435 27908 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0604 17:56:58.709448 27908 net.cpp:106] Creating Layer data_input-data_0_split
I0604 17:56:58.709452 27908 net.cpp:454] data_input-data_0_split <- data
I0604 17:56:58.709458 27908 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0604 17:56:58.709465 27908 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0604 17:56:58.709489 27908 net.cpp:150] Setting up data_input-data_0_split
I0604 17:56:58.709496 27908 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0604 17:56:58.709497 27908 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0604 17:56:58.709499 27908 net.cpp:165] Memory required for data: 21600040
I0604 17:56:58.709502 27908 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0604 17:56:58.709507 27908 net.cpp:106] Creating Layer im_info_input-data_1_split
I0604 17:56:58.709511 27908 net.cpp:454] im_info_input-data_1_split <- im_info
I0604 17:56:58.709516 27908 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0604 17:56:58.709519 27908 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0604 17:56:58.709527 27908 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0604 17:56:58.709554 27908 net.cpp:150] Setting up im_info_input-data_1_split
I0604 17:56:58.709558 27908 net.cpp:157] Top shape: 1 3 (3)
I0604 17:56:58.709561 27908 net.cpp:157] Top shape: 1 3 (3)
I0604 17:56:58.709563 27908 net.cpp:157] Top shape: 1 3 (3)
I0604 17:56:58.709576 27908 net.cpp:165] Memory required for data: 21600076
I0604 17:56:58.709579 27908 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0604 17:56:58.709583 27908 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0604 17:56:58.709595 27908 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0604 17:56:58.709601 27908 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0604 17:56:58.709605 27908 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0604 17:56:58.709623 27908 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0604 17:56:58.709626 27908 net.cpp:157] Top shape: 1 4 (4)
I0604 17:56:58.709630 27908 net.cpp:157] Top shape: 1 4 (4)
I0604 17:56:58.709632 27908 net.cpp:165] Memory required for data: 21600108
I0604 17:56:58.709635 27908 layer_factory.hpp:77] Creating layer conv1_1
I0604 17:56:58.709645 27908 net.cpp:106] Creating Layer conv1_1
I0604 17:56:58.709648 27908 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0604 17:56:58.709653 27908 net.cpp:411] conv1_1 -> conv1_1
I0604 17:56:59.010360 27908 net.cpp:150] Setting up conv1_1
I0604 17:56:59.010392 27908 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0604 17:56:59.010396 27908 net.cpp:165] Memory required for data: 175200108
I0604 17:56:59.010411 27908 layer_factory.hpp:77] Creating layer relu1_1
I0604 17:56:59.010421 27908 net.cpp:106] Creating Layer relu1_1
I0604 17:56:59.010424 27908 net.cpp:454] relu1_1 <- conv1_1
I0604 17:56:59.010432 27908 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0604 17:56:59.010578 27908 net.cpp:150] Setting up relu1_1
I0604 17:56:59.010587 27908 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0604 17:56:59.010591 27908 net.cpp:165] Memory required for data: 328800108
I0604 17:56:59.010593 27908 layer_factory.hpp:77] Creating layer conv1_2
I0604 17:56:59.010601 27908 net.cpp:106] Creating Layer conv1_2
I0604 17:56:59.010605 27908 net.cpp:454] conv1_2 <- conv1_1
I0604 17:56:59.010609 27908 net.cpp:411] conv1_2 -> conv1_2
I0604 17:56:59.012944 27908 net.cpp:150] Setting up conv1_2
I0604 17:56:59.012967 27908 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0604 17:56:59.012970 27908 net.cpp:165] Memory required for data: 482400108
I0604 17:56:59.012979 27908 layer_factory.hpp:77] Creating layer relu1_2
I0604 17:56:59.012987 27908 net.cpp:106] Creating Layer relu1_2
I0604 17:56:59.012991 27908 net.cpp:454] relu1_2 <- conv1_2
I0604 17:56:59.012995 27908 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0604 17:56:59.013123 27908 net.cpp:150] Setting up relu1_2
I0604 17:56:59.013128 27908 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0604 17:56:59.013140 27908 net.cpp:165] Memory required for data: 636000108
I0604 17:56:59.013144 27908 layer_factory.hpp:77] Creating layer pool1
I0604 17:56:59.013150 27908 net.cpp:106] Creating Layer pool1
I0604 17:56:59.013152 27908 net.cpp:454] pool1 <- conv1_2
I0604 17:56:59.013156 27908 net.cpp:411] pool1 -> pool1
I0604 17:56:59.013202 27908 net.cpp:150] Setting up pool1
I0604 17:56:59.013206 27908 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0604 17:56:59.013208 27908 net.cpp:165] Memory required for data: 674400108
I0604 17:56:59.013221 27908 layer_factory.hpp:77] Creating layer conv2_1
I0604 17:56:59.013226 27908 net.cpp:106] Creating Layer conv2_1
I0604 17:56:59.013231 27908 net.cpp:454] conv2_1 <- pool1
I0604 17:56:59.013234 27908 net.cpp:411] conv2_1 -> conv2_1
I0604 17:56:59.015149 27908 net.cpp:150] Setting up conv2_1
I0604 17:56:59.015170 27908 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0604 17:56:59.015172 27908 net.cpp:165] Memory required for data: 751200108
I0604 17:56:59.015182 27908 layer_factory.hpp:77] Creating layer relu2_1
I0604 17:56:59.015187 27908 net.cpp:106] Creating Layer relu2_1
I0604 17:56:59.015189 27908 net.cpp:454] relu2_1 <- conv2_1
I0604 17:56:59.015195 27908 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0604 17:56:59.015671 27908 net.cpp:150] Setting up relu2_1
I0604 17:56:59.015678 27908 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0604 17:56:59.015691 27908 net.cpp:165] Memory required for data: 828000108
I0604 17:56:59.015693 27908 layer_factory.hpp:77] Creating layer conv2_2
I0604 17:56:59.015700 27908 net.cpp:106] Creating Layer conv2_2
I0604 17:56:59.015713 27908 net.cpp:454] conv2_2 <- conv2_1
I0604 17:56:59.015719 27908 net.cpp:411] conv2_2 -> conv2_2
I0604 17:56:59.017015 27908 net.cpp:150] Setting up conv2_2
I0604 17:56:59.017024 27908 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0604 17:56:59.017037 27908 net.cpp:165] Memory required for data: 904800108
I0604 17:56:59.017041 27908 layer_factory.hpp:77] Creating layer relu2_2
I0604 17:56:59.017046 27908 net.cpp:106] Creating Layer relu2_2
I0604 17:56:59.017060 27908 net.cpp:454] relu2_2 <- conv2_2
I0604 17:56:59.017063 27908 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0604 17:56:59.017185 27908 net.cpp:150] Setting up relu2_2
I0604 17:56:59.017191 27908 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0604 17:56:59.017204 27908 net.cpp:165] Memory required for data: 981600108
I0604 17:56:59.017206 27908 layer_factory.hpp:77] Creating layer pool2
I0604 17:56:59.017212 27908 net.cpp:106] Creating Layer pool2
I0604 17:56:59.017215 27908 net.cpp:454] pool2 <- conv2_2
I0604 17:56:59.017220 27908 net.cpp:411] pool2 -> pool2
I0604 17:56:59.017248 27908 net.cpp:150] Setting up pool2
I0604 17:56:59.017253 27908 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0604 17:56:59.017256 27908 net.cpp:165] Memory required for data: 1000800108
I0604 17:56:59.017257 27908 layer_factory.hpp:77] Creating layer conv3_1
I0604 17:56:59.017266 27908 net.cpp:106] Creating Layer conv3_1
I0604 17:56:59.017269 27908 net.cpp:454] conv3_1 <- pool2
I0604 17:56:59.017274 27908 net.cpp:411] conv3_1 -> conv3_1
I0604 17:56:59.019136 27908 net.cpp:150] Setting up conv3_1
I0604 17:56:59.019147 27908 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0604 17:56:59.019150 27908 net.cpp:165] Memory required for data: 1039200108
I0604 17:56:59.019168 27908 layer_factory.hpp:77] Creating layer relu3_1
I0604 17:56:59.019173 27908 net.cpp:106] Creating Layer relu3_1
I0604 17:56:59.019177 27908 net.cpp:454] relu3_1 <- conv3_1
I0604 17:56:59.019181 27908 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0604 17:56:59.019309 27908 net.cpp:150] Setting up relu3_1
I0604 17:56:59.019315 27908 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0604 17:56:59.019327 27908 net.cpp:165] Memory required for data: 1077600108
I0604 17:56:59.019330 27908 layer_factory.hpp:77] Creating layer conv3_2
I0604 17:56:59.019338 27908 net.cpp:106] Creating Layer conv3_2
I0604 17:56:59.019341 27908 net.cpp:454] conv3_2 <- conv3_1
I0604 17:56:59.019345 27908 net.cpp:411] conv3_2 -> conv3_2
I0604 17:56:59.021456 27908 net.cpp:150] Setting up conv3_2
I0604 17:56:59.021476 27908 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0604 17:56:59.021478 27908 net.cpp:165] Memory required for data: 1116000108
I0604 17:56:59.021483 27908 layer_factory.hpp:77] Creating layer relu3_2
I0604 17:56:59.021497 27908 net.cpp:106] Creating Layer relu3_2
I0604 17:56:59.021500 27908 net.cpp:454] relu3_2 <- conv3_2
I0604 17:56:59.021504 27908 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0604 17:56:59.021641 27908 net.cpp:150] Setting up relu3_2
I0604 17:56:59.021647 27908 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0604 17:56:59.021659 27908 net.cpp:165] Memory required for data: 1154400108
I0604 17:56:59.021661 27908 layer_factory.hpp:77] Creating layer conv3_3
I0604 17:56:59.021669 27908 net.cpp:106] Creating Layer conv3_3
I0604 17:56:59.021672 27908 net.cpp:454] conv3_3 <- conv3_2
I0604 17:56:59.021677 27908 net.cpp:411] conv3_3 -> conv3_3
I0604 17:56:59.023645 27908 net.cpp:150] Setting up conv3_3
I0604 17:56:59.023665 27908 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0604 17:56:59.023669 27908 net.cpp:165] Memory required for data: 1192800108
I0604 17:56:59.023674 27908 layer_factory.hpp:77] Creating layer relu3_3
I0604 17:56:59.023680 27908 net.cpp:106] Creating Layer relu3_3
I0604 17:56:59.023684 27908 net.cpp:454] relu3_3 <- conv3_3
I0604 17:56:59.023687 27908 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0604 17:56:59.023819 27908 net.cpp:150] Setting up relu3_3
I0604 17:56:59.023826 27908 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0604 17:56:59.023828 27908 net.cpp:165] Memory required for data: 1231200108
I0604 17:56:59.023830 27908 layer_factory.hpp:77] Creating layer pool3
I0604 17:56:59.023847 27908 net.cpp:106] Creating Layer pool3
I0604 17:56:59.023850 27908 net.cpp:454] pool3 <- conv3_3
I0604 17:56:59.023854 27908 net.cpp:411] pool3 -> pool3
I0604 17:56:59.023895 27908 net.cpp:150] Setting up pool3
I0604 17:56:59.023898 27908 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0604 17:56:59.023900 27908 net.cpp:165] Memory required for data: 1240800108
I0604 17:56:59.023902 27908 layer_factory.hpp:77] Creating layer conv4_1
I0604 17:56:59.023919 27908 net.cpp:106] Creating Layer conv4_1
I0604 17:56:59.023923 27908 net.cpp:454] conv4_1 <- pool3
I0604 17:56:59.023928 27908 net.cpp:411] conv4_1 -> conv4_1
I0604 17:56:59.028046 27908 net.cpp:150] Setting up conv4_1
I0604 17:56:59.028065 27908 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0604 17:56:59.028069 27908 net.cpp:165] Memory required for data: 1260000108
I0604 17:56:59.028087 27908 layer_factory.hpp:77] Creating layer relu4_1
I0604 17:56:59.028096 27908 net.cpp:106] Creating Layer relu4_1
I0604 17:56:59.028101 27908 net.cpp:454] relu4_1 <- conv4_1
I0604 17:56:59.028115 27908 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0604 17:56:59.028255 27908 net.cpp:150] Setting up relu4_1
I0604 17:56:59.028261 27908 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0604 17:56:59.028264 27908 net.cpp:165] Memory required for data: 1279200108
I0604 17:56:59.028277 27908 layer_factory.hpp:77] Creating layer conv4_2
I0604 17:56:59.028286 27908 net.cpp:106] Creating Layer conv4_2
I0604 17:56:59.028290 27908 net.cpp:454] conv4_2 <- conv4_1
I0604 17:56:59.028303 27908 net.cpp:411] conv4_2 -> conv4_2
I0604 17:56:59.033255 27908 net.cpp:150] Setting up conv4_2
I0604 17:56:59.033285 27908 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0604 17:56:59.033288 27908 net.cpp:165] Memory required for data: 1298400108
I0604 17:56:59.033310 27908 layer_factory.hpp:77] Creating layer relu4_2
I0604 17:56:59.033319 27908 net.cpp:106] Creating Layer relu4_2
I0604 17:56:59.033324 27908 net.cpp:454] relu4_2 <- conv4_2
I0604 17:56:59.033329 27908 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0604 17:56:59.033833 27908 net.cpp:150] Setting up relu4_2
I0604 17:56:59.033840 27908 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0604 17:56:59.033852 27908 net.cpp:165] Memory required for data: 1317600108
I0604 17:56:59.033855 27908 layer_factory.hpp:77] Creating layer conv4_3
I0604 17:56:59.033864 27908 net.cpp:106] Creating Layer conv4_3
I0604 17:56:59.033875 27908 net.cpp:454] conv4_3 <- conv4_2
I0604 17:56:59.033880 27908 net.cpp:411] conv4_3 -> conv4_3
I0604 17:56:59.038657 27908 net.cpp:150] Setting up conv4_3
I0604 17:56:59.038686 27908 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0604 17:56:59.038689 27908 net.cpp:165] Memory required for data: 1336800108
I0604 17:56:59.038697 27908 layer_factory.hpp:77] Creating layer relu4_3
I0604 17:56:59.038715 27908 net.cpp:106] Creating Layer relu4_3
I0604 17:56:59.038720 27908 net.cpp:454] relu4_3 <- conv4_3
I0604 17:56:59.038725 27908 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0604 17:56:59.038873 27908 net.cpp:150] Setting up relu4_3
I0604 17:56:59.038878 27908 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0604 17:56:59.038892 27908 net.cpp:165] Memory required for data: 1356000108
I0604 17:56:59.038893 27908 layer_factory.hpp:77] Creating layer pool4
I0604 17:56:59.038909 27908 net.cpp:106] Creating Layer pool4
I0604 17:56:59.038913 27908 net.cpp:454] pool4 <- conv4_3
I0604 17:56:59.038918 27908 net.cpp:411] pool4 -> pool4
I0604 17:56:59.038966 27908 net.cpp:150] Setting up pool4
I0604 17:56:59.038970 27908 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0604 17:56:59.038972 27908 net.cpp:165] Memory required for data: 1360903020
I0604 17:56:59.038983 27908 layer_factory.hpp:77] Creating layer conv5_1
I0604 17:56:59.038990 27908 net.cpp:106] Creating Layer conv5_1
I0604 17:56:59.039003 27908 net.cpp:454] conv5_1 <- pool4
I0604 17:56:59.039008 27908 net.cpp:411] conv5_1 -> conv5_1
I0604 17:56:59.043704 27908 net.cpp:150] Setting up conv5_1
I0604 17:56:59.043731 27908 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0604 17:56:59.043735 27908 net.cpp:165] Memory required for data: 1365805932
I0604 17:56:59.043751 27908 layer_factory.hpp:77] Creating layer relu5_1
I0604 17:56:59.043761 27908 net.cpp:106] Creating Layer relu5_1
I0604 17:56:59.043764 27908 net.cpp:454] relu5_1 <- conv5_1
I0604 17:56:59.043769 27908 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0604 17:56:59.043896 27908 net.cpp:150] Setting up relu5_1
I0604 17:56:59.043915 27908 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0604 17:56:59.043917 27908 net.cpp:165] Memory required for data: 1370708844
I0604 17:56:59.043920 27908 layer_factory.hpp:77] Creating layer conv5_2
I0604 17:56:59.043926 27908 net.cpp:106] Creating Layer conv5_2
I0604 17:56:59.043929 27908 net.cpp:454] conv5_2 <- conv5_1
I0604 17:56:59.043933 27908 net.cpp:411] conv5_2 -> conv5_2
I0604 17:56:59.048586 27908 net.cpp:150] Setting up conv5_2
I0604 17:56:59.048619 27908 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0604 17:56:59.048621 27908 net.cpp:165] Memory required for data: 1375611756
I0604 17:56:59.048629 27908 layer_factory.hpp:77] Creating layer relu5_2
I0604 17:56:59.048640 27908 net.cpp:106] Creating Layer relu5_2
I0604 17:56:59.048655 27908 net.cpp:454] relu5_2 <- conv5_2
I0604 17:56:59.048660 27908 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0604 17:56:59.048802 27908 net.cpp:150] Setting up relu5_2
I0604 17:56:59.048810 27908 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0604 17:56:59.048822 27908 net.cpp:165] Memory required for data: 1380514668
I0604 17:56:59.048825 27908 layer_factory.hpp:77] Creating layer conv5_3
I0604 17:56:59.048847 27908 net.cpp:106] Creating Layer conv5_3
I0604 17:56:59.048851 27908 net.cpp:454] conv5_3 <- conv5_2
I0604 17:56:59.048856 27908 net.cpp:411] conv5_3 -> conv5_3
I0604 17:56:59.053315 27908 net.cpp:150] Setting up conv5_3
I0604 17:56:59.053345 27908 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0604 17:56:59.053349 27908 net.cpp:165] Memory required for data: 1385417580
I0604 17:56:59.053357 27908 layer_factory.hpp:77] Creating layer relu5_3
I0604 17:56:59.053375 27908 net.cpp:106] Creating Layer relu5_3
I0604 17:56:59.053380 27908 net.cpp:454] relu5_3 <- conv5_3
I0604 17:56:59.053386 27908 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0604 17:56:59.053558 27908 net.cpp:150] Setting up relu5_3
I0604 17:56:59.053565 27908 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0604 17:56:59.053577 27908 net.cpp:165] Memory required for data: 1390320492
I0604 17:56:59.053580 27908 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0604 17:56:59.053586 27908 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0604 17:56:59.053598 27908 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0604 17:56:59.053602 27908 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0604 17:56:59.053618 27908 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0604 17:56:59.053623 27908 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0604 17:56:59.053673 27908 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0604 17:56:59.053689 27908 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0604 17:56:59.053691 27908 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0604 17:56:59.053694 27908 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0604 17:56:59.053695 27908 net.cpp:165] Memory required for data: 1405029228
I0604 17:56:59.053697 27908 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0604 17:56:59.053707 27908 net.cpp:106] Creating Layer rpn_conv/3x3
I0604 17:56:59.053711 27908 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0604 17:56:59.053717 27908 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0604 17:56:59.109167 27908 net.cpp:150] Setting up rpn_conv/3x3
I0604 17:56:59.109187 27908 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0604 17:56:59.109191 27908 net.cpp:165] Memory required for data: 1409932140
I0604 17:56:59.109201 27908 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0604 17:56:59.109222 27908 net.cpp:106] Creating Layer rpn_relu/3x3
I0604 17:56:59.109230 27908 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0604 17:56:59.109237 27908 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0604 17:56:59.109370 27908 net.cpp:150] Setting up rpn_relu/3x3
I0604 17:56:59.109380 27908 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0604 17:56:59.109383 27908 net.cpp:165] Memory required for data: 1414835052
I0604 17:56:59.109388 27908 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0604 17:56:59.109406 27908 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0604 17:56:59.109429 27908 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0604 17:56:59.109437 27908 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0604 17:56:59.109445 27908 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0604 17:56:59.109496 27908 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0604 17:56:59.109504 27908 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0604 17:56:59.109509 27908 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0604 17:56:59.109524 27908 net.cpp:165] Memory required for data: 1424640876
I0604 17:56:59.109527 27908 layer_factory.hpp:77] Creating layer rpn_cls_score
I0604 17:56:59.109540 27908 net.cpp:106] Creating Layer rpn_cls_score
I0604 17:56:59.109545 27908 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0604 17:56:59.109552 27908 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0604 17:56:59.111395 27908 net.cpp:150] Setting up rpn_cls_score
I0604 17:56:59.111407 27908 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0604 17:56:59.111410 27908 net.cpp:165] Memory required for data: 1424928156
I0604 17:56:59.111418 27908 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0604 17:56:59.111426 27908 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0604 17:56:59.111441 27908 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0604 17:56:59.111451 27908 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0604 17:56:59.111459 27908 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0604 17:56:59.111524 27908 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0604 17:56:59.111531 27908 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0604 17:56:59.111534 27908 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0604 17:56:59.111537 27908 net.cpp:165] Memory required for data: 1425502716
I0604 17:56:59.111552 27908 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0604 17:56:59.111562 27908 net.cpp:106] Creating Layer rpn_bbox_pred
I0604 17:56:59.111568 27908 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0604 17:56:59.111577 27908 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0604 17:56:59.113086 27908 net.cpp:150] Setting up rpn_bbox_pred
I0604 17:56:59.113097 27908 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0604 17:56:59.113101 27908 net.cpp:165] Memory required for data: 1426077276
I0604 17:56:59.113119 27908 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0604 17:56:59.113126 27908 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0604 17:56:59.113131 27908 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0604 17:56:59.113140 27908 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0604 17:56:59.113149 27908 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0604 17:56:59.113190 27908 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0604 17:56:59.113195 27908 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0604 17:56:59.113199 27908 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0604 17:56:59.113202 27908 net.cpp:165] Memory required for data: 1427226396
I0604 17:56:59.113217 27908 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0604 17:56:59.113231 27908 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0604 17:56:59.113235 27908 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0604 17:56:59.113245 27908 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0604 17:56:59.113277 27908 net.cpp:150] Setting up rpn_cls_score_reshape
I0604 17:56:59.113283 27908 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0604 17:56:59.113286 27908 net.cpp:165] Memory required for data: 1427513676
I0604 17:56:59.113291 27908 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0604 17:56:59.113296 27908 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0604 17:56:59.113301 27908 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0604 17:56:59.113306 27908 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0604 17:56:59.113313 27908 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0604 17:56:59.113340 27908 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0604 17:56:59.113345 27908 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0604 17:56:59.113349 27908 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0604 17:56:59.113353 27908 net.cpp:165] Memory required for data: 1428088236
I0604 17:56:59.113356 27908 layer_factory.hpp:77] Creating layer rpn-data
I0604 17:56:59.113711 27908 net.cpp:106] Creating Layer rpn-data
I0604 17:56:59.113719 27908 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0604 17:56:59.113726 27908 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0604 17:56:59.113730 27908 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0604 17:56:59.113735 27908 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0604 17:56:59.113754 27908 net.cpp:411] rpn-data -> rpn_labels
I0604 17:56:59.113764 27908 net.cpp:411] rpn-data -> rpn_bbox_targets
I0604 17:56:59.113770 27908 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0604 17:56:59.113787 27908 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0604 17:56:59.114668 27908 net.cpp:150] Setting up rpn-data
I0604 17:56:59.114678 27908 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0604 17:56:59.114683 27908 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0604 17:56:59.114697 27908 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0604 17:56:59.114703 27908 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0604 17:56:59.114706 27908 net.cpp:165] Memory required for data: 1429955556
I0604 17:56:59.114711 27908 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0604 17:56:59.114717 27908 net.cpp:106] Creating Layer rpn_loss_cls
I0604 17:56:59.114723 27908 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0604 17:56:59.114738 27908 net.cpp:454] rpn_loss_cls <- rpn_labels
I0604 17:56:59.114744 27908 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0604 17:56:59.114768 27908 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0604 17:56:59.115392 27908 net.cpp:150] Setting up rpn_loss_cls
I0604 17:56:59.115401 27908 net.cpp:157] Top shape: (1)
I0604 17:56:59.115404 27908 net.cpp:160]     with loss weight 1
I0604 17:56:59.115417 27908 net.cpp:165] Memory required for data: 1429955560
I0604 17:56:59.115420 27908 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0604 17:56:59.115429 27908 net.cpp:106] Creating Layer rpn_loss_bbox
I0604 17:56:59.115434 27908 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0604 17:56:59.115439 27908 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0604 17:56:59.115443 27908 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0604 17:56:59.115449 27908 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0604 17:56:59.115454 27908 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0604 17:56:59.116621 27908 net.cpp:150] Setting up rpn_loss_bbox
I0604 17:56:59.116631 27908 net.cpp:157] Top shape: (1)
I0604 17:56:59.116633 27908 net.cpp:160]     with loss weight 1
I0604 17:56:59.116641 27908 net.cpp:165] Memory required for data: 1429955564
I0604 17:56:59.116644 27908 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0604 17:56:59.116654 27908 net.cpp:106] Creating Layer rpn_cls_prob
I0604 17:56:59.116659 27908 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0604 17:56:59.116665 27908 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0604 17:56:59.116822 27908 net.cpp:150] Setting up rpn_cls_prob
I0604 17:56:59.116829 27908 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0604 17:56:59.116833 27908 net.cpp:165] Memory required for data: 1430242844
I0604 17:56:59.116837 27908 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0604 17:56:59.116844 27908 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0604 17:56:59.116849 27908 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0604 17:56:59.116855 27908 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0604 17:56:59.116880 27908 net.cpp:150] Setting up rpn_cls_prob_reshape
I0604 17:56:59.116885 27908 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0604 17:56:59.116888 27908 net.cpp:165] Memory required for data: 1430530124
I0604 17:56:59.116892 27908 layer_factory.hpp:77] Creating layer proposal
I0604 17:56:59.117354 27908 net.cpp:106] Creating Layer proposal
I0604 17:56:59.117362 27908 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0604 17:56:59.117368 27908 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0604 17:56:59.117373 27908 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0604 17:56:59.117379 27908 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0604 17:56:59.118249 27908 net.cpp:150] Setting up proposal
I0604 17:56:59.118259 27908 net.cpp:157] Top shape: 1 5 (5)
I0604 17:56:59.118263 27908 net.cpp:165] Memory required for data: 1430530144
I0604 17:56:59.118276 27908 layer_factory.hpp:77] Creating layer roi-data
I0604 17:56:59.118475 27908 net.cpp:106] Creating Layer roi-data
I0604 17:56:59.118484 27908 net.cpp:454] roi-data <- rpn_rois
I0604 17:56:59.118489 27908 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0604 17:56:59.118505 27908 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0604 17:56:59.118510 27908 net.cpp:454] roi-data <- seg_mask_inds
I0604 17:56:59.118515 27908 net.cpp:454] roi-data <- flipped
I0604 17:56:59.118521 27908 net.cpp:411] roi-data -> rois
I0604 17:56:59.118531 27908 net.cpp:411] roi-data -> labels
I0604 17:56:59.118540 27908 net.cpp:411] roi-data -> bbox_targets
I0604 17:56:59.118554 27908 net.cpp:411] roi-data -> bbox_inside_weights
I0604 17:56:59.118571 27908 net.cpp:411] roi-data -> bbox_outside_weights
I0604 17:56:59.118579 27908 net.cpp:411] roi-data -> mask_targets
I0604 17:56:59.118587 27908 net.cpp:411] roi-data -> rois_pos
I0604 17:56:59.118875 27908 net.cpp:150] Setting up roi-data
I0604 17:56:59.118883 27908 net.cpp:157] Top shape: 1 5 (5)
I0604 17:56:59.118888 27908 net.cpp:157] Top shape: 1 1 (1)
I0604 17:56:59.118892 27908 net.cpp:157] Top shape: 1 8 (8)
I0604 17:56:59.118897 27908 net.cpp:157] Top shape: 1 8 (8)
I0604 17:56:59.118902 27908 net.cpp:157] Top shape: 1 8 (8)
I0604 17:56:59.118906 27908 net.cpp:157] Top shape: 1 244 244 (59536)
I0604 17:56:59.118911 27908 net.cpp:157] Top shape: 1 5 (5)
I0604 17:56:59.118914 27908 net.cpp:165] Memory required for data: 1430768428
I0604 17:56:59.118919 27908 layer_factory.hpp:77] Creating layer roi_pool5
I0604 17:56:59.118932 27908 net.cpp:106] Creating Layer roi_pool5
I0604 17:56:59.118937 27908 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0604 17:56:59.118942 27908 net.cpp:454] roi_pool5 <- rois
I0604 17:56:59.118948 27908 net.cpp:411] roi_pool5 -> pool5
I0604 17:56:59.118957 27908 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0604 17:56:59.119027 27908 net.cpp:150] Setting up roi_pool5
I0604 17:56:59.119035 27908 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0604 17:56:59.119037 27908 net.cpp:165] Memory required for data: 1430868780
I0604 17:56:59.119042 27908 layer_factory.hpp:77] Creating layer fc6
I0604 17:56:59.119050 27908 net.cpp:106] Creating Layer fc6
I0604 17:56:59.119055 27908 net.cpp:454] fc6 <- pool5
I0604 17:56:59.119060 27908 net.cpp:411] fc6 -> fc6
I0604 17:56:59.271204 27908 net.cpp:150] Setting up fc6
I0604 17:56:59.271229 27908 net.cpp:157] Top shape: 1 4096 (4096)
I0604 17:56:59.271234 27908 net.cpp:165] Memory required for data: 1430885164
I0604 17:56:59.271265 27908 layer_factory.hpp:77] Creating layer relu6
I0604 17:56:59.271281 27908 net.cpp:106] Creating Layer relu6
I0604 17:56:59.271288 27908 net.cpp:454] relu6 <- fc6
I0604 17:56:59.271296 27908 net.cpp:397] relu6 -> fc6 (in-place)
I0604 17:56:59.271509 27908 net.cpp:150] Setting up relu6
I0604 17:56:59.271519 27908 net.cpp:157] Top shape: 1 4096 (4096)
I0604 17:56:59.271523 27908 net.cpp:165] Memory required for data: 1430901548
I0604 17:56:59.271528 27908 layer_factory.hpp:77] Creating layer fc7
I0604 17:56:59.271541 27908 net.cpp:106] Creating Layer fc7
I0604 17:56:59.271546 27908 net.cpp:454] fc7 <- fc6
I0604 17:56:59.271553 27908 net.cpp:411] fc7 -> fc7
I0604 17:56:59.301282 27908 net.cpp:150] Setting up fc7
I0604 17:56:59.301306 27908 net.cpp:157] Top shape: 1 4096 (4096)
I0604 17:56:59.301309 27908 net.cpp:165] Memory required for data: 1430917932
I0604 17:56:59.301321 27908 layer_factory.hpp:77] Creating layer relu7
I0604 17:56:59.301333 27908 net.cpp:106] Creating Layer relu7
I0604 17:56:59.301340 27908 net.cpp:454] relu7 <- fc7
I0604 17:56:59.301349 27908 net.cpp:397] relu7 -> fc7 (in-place)
I0604 17:56:59.301602 27908 net.cpp:150] Setting up relu7
I0604 17:56:59.301614 27908 net.cpp:157] Top shape: 1 4096 (4096)
I0604 17:56:59.301616 27908 net.cpp:165] Memory required for data: 1430934316
I0604 17:56:59.301620 27908 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0604 17:56:59.301627 27908 net.cpp:106] Creating Layer fc7_relu7_0_split
I0604 17:56:59.301633 27908 net.cpp:454] fc7_relu7_0_split <- fc7
I0604 17:56:59.301640 27908 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0604 17:56:59.301651 27908 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0604 17:56:59.301702 27908 net.cpp:150] Setting up fc7_relu7_0_split
I0604 17:56:59.301708 27908 net.cpp:157] Top shape: 1 4096 (4096)
I0604 17:56:59.301714 27908 net.cpp:157] Top shape: 1 4096 (4096)
I0604 17:56:59.301718 27908 net.cpp:165] Memory required for data: 1430967084
I0604 17:56:59.301723 27908 layer_factory.hpp:77] Creating layer cls_score
I0604 17:56:59.301743 27908 net.cpp:106] Creating Layer cls_score
I0604 17:56:59.301746 27908 net.cpp:454] cls_score <- fc7_relu7_0_split_0
I0604 17:56:59.301755 27908 net.cpp:411] cls_score -> cls_score
I0604 17:56:59.302029 27908 net.cpp:150] Setting up cls_score
I0604 17:56:59.302037 27908 net.cpp:157] Top shape: 1 2 (2)
I0604 17:56:59.302039 27908 net.cpp:165] Memory required for data: 1430967092
I0604 17:56:59.302059 27908 layer_factory.hpp:77] Creating layer bbox_pred
I0604 17:56:59.302067 27908 net.cpp:106] Creating Layer bbox_pred
I0604 17:56:59.302073 27908 net.cpp:454] bbox_pred <- fc7_relu7_0_split_1
I0604 17:56:59.302083 27908 net.cpp:411] bbox_pred -> bbox_pred
I0604 17:56:59.302839 27908 net.cpp:150] Setting up bbox_pred
I0604 17:56:59.302845 27908 net.cpp:157] Top shape: 1 8 (8)
I0604 17:56:59.302850 27908 net.cpp:165] Memory required for data: 1430967124
I0604 17:56:59.302856 27908 layer_factory.hpp:77] Creating layer loss_cls
I0604 17:56:59.302866 27908 net.cpp:106] Creating Layer loss_cls
I0604 17:56:59.302872 27908 net.cpp:454] loss_cls <- cls_score
I0604 17:56:59.302878 27908 net.cpp:454] loss_cls <- labels
I0604 17:56:59.302884 27908 net.cpp:411] loss_cls -> loss_cls
I0604 17:56:59.302894 27908 layer_factory.hpp:77] Creating layer loss_cls
I0604 17:56:59.303567 27908 net.cpp:150] Setting up loss_cls
I0604 17:56:59.303576 27908 net.cpp:157] Top shape: (1)
I0604 17:56:59.303580 27908 net.cpp:160]     with loss weight 3
I0604 17:56:59.303591 27908 net.cpp:165] Memory required for data: 1430967128
I0604 17:56:59.303596 27908 layer_factory.hpp:77] Creating layer loss_bbox
I0604 17:56:59.303604 27908 net.cpp:106] Creating Layer loss_bbox
I0604 17:56:59.303611 27908 net.cpp:454] loss_bbox <- bbox_pred
I0604 17:56:59.303616 27908 net.cpp:454] loss_bbox <- bbox_targets
I0604 17:56:59.303623 27908 net.cpp:454] loss_bbox <- bbox_inside_weights
I0604 17:56:59.303627 27908 net.cpp:454] loss_bbox <- bbox_outside_weights
I0604 17:56:59.303637 27908 net.cpp:411] loss_bbox -> loss_bbox
I0604 17:56:59.303704 27908 net.cpp:150] Setting up loss_bbox
I0604 17:56:59.303710 27908 net.cpp:157] Top shape: (1)
I0604 17:56:59.303714 27908 net.cpp:160]     with loss weight 2
I0604 17:56:59.303720 27908 net.cpp:165] Memory required for data: 1430967132
I0604 17:56:59.303725 27908 layer_factory.hpp:77] Creating layer roi_pool5_2
I0604 17:56:59.303735 27908 net.cpp:106] Creating Layer roi_pool5_2
I0604 17:56:59.303740 27908 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0604 17:56:59.303746 27908 net.cpp:454] roi_pool5_2 <- rois_pos
I0604 17:56:59.303752 27908 net.cpp:411] roi_pool5_2 -> pool5_2
I0604 17:56:59.303761 27908 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0604 17:56:59.303833 27908 net.cpp:150] Setting up roi_pool5_2
I0604 17:56:59.303839 27908 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0604 17:56:59.303843 27908 net.cpp:165] Memory required for data: 1431067484
I0604 17:56:59.303848 27908 layer_factory.hpp:77] Creating layer pool5_2_conv
I0604 17:56:59.303859 27908 net.cpp:106] Creating Layer pool5_2_conv
I0604 17:56:59.303864 27908 net.cpp:454] pool5_2_conv <- pool5_2
I0604 17:56:59.303872 27908 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0604 17:56:59.310814 27908 net.cpp:150] Setting up pool5_2_conv
I0604 17:56:59.310829 27908 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0604 17:56:59.310833 27908 net.cpp:165] Memory required for data: 1431167836
I0604 17:56:59.310842 27908 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0604 17:56:59.310849 27908 net.cpp:106] Creating Layer pool5_2_conv_relu
I0604 17:56:59.310855 27908 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0604 17:56:59.310875 27908 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0604 17:56:59.311098 27908 net.cpp:150] Setting up pool5_2_conv_relu
I0604 17:56:59.311108 27908 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0604 17:56:59.311111 27908 net.cpp:165] Memory required for data: 1431268188
I0604 17:56:59.311115 27908 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0604 17:56:59.311152 27908 net.cpp:106] Creating Layer pool5_2_conv2
I0604 17:56:59.311158 27908 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0604 17:56:59.311175 27908 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0604 17:56:59.366618 27908 net.cpp:150] Setting up pool5_2_conv2
I0604 17:56:59.366638 27908 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0604 17:56:59.366641 27908 net.cpp:165] Memory required for data: 1431368540
I0604 17:56:59.366650 27908 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0604 17:56:59.366668 27908 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0604 17:56:59.366673 27908 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0604 17:56:59.366681 27908 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0604 17:56:59.366828 27908 net.cpp:150] Setting up pool5_2_conv2_relu
I0604 17:56:59.366837 27908 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0604 17:56:59.366855 27908 net.cpp:165] Memory required for data: 1431468892
I0604 17:56:59.366858 27908 layer_factory.hpp:77] Creating layer mask_deconv1
I0604 17:56:59.366865 27908 net.cpp:106] Creating Layer mask_deconv1
I0604 17:56:59.366868 27908 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0604 17:56:59.366883 27908 net.cpp:411] mask_deconv1 -> mask_deconv1
I0604 17:56:59.367681 27908 net.cpp:150] Setting up mask_deconv1
I0604 17:56:59.367686 27908 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0604 17:56:59.367688 27908 net.cpp:165] Memory required for data: 1432390492
I0604 17:56:59.367692 27908 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0604 17:56:59.367708 27908 net.cpp:106] Creating Layer pool5_2_conv3
I0604 17:56:59.367723 27908 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0604 17:56:59.367728 27908 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0604 17:56:59.397078 27908 net.cpp:150] Setting up pool5_2_conv3
I0604 17:56:59.397096 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.397099 27908 net.cpp:165] Memory required for data: 1434233692
I0604 17:56:59.397107 27908 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0604 17:56:59.397116 27908 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0604 17:56:59.397121 27908 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0604 17:56:59.397128 27908 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0604 17:56:59.397274 27908 net.cpp:150] Setting up pool5_2_conv3_relu
I0604 17:56:59.397281 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.397284 27908 net.cpp:165] Memory required for data: 1436076892
I0604 17:56:59.397286 27908 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0604 17:56:59.397297 27908 net.cpp:106] Creating Layer pool5_2_conv4
I0604 17:56:59.397300 27908 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0604 17:56:59.397305 27908 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0604 17:56:59.449340 27908 net.cpp:150] Setting up pool5_2_conv4
I0604 17:56:59.449359 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.449362 27908 net.cpp:165] Memory required for data: 1437920092
I0604 17:56:59.449369 27908 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0604 17:56:59.449378 27908 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0604 17:56:59.449393 27908 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0604 17:56:59.449396 27908 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0604 17:56:59.449556 27908 net.cpp:150] Setting up pool5_2_conv4_relu
I0604 17:56:59.449563 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.449565 27908 net.cpp:165] Memory required for data: 1439763292
I0604 17:56:59.449568 27908 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0604 17:56:59.449573 27908 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0604 17:56:59.449576 27908 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0604 17:56:59.449579 27908 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0604 17:56:59.449595 27908 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0604 17:56:59.449600 27908 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0604 17:56:59.449615 27908 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0604 17:56:59.449620 27908 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_4
I0604 17:56:59.449623 27908 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_5
I0604 17:56:59.449627 27908 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_6
I0604 17:56:59.449631 27908 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_7
I0604 17:56:59.449741 27908 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0604 17:56:59.449745 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.449757 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.449760 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.449764 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.449765 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.449767 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.449770 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.449774 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.449775 27908 net.cpp:165] Memory required for data: 1454508892
I0604 17:56:59.449777 27908 layer_factory.hpp:77] Creating layer query_conv
I0604 17:56:59.449796 27908 net.cpp:106] Creating Layer query_conv
I0604 17:56:59.449800 27908 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0604 17:56:59.449805 27908 net.cpp:411] query_conv -> query_conv
I0604 17:56:59.451331 27908 net.cpp:150] Setting up query_conv
I0604 17:56:59.451340 27908 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0604 17:56:59.451344 27908 net.cpp:165] Memory required for data: 1454739292
I0604 17:56:59.451347 27908 layer_factory.hpp:77] Creating layer key_conv
I0604 17:56:59.451354 27908 net.cpp:106] Creating Layer key_conv
I0604 17:56:59.451357 27908 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0604 17:56:59.451361 27908 net.cpp:411] key_conv -> key_conv
I0604 17:56:59.452879 27908 net.cpp:150] Setting up key_conv
I0604 17:56:59.452888 27908 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0604 17:56:59.452889 27908 net.cpp:165] Memory required for data: 1454969692
I0604 17:56:59.452894 27908 layer_factory.hpp:77] Creating layer value_conv
I0604 17:56:59.452901 27908 net.cpp:106] Creating Layer value_conv
I0604 17:56:59.452904 27908 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0604 17:56:59.452909 27908 net.cpp:411] value_conv -> value_conv
I0604 17:56:59.460065 27908 net.cpp:150] Setting up value_conv
I0604 17:56:59.460083 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.460086 27908 net.cpp:165] Memory required for data: 1456812892
I0604 17:56:59.460093 27908 layer_factory.hpp:77] Creating layer query_conv_reshape
I0604 17:56:59.460103 27908 net.cpp:106] Creating Layer query_conv_reshape
I0604 17:56:59.460119 27908 net.cpp:454] query_conv_reshape <- query_conv
I0604 17:56:59.460124 27908 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0604 17:56:59.460155 27908 net.cpp:150] Setting up query_conv_reshape
I0604 17:56:59.460161 27908 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0604 17:56:59.460165 27908 net.cpp:165] Memory required for data: 1457043292
I0604 17:56:59.460170 27908 layer_factory.hpp:77] Creating layer key_conv_reshape
I0604 17:56:59.460175 27908 net.cpp:106] Creating Layer key_conv_reshape
I0604 17:56:59.460181 27908 net.cpp:454] key_conv_reshape <- key_conv
I0604 17:56:59.460187 27908 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0604 17:56:59.460213 27908 net.cpp:150] Setting up key_conv_reshape
I0604 17:56:59.460219 27908 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0604 17:56:59.460232 27908 net.cpp:165] Memory required for data: 1457273692
I0604 17:56:59.460234 27908 layer_factory.hpp:77] Creating layer value_conv_reshape
I0604 17:56:59.460252 27908 net.cpp:106] Creating Layer value_conv_reshape
I0604 17:56:59.460255 27908 net.cpp:454] value_conv_reshape <- value_conv
I0604 17:56:59.460270 27908 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0604 17:56:59.460302 27908 net.cpp:150] Setting up value_conv_reshape
I0604 17:56:59.460319 27908 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0604 17:56:59.460321 27908 net.cpp:165] Memory required for data: 1459116892
I0604 17:56:59.460325 27908 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0604 17:56:59.460340 27908 net.cpp:106] Creating Layer query_conv_reshape_perm
I0604 17:56:59.460355 27908 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0604 17:56:59.460364 27908 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0604 17:56:59.460474 27908 net.cpp:150] Setting up query_conv_reshape_perm
I0604 17:56:59.460481 27908 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0604 17:56:59.460485 27908 net.cpp:165] Memory required for data: 1459347292
I0604 17:56:59.460499 27908 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0604 17:56:59.460506 27908 net.cpp:106] Creating Layer key_conv_reshape_perm
I0604 17:56:59.460510 27908 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0604 17:56:59.460515 27908 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0604 17:56:59.460618 27908 net.cpp:150] Setting up key_conv_reshape_perm
I0604 17:56:59.460628 27908 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0604 17:56:59.460631 27908 net.cpp:165] Memory required for data: 1459577692
I0604 17:56:59.460645 27908 layer_factory.hpp:77] Creating layer energy
I0604 17:56:59.460654 27908 net.cpp:106] Creating Layer energy
I0604 17:56:59.460659 27908 net.cpp:454] energy <- query_conv_reshape_perm
I0604 17:56:59.460665 27908 net.cpp:454] energy <- key_conv_reshape_perm
I0604 17:56:59.460674 27908 net.cpp:411] energy -> energy
I0604 17:56:59.460702 27908 net.cpp:150] Setting up energy
I0604 17:56:59.460709 27908 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0604 17:56:59.460726 27908 net.cpp:165] Memory required for data: 1462817692
I0604 17:56:59.460729 27908 layer_factory.hpp:77] Creating layer attention
I0604 17:56:59.460744 27908 net.cpp:106] Creating Layer attention
I0604 17:56:59.460747 27908 net.cpp:454] attention <- energy
I0604 17:56:59.460762 27908 net.cpp:411] attention -> attention
I0604 17:56:59.460996 27908 net.cpp:150] Setting up attention
I0604 17:56:59.461005 27908 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0604 17:56:59.461010 27908 net.cpp:165] Memory required for data: 1466057692
I0604 17:56:59.461015 27908 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0604 17:56:59.461022 27908 net.cpp:106] Creating Layer value_conv_reshape_perm
I0604 17:56:59.461028 27908 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0604 17:56:59.461035 27908 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0604 17:56:59.461145 27908 net.cpp:150] Setting up value_conv_reshape_perm
I0604 17:56:59.461154 27908 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0604 17:56:59.461159 27908 net.cpp:165] Memory required for data: 1467900892
I0604 17:56:59.461164 27908 layer_factory.hpp:77] Creating layer attention_perm
I0604 17:56:59.461169 27908 net.cpp:106] Creating Layer attention_perm
I0604 17:56:59.461174 27908 net.cpp:454] attention_perm <- attention
I0604 17:56:59.461179 27908 net.cpp:411] attention_perm -> attention_perm
I0604 17:56:59.461285 27908 net.cpp:150] Setting up attention_perm
I0604 17:56:59.461295 27908 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0604 17:56:59.461300 27908 net.cpp:165] Memory required for data: 1471140892
I0604 17:56:59.461304 27908 layer_factory.hpp:77] Creating layer out
I0604 17:56:59.461313 27908 net.cpp:106] Creating Layer out
I0604 17:56:59.461319 27908 net.cpp:454] out <- value_conv_reshape_perm
I0604 17:56:59.461323 27908 net.cpp:454] out <- attention_perm
I0604 17:56:59.461328 27908 net.cpp:411] out -> out
I0604 17:56:59.461351 27908 net.cpp:150] Setting up out
I0604 17:56:59.461359 27908 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0604 17:56:59.461364 27908 net.cpp:165] Memory required for data: 1472984092
I0604 17:56:59.461366 27908 layer_factory.hpp:77] Creating layer out_reshape
I0604 17:56:59.461372 27908 net.cpp:106] Creating Layer out_reshape
I0604 17:56:59.461380 27908 net.cpp:454] out_reshape <- out
I0604 17:56:59.461390 27908 net.cpp:411] out_reshape -> out_reshape
I0604 17:56:59.461447 27908 net.cpp:150] Setting up out_reshape
I0604 17:56:59.461452 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.461453 27908 net.cpp:165] Memory required for data: 1474827292
I0604 17:56:59.461465 27908 layer_factory.hpp:77] Creating layer out_reshape_scale
I0604 17:56:59.461470 27908 net.cpp:106] Creating Layer out_reshape_scale
I0604 17:56:59.461473 27908 net.cpp:454] out_reshape_scale <- out_reshape
I0604 17:56:59.461477 27908 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0604 17:56:59.461537 27908 net.cpp:150] Setting up out_reshape_scale
I0604 17:56:59.461541 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.461544 27908 net.cpp:165] Memory required for data: 1476670492
I0604 17:56:59.461546 27908 layer_factory.hpp:77] Creating layer out_x
I0604 17:56:59.461551 27908 net.cpp:106] Creating Layer out_x
I0604 17:56:59.461555 27908 net.cpp:454] out_x <- out_reshape_scale
I0604 17:56:59.461558 27908 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0604 17:56:59.461562 27908 net.cpp:411] out_x -> out_x
I0604 17:56:59.461578 27908 net.cpp:150] Setting up out_x
I0604 17:56:59.461582 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.461585 27908 net.cpp:165] Memory required for data: 1478513692
I0604 17:56:59.461586 27908 layer_factory.hpp:77] Creating layer query_conv_reshape_ch
I0604 17:56:59.461591 27908 net.cpp:106] Creating Layer query_conv_reshape_ch
I0604 17:56:59.461594 27908 net.cpp:454] query_conv_reshape_ch <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_4
I0604 17:56:59.461608 27908 net.cpp:411] query_conv_reshape_ch -> query_conv_reshape_ch
I0604 17:56:59.461624 27908 net.cpp:150] Setting up query_conv_reshape_ch
I0604 17:56:59.461628 27908 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0604 17:56:59.461632 27908 net.cpp:165] Memory required for data: 1480356892
I0604 17:56:59.461633 27908 layer_factory.hpp:77] Creating layer key_conv_reshape_ch
I0604 17:56:59.461637 27908 net.cpp:106] Creating Layer key_conv_reshape_ch
I0604 17:56:59.461639 27908 net.cpp:454] key_conv_reshape_ch <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_5
I0604 17:56:59.461643 27908 net.cpp:411] key_conv_reshape_ch -> key_conv_reshape_ch
I0604 17:56:59.461658 27908 net.cpp:150] Setting up key_conv_reshape_ch
I0604 17:56:59.461661 27908 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0604 17:56:59.461663 27908 net.cpp:165] Memory required for data: 1482200092
I0604 17:56:59.461666 27908 layer_factory.hpp:77] Creating layer value_conv_reshape_ch
I0604 17:56:59.461681 27908 net.cpp:106] Creating Layer value_conv_reshape_ch
I0604 17:56:59.461684 27908 net.cpp:454] value_conv_reshape_ch <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_6
I0604 17:56:59.461690 27908 net.cpp:411] value_conv_reshape_ch -> value_conv_reshape_ch
I0604 17:56:59.461705 27908 net.cpp:150] Setting up value_conv_reshape_ch
I0604 17:56:59.461709 27908 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0604 17:56:59.461720 27908 net.cpp:165] Memory required for data: 1484043292
I0604 17:56:59.461722 27908 layer_factory.hpp:77] Creating layer query_conv_reshape_perm_ch
I0604 17:56:59.461727 27908 net.cpp:106] Creating Layer query_conv_reshape_perm_ch
I0604 17:56:59.461730 27908 net.cpp:454] query_conv_reshape_perm_ch <- query_conv_reshape_ch
I0604 17:56:59.461732 27908 net.cpp:411] query_conv_reshape_perm_ch -> query_conv_reshape_perm_ch
I0604 17:56:59.461814 27908 net.cpp:150] Setting up query_conv_reshape_perm_ch
I0604 17:56:59.461828 27908 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0604 17:56:59.461830 27908 net.cpp:165] Memory required for data: 1485886492
I0604 17:56:59.461833 27908 layer_factory.hpp:77] Creating layer key_conv_reshape_perm_ch
I0604 17:56:59.461836 27908 net.cpp:106] Creating Layer key_conv_reshape_perm_ch
I0604 17:56:59.461838 27908 net.cpp:454] key_conv_reshape_perm_ch <- key_conv_reshape_ch
I0604 17:56:59.461841 27908 net.cpp:411] key_conv_reshape_perm_ch -> key_conv_reshape_perm_ch
I0604 17:56:59.461899 27908 net.cpp:150] Setting up key_conv_reshape_perm_ch
I0604 17:56:59.461903 27908 net.cpp:157] Top shape: 1 1 900 512 (460800)
I0604 17:56:59.461905 27908 net.cpp:165] Memory required for data: 1487729692
I0604 17:56:59.461907 27908 layer_factory.hpp:77] Creating layer energy_ch
I0604 17:56:59.461910 27908 net.cpp:106] Creating Layer energy_ch
I0604 17:56:59.461913 27908 net.cpp:454] energy_ch <- query_conv_reshape_perm_ch
I0604 17:56:59.461916 27908 net.cpp:454] energy_ch <- key_conv_reshape_perm_ch
I0604 17:56:59.461920 27908 net.cpp:411] energy_ch -> energy_ch
I0604 17:56:59.461935 27908 net.cpp:150] Setting up energy_ch
I0604 17:56:59.461938 27908 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0604 17:56:59.461941 27908 net.cpp:165] Memory required for data: 1488778268
I0604 17:56:59.461943 27908 layer_factory.hpp:77] Creating layer energy_ch_energy_ch_0_split
I0604 17:56:59.461946 27908 net.cpp:106] Creating Layer energy_ch_energy_ch_0_split
I0604 17:56:59.461949 27908 net.cpp:454] energy_ch_energy_ch_0_split <- energy_ch
I0604 17:56:59.461952 27908 net.cpp:411] energy_ch_energy_ch_0_split -> energy_ch_energy_ch_0_split_0
I0604 17:56:59.461956 27908 net.cpp:411] energy_ch_energy_ch_0_split -> energy_ch_energy_ch_0_split_1
I0604 17:56:59.461997 27908 net.cpp:150] Setting up energy_ch_energy_ch_0_split
I0604 17:56:59.462000 27908 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0604 17:56:59.462003 27908 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0604 17:56:59.462015 27908 net.cpp:165] Memory required for data: 1490875420
I0604 17:56:59.462018 27908 layer_factory.hpp:77] Creating layer energy_ch_perm
I0604 17:56:59.462021 27908 net.cpp:106] Creating Layer energy_ch_perm
I0604 17:56:59.462024 27908 net.cpp:454] energy_ch_perm <- energy_ch_energy_ch_0_split_0
I0604 17:56:59.462028 27908 net.cpp:411] energy_ch_perm -> energy_ch_perm
I0604 17:56:59.462098 27908 net.cpp:150] Setting up energy_ch_perm
I0604 17:56:59.462102 27908 net.cpp:157] Top shape: 1 512 1 512 (262144)
I0604 17:56:59.462105 27908 net.cpp:165] Memory required for data: 1491923996
I0604 17:56:59.462116 27908 layer_factory.hpp:77] Creating layer energy_ch_pool
I0604 17:56:59.462123 27908 net.cpp:106] Creating Layer energy_ch_pool
I0604 17:56:59.462126 27908 net.cpp:454] energy_ch_pool <- energy_ch_perm
I0604 17:56:59.462131 27908 net.cpp:411] energy_ch_pool -> energy_ch_pool
I0604 17:56:59.462165 27908 net.cpp:150] Setting up energy_ch_pool
I0604 17:56:59.462169 27908 net.cpp:157] Top shape: 1 512 1 1 (512)
I0604 17:56:59.462172 27908 net.cpp:165] Memory required for data: 1491926044
I0604 17:56:59.462185 27908 layer_factory.hpp:77] Creating layer energy_ch_reperm
I0604 17:56:59.462188 27908 net.cpp:106] Creating Layer energy_ch_reperm
I0604 17:56:59.462191 27908 net.cpp:454] energy_ch_reperm <- energy_ch_pool
I0604 17:56:59.462194 27908 net.cpp:411] energy_ch_reperm -> energy_ch_reperm
I0604 17:56:59.462252 27908 net.cpp:150] Setting up energy_ch_reperm
I0604 17:56:59.462256 27908 net.cpp:157] Top shape: 1 1 512 1 (512)
I0604 17:56:59.462260 27908 net.cpp:165] Memory required for data: 1491928092
I0604 17:56:59.462262 27908 layer_factory.hpp:77] Creating layer energy_ch_max
I0604 17:56:59.462267 27908 net.cpp:106] Creating Layer energy_ch_max
I0604 17:56:59.462271 27908 net.cpp:454] energy_ch_max <- energy_ch_reperm
I0604 17:56:59.462276 27908 net.cpp:411] energy_ch_max -> energy_ch_max
I0604 17:56:59.462293 27908 net.cpp:150] Setting up energy_ch_max
I0604 17:56:59.462297 27908 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0604 17:56:59.462299 27908 net.cpp:165] Memory required for data: 1492976668
I0604 17:56:59.462301 27908 layer_factory.hpp:77] Creating layer energy_ch_minus
I0604 17:56:59.462311 27908 net.cpp:106] Creating Layer energy_ch_minus
I0604 17:56:59.462313 27908 net.cpp:454] energy_ch_minus <- energy_ch_energy_ch_0_split_1
I0604 17:56:59.462316 27908 net.cpp:411] energy_ch_minus -> energy_ch_minus
I0604 17:56:59.462335 27908 net.cpp:150] Setting up energy_ch_minus
I0604 17:56:59.462338 27908 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0604 17:56:59.462342 27908 net.cpp:165] Memory required for data: 1494025244
I0604 17:56:59.462343 27908 layer_factory.hpp:77] Creating layer energy_new
I0604 17:56:59.462347 27908 net.cpp:106] Creating Layer energy_new
I0604 17:56:59.462350 27908 net.cpp:454] energy_new <- energy_ch_max
I0604 17:56:59.462353 27908 net.cpp:454] energy_new <- energy_ch_minus
I0604 17:56:59.462357 27908 net.cpp:411] energy_new -> energy_new
I0604 17:56:59.462371 27908 net.cpp:150] Setting up energy_new
I0604 17:56:59.462375 27908 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0604 17:56:59.462378 27908 net.cpp:165] Memory required for data: 1495073820
I0604 17:56:59.462379 27908 layer_factory.hpp:77] Creating layer attention_ch
I0604 17:56:59.462384 27908 net.cpp:106] Creating Layer attention_ch
I0604 17:56:59.462388 27908 net.cpp:454] attention_ch <- energy_new
I0604 17:56:59.462390 27908 net.cpp:411] attention_ch -> attention_ch
I0604 17:56:59.462937 27908 net.cpp:150] Setting up attention_ch
I0604 17:56:59.462946 27908 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0604 17:56:59.462950 27908 net.cpp:165] Memory required for data: 1496122396
I0604 17:56:59.462954 27908 layer_factory.hpp:77] Creating layer value_conv_reshape_ch_perm
I0604 17:56:59.462958 27908 net.cpp:106] Creating Layer value_conv_reshape_ch_perm
I0604 17:56:59.462961 27908 net.cpp:454] value_conv_reshape_ch_perm <- value_conv_reshape_ch
I0604 17:56:59.462966 27908 net.cpp:411] value_conv_reshape_ch_perm -> value_conv_reshape_ch_perm
I0604 17:56:59.463042 27908 net.cpp:150] Setting up value_conv_reshape_ch_perm
I0604 17:56:59.463047 27908 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0604 17:56:59.463049 27908 net.cpp:165] Memory required for data: 1497965596
I0604 17:56:59.463052 27908 layer_factory.hpp:77] Creating layer attention_ch_perm
I0604 17:56:59.463066 27908 net.cpp:106] Creating Layer attention_ch_perm
I0604 17:56:59.463069 27908 net.cpp:454] attention_ch_perm <- attention_ch
I0604 17:56:59.463073 27908 net.cpp:411] attention_ch_perm -> attention_ch_perm
I0604 17:56:59.463136 27908 net.cpp:150] Setting up attention_ch_perm
I0604 17:56:59.463141 27908 net.cpp:157] Top shape: 1 1 512 512 (262144)
I0604 17:56:59.463143 27908 net.cpp:165] Memory required for data: 1499014172
I0604 17:56:59.463146 27908 layer_factory.hpp:77] Creating layer out_ch
I0604 17:56:59.463150 27908 net.cpp:106] Creating Layer out_ch
I0604 17:56:59.463153 27908 net.cpp:454] out_ch <- attention_ch_perm
I0604 17:56:59.463156 27908 net.cpp:454] out_ch <- value_conv_reshape_ch_perm
I0604 17:56:59.463160 27908 net.cpp:411] out_ch -> out_ch
I0604 17:56:59.463176 27908 net.cpp:150] Setting up out_ch
I0604 17:56:59.463179 27908 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0604 17:56:59.463182 27908 net.cpp:165] Memory required for data: 1500857372
I0604 17:56:59.463186 27908 layer_factory.hpp:77] Creating layer out_ch_reshape
I0604 17:56:59.463189 27908 net.cpp:106] Creating Layer out_ch_reshape
I0604 17:56:59.463193 27908 net.cpp:454] out_ch_reshape <- out_ch
I0604 17:56:59.463196 27908 net.cpp:411] out_ch_reshape -> out_ch_reshape
I0604 17:56:59.463212 27908 net.cpp:150] Setting up out_ch_reshape
I0604 17:56:59.463217 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.463218 27908 net.cpp:165] Memory required for data: 1502700572
I0604 17:56:59.463222 27908 layer_factory.hpp:77] Creating layer out_ch_reshape_scale
I0604 17:56:59.463227 27908 net.cpp:106] Creating Layer out_ch_reshape_scale
I0604 17:56:59.463230 27908 net.cpp:454] out_ch_reshape_scale <- out_ch_reshape
I0604 17:56:59.463234 27908 net.cpp:411] out_ch_reshape_scale -> out_ch_reshape_scale
I0604 17:56:59.463287 27908 net.cpp:150] Setting up out_ch_reshape_scale
I0604 17:56:59.463291 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.463294 27908 net.cpp:165] Memory required for data: 1504543772
I0604 17:56:59.463299 27908 net.cpp:514] Sharing parameters 'scale_conv1_1' owned by layer 'out_reshape_scale', param index 0
I0604 17:56:59.463300 27908 layer_factory.hpp:77] Creating layer out_ch_x
I0604 17:56:59.463305 27908 net.cpp:106] Creating Layer out_ch_x
I0604 17:56:59.463307 27908 net.cpp:454] out_ch_x <- out_ch_reshape_scale
I0604 17:56:59.463311 27908 net.cpp:454] out_ch_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_7
I0604 17:56:59.463316 27908 net.cpp:411] out_ch_x -> out_ch_x
I0604 17:56:59.463333 27908 net.cpp:150] Setting up out_ch_x
I0604 17:56:59.463337 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.463340 27908 net.cpp:165] Memory required for data: 1506386972
I0604 17:56:59.463342 27908 layer_factory.hpp:77] Creating layer out_conv_ch_x
I0604 17:56:59.463351 27908 net.cpp:106] Creating Layer out_conv_ch_x
I0604 17:56:59.463353 27908 net.cpp:454] out_conv_ch_x <- out_ch_x
I0604 17:56:59.463358 27908 net.cpp:411] out_conv_ch_x -> out_conv_ch_x
I0604 17:56:59.469354 27908 net.cpp:150] Setting up out_conv_ch_x
I0604 17:56:59.469362 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.469364 27908 net.cpp:165] Memory required for data: 1508230172
I0604 17:56:59.469380 27908 layer_factory.hpp:77] Creating layer out_conv_x
I0604 17:56:59.469389 27908 net.cpp:106] Creating Layer out_conv_x
I0604 17:56:59.469393 27908 net.cpp:454] out_conv_x <- out_x
I0604 17:56:59.469398 27908 net.cpp:411] out_conv_x -> out_conv_x
I0604 17:56:59.476613 27908 net.cpp:150] Setting up out_conv_x
I0604 17:56:59.476627 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.476629 27908 net.cpp:165] Memory required for data: 1510073372
I0604 17:56:59.476635 27908 layer_factory.hpp:77] Creating layer out_x_sum
I0604 17:56:59.476652 27908 net.cpp:106] Creating Layer out_x_sum
I0604 17:56:59.476666 27908 net.cpp:454] out_x_sum <- out_conv_x
I0604 17:56:59.476670 27908 net.cpp:454] out_x_sum <- out_conv_ch_x
I0604 17:56:59.476675 27908 net.cpp:411] out_x_sum -> out_x_sum
I0604 17:56:59.476698 27908 net.cpp:150] Setting up out_x_sum
I0604 17:56:59.476702 27908 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0604 17:56:59.476704 27908 net.cpp:165] Memory required for data: 1511916572
I0604 17:56:59.476706 27908 layer_factory.hpp:77] Creating layer mask_deconv2
I0604 17:56:59.476713 27908 net.cpp:106] Creating Layer mask_deconv2
I0604 17:56:59.476717 27908 net.cpp:454] mask_deconv2 <- out_x_sum
I0604 17:56:59.476722 27908 net.cpp:411] mask_deconv2 -> mask_deconv2
I0604 17:56:59.477605 27908 net.cpp:150] Setting up mask_deconv2
I0604 17:56:59.477612 27908 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0604 17:56:59.477613 27908 net.cpp:165] Memory required for data: 1527157788
I0604 17:56:59.477617 27908 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0604 17:56:59.477623 27908 net.cpp:106] Creating Layer pool5_2_conv5
I0604 17:56:59.477627 27908 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0604 17:56:59.477632 27908 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0604 17:56:59.507258 27908 net.cpp:150] Setting up pool5_2_conv5
I0604 17:56:59.507277 27908 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0604 17:56:59.507282 27908 net.cpp:165] Memory required for data: 1557640220
I0604 17:56:59.507298 27908 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0604 17:56:59.507308 27908 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0604 17:56:59.507313 27908 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0604 17:56:59.507318 27908 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0604 17:56:59.507474 27908 net.cpp:150] Setting up pool5_2_conv5_relu
I0604 17:56:59.507480 27908 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0604 17:56:59.507483 27908 net.cpp:165] Memory required for data: 1588122652
I0604 17:56:59.507485 27908 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0604 17:56:59.507494 27908 net.cpp:106] Creating Layer pool5_2_conv6
I0604 17:56:59.507498 27908 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0604 17:56:59.507500 27908 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0604 17:56:59.559726 27908 net.cpp:150] Setting up pool5_2_conv6
I0604 17:56:59.559756 27908 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0604 17:56:59.559769 27908 net.cpp:165] Memory required for data: 1618605084
I0604 17:56:59.559777 27908 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0604 17:56:59.559793 27908 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0604 17:56:59.559799 27908 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0604 17:56:59.559818 27908 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0604 17:56:59.560345 27908 net.cpp:150] Setting up pool5_2_conv6_relu
I0604 17:56:59.560353 27908 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0604 17:56:59.560355 27908 net.cpp:165] Memory required for data: 1649087516
I0604 17:56:59.560359 27908 layer_factory.hpp:77] Creating layer mask_deconv3
I0604 17:56:59.560365 27908 net.cpp:106] Creating Layer mask_deconv3
I0604 17:56:59.560369 27908 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0604 17:56:59.560372 27908 net.cpp:411] mask_deconv3 -> mask_deconv3
I0604 17:56:59.560745 27908 net.cpp:150] Setting up mask_deconv3
I0604 17:56:59.560750 27908 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0604 17:56:59.560751 27908 net.cpp:165] Memory required for data: 1710052380
I0604 17:56:59.560755 27908 layer_factory.hpp:77] Creating layer mask_score
I0604 17:56:59.560762 27908 net.cpp:106] Creating Layer mask_score
I0604 17:56:59.560765 27908 net.cpp:454] mask_score <- mask_deconv3
I0604 17:56:59.560770 27908 net.cpp:411] mask_score -> mask_score
I0604 17:56:59.561798 27908 net.cpp:150] Setting up mask_score
I0604 17:56:59.561806 27908 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0604 17:56:59.561810 27908 net.cpp:165] Memory required for data: 1711957532
I0604 17:56:59.561813 27908 layer_factory.hpp:77] Creating layer loss_mask
I0604 17:56:59.561820 27908 net.cpp:106] Creating Layer loss_mask
I0604 17:56:59.561822 27908 net.cpp:454] loss_mask <- mask_score
I0604 17:56:59.561826 27908 net.cpp:454] loss_mask <- mask_targets
I0604 17:56:59.561830 27908 net.cpp:411] loss_mask -> loss_mask
I0604 17:56:59.561848 27908 layer_factory.hpp:77] Creating layer loss_mask
I0604 17:56:59.562762 27908 net.cpp:150] Setting up loss_mask
I0604 17:56:59.562770 27908 net.cpp:157] Top shape: (1)
I0604 17:56:59.562772 27908 net.cpp:160]     with loss weight 3
I0604 17:56:59.562780 27908 net.cpp:165] Memory required for data: 1711957536
I0604 17:56:59.562783 27908 net.cpp:226] loss_mask needs backward computation.
I0604 17:56:59.562785 27908 net.cpp:226] mask_score needs backward computation.
I0604 17:56:59.562788 27908 net.cpp:226] mask_deconv3 needs backward computation.
I0604 17:56:59.562789 27908 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0604 17:56:59.562793 27908 net.cpp:226] pool5_2_conv6 needs backward computation.
I0604 17:56:59.562805 27908 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0604 17:56:59.562808 27908 net.cpp:226] pool5_2_conv5 needs backward computation.
I0604 17:56:59.562810 27908 net.cpp:226] mask_deconv2 needs backward computation.
I0604 17:56:59.562813 27908 net.cpp:226] out_x_sum needs backward computation.
I0604 17:56:59.562817 27908 net.cpp:226] out_conv_x needs backward computation.
I0604 17:56:59.562832 27908 net.cpp:226] out_conv_ch_x needs backward computation.
I0604 17:56:59.562835 27908 net.cpp:226] out_ch_x needs backward computation.
I0604 17:56:59.562839 27908 net.cpp:226] out_ch_reshape_scale needs backward computation.
I0604 17:56:59.562844 27908 net.cpp:226] out_ch_reshape needs backward computation.
I0604 17:56:59.562846 27908 net.cpp:226] out_ch needs backward computation.
I0604 17:56:59.562849 27908 net.cpp:226] attention_ch_perm needs backward computation.
I0604 17:56:59.562853 27908 net.cpp:226] value_conv_reshape_ch_perm needs backward computation.
I0604 17:56:59.562855 27908 net.cpp:226] attention_ch needs backward computation.
I0604 17:56:59.562858 27908 net.cpp:226] energy_new needs backward computation.
I0604 17:56:59.562862 27908 net.cpp:226] energy_ch_minus needs backward computation.
I0604 17:56:59.562865 27908 net.cpp:226] energy_ch_max needs backward computation.
I0604 17:56:59.562870 27908 net.cpp:226] energy_ch_reperm needs backward computation.
I0604 17:56:59.562872 27908 net.cpp:226] energy_ch_pool needs backward computation.
I0604 17:56:59.562875 27908 net.cpp:226] energy_ch_perm needs backward computation.
I0604 17:56:59.562880 27908 net.cpp:226] energy_ch_energy_ch_0_split needs backward computation.
I0604 17:56:59.562882 27908 net.cpp:226] energy_ch needs backward computation.
I0604 17:56:59.562885 27908 net.cpp:226] key_conv_reshape_perm_ch needs backward computation.
I0604 17:56:59.562888 27908 net.cpp:226] query_conv_reshape_perm_ch needs backward computation.
I0604 17:56:59.562891 27908 net.cpp:226] value_conv_reshape_ch needs backward computation.
I0604 17:56:59.562896 27908 net.cpp:226] key_conv_reshape_ch needs backward computation.
I0604 17:56:59.562898 27908 net.cpp:226] query_conv_reshape_ch needs backward computation.
I0604 17:56:59.562901 27908 net.cpp:226] out_x needs backward computation.
I0604 17:56:59.562906 27908 net.cpp:226] out_reshape_scale needs backward computation.
I0604 17:56:59.562909 27908 net.cpp:226] out_reshape needs backward computation.
I0604 17:56:59.562912 27908 net.cpp:226] out needs backward computation.
I0604 17:56:59.562916 27908 net.cpp:226] attention_perm needs backward computation.
I0604 17:56:59.562919 27908 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0604 17:56:59.562922 27908 net.cpp:226] attention needs backward computation.
I0604 17:56:59.562925 27908 net.cpp:226] energy needs backward computation.
I0604 17:56:59.562929 27908 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0604 17:56:59.562932 27908 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0604 17:56:59.562935 27908 net.cpp:226] value_conv_reshape needs backward computation.
I0604 17:56:59.562937 27908 net.cpp:226] key_conv_reshape needs backward computation.
I0604 17:56:59.562942 27908 net.cpp:226] query_conv_reshape needs backward computation.
I0604 17:56:59.562943 27908 net.cpp:226] value_conv needs backward computation.
I0604 17:56:59.562947 27908 net.cpp:226] key_conv needs backward computation.
I0604 17:56:59.562949 27908 net.cpp:226] query_conv needs backward computation.
I0604 17:56:59.562963 27908 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0604 17:56:59.562965 27908 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0604 17:56:59.562968 27908 net.cpp:226] pool5_2_conv4 needs backward computation.
I0604 17:56:59.562971 27908 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0604 17:56:59.562974 27908 net.cpp:226] pool5_2_conv3 needs backward computation.
I0604 17:56:59.562978 27908 net.cpp:226] mask_deconv1 needs backward computation.
I0604 17:56:59.562981 27908 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0604 17:56:59.562984 27908 net.cpp:226] pool5_2_conv2 needs backward computation.
I0604 17:56:59.562986 27908 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0604 17:56:59.562999 27908 net.cpp:226] pool5_2_conv needs backward computation.
I0604 17:56:59.563000 27908 net.cpp:226] roi_pool5_2 needs backward computation.
I0604 17:56:59.563004 27908 net.cpp:226] loss_bbox needs backward computation.
I0604 17:56:59.563009 27908 net.cpp:226] loss_cls needs backward computation.
I0604 17:56:59.563012 27908 net.cpp:226] bbox_pred needs backward computation.
I0604 17:56:59.563015 27908 net.cpp:226] cls_score needs backward computation.
I0604 17:56:59.563017 27908 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0604 17:56:59.563020 27908 net.cpp:226] relu7 needs backward computation.
I0604 17:56:59.563022 27908 net.cpp:226] fc7 needs backward computation.
I0604 17:56:59.563025 27908 net.cpp:226] relu6 needs backward computation.
I0604 17:56:59.563027 27908 net.cpp:226] fc6 needs backward computation.
I0604 17:56:59.563030 27908 net.cpp:226] roi_pool5 needs backward computation.
I0604 17:56:59.563033 27908 net.cpp:226] roi-data needs backward computation.
I0604 17:56:59.563037 27908 net.cpp:226] proposal needs backward computation.
I0604 17:56:59.563041 27908 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0604 17:56:59.563045 27908 net.cpp:226] rpn_cls_prob needs backward computation.
I0604 17:56:59.563048 27908 net.cpp:226] rpn_loss_bbox needs backward computation.
I0604 17:56:59.563052 27908 net.cpp:226] rpn_loss_cls needs backward computation.
I0604 17:56:59.563056 27908 net.cpp:226] rpn-data needs backward computation.
I0604 17:56:59.563060 27908 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0604 17:56:59.563063 27908 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0604 17:56:59.563066 27908 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0604 17:56:59.563068 27908 net.cpp:226] rpn_bbox_pred needs backward computation.
I0604 17:56:59.563071 27908 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0604 17:56:59.563073 27908 net.cpp:226] rpn_cls_score needs backward computation.
I0604 17:56:59.563076 27908 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0604 17:56:59.563079 27908 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0604 17:56:59.563091 27908 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0604 17:56:59.563094 27908 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0604 17:56:59.563097 27908 net.cpp:226] relu5_3 needs backward computation.
I0604 17:56:59.563100 27908 net.cpp:226] conv5_3 needs backward computation.
I0604 17:56:59.563103 27908 net.cpp:226] relu5_2 needs backward computation.
I0604 17:56:59.563107 27908 net.cpp:226] conv5_2 needs backward computation.
I0604 17:56:59.563108 27908 net.cpp:226] relu5_1 needs backward computation.
I0604 17:56:59.563119 27908 net.cpp:226] conv5_1 needs backward computation.
I0604 17:56:59.563122 27908 net.cpp:226] pool4 needs backward computation.
I0604 17:56:59.563124 27908 net.cpp:226] relu4_3 needs backward computation.
I0604 17:56:59.563127 27908 net.cpp:226] conv4_3 needs backward computation.
I0604 17:56:59.563130 27908 net.cpp:226] relu4_2 needs backward computation.
I0604 17:56:59.563133 27908 net.cpp:226] conv4_2 needs backward computation.
I0604 17:56:59.563134 27908 net.cpp:226] relu4_1 needs backward computation.
I0604 17:56:59.563138 27908 net.cpp:226] conv4_1 needs backward computation.
I0604 17:56:59.563139 27908 net.cpp:226] pool3 needs backward computation.
I0604 17:56:59.563143 27908 net.cpp:226] relu3_3 needs backward computation.
I0604 17:56:59.563144 27908 net.cpp:226] conv3_3 needs backward computation.
I0604 17:56:59.563148 27908 net.cpp:226] relu3_2 needs backward computation.
I0604 17:56:59.563149 27908 net.cpp:226] conv3_2 needs backward computation.
I0604 17:56:59.563151 27908 net.cpp:226] relu3_1 needs backward computation.
I0604 17:56:59.563153 27908 net.cpp:226] conv3_1 needs backward computation.
I0604 17:56:59.563156 27908 net.cpp:228] pool2 does not need backward computation.
I0604 17:56:59.563159 27908 net.cpp:228] relu2_2 does not need backward computation.
I0604 17:56:59.563163 27908 net.cpp:228] conv2_2 does not need backward computation.
I0604 17:56:59.563165 27908 net.cpp:228] relu2_1 does not need backward computation.
I0604 17:56:59.563169 27908 net.cpp:228] conv2_1 does not need backward computation.
I0604 17:56:59.563171 27908 net.cpp:228] pool1 does not need backward computation.
I0604 17:56:59.563174 27908 net.cpp:228] relu1_2 does not need backward computation.
I0604 17:56:59.563176 27908 net.cpp:228] conv1_2 does not need backward computation.
I0604 17:56:59.563179 27908 net.cpp:228] relu1_1 does not need backward computation.
I0604 17:56:59.563182 27908 net.cpp:228] conv1_1 does not need backward computation.
I0604 17:56:59.563185 27908 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0604 17:56:59.563189 27908 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0604 17:56:59.563192 27908 net.cpp:228] data_input-data_0_split does not need backward computation.
I0604 17:56:59.563195 27908 net.cpp:228] input-data does not need backward computation.
I0604 17:56:59.563199 27908 net.cpp:270] This network produces output loss_bbox
I0604 17:56:59.563201 27908 net.cpp:270] This network produces output loss_cls
I0604 17:56:59.563205 27908 net.cpp:270] This network produces output loss_mask
I0604 17:56:59.563207 27908 net.cpp:270] This network produces output rpn_cls_loss
I0604 17:56:59.563210 27908 net.cpp:270] This network produces output rpn_loss_bbox
I0604 17:56:59.563282 27908 net.cpp:283] Network initialization done.
I0604 17:56:59.563468 27908 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0604 17:57:18.796757 27908 net.cpp:816] Ignoring source layer pool5
I0604 17:57:18.870713 27908 net.cpp:816] Ignoring source layer drop6
I0604 17:57:18.881306 27908 net.cpp:816] Ignoring source layer drop7
I0604 17:57:18.881325 27908 net.cpp:816] Ignoring source layer fc8
I0604 17:57:18.881328 27908 net.cpp:816] Ignoring source layer prob
Solving...
I0604 17:57:20.650338 27908 solver.cpp:229] Iteration 0, loss = 9.12671
I0604 17:57:20.650365 27908 solver.cpp:245]     Train net output #0: loss_bbox = 0.244229 (* 2 = 0.488458 loss)
I0604 17:57:20.650370 27908 solver.cpp:245]     Train net output #1: loss_cls = 0.52338 (* 3 = 1.57014 loss)
I0604 17:57:20.650375 27908 solver.cpp:245]     Train net output #2: loss_mask = 2.07894 (* 3 = 6.23681 loss)
I0604 17:57:20.650378 27908 solver.cpp:245]     Train net output #3: rpn_cls_loss = 0.728647 (* 1 = 0.728647 loss)
I0604 17:57:20.650382 27908 solver.cpp:245]     Train net output #4: rpn_loss_bbox = 0.0193384 (* 1 = 0.0193384 loss)
I0604 17:57:20.650398 27908 sgd_solver.cpp:106] Iteration 0, lr = 0.001
F0604 17:57:42.080646 27908 syncedmem.cpp:56] Check failed: error == cudaSuccess (2 vs. 0)  out of memory
*** Check failure stack trace: ***
./experiments/scripts/faster_rcnn_end2end.sh: line 65: 27908 Aborted                 /usr/bin/python ./tools/train_net.py --gpu ${GPU_ID} --solver models/${PT_DIR}/${NET}/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb ${TRAIN_IMDB} --iters ${ITERS} --cfg experiments/cfgs/faster_rcnn_end2end.yml ${EXTRA_ARGS}
