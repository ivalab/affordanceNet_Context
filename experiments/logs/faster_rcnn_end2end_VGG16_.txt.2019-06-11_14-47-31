+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-11_14-47-31
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-11_14-47-31
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0611 14:47:38.964673 17863 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0611 14:47:38.964702 17863 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0611 14:47:38.966037 17863 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  top: "attrArray"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "attr_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "attr_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_attribute"
  type: "SigmoidWithLoss"
  bottom: "attr_score"
  bottom: "attrArray"
  top: "loss_attribute"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_mask"
  type: "SoftmaxWithLoss"
  bottom: "mask_score"
  bottom: "mask_targets"
  top: "loss_mask"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
I0611 14:47:38.966434 17863 layer_factory.hpp:77] Creating layer input-data
I0611 14:47:39.009954 17863 net.cpp:106] Creating Layer input-data
I0611 14:47:39.009979 17863 net.cpp:411] input-data -> data
I0611 14:47:39.009989 17863 net.cpp:411] input-data -> im_info
I0611 14:47:39.009996 17863 net.cpp:411] input-data -> gt_boxes
I0611 14:47:39.010005 17863 net.cpp:411] input-data -> seg_mask_inds
I0611 14:47:39.010011 17863 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0611 14:47:39.022140 17863 net.cpp:150] Setting up input-data
I0611 14:47:39.022157 17863 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 14:47:39.022162 17863 net.cpp:157] Top shape: 1 3 (3)
I0611 14:47:39.022169 17863 net.cpp:157] Top shape: 1 4 (4)
I0611 14:47:39.022173 17863 net.cpp:157] Top shape: 1 2 (2)
I0611 14:47:39.022179 17863 net.cpp:157] Top shape: 1 1 (1)
I0611 14:47:39.022183 17863 net.cpp:165] Memory required for data: 7200040
I0611 14:47:39.022192 17863 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0611 14:47:39.022209 17863 net.cpp:106] Creating Layer data_input-data_0_split
I0611 14:47:39.022223 17863 net.cpp:454] data_input-data_0_split <- data
I0611 14:47:39.022229 17863 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0611 14:47:39.022245 17863 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0611 14:47:39.022289 17863 net.cpp:150] Setting up data_input-data_0_split
I0611 14:47:39.022294 17863 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 14:47:39.022300 17863 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 14:47:39.022307 17863 net.cpp:165] Memory required for data: 21600040
I0611 14:47:39.022312 17863 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0611 14:47:39.022322 17863 net.cpp:106] Creating Layer im_info_input-data_1_split
I0611 14:47:39.022331 17863 net.cpp:454] im_info_input-data_1_split <- im_info
I0611 14:47:39.022337 17863 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0611 14:47:39.022346 17863 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0611 14:47:39.022356 17863 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0611 14:47:39.022397 17863 net.cpp:150] Setting up im_info_input-data_1_split
I0611 14:47:39.022400 17863 net.cpp:157] Top shape: 1 3 (3)
I0611 14:47:39.022405 17863 net.cpp:157] Top shape: 1 3 (3)
I0611 14:47:39.022411 17863 net.cpp:157] Top shape: 1 3 (3)
I0611 14:47:39.022416 17863 net.cpp:165] Memory required for data: 21600076
I0611 14:47:39.022424 17863 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0611 14:47:39.022434 17863 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0611 14:47:39.022441 17863 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0611 14:47:39.022444 17863 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0611 14:47:39.022455 17863 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0611 14:47:39.022478 17863 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0611 14:47:39.022483 17863 net.cpp:157] Top shape: 1 4 (4)
I0611 14:47:39.022490 17863 net.cpp:157] Top shape: 1 4 (4)
I0611 14:47:39.022496 17863 net.cpp:165] Memory required for data: 21600108
I0611 14:47:39.022500 17863 layer_factory.hpp:77] Creating layer conv1_1
I0611 14:47:39.022509 17863 net.cpp:106] Creating Layer conv1_1
I0611 14:47:39.022513 17863 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0611 14:47:39.022517 17863 net.cpp:411] conv1_1 -> conv1_1
I0611 14:47:39.276418 17863 net.cpp:150] Setting up conv1_1
I0611 14:47:39.276437 17863 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 14:47:39.276440 17863 net.cpp:165] Memory required for data: 175200108
I0611 14:47:39.276451 17863 layer_factory.hpp:77] Creating layer relu1_1
I0611 14:47:39.276469 17863 net.cpp:106] Creating Layer relu1_1
I0611 14:47:39.276473 17863 net.cpp:454] relu1_1 <- conv1_1
I0611 14:47:39.276477 17863 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0611 14:47:39.276592 17863 net.cpp:150] Setting up relu1_1
I0611 14:47:39.276597 17863 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 14:47:39.276610 17863 net.cpp:165] Memory required for data: 328800108
I0611 14:47:39.276612 17863 layer_factory.hpp:77] Creating layer conv1_2
I0611 14:47:39.276620 17863 net.cpp:106] Creating Layer conv1_2
I0611 14:47:39.276623 17863 net.cpp:454] conv1_2 <- conv1_1
I0611 14:47:39.276628 17863 net.cpp:411] conv1_2 -> conv1_2
I0611 14:47:39.278884 17863 net.cpp:150] Setting up conv1_2
I0611 14:47:39.278909 17863 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 14:47:39.278913 17863 net.cpp:165] Memory required for data: 482400108
I0611 14:47:39.278921 17863 layer_factory.hpp:77] Creating layer relu1_2
I0611 14:47:39.278940 17863 net.cpp:106] Creating Layer relu1_2
I0611 14:47:39.278944 17863 net.cpp:454] relu1_2 <- conv1_2
I0611 14:47:39.278949 17863 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0611 14:47:39.279094 17863 net.cpp:150] Setting up relu1_2
I0611 14:47:39.279100 17863 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 14:47:39.279103 17863 net.cpp:165] Memory required for data: 636000108
I0611 14:47:39.279105 17863 layer_factory.hpp:77] Creating layer pool1
I0611 14:47:39.279124 17863 net.cpp:106] Creating Layer pool1
I0611 14:47:39.279126 17863 net.cpp:454] pool1 <- conv1_2
I0611 14:47:39.279130 17863 net.cpp:411] pool1 -> pool1
I0611 14:47:39.279176 17863 net.cpp:150] Setting up pool1
I0611 14:47:39.279182 17863 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0611 14:47:39.279184 17863 net.cpp:165] Memory required for data: 674400108
I0611 14:47:39.279186 17863 layer_factory.hpp:77] Creating layer conv2_1
I0611 14:47:39.279202 17863 net.cpp:106] Creating Layer conv2_1
I0611 14:47:39.279209 17863 net.cpp:454] conv2_1 <- pool1
I0611 14:47:39.279213 17863 net.cpp:411] conv2_1 -> conv2_1
I0611 14:47:39.281327 17863 net.cpp:150] Setting up conv2_1
I0611 14:47:39.281339 17863 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 14:47:39.281342 17863 net.cpp:165] Memory required for data: 751200108
I0611 14:47:39.281350 17863 layer_factory.hpp:77] Creating layer relu2_1
I0611 14:47:39.281366 17863 net.cpp:106] Creating Layer relu2_1
I0611 14:47:39.281370 17863 net.cpp:454] relu2_1 <- conv2_1
I0611 14:47:39.281385 17863 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0611 14:47:39.281888 17863 net.cpp:150] Setting up relu2_1
I0611 14:47:39.281895 17863 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 14:47:39.281898 17863 net.cpp:165] Memory required for data: 828000108
I0611 14:47:39.281900 17863 layer_factory.hpp:77] Creating layer conv2_2
I0611 14:47:39.281908 17863 net.cpp:106] Creating Layer conv2_2
I0611 14:47:39.281910 17863 net.cpp:454] conv2_2 <- conv2_1
I0611 14:47:39.281915 17863 net.cpp:411] conv2_2 -> conv2_2
I0611 14:47:39.283239 17863 net.cpp:150] Setting up conv2_2
I0611 14:47:39.283248 17863 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 14:47:39.283251 17863 net.cpp:165] Memory required for data: 904800108
I0611 14:47:39.283255 17863 layer_factory.hpp:77] Creating layer relu2_2
I0611 14:47:39.283259 17863 net.cpp:106] Creating Layer relu2_2
I0611 14:47:39.283262 17863 net.cpp:454] relu2_2 <- conv2_2
I0611 14:47:39.283265 17863 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0611 14:47:39.283406 17863 net.cpp:150] Setting up relu2_2
I0611 14:47:39.283412 17863 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 14:47:39.283414 17863 net.cpp:165] Memory required for data: 981600108
I0611 14:47:39.283416 17863 layer_factory.hpp:77] Creating layer pool2
I0611 14:47:39.283421 17863 net.cpp:106] Creating Layer pool2
I0611 14:47:39.283423 17863 net.cpp:454] pool2 <- conv2_2
I0611 14:47:39.283428 17863 net.cpp:411] pool2 -> pool2
I0611 14:47:39.283488 17863 net.cpp:150] Setting up pool2
I0611 14:47:39.283491 17863 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0611 14:47:39.283493 17863 net.cpp:165] Memory required for data: 1000800108
I0611 14:47:39.283506 17863 layer_factory.hpp:77] Creating layer conv3_1
I0611 14:47:39.283512 17863 net.cpp:106] Creating Layer conv3_1
I0611 14:47:39.283514 17863 net.cpp:454] conv3_1 <- pool2
I0611 14:47:39.283529 17863 net.cpp:411] conv3_1 -> conv3_1
I0611 14:47:39.285315 17863 net.cpp:150] Setting up conv3_1
I0611 14:47:39.285324 17863 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:47:39.285326 17863 net.cpp:165] Memory required for data: 1039200108
I0611 14:47:39.285333 17863 layer_factory.hpp:77] Creating layer relu3_1
I0611 14:47:39.285338 17863 net.cpp:106] Creating Layer relu3_1
I0611 14:47:39.285343 17863 net.cpp:454] relu3_1 <- conv3_1
I0611 14:47:39.285359 17863 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0611 14:47:39.285521 17863 net.cpp:150] Setting up relu3_1
I0611 14:47:39.285527 17863 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:47:39.285531 17863 net.cpp:165] Memory required for data: 1077600108
I0611 14:47:39.285532 17863 layer_factory.hpp:77] Creating layer conv3_2
I0611 14:47:39.285539 17863 net.cpp:106] Creating Layer conv3_2
I0611 14:47:39.285542 17863 net.cpp:454] conv3_2 <- conv3_1
I0611 14:47:39.285548 17863 net.cpp:411] conv3_2 -> conv3_2
I0611 14:47:39.287518 17863 net.cpp:150] Setting up conv3_2
I0611 14:47:39.287528 17863 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:47:39.287529 17863 net.cpp:165] Memory required for data: 1116000108
I0611 14:47:39.287534 17863 layer_factory.hpp:77] Creating layer relu3_2
I0611 14:47:39.287539 17863 net.cpp:106] Creating Layer relu3_2
I0611 14:47:39.287541 17863 net.cpp:454] relu3_2 <- conv3_2
I0611 14:47:39.287547 17863 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0611 14:47:39.287724 17863 net.cpp:150] Setting up relu3_2
I0611 14:47:39.287732 17863 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:47:39.287734 17863 net.cpp:165] Memory required for data: 1154400108
I0611 14:47:39.287737 17863 layer_factory.hpp:77] Creating layer conv3_3
I0611 14:47:39.287753 17863 net.cpp:106] Creating Layer conv3_3
I0611 14:47:39.287758 17863 net.cpp:454] conv3_3 <- conv3_2
I0611 14:47:39.287762 17863 net.cpp:411] conv3_3 -> conv3_3
I0611 14:47:39.289822 17863 net.cpp:150] Setting up conv3_3
I0611 14:47:39.289832 17863 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:47:39.289834 17863 net.cpp:165] Memory required for data: 1192800108
I0611 14:47:39.289839 17863 layer_factory.hpp:77] Creating layer relu3_3
I0611 14:47:39.289844 17863 net.cpp:106] Creating Layer relu3_3
I0611 14:47:39.289846 17863 net.cpp:454] relu3_3 <- conv3_3
I0611 14:47:39.289861 17863 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0611 14:47:39.290005 17863 net.cpp:150] Setting up relu3_3
I0611 14:47:39.290010 17863 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 14:47:39.290014 17863 net.cpp:165] Memory required for data: 1231200108
I0611 14:47:39.290015 17863 layer_factory.hpp:77] Creating layer pool3
I0611 14:47:39.290020 17863 net.cpp:106] Creating Layer pool3
I0611 14:47:39.290024 17863 net.cpp:454] pool3 <- conv3_3
I0611 14:47:39.290027 17863 net.cpp:411] pool3 -> pool3
I0611 14:47:39.290088 17863 net.cpp:150] Setting up pool3
I0611 14:47:39.290092 17863 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0611 14:47:39.290104 17863 net.cpp:165] Memory required for data: 1240800108
I0611 14:47:39.290107 17863 layer_factory.hpp:77] Creating layer conv4_1
I0611 14:47:39.290113 17863 net.cpp:106] Creating Layer conv4_1
I0611 14:47:39.290117 17863 net.cpp:454] conv4_1 <- pool3
I0611 14:47:39.290129 17863 net.cpp:411] conv4_1 -> conv4_1
I0611 14:47:39.294049 17863 net.cpp:150] Setting up conv4_1
I0611 14:47:39.294067 17863 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:47:39.294070 17863 net.cpp:165] Memory required for data: 1260000108
I0611 14:47:39.294080 17863 layer_factory.hpp:77] Creating layer relu4_1
I0611 14:47:39.294098 17863 net.cpp:106] Creating Layer relu4_1
I0611 14:47:39.294103 17863 net.cpp:454] relu4_1 <- conv4_1
I0611 14:47:39.294109 17863 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0611 14:47:39.294266 17863 net.cpp:150] Setting up relu4_1
I0611 14:47:39.294272 17863 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:47:39.294284 17863 net.cpp:165] Memory required for data: 1279200108
I0611 14:47:39.294287 17863 layer_factory.hpp:77] Creating layer conv4_2
I0611 14:47:39.294296 17863 net.cpp:106] Creating Layer conv4_2
I0611 14:47:39.294306 17863 net.cpp:454] conv4_2 <- conv4_1
I0611 14:47:39.294312 17863 net.cpp:411] conv4_2 -> conv4_2
I0611 14:47:39.299805 17863 net.cpp:150] Setting up conv4_2
I0611 14:47:39.299844 17863 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:47:39.299846 17863 net.cpp:165] Memory required for data: 1298400108
I0611 14:47:39.299860 17863 layer_factory.hpp:77] Creating layer relu4_2
I0611 14:47:39.299883 17863 net.cpp:106] Creating Layer relu4_2
I0611 14:47:39.299888 17863 net.cpp:454] relu4_2 <- conv4_2
I0611 14:47:39.299892 17863 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0611 14:47:39.300382 17863 net.cpp:150] Setting up relu4_2
I0611 14:47:39.300390 17863 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:47:39.300393 17863 net.cpp:165] Memory required for data: 1317600108
I0611 14:47:39.300395 17863 layer_factory.hpp:77] Creating layer conv4_3
I0611 14:47:39.300403 17863 net.cpp:106] Creating Layer conv4_3
I0611 14:47:39.300407 17863 net.cpp:454] conv4_3 <- conv4_2
I0611 14:47:39.300424 17863 net.cpp:411] conv4_3 -> conv4_3
I0611 14:47:39.304755 17863 net.cpp:150] Setting up conv4_3
I0611 14:47:39.304785 17863 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:47:39.304788 17863 net.cpp:165] Memory required for data: 1336800108
I0611 14:47:39.304796 17863 layer_factory.hpp:77] Creating layer relu4_3
I0611 14:47:39.304807 17863 net.cpp:106] Creating Layer relu4_3
I0611 14:47:39.304826 17863 net.cpp:454] relu4_3 <- conv4_3
I0611 14:47:39.304834 17863 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0611 14:47:39.304970 17863 net.cpp:150] Setting up relu4_3
I0611 14:47:39.304975 17863 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 14:47:39.304988 17863 net.cpp:165] Memory required for data: 1356000108
I0611 14:47:39.304991 17863 layer_factory.hpp:77] Creating layer pool4
I0611 14:47:39.304997 17863 net.cpp:106] Creating Layer pool4
I0611 14:47:39.305013 17863 net.cpp:454] pool4 <- conv4_3
I0611 14:47:39.305021 17863 net.cpp:411] pool4 -> pool4
I0611 14:47:39.305055 17863 net.cpp:150] Setting up pool4
I0611 14:47:39.305063 17863 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:47:39.305066 17863 net.cpp:165] Memory required for data: 1360903020
I0611 14:47:39.305070 17863 layer_factory.hpp:77] Creating layer conv5_1
I0611 14:47:39.305081 17863 net.cpp:106] Creating Layer conv5_1
I0611 14:47:39.305085 17863 net.cpp:454] conv5_1 <- pool4
I0611 14:47:39.305094 17863 net.cpp:411] conv5_1 -> conv5_1
I0611 14:47:39.309438 17863 net.cpp:150] Setting up conv5_1
I0611 14:47:39.309458 17863 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:47:39.309460 17863 net.cpp:165] Memory required for data: 1365805932
I0611 14:47:39.309480 17863 layer_factory.hpp:77] Creating layer relu5_1
I0611 14:47:39.309504 17863 net.cpp:106] Creating Layer relu5_1
I0611 14:47:39.309509 17863 net.cpp:454] relu5_1 <- conv5_1
I0611 14:47:39.309515 17863 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0611 14:47:39.309653 17863 net.cpp:150] Setting up relu5_1
I0611 14:47:39.309659 17863 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:47:39.309661 17863 net.cpp:165] Memory required for data: 1370708844
I0611 14:47:39.309664 17863 layer_factory.hpp:77] Creating layer conv5_2
I0611 14:47:39.309670 17863 net.cpp:106] Creating Layer conv5_2
I0611 14:47:39.309674 17863 net.cpp:454] conv5_2 <- conv5_1
I0611 14:47:39.309677 17863 net.cpp:411] conv5_2 -> conv5_2
I0611 14:47:39.314841 17863 net.cpp:150] Setting up conv5_2
I0611 14:47:39.314869 17863 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:47:39.314873 17863 net.cpp:165] Memory required for data: 1375611756
I0611 14:47:39.314889 17863 layer_factory.hpp:77] Creating layer relu5_2
I0611 14:47:39.314900 17863 net.cpp:106] Creating Layer relu5_2
I0611 14:47:39.314915 17863 net.cpp:454] relu5_2 <- conv5_2
I0611 14:47:39.314920 17863 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0611 14:47:39.315071 17863 net.cpp:150] Setting up relu5_2
I0611 14:47:39.315078 17863 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:47:39.315080 17863 net.cpp:165] Memory required for data: 1380514668
I0611 14:47:39.315083 17863 layer_factory.hpp:77] Creating layer conv5_3
I0611 14:47:39.315093 17863 net.cpp:106] Creating Layer conv5_3
I0611 14:47:39.315094 17863 net.cpp:454] conv5_3 <- conv5_2
I0611 14:47:39.315109 17863 net.cpp:411] conv5_3 -> conv5_3
I0611 14:47:39.319345 17863 net.cpp:150] Setting up conv5_3
I0611 14:47:39.319366 17863 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:47:39.319370 17863 net.cpp:165] Memory required for data: 1385417580
I0611 14:47:39.319376 17863 layer_factory.hpp:77] Creating layer relu5_3
I0611 14:47:39.319383 17863 net.cpp:106] Creating Layer relu5_3
I0611 14:47:39.319387 17863 net.cpp:454] relu5_3 <- conv5_3
I0611 14:47:39.319402 17863 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0611 14:47:39.319550 17863 net.cpp:150] Setting up relu5_3
I0611 14:47:39.319555 17863 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:47:39.319557 17863 net.cpp:165] Memory required for data: 1390320492
I0611 14:47:39.319561 17863 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0611 14:47:39.319566 17863 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0611 14:47:39.319567 17863 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0611 14:47:39.319571 17863 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0611 14:47:39.319577 17863 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0611 14:47:39.319582 17863 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0611 14:47:39.319638 17863 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0611 14:47:39.319643 17863 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:47:39.319658 17863 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:47:39.319659 17863 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:47:39.319663 17863 net.cpp:165] Memory required for data: 1405029228
I0611 14:47:39.319664 17863 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0611 14:47:39.319684 17863 net.cpp:106] Creating Layer rpn_conv/3x3
I0611 14:47:39.319687 17863 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0611 14:47:39.319691 17863 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0611 14:47:39.370440 17863 net.cpp:150] Setting up rpn_conv/3x3
I0611 14:47:39.370457 17863 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:47:39.370460 17863 net.cpp:165] Memory required for data: 1409932140
I0611 14:47:39.370470 17863 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0611 14:47:39.370491 17863 net.cpp:106] Creating Layer rpn_relu/3x3
I0611 14:47:39.370496 17863 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0611 14:47:39.370501 17863 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0611 14:47:39.370632 17863 net.cpp:150] Setting up rpn_relu/3x3
I0611 14:47:39.370640 17863 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:47:39.370641 17863 net.cpp:165] Memory required for data: 1414835052
I0611 14:47:39.370645 17863 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0611 14:47:39.370651 17863 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0611 14:47:39.370667 17863 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0611 14:47:39.370671 17863 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0611 14:47:39.370676 17863 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0611 14:47:39.370715 17863 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0611 14:47:39.370719 17863 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:47:39.370723 17863 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 14:47:39.370724 17863 net.cpp:165] Memory required for data: 1424640876
I0611 14:47:39.370728 17863 layer_factory.hpp:77] Creating layer rpn_cls_score
I0611 14:47:39.370746 17863 net.cpp:106] Creating Layer rpn_cls_score
I0611 14:47:39.370749 17863 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0611 14:47:39.370754 17863 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0611 14:47:39.372479 17863 net.cpp:150] Setting up rpn_cls_score
I0611 14:47:39.372488 17863 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 14:47:39.372499 17863 net.cpp:165] Memory required for data: 1424928156
I0611 14:47:39.372504 17863 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0611 14:47:39.372509 17863 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0611 14:47:39.372522 17863 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0611 14:47:39.372527 17863 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0611 14:47:39.372532 17863 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0611 14:47:39.372578 17863 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0611 14:47:39.372582 17863 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 14:47:39.372594 17863 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 14:47:39.372596 17863 net.cpp:165] Memory required for data: 1425502716
I0611 14:47:39.372599 17863 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0611 14:47:39.372615 17863 net.cpp:106] Creating Layer rpn_bbox_pred
I0611 14:47:39.372617 17863 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0611 14:47:39.372622 17863 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0611 14:47:39.374164 17863 net.cpp:150] Setting up rpn_bbox_pred
I0611 14:47:39.374172 17863 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:47:39.374176 17863 net.cpp:165] Memory required for data: 1426077276
I0611 14:47:39.374181 17863 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 14:47:39.374183 17863 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 14:47:39.374187 17863 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0611 14:47:39.374200 17863 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0611 14:47:39.374207 17863 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0611 14:47:39.374270 17863 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 14:47:39.374274 17863 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:47:39.374287 17863 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:47:39.374289 17863 net.cpp:165] Memory required for data: 1427226396
I0611 14:47:39.374292 17863 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0611 14:47:39.374312 17863 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0611 14:47:39.374316 17863 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0611 14:47:39.374332 17863 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0611 14:47:39.374352 17863 net.cpp:150] Setting up rpn_cls_score_reshape
I0611 14:47:39.374357 17863 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 14:47:39.374361 17863 net.cpp:165] Memory required for data: 1427513676
I0611 14:47:39.374377 17863 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 14:47:39.374385 17863 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 14:47:39.374390 17863 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0611 14:47:39.374397 17863 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0611 14:47:39.374402 17863 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0611 14:47:39.374429 17863 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 14:47:39.374434 17863 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 14:47:39.374440 17863 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 14:47:39.374445 17863 net.cpp:165] Memory required for data: 1428088236
I0611 14:47:39.374449 17863 layer_factory.hpp:77] Creating layer rpn-data
I0611 14:47:39.374788 17863 net.cpp:106] Creating Layer rpn-data
I0611 14:47:39.374794 17863 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0611 14:47:39.374809 17863 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0611 14:47:39.374814 17863 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0611 14:47:39.374819 17863 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0611 14:47:39.374825 17863 net.cpp:411] rpn-data -> rpn_labels
I0611 14:47:39.374831 17863 net.cpp:411] rpn-data -> rpn_bbox_targets
I0611 14:47:39.374836 17863 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0611 14:47:39.374851 17863 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0611 14:47:39.375663 17863 net.cpp:150] Setting up rpn-data
I0611 14:47:39.375672 17863 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0611 14:47:39.375677 17863 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:47:39.375680 17863 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:47:39.375682 17863 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 14:47:39.375685 17863 net.cpp:165] Memory required for data: 1429955556
I0611 14:47:39.375689 17863 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0611 14:47:39.375699 17863 net.cpp:106] Creating Layer rpn_loss_cls
I0611 14:47:39.375703 17863 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0611 14:47:39.375711 17863 net.cpp:454] rpn_loss_cls <- rpn_labels
I0611 14:47:39.375717 17863 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0611 14:47:39.375730 17863 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0611 14:47:39.376370 17863 net.cpp:150] Setting up rpn_loss_cls
I0611 14:47:39.376380 17863 net.cpp:157] Top shape: (1)
I0611 14:47:39.376399 17863 net.cpp:160]     with loss weight 1
I0611 14:47:39.376418 17863 net.cpp:165] Memory required for data: 1429955560
I0611 14:47:39.376422 17863 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0611 14:47:39.376441 17863 net.cpp:106] Creating Layer rpn_loss_bbox
I0611 14:47:39.376447 17863 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0611 14:47:39.376457 17863 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0611 14:47:39.376466 17863 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0611 14:47:39.376471 17863 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0611 14:47:39.376474 17863 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0611 14:47:39.377581 17863 net.cpp:150] Setting up rpn_loss_bbox
I0611 14:47:39.377600 17863 net.cpp:157] Top shape: (1)
I0611 14:47:39.377602 17863 net.cpp:160]     with loss weight 1
I0611 14:47:39.377607 17863 net.cpp:165] Memory required for data: 1429955564
I0611 14:47:39.377610 17863 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0611 14:47:39.377614 17863 net.cpp:106] Creating Layer rpn_cls_prob
I0611 14:47:39.377629 17863 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0611 14:47:39.377635 17863 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0611 14:47:39.377818 17863 net.cpp:150] Setting up rpn_cls_prob
I0611 14:47:39.377835 17863 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 14:47:39.377840 17863 net.cpp:165] Memory required for data: 1430242844
I0611 14:47:39.377842 17863 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0611 14:47:39.377861 17863 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0611 14:47:39.377866 17863 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0611 14:47:39.377871 17863 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0611 14:47:39.377918 17863 net.cpp:150] Setting up rpn_cls_prob_reshape
I0611 14:47:39.377944 17863 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 14:47:39.377959 17863 net.cpp:165] Memory required for data: 1430530124
I0611 14:47:39.377967 17863 layer_factory.hpp:77] Creating layer proposal
I0611 14:47:39.378582 17863 net.cpp:106] Creating Layer proposal
I0611 14:47:39.378590 17863 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0611 14:47:39.378595 17863 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0611 14:47:39.378599 17863 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0611 14:47:39.378608 17863 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0611 14:47:39.379456 17863 net.cpp:150] Setting up proposal
I0611 14:47:39.379464 17863 net.cpp:157] Top shape: 1 5 (5)
I0611 14:47:39.379467 17863 net.cpp:165] Memory required for data: 1430530144
I0611 14:47:39.379472 17863 layer_factory.hpp:77] Creating layer roi-data
I0611 14:47:39.379662 17863 net.cpp:106] Creating Layer roi-data
I0611 14:47:39.379669 17863 net.cpp:454] roi-data <- rpn_rois
I0611 14:47:39.379674 17863 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0611 14:47:39.379689 17863 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0611 14:47:39.379695 17863 net.cpp:454] roi-data <- seg_mask_inds
I0611 14:47:39.379700 17863 net.cpp:454] roi-data <- flipped
I0611 14:47:39.379717 17863 net.cpp:411] roi-data -> rois
I0611 14:47:39.379735 17863 net.cpp:411] roi-data -> labels
I0611 14:47:39.379753 17863 net.cpp:411] roi-data -> bbox_targets
I0611 14:47:39.379760 17863 net.cpp:411] roi-data -> bbox_inside_weights
I0611 14:47:39.379781 17863 net.cpp:411] roi-data -> bbox_outside_weights
I0611 14:47:39.379801 17863 net.cpp:411] roi-data -> mask_targets
I0611 14:47:39.379808 17863 net.cpp:411] roi-data -> rois_pos
I0611 14:47:39.379817 17863 net.cpp:411] roi-data -> attrArray
I0611 14:47:39.380134 17863 net.cpp:150] Setting up roi-data
I0611 14:47:39.380144 17863 net.cpp:157] Top shape: 1 5 (5)
I0611 14:47:39.380148 17863 net.cpp:157] Top shape: 1 1 (1)
I0611 14:47:39.380152 17863 net.cpp:157] Top shape: 1 8 (8)
I0611 14:47:39.380157 17863 net.cpp:157] Top shape: 1 8 (8)
I0611 14:47:39.380163 17863 net.cpp:157] Top shape: 1 8 (8)
I0611 14:47:39.380167 17863 net.cpp:157] Top shape: 1 244 244 (59536)
I0611 14:47:39.380172 17863 net.cpp:157] Top shape: 1 5 (5)
I0611 14:47:39.380177 17863 net.cpp:157] Top shape: 1 10 (10)
I0611 14:47:39.380180 17863 net.cpp:165] Memory required for data: 1430768468
I0611 14:47:39.380195 17863 layer_factory.hpp:77] Creating layer roi_pool5
I0611 14:47:39.380206 17863 net.cpp:106] Creating Layer roi_pool5
I0611 14:47:39.380213 17863 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0611 14:47:39.380228 17863 net.cpp:454] roi_pool5 <- rois
I0611 14:47:39.380244 17863 net.cpp:411] roi_pool5 -> pool5
I0611 14:47:39.380271 17863 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0611 14:47:39.380342 17863 net.cpp:150] Setting up roi_pool5
I0611 14:47:39.380349 17863 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 14:47:39.380353 17863 net.cpp:165] Memory required for data: 1430868820
I0611 14:47:39.380357 17863 layer_factory.hpp:77] Creating layer fc6
I0611 14:47:39.380376 17863 net.cpp:106] Creating Layer fc6
I0611 14:47:39.380383 17863 net.cpp:454] fc6 <- pool5
I0611 14:47:39.380388 17863 net.cpp:411] fc6 -> fc6
I0611 14:47:39.527357 17863 net.cpp:150] Setting up fc6
I0611 14:47:39.527382 17863 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:47:39.527386 17863 net.cpp:165] Memory required for data: 1430885204
I0611 14:47:39.527431 17863 layer_factory.hpp:77] Creating layer relu6
I0611 14:47:39.527453 17863 net.cpp:106] Creating Layer relu6
I0611 14:47:39.527469 17863 net.cpp:454] relu6 <- fc6
I0611 14:47:39.527479 17863 net.cpp:397] relu6 -> fc6 (in-place)
I0611 14:47:39.527710 17863 net.cpp:150] Setting up relu6
I0611 14:47:39.527719 17863 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:47:39.527724 17863 net.cpp:165] Memory required for data: 1430901588
I0611 14:47:39.527727 17863 layer_factory.hpp:77] Creating layer fc7
I0611 14:47:39.527750 17863 net.cpp:106] Creating Layer fc7
I0611 14:47:39.527765 17863 net.cpp:454] fc7 <- fc6
I0611 14:47:39.527771 17863 net.cpp:411] fc7 -> fc7
I0611 14:47:39.553037 17863 net.cpp:150] Setting up fc7
I0611 14:47:39.553063 17863 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:47:39.553067 17863 net.cpp:165] Memory required for data: 1430917972
I0611 14:47:39.553077 17863 layer_factory.hpp:77] Creating layer relu7
I0611 14:47:39.553088 17863 net.cpp:106] Creating Layer relu7
I0611 14:47:39.553095 17863 net.cpp:454] relu7 <- fc7
I0611 14:47:39.553115 17863 net.cpp:397] relu7 -> fc7 (in-place)
I0611 14:47:39.553347 17863 net.cpp:150] Setting up relu7
I0611 14:47:39.553356 17863 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:47:39.553359 17863 net.cpp:165] Memory required for data: 1430934356
I0611 14:47:39.553373 17863 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0611 14:47:39.553382 17863 net.cpp:106] Creating Layer fc7_relu7_0_split
I0611 14:47:39.553388 17863 net.cpp:454] fc7_relu7_0_split <- fc7
I0611 14:47:39.553396 17863 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0611 14:47:39.553421 17863 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0611 14:47:39.553427 17863 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0611 14:47:39.553483 17863 net.cpp:150] Setting up fc7_relu7_0_split
I0611 14:47:39.553491 17863 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:47:39.553496 17863 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:47:39.553510 17863 net.cpp:157] Top shape: 1 4096 (4096)
I0611 14:47:39.553515 17863 net.cpp:165] Memory required for data: 1430983508
I0611 14:47:39.553519 17863 layer_factory.hpp:77] Creating layer attr_score
I0611 14:47:39.553530 17863 net.cpp:106] Creating Layer attr_score
I0611 14:47:39.553535 17863 net.cpp:454] attr_score <- fc7_relu7_0_split_0
I0611 14:47:39.553544 17863 net.cpp:411] attr_score -> attr_score
I0611 14:47:39.554484 17863 net.cpp:150] Setting up attr_score
I0611 14:47:39.554491 17863 net.cpp:157] Top shape: 1 10 (10)
I0611 14:47:39.554494 17863 net.cpp:165] Memory required for data: 1430983548
I0611 14:47:39.554512 17863 layer_factory.hpp:77] Creating layer cls_score
I0611 14:47:39.554522 17863 net.cpp:106] Creating Layer cls_score
I0611 14:47:39.554528 17863 net.cpp:454] cls_score <- fc7_relu7_0_split_1
I0611 14:47:39.554536 17863 net.cpp:411] cls_score -> cls_score
I0611 14:47:39.554781 17863 net.cpp:150] Setting up cls_score
I0611 14:47:39.554787 17863 net.cpp:157] Top shape: 1 2 (2)
I0611 14:47:39.554790 17863 net.cpp:165] Memory required for data: 1430983556
I0611 14:47:39.554807 17863 layer_factory.hpp:77] Creating layer bbox_pred
I0611 14:47:39.554816 17863 net.cpp:106] Creating Layer bbox_pred
I0611 14:47:39.554822 17863 net.cpp:454] bbox_pred <- fc7_relu7_0_split_2
I0611 14:47:39.554831 17863 net.cpp:411] bbox_pred -> bbox_pred
I0611 14:47:39.555570 17863 net.cpp:150] Setting up bbox_pred
I0611 14:47:39.555577 17863 net.cpp:157] Top shape: 1 8 (8)
I0611 14:47:39.555579 17863 net.cpp:165] Memory required for data: 1430983588
I0611 14:47:39.555586 17863 layer_factory.hpp:77] Creating layer loss_attribute
F0611 14:47:39.555632 17863 layer_factory.hpp:81] Check failed: registry.count(type) == 1 (0 vs. 1) Unknown layer type: SigmoidWithLoss (known types: AbsVal, Accuracy, ArgMax, BNLL, BatchNorm, BatchReindex, Bias, Concat, ContrastiveLoss, Convolution, Data, Deconvolution, Dropout, DummyData, ELU, Eltwise, Embed, EuclideanLoss, Exp, Filter, Flatten, GradientScaler, GradientSilent, HDF5Data, HDF5Output, HingeLoss, Im2col, ImageData, InfogainLoss, InnerProduct, LRN, Log, MVN, MatrixMultiplication, MemoryData, MultinomialLogisticLoss, PReLU, Permute, Pooling, Power, Python, ROIAlignment, ROIAlignment2, ROIPooling, ReLU, Reduction, Reshape, SPP, Scale, Sigmoid, SigmoidCrossEntropyLoss, Silence, Slice, SmoothL1Loss, Softmax, SoftmaxWithLoss, Split, TanH, Threshold, Tile, WindowData)
*** Check failure stack trace: ***
./experiments/scripts/faster_rcnn_end2end.sh: line 65: 17863 Aborted                 /usr/bin/python ./tools/train_net.py --gpu ${GPU_ID} --solver models/${PT_DIR}/${NET}/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb ${TRAIN_IMDB} --iters ${ITERS} --cfg experiments/cfgs/faster_rcnn_end2end.yml ${EXTRA_ARGS}
