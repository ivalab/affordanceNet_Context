+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-28_16-09-37
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-28_16-09-37
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/vgg16_faster_rcnn_iter_5000.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/vgg16_faster_rcnn_iter_5000.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 36,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0628 16:09:44.866202 23941 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 1e-05
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0628 16:09:44.866219 23941 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0628 16:09:44.867542 23941 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "mask_score"
  top: "mask_score_softmax"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "log"
  type: "Log"
  bottom: "mask_score_softmax"
  top: "log"
}
layer {
  name: "mult1"
  type: "Eltwise"
  bottom: "log"
  bottom: "mask_targets"
  top: "mult1"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "cross_entropy"
  type: "Power"
  bottom: "mult1"
  top: "cross_entropy"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "ce_sum"
  type: "Convolution"
  bottom: "cross_entropy"
  top: "cross_entropy_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "ce_mean"
  type: "Reduction"
  bottom: "cross_entropy_sum"
  top: "cross_entropy_mean"
  loss_weight: 3
  reduction_param {
    operation: MEAN
    axis: 0
  }
}
I0628 16:09:44.867839 23941 layer_factory.hpp:77] Creating layer input-data
I0628 16:09:44.888190 23941 net.cpp:106] Creating Layer input-data
I0628 16:09:44.888206 23941 net.cpp:411] input-data -> data
I0628 16:09:44.888212 23941 net.cpp:411] input-data -> im_info
I0628 16:09:44.888216 23941 net.cpp:411] input-data -> gt_boxes
I0628 16:09:44.888221 23941 net.cpp:411] input-data -> seg_mask_inds
I0628 16:09:44.888223 23941 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0628 16:09:44.899523 23941 net.cpp:150] Setting up input-data
I0628 16:09:44.899543 23941 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0628 16:09:44.899546 23941 net.cpp:157] Top shape: 1 3 (3)
I0628 16:09:44.899550 23941 net.cpp:157] Top shape: 1 4 (4)
I0628 16:09:44.899554 23941 net.cpp:157] Top shape: 1 2 (2)
I0628 16:09:44.899567 23941 net.cpp:157] Top shape: 1 1 (1)
I0628 16:09:44.899569 23941 net.cpp:165] Memory required for data: 7200040
I0628 16:09:44.899574 23941 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0628 16:09:44.899590 23941 net.cpp:106] Creating Layer data_input-data_0_split
I0628 16:09:44.899605 23941 net.cpp:454] data_input-data_0_split <- data
I0628 16:09:44.899611 23941 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0628 16:09:44.899632 23941 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0628 16:09:44.899668 23941 net.cpp:150] Setting up data_input-data_0_split
I0628 16:09:44.899674 23941 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0628 16:09:44.899688 23941 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0628 16:09:44.899689 23941 net.cpp:165] Memory required for data: 21600040
I0628 16:09:44.899691 23941 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0628 16:09:44.899706 23941 net.cpp:106] Creating Layer im_info_input-data_1_split
I0628 16:09:44.899710 23941 net.cpp:454] im_info_input-data_1_split <- im_info
I0628 16:09:44.899714 23941 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0628 16:09:44.899720 23941 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0628 16:09:44.899727 23941 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0628 16:09:44.899771 23941 net.cpp:150] Setting up im_info_input-data_1_split
I0628 16:09:44.899776 23941 net.cpp:157] Top shape: 1 3 (3)
I0628 16:09:44.899780 23941 net.cpp:157] Top shape: 1 3 (3)
I0628 16:09:44.899792 23941 net.cpp:157] Top shape: 1 3 (3)
I0628 16:09:44.899794 23941 net.cpp:165] Memory required for data: 21600076
I0628 16:09:44.899796 23941 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0628 16:09:44.899801 23941 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0628 16:09:44.899806 23941 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0628 16:09:44.899819 23941 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0628 16:09:44.899825 23941 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0628 16:09:44.899850 23941 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0628 16:09:44.899854 23941 net.cpp:157] Top shape: 1 4 (4)
I0628 16:09:44.899858 23941 net.cpp:157] Top shape: 1 4 (4)
I0628 16:09:44.899861 23941 net.cpp:165] Memory required for data: 21600108
I0628 16:09:44.899865 23941 layer_factory.hpp:77] Creating layer conv1_1
I0628 16:09:44.899888 23941 net.cpp:106] Creating Layer conv1_1
I0628 16:09:44.899891 23941 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0628 16:09:44.899907 23941 net.cpp:411] conv1_1 -> conv1_1
I0628 16:09:45.093945 23941 net.cpp:150] Setting up conv1_1
I0628 16:09:45.093964 23941 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0628 16:09:45.093966 23941 net.cpp:165] Memory required for data: 175200108
I0628 16:09:45.093978 23941 layer_factory.hpp:77] Creating layer relu1_1
I0628 16:09:45.093997 23941 net.cpp:106] Creating Layer relu1_1
I0628 16:09:45.094002 23941 net.cpp:454] relu1_1 <- conv1_1
I0628 16:09:45.094019 23941 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0628 16:09:45.094182 23941 net.cpp:150] Setting up relu1_1
I0628 16:09:45.094193 23941 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0628 16:09:45.094197 23941 net.cpp:165] Memory required for data: 328800108
I0628 16:09:45.094199 23941 layer_factory.hpp:77] Creating layer conv1_2
I0628 16:09:45.094221 23941 net.cpp:106] Creating Layer conv1_2
I0628 16:09:45.094228 23941 net.cpp:454] conv1_2 <- conv1_1
I0628 16:09:45.094233 23941 net.cpp:411] conv1_2 -> conv1_2
I0628 16:09:45.096838 23941 net.cpp:150] Setting up conv1_2
I0628 16:09:45.096859 23941 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0628 16:09:45.096863 23941 net.cpp:165] Memory required for data: 482400108
I0628 16:09:45.096870 23941 layer_factory.hpp:77] Creating layer relu1_2
I0628 16:09:45.096877 23941 net.cpp:106] Creating Layer relu1_2
I0628 16:09:45.096881 23941 net.cpp:454] relu1_2 <- conv1_2
I0628 16:09:45.096886 23941 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0628 16:09:45.097004 23941 net.cpp:150] Setting up relu1_2
I0628 16:09:45.097012 23941 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0628 16:09:45.097016 23941 net.cpp:165] Memory required for data: 636000108
I0628 16:09:45.097019 23941 layer_factory.hpp:77] Creating layer pool1
I0628 16:09:45.097030 23941 net.cpp:106] Creating Layer pool1
I0628 16:09:45.097035 23941 net.cpp:454] pool1 <- conv1_2
I0628 16:09:45.097041 23941 net.cpp:411] pool1 -> pool1
I0628 16:09:45.097085 23941 net.cpp:150] Setting up pool1
I0628 16:09:45.097091 23941 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0628 16:09:45.097095 23941 net.cpp:165] Memory required for data: 674400108
I0628 16:09:45.097097 23941 layer_factory.hpp:77] Creating layer conv2_1
I0628 16:09:45.097106 23941 net.cpp:106] Creating Layer conv2_1
I0628 16:09:45.097110 23941 net.cpp:454] conv2_1 <- pool1
I0628 16:09:45.097116 23941 net.cpp:411] conv2_1 -> conv2_1
I0628 16:09:45.099057 23941 net.cpp:150] Setting up conv2_1
I0628 16:09:45.099066 23941 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0628 16:09:45.099068 23941 net.cpp:165] Memory required for data: 751200108
I0628 16:09:45.099086 23941 layer_factory.hpp:77] Creating layer relu2_1
I0628 16:09:45.099092 23941 net.cpp:106] Creating Layer relu2_1
I0628 16:09:45.099097 23941 net.cpp:454] relu2_1 <- conv2_1
I0628 16:09:45.099102 23941 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0628 16:09:45.099545 23941 net.cpp:150] Setting up relu2_1
I0628 16:09:45.099552 23941 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0628 16:09:45.099556 23941 net.cpp:165] Memory required for data: 828000108
I0628 16:09:45.099560 23941 layer_factory.hpp:77] Creating layer conv2_2
I0628 16:09:45.099568 23941 net.cpp:106] Creating Layer conv2_2
I0628 16:09:45.099572 23941 net.cpp:454] conv2_2 <- conv2_1
I0628 16:09:45.099577 23941 net.cpp:411] conv2_2 -> conv2_2
I0628 16:09:45.100864 23941 net.cpp:150] Setting up conv2_2
I0628 16:09:45.100873 23941 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0628 16:09:45.100878 23941 net.cpp:165] Memory required for data: 904800108
I0628 16:09:45.100885 23941 layer_factory.hpp:77] Creating layer relu2_2
I0628 16:09:45.100893 23941 net.cpp:106] Creating Layer relu2_2
I0628 16:09:45.100896 23941 net.cpp:454] relu2_2 <- conv2_2
I0628 16:09:45.100903 23941 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0628 16:09:45.101016 23941 net.cpp:150] Setting up relu2_2
I0628 16:09:45.101023 23941 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0628 16:09:45.101027 23941 net.cpp:165] Memory required for data: 981600108
I0628 16:09:45.101029 23941 layer_factory.hpp:77] Creating layer pool2
I0628 16:09:45.101037 23941 net.cpp:106] Creating Layer pool2
I0628 16:09:45.101040 23941 net.cpp:454] pool2 <- conv2_2
I0628 16:09:45.101045 23941 net.cpp:411] pool2 -> pool2
I0628 16:09:45.101079 23941 net.cpp:150] Setting up pool2
I0628 16:09:45.101084 23941 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0628 16:09:45.101088 23941 net.cpp:165] Memory required for data: 1000800108
I0628 16:09:45.101090 23941 layer_factory.hpp:77] Creating layer conv3_1
I0628 16:09:45.101099 23941 net.cpp:106] Creating Layer conv3_1
I0628 16:09:45.101102 23941 net.cpp:454] conv3_1 <- pool2
I0628 16:09:45.101109 23941 net.cpp:411] conv3_1 -> conv3_1
I0628 16:09:45.102870 23941 net.cpp:150] Setting up conv3_1
I0628 16:09:45.102879 23941 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 16:09:45.102881 23941 net.cpp:165] Memory required for data: 1039200108
I0628 16:09:45.102891 23941 layer_factory.hpp:77] Creating layer relu3_1
I0628 16:09:45.102898 23941 net.cpp:106] Creating Layer relu3_1
I0628 16:09:45.102903 23941 net.cpp:454] relu3_1 <- conv3_1
I0628 16:09:45.102908 23941 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0628 16:09:45.103019 23941 net.cpp:150] Setting up relu3_1
I0628 16:09:45.103025 23941 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 16:09:45.103029 23941 net.cpp:165] Memory required for data: 1077600108
I0628 16:09:45.103032 23941 layer_factory.hpp:77] Creating layer conv3_2
I0628 16:09:45.103040 23941 net.cpp:106] Creating Layer conv3_2
I0628 16:09:45.103044 23941 net.cpp:454] conv3_2 <- conv3_1
I0628 16:09:45.103050 23941 net.cpp:411] conv3_2 -> conv3_2
I0628 16:09:45.104925 23941 net.cpp:150] Setting up conv3_2
I0628 16:09:45.104933 23941 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 16:09:45.104936 23941 net.cpp:165] Memory required for data: 1116000108
I0628 16:09:45.104944 23941 layer_factory.hpp:77] Creating layer relu3_2
I0628 16:09:45.104950 23941 net.cpp:106] Creating Layer relu3_2
I0628 16:09:45.104955 23941 net.cpp:454] relu3_2 <- conv3_2
I0628 16:09:45.104961 23941 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0628 16:09:45.105072 23941 net.cpp:150] Setting up relu3_2
I0628 16:09:45.105079 23941 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 16:09:45.105082 23941 net.cpp:165] Memory required for data: 1154400108
I0628 16:09:45.105085 23941 layer_factory.hpp:77] Creating layer conv3_3
I0628 16:09:45.105093 23941 net.cpp:106] Creating Layer conv3_3
I0628 16:09:45.105108 23941 net.cpp:454] conv3_3 <- conv3_2
I0628 16:09:45.105113 23941 net.cpp:411] conv3_3 -> conv3_3
I0628 16:09:45.107071 23941 net.cpp:150] Setting up conv3_3
I0628 16:09:45.107081 23941 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 16:09:45.107084 23941 net.cpp:165] Memory required for data: 1192800108
I0628 16:09:45.107098 23941 layer_factory.hpp:77] Creating layer relu3_3
I0628 16:09:45.107105 23941 net.cpp:106] Creating Layer relu3_3
I0628 16:09:45.107110 23941 net.cpp:454] relu3_3 <- conv3_3
I0628 16:09:45.107115 23941 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0628 16:09:45.107236 23941 net.cpp:150] Setting up relu3_3
I0628 16:09:45.107244 23941 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0628 16:09:45.107245 23941 net.cpp:165] Memory required for data: 1231200108
I0628 16:09:45.107249 23941 layer_factory.hpp:77] Creating layer pool3
I0628 16:09:45.107265 23941 net.cpp:106] Creating Layer pool3
I0628 16:09:45.107270 23941 net.cpp:454] pool3 <- conv3_3
I0628 16:09:45.107275 23941 net.cpp:411] pool3 -> pool3
I0628 16:09:45.107318 23941 net.cpp:150] Setting up pool3
I0628 16:09:45.107323 23941 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0628 16:09:45.107326 23941 net.cpp:165] Memory required for data: 1240800108
I0628 16:09:45.107329 23941 layer_factory.hpp:77] Creating layer conv4_1
I0628 16:09:45.107336 23941 net.cpp:106] Creating Layer conv4_1
I0628 16:09:45.107339 23941 net.cpp:454] conv4_1 <- pool3
I0628 16:09:45.107345 23941 net.cpp:411] conv4_1 -> conv4_1
I0628 16:09:45.111105 23941 net.cpp:150] Setting up conv4_1
I0628 16:09:45.111124 23941 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 16:09:45.111125 23941 net.cpp:165] Memory required for data: 1260000108
I0628 16:09:45.111135 23941 layer_factory.hpp:77] Creating layer relu4_1
I0628 16:09:45.111145 23941 net.cpp:106] Creating Layer relu4_1
I0628 16:09:45.111150 23941 net.cpp:454] relu4_1 <- conv4_1
I0628 16:09:45.111156 23941 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0628 16:09:45.111276 23941 net.cpp:150] Setting up relu4_1
I0628 16:09:45.111282 23941 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 16:09:45.111285 23941 net.cpp:165] Memory required for data: 1279200108
I0628 16:09:45.111289 23941 layer_factory.hpp:77] Creating layer conv4_2
I0628 16:09:45.111299 23941 net.cpp:106] Creating Layer conv4_2
I0628 16:09:45.111302 23941 net.cpp:454] conv4_2 <- conv4_1
I0628 16:09:45.111307 23941 net.cpp:411] conv4_2 -> conv4_2
I0628 16:09:45.115921 23941 net.cpp:150] Setting up conv4_2
I0628 16:09:45.115939 23941 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 16:09:45.115942 23941 net.cpp:165] Memory required for data: 1298400108
I0628 16:09:45.115967 23941 layer_factory.hpp:77] Creating layer relu4_2
I0628 16:09:45.115979 23941 net.cpp:106] Creating Layer relu4_2
I0628 16:09:45.115986 23941 net.cpp:454] relu4_2 <- conv4_2
I0628 16:09:45.115993 23941 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0628 16:09:45.116482 23941 net.cpp:150] Setting up relu4_2
I0628 16:09:45.116492 23941 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 16:09:45.116494 23941 net.cpp:165] Memory required for data: 1317600108
I0628 16:09:45.116498 23941 layer_factory.hpp:77] Creating layer conv4_3
I0628 16:09:45.116509 23941 net.cpp:106] Creating Layer conv4_3
I0628 16:09:45.116515 23941 net.cpp:454] conv4_3 <- conv4_2
I0628 16:09:45.116520 23941 net.cpp:411] conv4_3 -> conv4_3
I0628 16:09:45.120898 23941 net.cpp:150] Setting up conv4_3
I0628 16:09:45.120914 23941 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 16:09:45.120918 23941 net.cpp:165] Memory required for data: 1336800108
I0628 16:09:45.120925 23941 layer_factory.hpp:77] Creating layer relu4_3
I0628 16:09:45.120935 23941 net.cpp:106] Creating Layer relu4_3
I0628 16:09:45.120941 23941 net.cpp:454] relu4_3 <- conv4_3
I0628 16:09:45.120947 23941 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0628 16:09:45.121073 23941 net.cpp:150] Setting up relu4_3
I0628 16:09:45.121080 23941 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0628 16:09:45.121083 23941 net.cpp:165] Memory required for data: 1356000108
I0628 16:09:45.121088 23941 layer_factory.hpp:77] Creating layer pool4
I0628 16:09:45.121095 23941 net.cpp:106] Creating Layer pool4
I0628 16:09:45.121099 23941 net.cpp:454] pool4 <- conv4_3
I0628 16:09:45.121104 23941 net.cpp:411] pool4 -> pool4
I0628 16:09:45.121153 23941 net.cpp:150] Setting up pool4
I0628 16:09:45.121158 23941 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 16:09:45.121161 23941 net.cpp:165] Memory required for data: 1360903020
I0628 16:09:45.121165 23941 layer_factory.hpp:77] Creating layer conv5_1
I0628 16:09:45.121173 23941 net.cpp:106] Creating Layer conv5_1
I0628 16:09:45.121177 23941 net.cpp:454] conv5_1 <- pool4
I0628 16:09:45.121183 23941 net.cpp:411] conv5_1 -> conv5_1
I0628 16:09:45.125622 23941 net.cpp:150] Setting up conv5_1
I0628 16:09:45.125645 23941 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 16:09:45.125649 23941 net.cpp:165] Memory required for data: 1365805932
I0628 16:09:45.125658 23941 layer_factory.hpp:77] Creating layer relu5_1
I0628 16:09:45.125669 23941 net.cpp:106] Creating Layer relu5_1
I0628 16:09:45.125674 23941 net.cpp:454] relu5_1 <- conv5_1
I0628 16:09:45.125680 23941 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0628 16:09:45.125824 23941 net.cpp:150] Setting up relu5_1
I0628 16:09:45.125833 23941 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 16:09:45.125835 23941 net.cpp:165] Memory required for data: 1370708844
I0628 16:09:45.125839 23941 layer_factory.hpp:77] Creating layer conv5_2
I0628 16:09:45.125847 23941 net.cpp:106] Creating Layer conv5_2
I0628 16:09:45.125851 23941 net.cpp:454] conv5_2 <- conv5_1
I0628 16:09:45.125856 23941 net.cpp:411] conv5_2 -> conv5_2
I0628 16:09:45.130811 23941 net.cpp:150] Setting up conv5_2
I0628 16:09:45.130831 23941 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 16:09:45.130833 23941 net.cpp:165] Memory required for data: 1375611756
I0628 16:09:45.130841 23941 layer_factory.hpp:77] Creating layer relu5_2
I0628 16:09:45.130849 23941 net.cpp:106] Creating Layer relu5_2
I0628 16:09:45.130856 23941 net.cpp:454] relu5_2 <- conv5_2
I0628 16:09:45.130861 23941 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0628 16:09:45.130985 23941 net.cpp:150] Setting up relu5_2
I0628 16:09:45.130991 23941 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 16:09:45.130993 23941 net.cpp:165] Memory required for data: 1380514668
I0628 16:09:45.130996 23941 layer_factory.hpp:77] Creating layer conv5_3
I0628 16:09:45.131011 23941 net.cpp:106] Creating Layer conv5_3
I0628 16:09:45.131014 23941 net.cpp:454] conv5_3 <- conv5_2
I0628 16:09:45.131028 23941 net.cpp:411] conv5_3 -> conv5_3
I0628 16:09:45.135327 23941 net.cpp:150] Setting up conv5_3
I0628 16:09:45.135347 23941 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 16:09:45.135349 23941 net.cpp:165] Memory required for data: 1385417580
I0628 16:09:45.135358 23941 layer_factory.hpp:77] Creating layer relu5_3
I0628 16:09:45.135368 23941 net.cpp:106] Creating Layer relu5_3
I0628 16:09:45.135373 23941 net.cpp:454] relu5_3 <- conv5_3
I0628 16:09:45.135380 23941 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0628 16:09:45.135499 23941 net.cpp:150] Setting up relu5_3
I0628 16:09:45.135504 23941 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 16:09:45.135507 23941 net.cpp:165] Memory required for data: 1390320492
I0628 16:09:45.135510 23941 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0628 16:09:45.135516 23941 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0628 16:09:45.135520 23941 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0628 16:09:45.135525 23941 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0628 16:09:45.135532 23941 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0628 16:09:45.135538 23941 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0628 16:09:45.135597 23941 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0628 16:09:45.135602 23941 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 16:09:45.135605 23941 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 16:09:45.135618 23941 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 16:09:45.135620 23941 net.cpp:165] Memory required for data: 1405029228
I0628 16:09:45.135623 23941 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0628 16:09:45.135643 23941 net.cpp:106] Creating Layer rpn_conv/3x3
I0628 16:09:45.135648 23941 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0628 16:09:45.135654 23941 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0628 16:09:45.186013 23941 net.cpp:150] Setting up rpn_conv/3x3
I0628 16:09:45.186036 23941 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 16:09:45.186040 23941 net.cpp:165] Memory required for data: 1409932140
I0628 16:09:45.186049 23941 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0628 16:09:45.186059 23941 net.cpp:106] Creating Layer rpn_relu/3x3
I0628 16:09:45.186064 23941 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0628 16:09:45.186069 23941 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0628 16:09:45.186213 23941 net.cpp:150] Setting up rpn_relu/3x3
I0628 16:09:45.186221 23941 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 16:09:45.186233 23941 net.cpp:165] Memory required for data: 1414835052
I0628 16:09:45.186235 23941 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0628 16:09:45.186239 23941 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0628 16:09:45.186241 23941 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0628 16:09:45.186245 23941 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0628 16:09:45.186251 23941 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0628 16:09:45.186301 23941 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0628 16:09:45.186309 23941 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 16:09:45.186312 23941 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0628 16:09:45.186314 23941 net.cpp:165] Memory required for data: 1424640876
I0628 16:09:45.186316 23941 layer_factory.hpp:77] Creating layer rpn_cls_score
I0628 16:09:45.186337 23941 net.cpp:106] Creating Layer rpn_cls_score
I0628 16:09:45.186352 23941 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0628 16:09:45.186357 23941 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0628 16:09:45.188081 23941 net.cpp:150] Setting up rpn_cls_score
I0628 16:09:45.188089 23941 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0628 16:09:45.188102 23941 net.cpp:165] Memory required for data: 1424928156
I0628 16:09:45.188107 23941 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0628 16:09:45.188109 23941 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0628 16:09:45.188112 23941 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0628 16:09:45.188127 23941 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0628 16:09:45.188134 23941 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0628 16:09:45.188201 23941 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0628 16:09:45.188217 23941 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0628 16:09:45.188231 23941 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0628 16:09:45.188233 23941 net.cpp:165] Memory required for data: 1425502716
I0628 16:09:45.188235 23941 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0628 16:09:45.188249 23941 net.cpp:106] Creating Layer rpn_bbox_pred
I0628 16:09:45.188251 23941 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0628 16:09:45.188256 23941 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0628 16:09:45.189970 23941 net.cpp:150] Setting up rpn_bbox_pred
I0628 16:09:45.189980 23941 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0628 16:09:45.189981 23941 net.cpp:165] Memory required for data: 1426077276
I0628 16:09:45.189985 23941 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0628 16:09:45.189988 23941 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0628 16:09:45.189991 23941 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0628 16:09:45.190003 23941 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0628 16:09:45.190008 23941 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0628 16:09:45.190078 23941 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0628 16:09:45.190083 23941 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0628 16:09:45.190085 23941 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0628 16:09:45.190086 23941 net.cpp:165] Memory required for data: 1427226396
I0628 16:09:45.190088 23941 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0628 16:09:45.190109 23941 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0628 16:09:45.190111 23941 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0628 16:09:45.190117 23941 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0628 16:09:45.190151 23941 net.cpp:150] Setting up rpn_cls_score_reshape
I0628 16:09:45.190158 23941 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0628 16:09:45.190171 23941 net.cpp:165] Memory required for data: 1427513676
I0628 16:09:45.190173 23941 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0628 16:09:45.190178 23941 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0628 16:09:45.190193 23941 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0628 16:09:45.190199 23941 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0628 16:09:45.190207 23941 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0628 16:09:45.190237 23941 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0628 16:09:45.190241 23941 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0628 16:09:45.190245 23941 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0628 16:09:45.190249 23941 net.cpp:165] Memory required for data: 1428088236
I0628 16:09:45.190253 23941 layer_factory.hpp:77] Creating layer rpn-data
I0628 16:09:45.190584 23941 net.cpp:106] Creating Layer rpn-data
I0628 16:09:45.190593 23941 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0628 16:09:45.190598 23941 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0628 16:09:45.190603 23941 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0628 16:09:45.190608 23941 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0628 16:09:45.190614 23941 net.cpp:411] rpn-data -> rpn_labels
I0628 16:09:45.190623 23941 net.cpp:411] rpn-data -> rpn_bbox_targets
I0628 16:09:45.190629 23941 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0628 16:09:45.190637 23941 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0628 16:09:45.191462 23941 net.cpp:150] Setting up rpn-data
I0628 16:09:45.191470 23941 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0628 16:09:45.191475 23941 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0628 16:09:45.191480 23941 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0628 16:09:45.191485 23941 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0628 16:09:45.191488 23941 net.cpp:165] Memory required for data: 1429955556
I0628 16:09:45.191493 23941 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0628 16:09:45.191500 23941 net.cpp:106] Creating Layer rpn_loss_cls
I0628 16:09:45.191505 23941 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0628 16:09:45.191511 23941 net.cpp:454] rpn_loss_cls <- rpn_labels
I0628 16:09:45.191517 23941 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0628 16:09:45.191530 23941 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0628 16:09:45.192116 23941 net.cpp:150] Setting up rpn_loss_cls
I0628 16:09:45.192126 23941 net.cpp:157] Top shape: (1)
I0628 16:09:45.192129 23941 net.cpp:160]     with loss weight 1
I0628 16:09:45.192140 23941 net.cpp:165] Memory required for data: 1429955560
I0628 16:09:45.192144 23941 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0628 16:09:45.192152 23941 net.cpp:106] Creating Layer rpn_loss_bbox
I0628 16:09:45.192157 23941 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0628 16:09:45.192163 23941 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0628 16:09:45.192168 23941 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0628 16:09:45.192173 23941 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0628 16:09:45.192178 23941 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0628 16:09:45.193272 23941 net.cpp:150] Setting up rpn_loss_bbox
I0628 16:09:45.193280 23941 net.cpp:157] Top shape: (1)
I0628 16:09:45.193284 23941 net.cpp:160]     with loss weight 1
I0628 16:09:45.193290 23941 net.cpp:165] Memory required for data: 1429955564
I0628 16:09:45.193295 23941 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0628 16:09:45.193301 23941 net.cpp:106] Creating Layer rpn_cls_prob
I0628 16:09:45.193305 23941 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0628 16:09:45.193312 23941 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0628 16:09:45.193470 23941 net.cpp:150] Setting up rpn_cls_prob
I0628 16:09:45.193477 23941 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0628 16:09:45.193480 23941 net.cpp:165] Memory required for data: 1430242844
I0628 16:09:45.193485 23941 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0628 16:09:45.193491 23941 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0628 16:09:45.193495 23941 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0628 16:09:45.193502 23941 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0628 16:09:45.193526 23941 net.cpp:150] Setting up rpn_cls_prob_reshape
I0628 16:09:45.193533 23941 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0628 16:09:45.193537 23941 net.cpp:165] Memory required for data: 1430530124
I0628 16:09:45.193542 23941 layer_factory.hpp:77] Creating layer proposal
I0628 16:09:45.193965 23941 net.cpp:106] Creating Layer proposal
I0628 16:09:45.193972 23941 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0628 16:09:45.193977 23941 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0628 16:09:45.193982 23941 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0628 16:09:45.193989 23941 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0628 16:09:45.194773 23941 net.cpp:150] Setting up proposal
I0628 16:09:45.194782 23941 net.cpp:157] Top shape: 1 5 (5)
I0628 16:09:45.194793 23941 net.cpp:165] Memory required for data: 1430530144
I0628 16:09:45.194797 23941 layer_factory.hpp:77] Creating layer roi-data
I0628 16:09:45.195014 23941 net.cpp:106] Creating Layer roi-data
I0628 16:09:45.195021 23941 net.cpp:454] roi-data <- rpn_rois
I0628 16:09:45.195034 23941 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0628 16:09:45.195037 23941 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0628 16:09:45.195039 23941 net.cpp:454] roi-data <- seg_mask_inds
I0628 16:09:45.195051 23941 net.cpp:454] roi-data <- flipped
I0628 16:09:45.195055 23941 net.cpp:411] roi-data -> rois
I0628 16:09:45.195063 23941 net.cpp:411] roi-data -> labels
I0628 16:09:45.195070 23941 net.cpp:411] roi-data -> bbox_targets
I0628 16:09:45.195076 23941 net.cpp:411] roi-data -> bbox_inside_weights
I0628 16:09:45.195092 23941 net.cpp:411] roi-data -> bbox_outside_weights
I0628 16:09:45.195096 23941 net.cpp:411] roi-data -> mask_targets
I0628 16:09:45.195111 23941 net.cpp:411] roi-data -> rois_pos
I0628 16:09:45.195370 23941 net.cpp:150] Setting up roi-data
I0628 16:09:45.195379 23941 net.cpp:157] Top shape: 1 5 (5)
I0628 16:09:45.195390 23941 net.cpp:157] Top shape: 1 1 (1)
I0628 16:09:45.195394 23941 net.cpp:157] Top shape: 1 8 (8)
I0628 16:09:45.195396 23941 net.cpp:157] Top shape: 1 8 (8)
I0628 16:09:45.195401 23941 net.cpp:157] Top shape: 1 8 (8)
I0628 16:09:45.195405 23941 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0628 16:09:45.195408 23941 net.cpp:157] Top shape: 1 5 (5)
I0628 16:09:45.195411 23941 net.cpp:165] Memory required for data: 1432435436
I0628 16:09:45.195415 23941 layer_factory.hpp:77] Creating layer roi_pool5
I0628 16:09:45.195427 23941 net.cpp:106] Creating Layer roi_pool5
I0628 16:09:45.195432 23941 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0628 16:09:45.195437 23941 net.cpp:454] roi_pool5 <- rois
I0628 16:09:45.195443 23941 net.cpp:411] roi_pool5 -> pool5
I0628 16:09:45.195451 23941 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0628 16:09:45.195523 23941 net.cpp:150] Setting up roi_pool5
I0628 16:09:45.195528 23941 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 16:09:45.195531 23941 net.cpp:165] Memory required for data: 1432535788
I0628 16:09:45.195535 23941 layer_factory.hpp:77] Creating layer fc6
I0628 16:09:45.195546 23941 net.cpp:106] Creating Layer fc6
I0628 16:09:45.195551 23941 net.cpp:454] fc6 <- pool5
I0628 16:09:45.195556 23941 net.cpp:411] fc6 -> fc6
I0628 16:09:45.337606 23941 net.cpp:150] Setting up fc6
I0628 16:09:45.337630 23941 net.cpp:157] Top shape: 1 4096 (4096)
I0628 16:09:45.337633 23941 net.cpp:165] Memory required for data: 1432552172
I0628 16:09:45.337648 23941 layer_factory.hpp:77] Creating layer relu6
I0628 16:09:45.337667 23941 net.cpp:106] Creating Layer relu6
I0628 16:09:45.337672 23941 net.cpp:454] relu6 <- fc6
I0628 16:09:45.337682 23941 net.cpp:397] relu6 -> fc6 (in-place)
I0628 16:09:45.337906 23941 net.cpp:150] Setting up relu6
I0628 16:09:45.337914 23941 net.cpp:157] Top shape: 1 4096 (4096)
I0628 16:09:45.337918 23941 net.cpp:165] Memory required for data: 1432568556
I0628 16:09:45.337919 23941 layer_factory.hpp:77] Creating layer fc7
I0628 16:09:45.337925 23941 net.cpp:106] Creating Layer fc7
I0628 16:09:45.337939 23941 net.cpp:454] fc7 <- fc6
I0628 16:09:45.337944 23941 net.cpp:411] fc7 -> fc7
I0628 16:09:45.361614 23941 net.cpp:150] Setting up fc7
I0628 16:09:45.361650 23941 net.cpp:157] Top shape: 1 4096 (4096)
I0628 16:09:45.361654 23941 net.cpp:165] Memory required for data: 1432584940
I0628 16:09:45.361663 23941 layer_factory.hpp:77] Creating layer relu7
I0628 16:09:45.361682 23941 net.cpp:106] Creating Layer relu7
I0628 16:09:45.361697 23941 net.cpp:454] relu7 <- fc7
I0628 16:09:45.361704 23941 net.cpp:397] relu7 -> fc7 (in-place)
I0628 16:09:45.361902 23941 net.cpp:150] Setting up relu7
I0628 16:09:45.361910 23941 net.cpp:157] Top shape: 1 4096 (4096)
I0628 16:09:45.361912 23941 net.cpp:165] Memory required for data: 1432601324
I0628 16:09:45.361914 23941 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0628 16:09:45.361918 23941 net.cpp:106] Creating Layer fc7_relu7_0_split
I0628 16:09:45.361922 23941 net.cpp:454] fc7_relu7_0_split <- fc7
I0628 16:09:45.361935 23941 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0628 16:09:45.361941 23941 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0628 16:09:45.361999 23941 net.cpp:150] Setting up fc7_relu7_0_split
I0628 16:09:45.362005 23941 net.cpp:157] Top shape: 1 4096 (4096)
I0628 16:09:45.362017 23941 net.cpp:157] Top shape: 1 4096 (4096)
I0628 16:09:45.362020 23941 net.cpp:165] Memory required for data: 1432634092
I0628 16:09:45.362021 23941 layer_factory.hpp:77] Creating layer cls_score
I0628 16:09:45.362030 23941 net.cpp:106] Creating Layer cls_score
I0628 16:09:45.362035 23941 net.cpp:454] cls_score <- fc7_relu7_0_split_0
I0628 16:09:45.362049 23941 net.cpp:411] cls_score -> cls_score
I0628 16:09:45.362314 23941 net.cpp:150] Setting up cls_score
I0628 16:09:45.362320 23941 net.cpp:157] Top shape: 1 2 (2)
I0628 16:09:45.362323 23941 net.cpp:165] Memory required for data: 1432634100
I0628 16:09:45.362330 23941 layer_factory.hpp:77] Creating layer bbox_pred
I0628 16:09:45.362339 23941 net.cpp:106] Creating Layer bbox_pred
I0628 16:09:45.362344 23941 net.cpp:454] bbox_pred <- fc7_relu7_0_split_1
I0628 16:09:45.362349 23941 net.cpp:411] bbox_pred -> bbox_pred
I0628 16:09:45.363088 23941 net.cpp:150] Setting up bbox_pred
I0628 16:09:45.363093 23941 net.cpp:157] Top shape: 1 8 (8)
I0628 16:09:45.363096 23941 net.cpp:165] Memory required for data: 1432634132
I0628 16:09:45.363102 23941 layer_factory.hpp:77] Creating layer loss_cls
I0628 16:09:45.363109 23941 net.cpp:106] Creating Layer loss_cls
I0628 16:09:45.363114 23941 net.cpp:454] loss_cls <- cls_score
I0628 16:09:45.363119 23941 net.cpp:454] loss_cls <- labels
I0628 16:09:45.363126 23941 net.cpp:411] loss_cls -> loss_cls
I0628 16:09:45.363133 23941 layer_factory.hpp:77] Creating layer loss_cls
I0628 16:09:45.363775 23941 net.cpp:150] Setting up loss_cls
I0628 16:09:45.363783 23941 net.cpp:157] Top shape: (1)
I0628 16:09:45.363787 23941 net.cpp:160]     with loss weight 3
I0628 16:09:45.363798 23941 net.cpp:165] Memory required for data: 1432634136
I0628 16:09:45.363803 23941 layer_factory.hpp:77] Creating layer loss_bbox
I0628 16:09:45.363811 23941 net.cpp:106] Creating Layer loss_bbox
I0628 16:09:45.363814 23941 net.cpp:454] loss_bbox <- bbox_pred
I0628 16:09:45.363821 23941 net.cpp:454] loss_bbox <- bbox_targets
I0628 16:09:45.363826 23941 net.cpp:454] loss_bbox <- bbox_inside_weights
I0628 16:09:45.363829 23941 net.cpp:454] loss_bbox <- bbox_outside_weights
I0628 16:09:45.363835 23941 net.cpp:411] loss_bbox -> loss_bbox
I0628 16:09:45.363903 23941 net.cpp:150] Setting up loss_bbox
I0628 16:09:45.363907 23941 net.cpp:157] Top shape: (1)
I0628 16:09:45.363910 23941 net.cpp:160]     with loss weight 2
I0628 16:09:45.363916 23941 net.cpp:165] Memory required for data: 1432634140
I0628 16:09:45.363920 23941 layer_factory.hpp:77] Creating layer roi_pool5_2
I0628 16:09:45.363929 23941 net.cpp:106] Creating Layer roi_pool5_2
I0628 16:09:45.363932 23941 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0628 16:09:45.363937 23941 net.cpp:454] roi_pool5_2 <- rois_pos
I0628 16:09:45.363942 23941 net.cpp:411] roi_pool5_2 -> pool5_2
I0628 16:09:45.363950 23941 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0628 16:09:45.364015 23941 net.cpp:150] Setting up roi_pool5_2
I0628 16:09:45.364020 23941 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 16:09:45.364023 23941 net.cpp:165] Memory required for data: 1432734492
I0628 16:09:45.364025 23941 layer_factory.hpp:77] Creating layer pool5_2_conv
I0628 16:09:45.364032 23941 net.cpp:106] Creating Layer pool5_2_conv
I0628 16:09:45.364034 23941 net.cpp:454] pool5_2_conv <- pool5_2
I0628 16:09:45.364037 23941 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0628 16:09:45.370803 23941 net.cpp:150] Setting up pool5_2_conv
I0628 16:09:45.370815 23941 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 16:09:45.370818 23941 net.cpp:165] Memory required for data: 1432834844
I0628 16:09:45.370823 23941 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0628 16:09:45.370828 23941 net.cpp:106] Creating Layer pool5_2_conv_relu
I0628 16:09:45.370831 23941 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0628 16:09:45.370834 23941 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0628 16:09:45.371002 23941 net.cpp:150] Setting up pool5_2_conv_relu
I0628 16:09:45.371018 23941 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 16:09:45.371021 23941 net.cpp:165] Memory required for data: 1432935196
I0628 16:09:45.371022 23941 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0628 16:09:45.371044 23941 net.cpp:106] Creating Layer pool5_2_conv2
I0628 16:09:45.371047 23941 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0628 16:09:45.371050 23941 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0628 16:09:45.423230 23941 net.cpp:150] Setting up pool5_2_conv2
I0628 16:09:45.423249 23941 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 16:09:45.423252 23941 net.cpp:165] Memory required for data: 1433035548
I0628 16:09:45.423271 23941 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0628 16:09:45.423280 23941 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0628 16:09:45.423288 23941 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0628 16:09:45.423295 23941 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0628 16:09:45.423470 23941 net.cpp:150] Setting up pool5_2_conv2_relu
I0628 16:09:45.423490 23941 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0628 16:09:45.423491 23941 net.cpp:165] Memory required for data: 1433135900
I0628 16:09:45.423494 23941 layer_factory.hpp:77] Creating layer mask_deconv1
I0628 16:09:45.423512 23941 net.cpp:106] Creating Layer mask_deconv1
I0628 16:09:45.423516 23941 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0628 16:09:45.423522 23941 net.cpp:411] mask_deconv1 -> mask_deconv1
I0628 16:09:45.424342 23941 net.cpp:150] Setting up mask_deconv1
I0628 16:09:45.424350 23941 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0628 16:09:45.424353 23941 net.cpp:165] Memory required for data: 1434057500
I0628 16:09:45.424360 23941 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0628 16:09:45.424371 23941 net.cpp:106] Creating Layer pool5_2_conv3
I0628 16:09:45.424376 23941 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0628 16:09:45.424383 23941 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0628 16:09:45.450911 23941 net.cpp:150] Setting up pool5_2_conv3
I0628 16:09:45.450938 23941 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0628 16:09:45.450942 23941 net.cpp:165] Memory required for data: 1435900700
I0628 16:09:45.450958 23941 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0628 16:09:45.450966 23941 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0628 16:09:45.450971 23941 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0628 16:09:45.450984 23941 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0628 16:09:45.451133 23941 net.cpp:150] Setting up pool5_2_conv3_relu
I0628 16:09:45.451140 23941 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0628 16:09:45.451153 23941 net.cpp:165] Memory required for data: 1437743900
I0628 16:09:45.451154 23941 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0628 16:09:45.451162 23941 net.cpp:106] Creating Layer pool5_2_conv4
I0628 16:09:45.451169 23941 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0628 16:09:45.451174 23941 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0628 16:09:45.501861 23941 net.cpp:150] Setting up pool5_2_conv4
I0628 16:09:45.501899 23941 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0628 16:09:45.501901 23941 net.cpp:165] Memory required for data: 1439587100
I0628 16:09:45.501909 23941 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0628 16:09:45.501926 23941 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0628 16:09:45.501931 23941 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0628 16:09:45.501937 23941 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0628 16:09:45.502087 23941 net.cpp:150] Setting up pool5_2_conv4_relu
I0628 16:09:45.502094 23941 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0628 16:09:45.502105 23941 net.cpp:165] Memory required for data: 1441430300
I0628 16:09:45.502107 23941 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0628 16:09:45.502112 23941 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0628 16:09:45.502125 23941 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0628 16:09:45.502128 23941 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0628 16:09:45.502132 23941 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0628 16:09:45.502140 23941 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0628 16:09:45.502144 23941 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0628 16:09:45.502194 23941 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0628 16:09:45.502199 23941 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0628 16:09:45.502203 23941 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0628 16:09:45.502208 23941 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0628 16:09:45.502213 23941 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0628 16:09:45.502216 23941 net.cpp:165] Memory required for data: 1448803100
I0628 16:09:45.502221 23941 layer_factory.hpp:77] Creating layer query_conv
I0628 16:09:45.502231 23941 net.cpp:106] Creating Layer query_conv
I0628 16:09:45.502236 23941 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0628 16:09:45.502243 23941 net.cpp:411] query_conv -> query_conv
I0628 16:09:45.505270 23941 net.cpp:150] Setting up query_conv
I0628 16:09:45.505278 23941 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0628 16:09:45.505282 23941 net.cpp:165] Memory required for data: 1449033500
I0628 16:09:45.505288 23941 layer_factory.hpp:77] Creating layer key_conv
I0628 16:09:45.505300 23941 net.cpp:106] Creating Layer key_conv
I0628 16:09:45.505304 23941 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0628 16:09:45.505311 23941 net.cpp:411] key_conv -> key_conv
I0628 16:09:45.506881 23941 net.cpp:150] Setting up key_conv
I0628 16:09:45.506889 23941 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0628 16:09:45.506893 23941 net.cpp:165] Memory required for data: 1449263900
I0628 16:09:45.506901 23941 layer_factory.hpp:77] Creating layer value_conv
I0628 16:09:45.506909 23941 net.cpp:106] Creating Layer value_conv
I0628 16:09:45.506914 23941 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0628 16:09:45.506922 23941 net.cpp:411] value_conv -> value_conv
I0628 16:09:45.513536 23941 net.cpp:150] Setting up value_conv
I0628 16:09:45.513558 23941 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0628 16:09:45.513562 23941 net.cpp:165] Memory required for data: 1451107100
I0628 16:09:45.513569 23941 layer_factory.hpp:77] Creating layer query_conv_reshape
I0628 16:09:45.513586 23941 net.cpp:106] Creating Layer query_conv_reshape
I0628 16:09:45.513590 23941 net.cpp:454] query_conv_reshape <- query_conv
I0628 16:09:45.513595 23941 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0628 16:09:45.513633 23941 net.cpp:150] Setting up query_conv_reshape
I0628 16:09:45.513639 23941 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0628 16:09:45.513643 23941 net.cpp:165] Memory required for data: 1451337500
I0628 16:09:45.513655 23941 layer_factory.hpp:77] Creating layer key_conv_reshape
I0628 16:09:45.513661 23941 net.cpp:106] Creating Layer key_conv_reshape
I0628 16:09:45.513675 23941 net.cpp:454] key_conv_reshape <- key_conv
I0628 16:09:45.513680 23941 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0628 16:09:45.513705 23941 net.cpp:150] Setting up key_conv_reshape
I0628 16:09:45.513711 23941 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0628 16:09:45.513715 23941 net.cpp:165] Memory required for data: 1451567900
I0628 16:09:45.513718 23941 layer_factory.hpp:77] Creating layer value_conv_reshape
I0628 16:09:45.513723 23941 net.cpp:106] Creating Layer value_conv_reshape
I0628 16:09:45.513737 23941 net.cpp:454] value_conv_reshape <- value_conv
I0628 16:09:45.513742 23941 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0628 16:09:45.513777 23941 net.cpp:150] Setting up value_conv_reshape
I0628 16:09:45.513783 23941 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0628 16:09:45.513797 23941 net.cpp:165] Memory required for data: 1453411100
I0628 16:09:45.513799 23941 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0628 16:09:45.513806 23941 net.cpp:106] Creating Layer query_conv_reshape_perm
I0628 16:09:45.513820 23941 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0628 16:09:45.513824 23941 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0628 16:09:45.513924 23941 net.cpp:150] Setting up query_conv_reshape_perm
I0628 16:09:45.513929 23941 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0628 16:09:45.513931 23941 net.cpp:165] Memory required for data: 1453641500
I0628 16:09:45.513934 23941 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0628 16:09:45.513939 23941 net.cpp:106] Creating Layer key_conv_reshape_perm
I0628 16:09:45.513943 23941 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0628 16:09:45.513949 23941 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0628 16:09:45.514026 23941 net.cpp:150] Setting up key_conv_reshape_perm
I0628 16:09:45.514031 23941 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0628 16:09:45.514034 23941 net.cpp:165] Memory required for data: 1453871900
I0628 16:09:45.514039 23941 layer_factory.hpp:77] Creating layer energy
I0628 16:09:45.514045 23941 net.cpp:106] Creating Layer energy
I0628 16:09:45.514048 23941 net.cpp:454] energy <- query_conv_reshape_perm
I0628 16:09:45.514053 23941 net.cpp:454] energy <- key_conv_reshape_perm
I0628 16:09:45.514068 23941 net.cpp:411] energy -> energy
I0628 16:09:45.514091 23941 net.cpp:150] Setting up energy
I0628 16:09:45.514096 23941 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0628 16:09:45.514099 23941 net.cpp:165] Memory required for data: 1457111900
I0628 16:09:45.514103 23941 layer_factory.hpp:77] Creating layer attention
I0628 16:09:45.514109 23941 net.cpp:106] Creating Layer attention
I0628 16:09:45.514113 23941 net.cpp:454] attention <- energy
I0628 16:09:45.514119 23941 net.cpp:411] attention -> attention
I0628 16:09:45.514294 23941 net.cpp:150] Setting up attention
I0628 16:09:45.514302 23941 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0628 16:09:45.514305 23941 net.cpp:165] Memory required for data: 1460351900
I0628 16:09:45.514309 23941 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0628 16:09:45.514315 23941 net.cpp:106] Creating Layer value_conv_reshape_perm
I0628 16:09:45.514319 23941 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0628 16:09:45.514326 23941 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0628 16:09:45.514396 23941 net.cpp:150] Setting up value_conv_reshape_perm
I0628 16:09:45.514401 23941 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0628 16:09:45.514405 23941 net.cpp:165] Memory required for data: 1462195100
I0628 16:09:45.514410 23941 layer_factory.hpp:77] Creating layer attention_perm
I0628 16:09:45.514415 23941 net.cpp:106] Creating Layer attention_perm
I0628 16:09:45.514420 23941 net.cpp:454] attention_perm <- attention
I0628 16:09:45.514425 23941 net.cpp:411] attention_perm -> attention_perm
I0628 16:09:45.514494 23941 net.cpp:150] Setting up attention_perm
I0628 16:09:45.514499 23941 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0628 16:09:45.514503 23941 net.cpp:165] Memory required for data: 1465435100
I0628 16:09:45.514508 23941 layer_factory.hpp:77] Creating layer out
I0628 16:09:45.514513 23941 net.cpp:106] Creating Layer out
I0628 16:09:45.514516 23941 net.cpp:454] out <- value_conv_reshape_perm
I0628 16:09:45.514521 23941 net.cpp:454] out <- attention_perm
I0628 16:09:45.514526 23941 net.cpp:411] out -> out
I0628 16:09:45.514549 23941 net.cpp:150] Setting up out
I0628 16:09:45.514554 23941 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0628 16:09:45.514557 23941 net.cpp:165] Memory required for data: 1467278300
I0628 16:09:45.514560 23941 layer_factory.hpp:77] Creating layer out_reshape
I0628 16:09:45.514566 23941 net.cpp:106] Creating Layer out_reshape
I0628 16:09:45.514570 23941 net.cpp:454] out_reshape <- out
I0628 16:09:45.514575 23941 net.cpp:411] out_reshape -> out_reshape
I0628 16:09:45.514597 23941 net.cpp:150] Setting up out_reshape
I0628 16:09:45.514602 23941 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0628 16:09:45.514605 23941 net.cpp:165] Memory required for data: 1469121500
I0628 16:09:45.514609 23941 layer_factory.hpp:77] Creating layer out_reshape_scale
I0628 16:09:45.514616 23941 net.cpp:106] Creating Layer out_reshape_scale
I0628 16:09:45.514621 23941 net.cpp:454] out_reshape_scale <- out_reshape
I0628 16:09:45.514626 23941 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0628 16:09:45.514693 23941 net.cpp:150] Setting up out_reshape_scale
I0628 16:09:45.514698 23941 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0628 16:09:45.514700 23941 net.cpp:165] Memory required for data: 1470964700
I0628 16:09:45.514705 23941 layer_factory.hpp:77] Creating layer out_x
I0628 16:09:45.514712 23941 net.cpp:106] Creating Layer out_x
I0628 16:09:45.514716 23941 net.cpp:454] out_x <- out_reshape_scale
I0628 16:09:45.514722 23941 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0628 16:09:45.514727 23941 net.cpp:411] out_x -> out_x
I0628 16:09:45.514751 23941 net.cpp:150] Setting up out_x
I0628 16:09:45.514755 23941 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0628 16:09:45.514758 23941 net.cpp:165] Memory required for data: 1472807900
I0628 16:09:45.514762 23941 layer_factory.hpp:77] Creating layer mask_deconv2
I0628 16:09:45.514770 23941 net.cpp:106] Creating Layer mask_deconv2
I0628 16:09:45.514773 23941 net.cpp:454] mask_deconv2 <- out_x
I0628 16:09:45.514780 23941 net.cpp:411] mask_deconv2 -> mask_deconv2
I0628 16:09:45.515620 23941 net.cpp:150] Setting up mask_deconv2
I0628 16:09:45.515626 23941 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0628 16:09:45.515628 23941 net.cpp:165] Memory required for data: 1488049116
I0628 16:09:45.515633 23941 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0628 16:09:45.515642 23941 net.cpp:106] Creating Layer pool5_2_conv5
I0628 16:09:45.515647 23941 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0628 16:09:45.515655 23941 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0628 16:09:45.542053 23941 net.cpp:150] Setting up pool5_2_conv5
I0628 16:09:45.542070 23941 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0628 16:09:45.542073 23941 net.cpp:165] Memory required for data: 1518531548
I0628 16:09:45.542079 23941 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0628 16:09:45.542086 23941 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0628 16:09:45.542100 23941 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0628 16:09:45.542104 23941 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0628 16:09:45.542244 23941 net.cpp:150] Setting up pool5_2_conv5_relu
I0628 16:09:45.542251 23941 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0628 16:09:45.542258 23941 net.cpp:165] Memory required for data: 1549013980
I0628 16:09:45.542273 23941 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0628 16:09:45.542284 23941 net.cpp:106] Creating Layer pool5_2_conv6
I0628 16:09:45.542289 23941 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0628 16:09:45.542304 23941 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0628 16:09:45.591949 23941 net.cpp:150] Setting up pool5_2_conv6
I0628 16:09:45.591967 23941 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0628 16:09:45.591970 23941 net.cpp:165] Memory required for data: 1579496412
I0628 16:09:45.591977 23941 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0628 16:09:45.591984 23941 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0628 16:09:45.591997 23941 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0628 16:09:45.592001 23941 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0628 16:09:45.592519 23941 net.cpp:150] Setting up pool5_2_conv6_relu
I0628 16:09:45.592527 23941 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0628 16:09:45.592530 23941 net.cpp:165] Memory required for data: 1609978844
I0628 16:09:45.592531 23941 layer_factory.hpp:77] Creating layer mask_deconv3
I0628 16:09:45.592537 23941 net.cpp:106] Creating Layer mask_deconv3
I0628 16:09:45.592540 23941 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0628 16:09:45.592543 23941 net.cpp:411] mask_deconv3 -> mask_deconv3
I0628 16:09:45.592914 23941 net.cpp:150] Setting up mask_deconv3
I0628 16:09:45.592921 23941 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0628 16:09:45.592923 23941 net.cpp:165] Memory required for data: 1670943708
I0628 16:09:45.592933 23941 layer_factory.hpp:77] Creating layer mask_score
I0628 16:09:45.592949 23941 net.cpp:106] Creating Layer mask_score
I0628 16:09:45.592952 23941 net.cpp:454] mask_score <- mask_deconv3
I0628 16:09:45.592955 23941 net.cpp:411] mask_score -> mask_score
I0628 16:09:45.593536 23941 net.cpp:150] Setting up mask_score
I0628 16:09:45.593544 23941 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0628 16:09:45.593545 23941 net.cpp:165] Memory required for data: 1672848860
I0628 16:09:45.593549 23941 layer_factory.hpp:77] Creating layer prob
I0628 16:09:45.593554 23941 net.cpp:106] Creating Layer prob
I0628 16:09:45.593556 23941 net.cpp:454] prob <- mask_score
I0628 16:09:45.593559 23941 net.cpp:411] prob -> mask_score_softmax
I0628 16:09:45.594079 23941 net.cpp:150] Setting up prob
I0628 16:09:45.594087 23941 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0628 16:09:45.594089 23941 net.cpp:165] Memory required for data: 1674754012
I0628 16:09:45.594091 23941 layer_factory.hpp:77] Creating layer log
I0628 16:09:45.594099 23941 net.cpp:106] Creating Layer log
I0628 16:09:45.594115 23941 net.cpp:454] log <- mask_score_softmax
I0628 16:09:45.594118 23941 net.cpp:411] log -> log
I0628 16:09:45.594169 23941 net.cpp:150] Setting up log
I0628 16:09:45.594177 23941 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0628 16:09:45.594179 23941 net.cpp:165] Memory required for data: 1676659164
I0628 16:09:45.594182 23941 layer_factory.hpp:77] Creating layer mult1
I0628 16:09:45.594187 23941 net.cpp:106] Creating Layer mult1
I0628 16:09:45.594202 23941 net.cpp:454] mult1 <- log
I0628 16:09:45.594208 23941 net.cpp:454] mult1 <- mask_targets
I0628 16:09:45.594223 23941 net.cpp:411] mult1 -> mult1
I0628 16:09:45.594278 23941 net.cpp:150] Setting up mult1
I0628 16:09:45.594286 23941 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0628 16:09:45.594298 23941 net.cpp:165] Memory required for data: 1678564316
I0628 16:09:45.594300 23941 layer_factory.hpp:77] Creating layer cross_entropy
I0628 16:09:45.594305 23941 net.cpp:106] Creating Layer cross_entropy
I0628 16:09:45.594321 23941 net.cpp:454] cross_entropy <- mult1
I0628 16:09:45.594324 23941 net.cpp:411] cross_entropy -> cross_entropy
I0628 16:09:45.594365 23941 net.cpp:150] Setting up cross_entropy
I0628 16:09:45.594372 23941 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0628 16:09:45.594384 23941 net.cpp:165] Memory required for data: 1680469468
I0628 16:09:45.594386 23941 layer_factory.hpp:77] Creating layer ce_sum
I0628 16:09:45.594393 23941 net.cpp:106] Creating Layer ce_sum
I0628 16:09:45.594410 23941 net.cpp:454] ce_sum <- cross_entropy
I0628 16:09:45.594416 23941 net.cpp:411] ce_sum -> cross_entropy_sum
I0628 16:09:45.595585 23941 net.cpp:150] Setting up ce_sum
I0628 16:09:45.595593 23941 net.cpp:157] Top shape: 1 1 244 244 (59536)
I0628 16:09:45.595607 23941 net.cpp:165] Memory required for data: 1680707612
I0628 16:09:45.595610 23941 layer_factory.hpp:77] Creating layer ce_mean
I0628 16:09:45.595628 23941 net.cpp:106] Creating Layer ce_mean
I0628 16:09:45.595633 23941 net.cpp:454] ce_mean <- cross_entropy_sum
I0628 16:09:45.595638 23941 net.cpp:411] ce_mean -> cross_entropy_mean
I0628 16:09:45.595732 23941 net.cpp:150] Setting up ce_mean
I0628 16:09:45.595737 23941 net.cpp:157] Top shape: (1)
I0628 16:09:45.595739 23941 net.cpp:160]     with loss weight 3
I0628 16:09:45.595748 23941 net.cpp:165] Memory required for data: 1680707616
I0628 16:09:45.595751 23941 net.cpp:226] ce_mean needs backward computation.
I0628 16:09:45.595752 23941 net.cpp:226] ce_sum needs backward computation.
I0628 16:09:45.595753 23941 net.cpp:226] cross_entropy needs backward computation.
I0628 16:09:45.595755 23941 net.cpp:226] mult1 needs backward computation.
I0628 16:09:45.595757 23941 net.cpp:226] log needs backward computation.
I0628 16:09:45.595759 23941 net.cpp:226] prob needs backward computation.
I0628 16:09:45.595760 23941 net.cpp:226] mask_score needs backward computation.
I0628 16:09:45.595762 23941 net.cpp:226] mask_deconv3 needs backward computation.
I0628 16:09:45.595764 23941 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0628 16:09:45.595767 23941 net.cpp:226] pool5_2_conv6 needs backward computation.
I0628 16:09:45.595768 23941 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0628 16:09:45.595769 23941 net.cpp:226] pool5_2_conv5 needs backward computation.
I0628 16:09:45.595772 23941 net.cpp:226] mask_deconv2 needs backward computation.
I0628 16:09:45.595773 23941 net.cpp:226] out_x needs backward computation.
I0628 16:09:45.595777 23941 net.cpp:226] out_reshape_scale needs backward computation.
I0628 16:09:45.595777 23941 net.cpp:226] out_reshape needs backward computation.
I0628 16:09:45.595779 23941 net.cpp:226] out needs backward computation.
I0628 16:09:45.595782 23941 net.cpp:226] attention_perm needs backward computation.
I0628 16:09:45.595784 23941 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0628 16:09:45.595787 23941 net.cpp:226] attention needs backward computation.
I0628 16:09:45.595788 23941 net.cpp:226] energy needs backward computation.
I0628 16:09:45.595790 23941 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0628 16:09:45.595793 23941 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0628 16:09:45.595795 23941 net.cpp:226] value_conv_reshape needs backward computation.
I0628 16:09:45.595798 23941 net.cpp:226] key_conv_reshape needs backward computation.
I0628 16:09:45.595799 23941 net.cpp:226] query_conv_reshape needs backward computation.
I0628 16:09:45.595801 23941 net.cpp:226] value_conv needs backward computation.
I0628 16:09:45.595803 23941 net.cpp:226] key_conv needs backward computation.
I0628 16:09:45.595805 23941 net.cpp:226] query_conv needs backward computation.
I0628 16:09:45.595808 23941 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0628 16:09:45.595810 23941 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0628 16:09:45.595813 23941 net.cpp:226] pool5_2_conv4 needs backward computation.
I0628 16:09:45.595814 23941 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0628 16:09:45.595816 23941 net.cpp:226] pool5_2_conv3 needs backward computation.
I0628 16:09:45.595818 23941 net.cpp:226] mask_deconv1 needs backward computation.
I0628 16:09:45.595819 23941 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0628 16:09:45.595821 23941 net.cpp:226] pool5_2_conv2 needs backward computation.
I0628 16:09:45.595824 23941 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0628 16:09:45.595825 23941 net.cpp:226] pool5_2_conv needs backward computation.
I0628 16:09:45.595827 23941 net.cpp:226] roi_pool5_2 needs backward computation.
I0628 16:09:45.595830 23941 net.cpp:226] loss_bbox needs backward computation.
I0628 16:09:45.595834 23941 net.cpp:226] loss_cls needs backward computation.
I0628 16:09:45.595836 23941 net.cpp:226] bbox_pred needs backward computation.
I0628 16:09:45.595839 23941 net.cpp:226] cls_score needs backward computation.
I0628 16:09:45.595841 23941 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0628 16:09:45.595844 23941 net.cpp:226] relu7 needs backward computation.
I0628 16:09:45.595845 23941 net.cpp:226] fc7 needs backward computation.
I0628 16:09:45.595846 23941 net.cpp:226] relu6 needs backward computation.
I0628 16:09:45.595849 23941 net.cpp:226] fc6 needs backward computation.
I0628 16:09:45.595851 23941 net.cpp:226] roi_pool5 needs backward computation.
I0628 16:09:45.595854 23941 net.cpp:226] roi-data needs backward computation.
I0628 16:09:45.595857 23941 net.cpp:226] proposal needs backward computation.
I0628 16:09:45.595861 23941 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0628 16:09:45.595863 23941 net.cpp:226] rpn_cls_prob needs backward computation.
I0628 16:09:45.595865 23941 net.cpp:226] rpn_loss_bbox needs backward computation.
I0628 16:09:45.595868 23941 net.cpp:226] rpn_loss_cls needs backward computation.
I0628 16:09:45.595872 23941 net.cpp:226] rpn-data needs backward computation.
I0628 16:09:45.595876 23941 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0628 16:09:45.595880 23941 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0628 16:09:45.595881 23941 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0628 16:09:45.595883 23941 net.cpp:226] rpn_bbox_pred needs backward computation.
I0628 16:09:45.595886 23941 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0628 16:09:45.595888 23941 net.cpp:226] rpn_cls_score needs backward computation.
I0628 16:09:45.595890 23941 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0628 16:09:45.595893 23941 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0628 16:09:45.595896 23941 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0628 16:09:45.595897 23941 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0628 16:09:45.595901 23941 net.cpp:226] relu5_3 needs backward computation.
I0628 16:09:45.595902 23941 net.cpp:226] conv5_3 needs backward computation.
I0628 16:09:45.595904 23941 net.cpp:226] relu5_2 needs backward computation.
I0628 16:09:45.595906 23941 net.cpp:226] conv5_2 needs backward computation.
I0628 16:09:45.595908 23941 net.cpp:226] relu5_1 needs backward computation.
I0628 16:09:45.595911 23941 net.cpp:226] conv5_1 needs backward computation.
I0628 16:09:45.595912 23941 net.cpp:226] pool4 needs backward computation.
I0628 16:09:45.595914 23941 net.cpp:226] relu4_3 needs backward computation.
I0628 16:09:45.595916 23941 net.cpp:226] conv4_3 needs backward computation.
I0628 16:09:45.595918 23941 net.cpp:226] relu4_2 needs backward computation.
I0628 16:09:45.595921 23941 net.cpp:226] conv4_2 needs backward computation.
I0628 16:09:45.595922 23941 net.cpp:226] relu4_1 needs backward computation.
I0628 16:09:45.595924 23941 net.cpp:226] conv4_1 needs backward computation.
I0628 16:09:45.595927 23941 net.cpp:226] pool3 needs backward computation.
I0628 16:09:45.595928 23941 net.cpp:226] relu3_3 needs backward computation.
I0628 16:09:45.595930 23941 net.cpp:226] conv3_3 needs backward computation.
I0628 16:09:45.595932 23941 net.cpp:226] relu3_2 needs backward computation.
I0628 16:09:45.595933 23941 net.cpp:226] conv3_2 needs backward computation.
I0628 16:09:45.595935 23941 net.cpp:226] relu3_1 needs backward computation.
I0628 16:09:45.595937 23941 net.cpp:226] conv3_1 needs backward computation.
I0628 16:09:45.595939 23941 net.cpp:228] pool2 does not need backward computation.
I0628 16:09:45.595942 23941 net.cpp:228] relu2_2 does not need backward computation.
I0628 16:09:45.595944 23941 net.cpp:228] conv2_2 does not need backward computation.
I0628 16:09:45.595947 23941 net.cpp:228] relu2_1 does not need backward computation.
I0628 16:09:45.595948 23941 net.cpp:228] conv2_1 does not need backward computation.
I0628 16:09:45.595950 23941 net.cpp:228] pool1 does not need backward computation.
I0628 16:09:45.595952 23941 net.cpp:228] relu1_2 does not need backward computation.
I0628 16:09:45.595955 23941 net.cpp:228] conv1_2 does not need backward computation.
I0628 16:09:45.595957 23941 net.cpp:228] relu1_1 does not need backward computation.
I0628 16:09:45.595959 23941 net.cpp:228] conv1_1 does not need backward computation.
I0628 16:09:45.595962 23941 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0628 16:09:45.595964 23941 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0628 16:09:45.595968 23941 net.cpp:228] data_input-data_0_split does not need backward computation.
I0628 16:09:45.595971 23941 net.cpp:228] input-data does not need backward computation.
I0628 16:09:45.595973 23941 net.cpp:270] This network produces output cross_entropy_mean
I0628 16:09:45.595974 23941 net.cpp:270] This network produces output loss_bbox
I0628 16:09:45.595978 23941 net.cpp:270] This network produces output loss_cls
I0628 16:09:45.595979 23941 net.cpp:270] This network produces output rpn_cls_loss
I0628 16:09:45.595980 23941 net.cpp:270] This network produces output rpn_loss_bbox
I0628 16:09:45.596026 23941 net.cpp:283] Network initialization done.
I0628 16:09:45.596185 23941 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/vgg16_faster_rcnn_iter_5000.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 587271744
Solving...
I0628 16:09:49.094964 23941 solver.cpp:229] Iteration 0, loss = 1.38739
I0628 16:09:49.148209 23941 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.23474 (* 3 = 0.70422 loss)
I0628 16:09:49.148226 23941 solver.cpp:245]     Train net output #1: loss_bbox = 0.360412 (* 2 = 0.720824 loss)
I0628 16:09:49.148231 23941 solver.cpp:245]     Train net output #2: loss_cls = 0.0494107 (* 3 = 0.148232 loss)
I0628 16:09:49.148234 23941 solver.cpp:245]     Train net output #3: rpn_cls_loss = 7.98559e-05 (* 1 = 7.98559e-05 loss)
I0628 16:09:49.148238 23941 solver.cpp:245]     Train net output #4: rpn_loss_bbox = 0.000153878 (* 1 = 0.000153878 loss)
I0628 16:09:49.148243 23941 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0628 16:10:31.942361 23941 solver.cpp:229] Iteration 20, loss = 1.48893
I0628 16:10:31.996323 23941 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.168377 (* 3 = 0.505131 loss)
I0628 16:10:31.996349 23941 solver.cpp:245]     Train net output #1: loss_bbox = 0.465755 (* 2 = 0.93151 loss)
I0628 16:10:31.996353 23941 solver.cpp:245]     Train net output #2: loss_cls = 0.00189889 (* 3 = 0.00569666 loss)
I0628 16:10:31.996358 23941 solver.cpp:245]     Train net output #3: rpn_cls_loss = 0.000330214 (* 1 = 0.000330214 loss)
I0628 16:10:31.996362 23941 solver.cpp:245]     Train net output #4: rpn_loss_bbox = 0.000540925 (* 1 = 0.000540925 loss)
I0628 16:10:31.996377 23941 sgd_solver.cpp:106] Iteration 20, lr = 1e-05
I0628 16:11:13.832769 23941 solver.cpp:229] Iteration 40, loss = 1.3164
I0628 16:11:13.886715 23941 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.124396 (* 3 = 0.373187 loss)
I0628 16:11:13.886732 23941 solver.cpp:245]     Train net output #1: loss_bbox = 0.295234 (* 2 = 0.590469 loss)
I0628 16:11:13.886736 23941 solver.cpp:245]     Train net output #2: loss_cls = 0.000884529 (* 3 = 0.00265359 loss)
I0628 16:11:13.886740 23941 solver.cpp:245]     Train net output #3: rpn_cls_loss = 0.000152967 (* 1 = 0.000152967 loss)
I0628 16:11:13.886744 23941 solver.cpp:245]     Train net output #4: rpn_loss_bbox = 0.000885934 (* 1 = 0.000885934 loss)
I0628 16:11:13.886750 23941 sgd_solver.cpp:106] Iteration 40, lr = 1e-05
I0628 16:11:58.091545 23941 solver.cpp:229] Iteration 60, loss = 1.07873
I0628 16:11:58.149165 23941 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.0846715 (* 3 = 0.254015 loss)
I0628 16:11:58.149179 23941 solver.cpp:245]     Train net output #1: loss_bbox = 0.26204 (* 2 = 0.52408 loss)
I0628 16:11:58.149183 23941 solver.cpp:245]     Train net output #2: loss_cls = 0.00146026 (* 3 = 0.00438078 loss)
I0628 16:11:58.149188 23941 solver.cpp:245]     Train net output #3: rpn_cls_loss = 0.00182338 (* 1 = 0.00182338 loss)
I0628 16:11:58.149191 23941 solver.cpp:245]     Train net output #4: rpn_loss_bbox = 0.000614564 (* 1 = 0.000614564 loss)
I0628 16:11:58.149206 23941 sgd_solver.cpp:106] Iteration 60, lr = 1e-05
I0628 16:12:41.101923 23941 solver.cpp:229] Iteration 80, loss = 1.18246
I0628 16:12:41.156862 23941 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.218474 (* 3 = 0.655421 loss)
I0628 16:12:41.156873 23941 solver.cpp:245]     Train net output #1: loss_bbox = 0.370865 (* 2 = 0.741729 loss)
I0628 16:12:41.156877 23941 solver.cpp:245]     Train net output #2: loss_cls = 0.0291881 (* 3 = 0.0875643 loss)
I0628 16:12:41.156882 23941 solver.cpp:245]     Train net output #3: rpn_cls_loss = 0.00129988 (* 1 = 0.00129988 loss)
I0628 16:12:41.156885 23941 solver.cpp:245]     Train net output #4: rpn_loss_bbox = 0.0105926 (* 1 = 0.0105926 loss)
I0628 16:12:41.156890 23941 sgd_solver.cpp:106] Iteration 80, lr = 1e-05
I0628 16:13:25.032464 23941 solver.cpp:229] Iteration 100, loss = 1.83477
I0628 16:13:25.091398 23941 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.384828 (* 3 = 1.15449 loss)
I0628 16:13:25.091414 23941 solver.cpp:245]     Train net output #1: loss_bbox = 0.247294 (* 2 = 0.494588 loss)
I0628 16:13:25.091420 23941 solver.cpp:245]     Train net output #2: loss_cls = 0.00434385 (* 3 = 0.0130315 loss)
I0628 16:13:25.091425 23941 solver.cpp:245]     Train net output #3: rpn_cls_loss = 0.0107944 (* 1 = 0.0107944 loss)
I0628 16:13:25.091430 23941 solver.cpp:245]     Train net output #4: rpn_loss_bbox = 0.0101218 (* 1 = 0.0101218 loss)
I0628 16:13:25.091435 23941 sgd_solver.cpp:106] Iteration 100, lr = 1e-05
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:83: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:83: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:85: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:85: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:87: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:87: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:89: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:89: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/rpn/proposal_layer.py:187: RuntimeWarning: invalid value encountered in greater_equal
  keep = np.where((ws >= min_size) & (hs >= min_size))[0]
---- WARNING: filter_boxes() remove ALL proposal.
./experiments/scripts/faster_rcnn_end2end.sh: line 65: 23941 Floating point exception/usr/bin/python ./tools/train_net.py --gpu ${GPU_ID} --solver models/${PT_DIR}/${NET}/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/vgg16_faster_rcnn_iter_5000.caffemodel --imdb ${TRAIN_IMDB} --iters ${ITERS} --cfg experiments/cfgs/faster_rcnn_end2end.yml ${EXTRA_ARGS}
