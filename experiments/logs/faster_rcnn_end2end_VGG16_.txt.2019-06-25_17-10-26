+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-25_17-10-26
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-25_17-10-26
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0625 17:10:33.534987   431 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0625 17:10:33.535006   431 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0625 17:10:33.536365   431 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  top: "attrArray"
  top: "attrArrayInd"
  top: "attrArrayShift"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "attr_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "attr_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "attr_score_pos"
  type: "Eltwise"
  bottom: "attr_score"
  bottom: "attrArrayInd"
  top: "attr_score_pos"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "attr_score_pos_shift"
  type: "Eltwise"
  bottom: "attr_score_pos"
  bottom: "attrArrayShift"
  top: "attr_score_pos_shift"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_attribute"
  type: "SigmoidCrossEntropyLoss"
  bottom: "attr_score_pos_shift"
  bottom: "attrArray"
  top: "loss_attribute"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "mask_score"
  top: "mask_score_softmax"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "log"
  type: "Log"
  bottom: "mask_score_softmax"
  top: "log"
}
layer {
  name: "mult1"
  type: "Eltwise"
  bottom: "log"
  bottom: "mask_targets"
  top: "mult1"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "cross_entropy"
  type: "Power"
  bottom: "mult1"
  top: "cross_entropy"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "ce_sum"
  type: "Convolution"
  bottom: "cross_entropy"
  top: "cross_entropy_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "ce_mean"
  type: "Reduction"
  bottom: "cross_entropy_sum"
  top: "cross_entropy_mean"
  loss_weight: 1
  reduction_param {
    operation: MEAN
    axis: 0
  }
}
I0625 17:10:33.536696   431 layer_factory.hpp:77] Creating layer input-data
I0625 17:10:33.548399   431 net.cpp:106] Creating Layer input-data
I0625 17:10:33.548425   431 net.cpp:411] input-data -> data
I0625 17:10:33.548432   431 net.cpp:411] input-data -> im_info
I0625 17:10:33.548447   431 net.cpp:411] input-data -> gt_boxes
I0625 17:10:33.548454   431 net.cpp:411] input-data -> seg_mask_inds
I0625 17:10:33.548457   431 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0625 17:10:33.559553   431 net.cpp:150] Setting up input-data
I0625 17:10:33.559571   431 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 17:10:33.559584   431 net.cpp:157] Top shape: 1 3 (3)
I0625 17:10:33.559587   431 net.cpp:157] Top shape: 1 4 (4)
I0625 17:10:33.559602   431 net.cpp:157] Top shape: 1 2 (2)
I0625 17:10:33.559605   431 net.cpp:157] Top shape: 1 1 (1)
I0625 17:10:33.559609   431 net.cpp:165] Memory required for data: 7200040
I0625 17:10:33.559625   431 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0625 17:10:33.559639   431 net.cpp:106] Creating Layer data_input-data_0_split
I0625 17:10:33.559643   431 net.cpp:454] data_input-data_0_split <- data
I0625 17:10:33.559649   431 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0625 17:10:33.559657   431 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0625 17:10:33.559682   431 net.cpp:150] Setting up data_input-data_0_split
I0625 17:10:33.559696   431 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 17:10:33.559700   431 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 17:10:33.559713   431 net.cpp:165] Memory required for data: 21600040
I0625 17:10:33.559716   431 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0625 17:10:33.559721   431 net.cpp:106] Creating Layer im_info_input-data_1_split
I0625 17:10:33.559725   431 net.cpp:454] im_info_input-data_1_split <- im_info
I0625 17:10:33.559729   431 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0625 17:10:33.559736   431 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0625 17:10:33.559743   431 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0625 17:10:33.559767   431 net.cpp:150] Setting up im_info_input-data_1_split
I0625 17:10:33.559770   431 net.cpp:157] Top shape: 1 3 (3)
I0625 17:10:33.559772   431 net.cpp:157] Top shape: 1 3 (3)
I0625 17:10:33.559775   431 net.cpp:157] Top shape: 1 3 (3)
I0625 17:10:33.559777   431 net.cpp:165] Memory required for data: 21600076
I0625 17:10:33.559778   431 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0625 17:10:33.559782   431 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0625 17:10:33.559784   431 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0625 17:10:33.559788   431 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0625 17:10:33.559793   431 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0625 17:10:33.559814   431 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0625 17:10:33.559818   431 net.cpp:157] Top shape: 1 4 (4)
I0625 17:10:33.559823   431 net.cpp:157] Top shape: 1 4 (4)
I0625 17:10:33.559825   431 net.cpp:165] Memory required for data: 21600108
I0625 17:10:33.559828   431 layer_factory.hpp:77] Creating layer conv1_1
I0625 17:10:33.559835   431 net.cpp:106] Creating Layer conv1_1
I0625 17:10:33.559839   431 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0625 17:10:33.559842   431 net.cpp:411] conv1_1 -> conv1_1
I0625 17:10:33.722692   431 net.cpp:150] Setting up conv1_1
I0625 17:10:33.722710   431 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 17:10:33.722713   431 net.cpp:165] Memory required for data: 175200108
I0625 17:10:33.722724   431 layer_factory.hpp:77] Creating layer relu1_1
I0625 17:10:33.722745   431 net.cpp:106] Creating Layer relu1_1
I0625 17:10:33.722749   431 net.cpp:454] relu1_1 <- conv1_1
I0625 17:10:33.722754   431 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0625 17:10:33.722868   431 net.cpp:150] Setting up relu1_1
I0625 17:10:33.722874   431 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 17:10:33.722877   431 net.cpp:165] Memory required for data: 328800108
I0625 17:10:33.722878   431 layer_factory.hpp:77] Creating layer conv1_2
I0625 17:10:33.722885   431 net.cpp:106] Creating Layer conv1_2
I0625 17:10:33.722887   431 net.cpp:454] conv1_2 <- conv1_1
I0625 17:10:33.722890   431 net.cpp:411] conv1_2 -> conv1_2
I0625 17:10:33.725100   431 net.cpp:150] Setting up conv1_2
I0625 17:10:33.725109   431 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 17:10:33.725111   431 net.cpp:165] Memory required for data: 482400108
I0625 17:10:33.725117   431 layer_factory.hpp:77] Creating layer relu1_2
I0625 17:10:33.725122   431 net.cpp:106] Creating Layer relu1_2
I0625 17:10:33.725124   431 net.cpp:454] relu1_2 <- conv1_2
I0625 17:10:33.725138   431 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0625 17:10:33.725248   431 net.cpp:150] Setting up relu1_2
I0625 17:10:33.725255   431 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 17:10:33.725255   431 net.cpp:165] Memory required for data: 636000108
I0625 17:10:33.725258   431 layer_factory.hpp:77] Creating layer pool1
I0625 17:10:33.725263   431 net.cpp:106] Creating Layer pool1
I0625 17:10:33.725265   431 net.cpp:454] pool1 <- conv1_2
I0625 17:10:33.725270   431 net.cpp:411] pool1 -> pool1
I0625 17:10:33.725317   431 net.cpp:150] Setting up pool1
I0625 17:10:33.725322   431 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0625 17:10:33.725333   431 net.cpp:165] Memory required for data: 674400108
I0625 17:10:33.725335   431 layer_factory.hpp:77] Creating layer conv2_1
I0625 17:10:33.725339   431 net.cpp:106] Creating Layer conv2_1
I0625 17:10:33.725342   431 net.cpp:454] conv2_1 <- pool1
I0625 17:10:33.725345   431 net.cpp:411] conv2_1 -> conv2_1
I0625 17:10:33.727052   431 net.cpp:150] Setting up conv2_1
I0625 17:10:33.727062   431 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 17:10:33.727064   431 net.cpp:165] Memory required for data: 751200108
I0625 17:10:33.727071   431 layer_factory.hpp:77] Creating layer relu2_1
I0625 17:10:33.727075   431 net.cpp:106] Creating Layer relu2_1
I0625 17:10:33.727077   431 net.cpp:454] relu2_1 <- conv2_1
I0625 17:10:33.727090   431 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0625 17:10:33.727526   431 net.cpp:150] Setting up relu2_1
I0625 17:10:33.727535   431 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 17:10:33.727536   431 net.cpp:165] Memory required for data: 828000108
I0625 17:10:33.727538   431 layer_factory.hpp:77] Creating layer conv2_2
I0625 17:10:33.727543   431 net.cpp:106] Creating Layer conv2_2
I0625 17:10:33.727545   431 net.cpp:454] conv2_2 <- conv2_1
I0625 17:10:33.727550   431 net.cpp:411] conv2_2 -> conv2_2
I0625 17:10:33.728762   431 net.cpp:150] Setting up conv2_2
I0625 17:10:33.728771   431 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 17:10:33.728773   431 net.cpp:165] Memory required for data: 904800108
I0625 17:10:33.728777   431 layer_factory.hpp:77] Creating layer relu2_2
I0625 17:10:33.728781   431 net.cpp:106] Creating Layer relu2_2
I0625 17:10:33.728783   431 net.cpp:454] relu2_2 <- conv2_2
I0625 17:10:33.728786   431 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0625 17:10:33.728907   431 net.cpp:150] Setting up relu2_2
I0625 17:10:33.728914   431 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 17:10:33.728915   431 net.cpp:165] Memory required for data: 981600108
I0625 17:10:33.728917   431 layer_factory.hpp:77] Creating layer pool2
I0625 17:10:33.728921   431 net.cpp:106] Creating Layer pool2
I0625 17:10:33.728922   431 net.cpp:454] pool2 <- conv2_2
I0625 17:10:33.728926   431 net.cpp:411] pool2 -> pool2
I0625 17:10:33.728968   431 net.cpp:150] Setting up pool2
I0625 17:10:33.728972   431 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0625 17:10:33.728986   431 net.cpp:165] Memory required for data: 1000800108
I0625 17:10:33.728988   431 layer_factory.hpp:77] Creating layer conv3_1
I0625 17:10:33.728992   431 net.cpp:106] Creating Layer conv3_1
I0625 17:10:33.728994   431 net.cpp:454] conv3_1 <- pool2
I0625 17:10:33.729007   431 net.cpp:411] conv3_1 -> conv3_1
I0625 17:10:33.730978   431 net.cpp:150] Setting up conv3_1
I0625 17:10:33.731031   431 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:10:33.731042   431 net.cpp:165] Memory required for data: 1039200108
I0625 17:10:33.731062   431 layer_factory.hpp:77] Creating layer relu3_1
I0625 17:10:33.731081   431 net.cpp:106] Creating Layer relu3_1
I0625 17:10:33.731093   431 net.cpp:454] relu3_1 <- conv3_1
I0625 17:10:33.731106   431 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0625 17:10:33.731289   431 net.cpp:150] Setting up relu3_1
I0625 17:10:33.731308   431 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:10:33.731317   431 net.cpp:165] Memory required for data: 1077600108
I0625 17:10:33.731326   431 layer_factory.hpp:77] Creating layer conv3_2
I0625 17:10:33.731349   431 net.cpp:106] Creating Layer conv3_2
I0625 17:10:33.731360   431 net.cpp:454] conv3_2 <- conv3_1
I0625 17:10:33.731372   431 net.cpp:411] conv3_2 -> conv3_2
I0625 17:10:33.734674   431 net.cpp:150] Setting up conv3_2
I0625 17:10:33.734738   431 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:10:33.734753   431 net.cpp:165] Memory required for data: 1116000108
I0625 17:10:33.734776   431 layer_factory.hpp:77] Creating layer relu3_2
I0625 17:10:33.734800   431 net.cpp:106] Creating Layer relu3_2
I0625 17:10:33.734814   431 net.cpp:454] relu3_2 <- conv3_2
I0625 17:10:33.734830   431 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0625 17:10:33.735033   431 net.cpp:150] Setting up relu3_2
I0625 17:10:33.735054   431 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:10:33.735064   431 net.cpp:165] Memory required for data: 1154400108
I0625 17:10:33.735074   431 layer_factory.hpp:77] Creating layer conv3_3
I0625 17:10:33.735091   431 net.cpp:106] Creating Layer conv3_3
I0625 17:10:33.735102   431 net.cpp:454] conv3_3 <- conv3_2
I0625 17:10:33.735116   431 net.cpp:411] conv3_3 -> conv3_3
I0625 17:10:33.738242   431 net.cpp:150] Setting up conv3_3
I0625 17:10:33.738312   431 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:10:33.738323   431 net.cpp:165] Memory required for data: 1192800108
I0625 17:10:33.738340   431 layer_factory.hpp:77] Creating layer relu3_3
I0625 17:10:33.738360   431 net.cpp:106] Creating Layer relu3_3
I0625 17:10:33.738374   431 net.cpp:454] relu3_3 <- conv3_3
I0625 17:10:33.738386   431 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0625 17:10:33.738548   431 net.cpp:150] Setting up relu3_3
I0625 17:10:33.738564   431 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:10:33.738572   431 net.cpp:165] Memory required for data: 1231200108
I0625 17:10:33.738581   431 layer_factory.hpp:77] Creating layer pool3
I0625 17:10:33.738596   431 net.cpp:106] Creating Layer pool3
I0625 17:10:33.738605   431 net.cpp:454] pool3 <- conv3_3
I0625 17:10:33.738617   431 net.cpp:411] pool3 -> pool3
I0625 17:10:33.738665   431 net.cpp:150] Setting up pool3
I0625 17:10:33.738678   431 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0625 17:10:33.738687   431 net.cpp:165] Memory required for data: 1240800108
I0625 17:10:33.738695   431 layer_factory.hpp:77] Creating layer conv4_1
I0625 17:10:33.738713   431 net.cpp:106] Creating Layer conv4_1
I0625 17:10:33.738721   431 net.cpp:454] conv4_1 <- pool3
I0625 17:10:33.738734   431 net.cpp:411] conv4_1 -> conv4_1
I0625 17:10:33.744840   431 net.cpp:150] Setting up conv4_1
I0625 17:10:33.744864   431 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:10:33.744869   431 net.cpp:165] Memory required for data: 1260000108
I0625 17:10:33.744881   431 layer_factory.hpp:77] Creating layer relu4_1
I0625 17:10:33.744894   431 net.cpp:106] Creating Layer relu4_1
I0625 17:10:33.744910   431 net.cpp:454] relu4_1 <- conv4_1
I0625 17:10:33.744918   431 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0625 17:10:33.745091   431 net.cpp:150] Setting up relu4_1
I0625 17:10:33.745097   431 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:10:33.745110   431 net.cpp:165] Memory required for data: 1279200108
I0625 17:10:33.745111   431 layer_factory.hpp:77] Creating layer conv4_2
I0625 17:10:33.745120   431 net.cpp:106] Creating Layer conv4_2
I0625 17:10:33.745122   431 net.cpp:454] conv4_2 <- conv4_1
I0625 17:10:33.745129   431 net.cpp:411] conv4_2 -> conv4_2
I0625 17:10:33.751101   431 net.cpp:150] Setting up conv4_2
I0625 17:10:33.751123   431 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:10:33.751127   431 net.cpp:165] Memory required for data: 1298400108
I0625 17:10:33.751139   431 layer_factory.hpp:77] Creating layer relu4_2
I0625 17:10:33.751147   431 net.cpp:106] Creating Layer relu4_2
I0625 17:10:33.751150   431 net.cpp:454] relu4_2 <- conv4_2
I0625 17:10:33.751159   431 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0625 17:10:33.751658   431 net.cpp:150] Setting up relu4_2
I0625 17:10:33.751668   431 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:10:33.751672   431 net.cpp:165] Memory required for data: 1317600108
I0625 17:10:33.751675   431 layer_factory.hpp:77] Creating layer conv4_3
I0625 17:10:33.751685   431 net.cpp:106] Creating Layer conv4_3
I0625 17:10:33.751701   431 net.cpp:454] conv4_3 <- conv4_2
I0625 17:10:33.751716   431 net.cpp:411] conv4_3 -> conv4_3
I0625 17:10:33.757084   431 net.cpp:150] Setting up conv4_3
I0625 17:10:33.757112   431 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:10:33.757117   431 net.cpp:165] Memory required for data: 1336800108
I0625 17:10:33.757128   431 layer_factory.hpp:77] Creating layer relu4_3
I0625 17:10:33.757139   431 net.cpp:106] Creating Layer relu4_3
I0625 17:10:33.757145   431 net.cpp:454] relu4_3 <- conv4_3
I0625 17:10:33.757151   431 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0625 17:10:33.757298   431 net.cpp:150] Setting up relu4_3
I0625 17:10:33.757305   431 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:10:33.757309   431 net.cpp:165] Memory required for data: 1356000108
I0625 17:10:33.757313   431 layer_factory.hpp:77] Creating layer pool4
I0625 17:10:33.757334   431 net.cpp:106] Creating Layer pool4
I0625 17:10:33.757339   431 net.cpp:454] pool4 <- conv4_3
I0625 17:10:33.757344   431 net.cpp:411] pool4 -> pool4
I0625 17:10:33.757386   431 net.cpp:150] Setting up pool4
I0625 17:10:33.757392   431 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:10:33.757395   431 net.cpp:165] Memory required for data: 1360903020
I0625 17:10:33.757398   431 layer_factory.hpp:77] Creating layer conv5_1
I0625 17:10:33.757408   431 net.cpp:106] Creating Layer conv5_1
I0625 17:10:33.757412   431 net.cpp:454] conv5_1 <- pool4
I0625 17:10:33.757419   431 net.cpp:411] conv5_1 -> conv5_1
I0625 17:10:33.762850   431 net.cpp:150] Setting up conv5_1
I0625 17:10:33.762874   431 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:10:33.762877   431 net.cpp:165] Memory required for data: 1365805932
I0625 17:10:33.762887   431 layer_factory.hpp:77] Creating layer relu5_1
I0625 17:10:33.762897   431 net.cpp:106] Creating Layer relu5_1
I0625 17:10:33.762917   431 net.cpp:454] relu5_1 <- conv5_1
I0625 17:10:33.762934   431 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0625 17:10:33.763079   431 net.cpp:150] Setting up relu5_1
I0625 17:10:33.763087   431 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:10:33.763090   431 net.cpp:165] Memory required for data: 1370708844
I0625 17:10:33.763094   431 layer_factory.hpp:77] Creating layer conv5_2
I0625 17:10:33.763119   431 net.cpp:106] Creating Layer conv5_2
I0625 17:10:33.763132   431 net.cpp:454] conv5_2 <- conv5_1
I0625 17:10:33.763146   431 net.cpp:411] conv5_2 -> conv5_2
I0625 17:10:33.768415   431 net.cpp:150] Setting up conv5_2
I0625 17:10:33.768440   431 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:10:33.768443   431 net.cpp:165] Memory required for data: 1375611756
I0625 17:10:33.768452   431 layer_factory.hpp:77] Creating layer relu5_2
I0625 17:10:33.768465   431 net.cpp:106] Creating Layer relu5_2
I0625 17:10:33.768469   431 net.cpp:454] relu5_2 <- conv5_2
I0625 17:10:33.768476   431 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0625 17:10:33.768636   431 net.cpp:150] Setting up relu5_2
I0625 17:10:33.768645   431 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:10:33.768647   431 net.cpp:165] Memory required for data: 1380514668
I0625 17:10:33.768651   431 layer_factory.hpp:77] Creating layer conv5_3
I0625 17:10:33.768676   431 net.cpp:106] Creating Layer conv5_3
I0625 17:10:33.768690   431 net.cpp:454] conv5_3 <- conv5_2
I0625 17:10:33.768705   431 net.cpp:411] conv5_3 -> conv5_3
I0625 17:10:33.774557   431 net.cpp:150] Setting up conv5_3
I0625 17:10:33.774585   431 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:10:33.774591   431 net.cpp:165] Memory required for data: 1385417580
I0625 17:10:33.774603   431 layer_factory.hpp:77] Creating layer relu5_3
I0625 17:10:33.774639   431 net.cpp:106] Creating Layer relu5_3
I0625 17:10:33.774659   431 net.cpp:454] relu5_3 <- conv5_3
I0625 17:10:33.774677   431 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0625 17:10:33.774860   431 net.cpp:150] Setting up relu5_3
I0625 17:10:33.774873   431 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:10:33.774876   431 net.cpp:165] Memory required for data: 1390320492
I0625 17:10:33.774881   431 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0625 17:10:33.774899   431 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0625 17:10:33.774911   431 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0625 17:10:33.774926   431 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0625 17:10:33.774943   431 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0625 17:10:33.774960   431 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0625 17:10:33.775032   431 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0625 17:10:33.775041   431 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:10:33.775045   431 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:10:33.775049   431 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:10:33.775061   431 net.cpp:165] Memory required for data: 1405029228
I0625 17:10:33.775074   431 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0625 17:10:33.775095   431 net.cpp:106] Creating Layer rpn_conv/3x3
I0625 17:10:33.775108   431 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0625 17:10:33.775125   431 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0625 17:10:33.829342   431 net.cpp:150] Setting up rpn_conv/3x3
I0625 17:10:33.829363   431 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:10:33.829367   431 net.cpp:165] Memory required for data: 1409932140
I0625 17:10:33.829376   431 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0625 17:10:33.829386   431 net.cpp:106] Creating Layer rpn_relu/3x3
I0625 17:10:33.829392   431 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0625 17:10:33.829398   431 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0625 17:10:33.829540   431 net.cpp:150] Setting up rpn_relu/3x3
I0625 17:10:33.829547   431 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:10:33.829550   431 net.cpp:165] Memory required for data: 1414835052
I0625 17:10:33.829552   431 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0625 17:10:33.829557   431 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0625 17:10:33.829560   431 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0625 17:10:33.829565   431 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0625 17:10:33.829571   431 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0625 17:10:33.829607   431 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0625 17:10:33.829612   431 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:10:33.829614   431 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:10:33.829615   431 net.cpp:165] Memory required for data: 1424640876
I0625 17:10:33.829617   431 layer_factory.hpp:77] Creating layer rpn_cls_score
I0625 17:10:33.829627   431 net.cpp:106] Creating Layer rpn_cls_score
I0625 17:10:33.829629   431 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0625 17:10:33.829636   431 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0625 17:10:33.831288   431 net.cpp:150] Setting up rpn_cls_score
I0625 17:10:33.831297   431 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 17:10:33.831300   431 net.cpp:165] Memory required for data: 1424928156
I0625 17:10:33.831305   431 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0625 17:10:33.831310   431 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0625 17:10:33.831312   431 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0625 17:10:33.831326   431 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0625 17:10:33.831331   431 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0625 17:10:33.831382   431 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0625 17:10:33.831395   431 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 17:10:33.831398   431 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 17:10:33.831399   431 net.cpp:165] Memory required for data: 1425502716
I0625 17:10:33.831411   431 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0625 17:10:33.831418   431 net.cpp:106] Creating Layer rpn_bbox_pred
I0625 17:10:33.831419   431 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0625 17:10:33.831432   431 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0625 17:10:33.833081   431 net.cpp:150] Setting up rpn_bbox_pred
I0625 17:10:33.833089   431 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:10:33.833091   431 net.cpp:165] Memory required for data: 1426077276
I0625 17:10:33.833096   431 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 17:10:33.833101   431 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 17:10:33.833113   431 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0625 17:10:33.833117   431 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0625 17:10:33.833137   431 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0625 17:10:33.833191   431 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 17:10:33.833195   431 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:10:33.833199   431 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:10:33.833199   431 net.cpp:165] Memory required for data: 1427226396
I0625 17:10:33.833218   431 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0625 17:10:33.833225   431 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0625 17:10:33.833242   431 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0625 17:10:33.833245   431 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0625 17:10:33.833283   431 net.cpp:150] Setting up rpn_cls_score_reshape
I0625 17:10:33.833287   431 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 17:10:33.833298   431 net.cpp:165] Memory required for data: 1427513676
I0625 17:10:33.833299   431 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 17:10:33.833302   431 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 17:10:33.833304   431 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0625 17:10:33.833320   431 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0625 17:10:33.833324   431 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0625 17:10:33.833376   431 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 17:10:33.833381   431 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 17:10:33.833393   431 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 17:10:33.833395   431 net.cpp:165] Memory required for data: 1428088236
I0625 17:10:33.833397   431 layer_factory.hpp:77] Creating layer rpn-data
I0625 17:10:33.833720   431 net.cpp:106] Creating Layer rpn-data
I0625 17:10:33.833729   431 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0625 17:10:33.833732   431 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0625 17:10:33.833735   431 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0625 17:10:33.833739   431 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0625 17:10:33.833743   431 net.cpp:411] rpn-data -> rpn_labels
I0625 17:10:33.833762   431 net.cpp:411] rpn-data -> rpn_bbox_targets
I0625 17:10:33.833767   431 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0625 17:10:33.833787   431 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0625 17:10:33.834700   431 net.cpp:150] Setting up rpn-data
I0625 17:10:33.834708   431 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0625 17:10:33.834712   431 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:10:33.834713   431 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:10:33.834715   431 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:10:33.834717   431 net.cpp:165] Memory required for data: 1429955556
I0625 17:10:33.834718   431 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0625 17:10:33.834724   431 net.cpp:106] Creating Layer rpn_loss_cls
I0625 17:10:33.834736   431 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0625 17:10:33.834740   431 net.cpp:454] rpn_loss_cls <- rpn_labels
I0625 17:10:33.834758   431 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0625 17:10:33.834782   431 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0625 17:10:33.835378   431 net.cpp:150] Setting up rpn_loss_cls
I0625 17:10:33.835386   431 net.cpp:157] Top shape: (1)
I0625 17:10:33.835387   431 net.cpp:160]     with loss weight 1
I0625 17:10:33.835393   431 net.cpp:165] Memory required for data: 1429955560
I0625 17:10:33.835397   431 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0625 17:10:33.835418   431 net.cpp:106] Creating Layer rpn_loss_bbox
I0625 17:10:33.835422   431 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0625 17:10:33.835436   431 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0625 17:10:33.835439   431 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0625 17:10:33.835441   431 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0625 17:10:33.835444   431 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0625 17:10:33.836549   431 net.cpp:150] Setting up rpn_loss_bbox
I0625 17:10:33.836557   431 net.cpp:157] Top shape: (1)
I0625 17:10:33.836560   431 net.cpp:160]     with loss weight 1
I0625 17:10:33.836562   431 net.cpp:165] Memory required for data: 1429955564
I0625 17:10:33.836565   431 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0625 17:10:33.836570   431 net.cpp:106] Creating Layer rpn_cls_prob
I0625 17:10:33.836585   431 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0625 17:10:33.836587   431 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0625 17:10:33.836773   431 net.cpp:150] Setting up rpn_cls_prob
I0625 17:10:33.836779   431 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 17:10:33.836781   431 net.cpp:165] Memory required for data: 1430242844
I0625 17:10:33.836782   431 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0625 17:10:33.836787   431 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0625 17:10:33.836791   431 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0625 17:10:33.836804   431 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0625 17:10:33.836841   431 net.cpp:150] Setting up rpn_cls_prob_reshape
I0625 17:10:33.836844   431 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 17:10:33.836846   431 net.cpp:165] Memory required for data: 1430530124
I0625 17:10:33.836848   431 layer_factory.hpp:77] Creating layer proposal
I0625 17:10:33.837329   431 net.cpp:106] Creating Layer proposal
I0625 17:10:33.837337   431 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0625 17:10:33.837339   431 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0625 17:10:33.837342   431 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0625 17:10:33.837345   431 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0625 17:10:33.838122   431 net.cpp:150] Setting up proposal
I0625 17:10:33.838130   431 net.cpp:157] Top shape: 1 5 (5)
I0625 17:10:33.838132   431 net.cpp:165] Memory required for data: 1430530144
I0625 17:10:33.838135   431 layer_factory.hpp:77] Creating layer roi-data
I0625 17:10:33.838378   431 net.cpp:106] Creating Layer roi-data
I0625 17:10:33.838385   431 net.cpp:454] roi-data <- rpn_rois
I0625 17:10:33.838389   431 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0625 17:10:33.838392   431 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0625 17:10:33.838394   431 net.cpp:454] roi-data <- seg_mask_inds
I0625 17:10:33.838397   431 net.cpp:454] roi-data <- flipped
I0625 17:10:33.838412   431 net.cpp:411] roi-data -> rois
I0625 17:10:33.838418   431 net.cpp:411] roi-data -> labels
I0625 17:10:33.838434   431 net.cpp:411] roi-data -> bbox_targets
I0625 17:10:33.838439   431 net.cpp:411] roi-data -> bbox_inside_weights
I0625 17:10:33.838459   431 net.cpp:411] roi-data -> bbox_outside_weights
I0625 17:10:33.838464   431 net.cpp:411] roi-data -> mask_targets
I0625 17:10:33.838480   431 net.cpp:411] roi-data -> rois_pos
I0625 17:10:33.838485   431 net.cpp:411] roi-data -> attrArray
I0625 17:10:33.838497   431 net.cpp:411] roi-data -> attrArrayInd
I0625 17:10:33.838501   431 net.cpp:411] roi-data -> attrArrayShift
I0625 17:10:33.838819   431 net.cpp:150] Setting up roi-data
I0625 17:10:33.838826   431 net.cpp:157] Top shape: 1 5 (5)
I0625 17:10:33.838829   431 net.cpp:157] Top shape: 1 1 (1)
I0625 17:10:33.838830   431 net.cpp:157] Top shape: 1 8 (8)
I0625 17:10:33.838832   431 net.cpp:157] Top shape: 1 8 (8)
I0625 17:10:33.838835   431 net.cpp:157] Top shape: 1 8 (8)
I0625 17:10:33.838837   431 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:10:33.838850   431 net.cpp:157] Top shape: 1 5 (5)
I0625 17:10:33.838853   431 net.cpp:157] Top shape: 1 7 (7)
I0625 17:10:33.838855   431 net.cpp:157] Top shape: 1 7 (7)
I0625 17:10:33.838857   431 net.cpp:157] Top shape: 1 7 (7)
I0625 17:10:33.838871   431 net.cpp:165] Memory required for data: 1432435520
I0625 17:10:33.838873   431 layer_factory.hpp:77] Creating layer roi_pool5
I0625 17:10:33.838878   431 net.cpp:106] Creating Layer roi_pool5
I0625 17:10:33.838891   431 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0625 17:10:33.838894   431 net.cpp:454] roi_pool5 <- rois
I0625 17:10:33.838908   431 net.cpp:411] roi_pool5 -> pool5
I0625 17:10:33.838913   431 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0625 17:10:33.839026   431 net.cpp:150] Setting up roi_pool5
I0625 17:10:33.839031   431 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:10:33.839043   431 net.cpp:165] Memory required for data: 1432535872
I0625 17:10:33.839046   431 layer_factory.hpp:77] Creating layer fc6
I0625 17:10:33.839061   431 net.cpp:106] Creating Layer fc6
I0625 17:10:33.839066   431 net.cpp:454] fc6 <- pool5
I0625 17:10:33.839082   431 net.cpp:411] fc6 -> fc6
I0625 17:10:33.986543   431 net.cpp:150] Setting up fc6
I0625 17:10:33.986567   431 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:10:33.986568   431 net.cpp:165] Memory required for data: 1432552256
I0625 17:10:33.986583   431 layer_factory.hpp:77] Creating layer relu6
I0625 17:10:33.986603   431 net.cpp:106] Creating Layer relu6
I0625 17:10:33.986611   431 net.cpp:454] relu6 <- fc6
I0625 17:10:33.986616   431 net.cpp:397] relu6 -> fc6 (in-place)
I0625 17:10:33.986799   431 net.cpp:150] Setting up relu6
I0625 17:10:33.986805   431 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:10:33.986807   431 net.cpp:165] Memory required for data: 1432568640
I0625 17:10:33.986809   431 layer_factory.hpp:77] Creating layer fc7
I0625 17:10:33.986817   431 net.cpp:106] Creating Layer fc7
I0625 17:10:33.986819   431 net.cpp:454] fc7 <- fc6
I0625 17:10:33.986824   431 net.cpp:411] fc7 -> fc7
I0625 17:10:34.011099   431 net.cpp:150] Setting up fc7
I0625 17:10:34.011121   431 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:10:34.011123   431 net.cpp:165] Memory required for data: 1432585024
I0625 17:10:34.011132   431 layer_factory.hpp:77] Creating layer relu7
I0625 17:10:34.011139   431 net.cpp:106] Creating Layer relu7
I0625 17:10:34.011145   431 net.cpp:454] relu7 <- fc7
I0625 17:10:34.011162   431 net.cpp:397] relu7 -> fc7 (in-place)
I0625 17:10:34.011340   431 net.cpp:150] Setting up relu7
I0625 17:10:34.011348   431 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:10:34.011349   431 net.cpp:165] Memory required for data: 1432601408
I0625 17:10:34.011351   431 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0625 17:10:34.011355   431 net.cpp:106] Creating Layer fc7_relu7_0_split
I0625 17:10:34.011358   431 net.cpp:454] fc7_relu7_0_split <- fc7
I0625 17:10:34.011361   431 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0625 17:10:34.011366   431 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0625 17:10:34.011381   431 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0625 17:10:34.011427   431 net.cpp:150] Setting up fc7_relu7_0_split
I0625 17:10:34.011431   431 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:10:34.011433   431 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:10:34.011435   431 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:10:34.011437   431 net.cpp:165] Memory required for data: 1432650560
I0625 17:10:34.011440   431 layer_factory.hpp:77] Creating layer attr_score
I0625 17:10:34.011445   431 net.cpp:106] Creating Layer attr_score
I0625 17:10:34.011447   431 net.cpp:454] attr_score <- fc7_relu7_0_split_0
I0625 17:10:34.011463   431 net.cpp:411] attr_score -> attr_score
I0625 17:10:34.012109   431 net.cpp:150] Setting up attr_score
I0625 17:10:34.012115   431 net.cpp:157] Top shape: 1 7 (7)
I0625 17:10:34.012116   431 net.cpp:165] Memory required for data: 1432650588
I0625 17:10:34.012120   431 layer_factory.hpp:77] Creating layer attr_score_pos
I0625 17:10:34.012125   431 net.cpp:106] Creating Layer attr_score_pos
I0625 17:10:34.012127   431 net.cpp:454] attr_score_pos <- attr_score
I0625 17:10:34.012130   431 net.cpp:454] attr_score_pos <- attrArrayInd
I0625 17:10:34.012135   431 net.cpp:411] attr_score_pos -> attr_score_pos
I0625 17:10:34.012172   431 net.cpp:150] Setting up attr_score_pos
I0625 17:10:34.012176   431 net.cpp:157] Top shape: 1 7 (7)
I0625 17:10:34.012177   431 net.cpp:165] Memory required for data: 1432650616
I0625 17:10:34.012189   431 layer_factory.hpp:77] Creating layer attr_score_pos_shift
I0625 17:10:34.012192   431 net.cpp:106] Creating Layer attr_score_pos_shift
I0625 17:10:34.012194   431 net.cpp:454] attr_score_pos_shift <- attr_score_pos
I0625 17:10:34.012197   431 net.cpp:454] attr_score_pos_shift <- attrArrayShift
I0625 17:10:34.012209   431 net.cpp:411] attr_score_pos_shift -> attr_score_pos_shift
I0625 17:10:34.012235   431 net.cpp:150] Setting up attr_score_pos_shift
I0625 17:10:34.012251   431 net.cpp:157] Top shape: 1 7 (7)
I0625 17:10:34.012253   431 net.cpp:165] Memory required for data: 1432650644
I0625 17:10:34.012254   431 layer_factory.hpp:77] Creating layer cls_score
I0625 17:10:34.012270   431 net.cpp:106] Creating Layer cls_score
I0625 17:10:34.012274   431 net.cpp:454] cls_score <- fc7_relu7_0_split_1
I0625 17:10:34.012276   431 net.cpp:411] cls_score -> cls_score
I0625 17:10:34.012564   431 net.cpp:150] Setting up cls_score
I0625 17:10:34.012568   431 net.cpp:157] Top shape: 1 2 (2)
I0625 17:10:34.012570   431 net.cpp:165] Memory required for data: 1432650652
I0625 17:10:34.012584   431 layer_factory.hpp:77] Creating layer bbox_pred
I0625 17:10:34.012588   431 net.cpp:106] Creating Layer bbox_pred
I0625 17:10:34.012591   431 net.cpp:454] bbox_pred <- fc7_relu7_0_split_2
I0625 17:10:34.012609   431 net.cpp:411] bbox_pred -> bbox_pred
I0625 17:10:34.013366   431 net.cpp:150] Setting up bbox_pred
I0625 17:10:34.013370   431 net.cpp:157] Top shape: 1 8 (8)
I0625 17:10:34.013372   431 net.cpp:165] Memory required for data: 1432650684
I0625 17:10:34.013375   431 layer_factory.hpp:77] Creating layer loss_attribute
I0625 17:10:34.013381   431 net.cpp:106] Creating Layer loss_attribute
I0625 17:10:34.013382   431 net.cpp:454] loss_attribute <- attr_score_pos_shift
I0625 17:10:34.013386   431 net.cpp:454] loss_attribute <- attrArray
I0625 17:10:34.013401   431 net.cpp:411] loss_attribute -> loss_attribute
I0625 17:10:34.013461   431 net.cpp:150] Setting up loss_attribute
I0625 17:10:34.013464   431 net.cpp:157] Top shape: (1)
I0625 17:10:34.013466   431 net.cpp:160]     with loss weight 1
I0625 17:10:34.013484   431 net.cpp:165] Memory required for data: 1432650688
I0625 17:10:34.013495   431 layer_factory.hpp:77] Creating layer loss_cls
I0625 17:10:34.013499   431 net.cpp:106] Creating Layer loss_cls
I0625 17:10:34.013502   431 net.cpp:454] loss_cls <- cls_score
I0625 17:10:34.013514   431 net.cpp:454] loss_cls <- labels
I0625 17:10:34.013517   431 net.cpp:411] loss_cls -> loss_cls
I0625 17:10:34.013522   431 layer_factory.hpp:77] Creating layer loss_cls
I0625 17:10:34.014134   431 net.cpp:150] Setting up loss_cls
I0625 17:10:34.014142   431 net.cpp:157] Top shape: (1)
I0625 17:10:34.014143   431 net.cpp:160]     with loss weight 3
I0625 17:10:34.014147   431 net.cpp:165] Memory required for data: 1432650692
I0625 17:10:34.014148   431 layer_factory.hpp:77] Creating layer loss_bbox
I0625 17:10:34.014169   431 net.cpp:106] Creating Layer loss_bbox
I0625 17:10:34.014173   431 net.cpp:454] loss_bbox <- bbox_pred
I0625 17:10:34.014176   431 net.cpp:454] loss_bbox <- bbox_targets
I0625 17:10:34.014181   431 net.cpp:454] loss_bbox <- bbox_inside_weights
I0625 17:10:34.014185   431 net.cpp:454] loss_bbox <- bbox_outside_weights
I0625 17:10:34.014200   431 net.cpp:411] loss_bbox -> loss_bbox
I0625 17:10:34.014262   431 net.cpp:150] Setting up loss_bbox
I0625 17:10:34.014268   431 net.cpp:157] Top shape: (1)
I0625 17:10:34.014281   431 net.cpp:160]     with loss weight 2
I0625 17:10:34.014283   431 net.cpp:165] Memory required for data: 1432650696
I0625 17:10:34.014286   431 layer_factory.hpp:77] Creating layer roi_pool5_2
I0625 17:10:34.014292   431 net.cpp:106] Creating Layer roi_pool5_2
I0625 17:10:34.014295   431 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0625 17:10:34.014299   431 net.cpp:454] roi_pool5_2 <- rois_pos
I0625 17:10:34.014314   431 net.cpp:411] roi_pool5_2 -> pool5_2
I0625 17:10:34.014318   431 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0625 17:10:34.014425   431 net.cpp:150] Setting up roi_pool5_2
I0625 17:10:34.014430   431 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:10:34.014441   431 net.cpp:165] Memory required for data: 1432751048
I0625 17:10:34.014443   431 layer_factory.hpp:77] Creating layer pool5_2_conv
I0625 17:10:34.014451   431 net.cpp:106] Creating Layer pool5_2_conv
I0625 17:10:34.014462   431 net.cpp:454] pool5_2_conv <- pool5_2
I0625 17:10:34.014467   431 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0625 17:10:34.021023   431 net.cpp:150] Setting up pool5_2_conv
I0625 17:10:34.021034   431 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:10:34.021036   431 net.cpp:165] Memory required for data: 1432851400
I0625 17:10:34.021041   431 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0625 17:10:34.021047   431 net.cpp:106] Creating Layer pool5_2_conv_relu
I0625 17:10:34.021049   431 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0625 17:10:34.021064   431 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0625 17:10:34.021203   431 net.cpp:150] Setting up pool5_2_conv_relu
I0625 17:10:34.021210   431 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:10:34.021212   431 net.cpp:165] Memory required for data: 1432951752
I0625 17:10:34.021214   431 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0625 17:10:34.021220   431 net.cpp:106] Creating Layer pool5_2_conv2
I0625 17:10:34.021222   431 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0625 17:10:34.021225   431 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0625 17:10:34.071911   431 net.cpp:150] Setting up pool5_2_conv2
I0625 17:10:34.071928   431 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:10:34.071931   431 net.cpp:165] Memory required for data: 1433052104
I0625 17:10:34.071938   431 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0625 17:10:34.071945   431 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0625 17:10:34.071960   431 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0625 17:10:34.071964   431 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0625 17:10:34.072104   431 net.cpp:150] Setting up pool5_2_conv2_relu
I0625 17:10:34.072110   431 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:10:34.072113   431 net.cpp:165] Memory required for data: 1433152456
I0625 17:10:34.072114   431 layer_factory.hpp:77] Creating layer mask_deconv1
I0625 17:10:34.072121   431 net.cpp:106] Creating Layer mask_deconv1
I0625 17:10:34.072124   431 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0625 17:10:34.072127   431 net.cpp:411] mask_deconv1 -> mask_deconv1
I0625 17:10:34.072892   431 net.cpp:150] Setting up mask_deconv1
I0625 17:10:34.072897   431 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0625 17:10:34.072898   431 net.cpp:165] Memory required for data: 1434074056
I0625 17:10:34.072902   431 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0625 17:10:34.072909   431 net.cpp:106] Creating Layer pool5_2_conv3
I0625 17:10:34.072912   431 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0625 17:10:34.072926   431 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0625 17:10:34.098886   431 net.cpp:150] Setting up pool5_2_conv3
I0625 17:10:34.098914   431 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:10:34.098917   431 net.cpp:165] Memory required for data: 1435917256
I0625 17:10:34.098923   431 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0625 17:10:34.098944   431 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0625 17:10:34.098951   431 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0625 17:10:34.098958   431 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0625 17:10:34.099140   431 net.cpp:150] Setting up pool5_2_conv3_relu
I0625 17:10:34.099148   431 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:10:34.099149   431 net.cpp:165] Memory required for data: 1437760456
I0625 17:10:34.099153   431 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0625 17:10:34.099171   431 net.cpp:106] Creating Layer pool5_2_conv4
I0625 17:10:34.099175   431 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0625 17:10:34.099189   431 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0625 17:10:34.149310   431 net.cpp:150] Setting up pool5_2_conv4
I0625 17:10:34.149328   431 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:10:34.149332   431 net.cpp:165] Memory required for data: 1439603656
I0625 17:10:34.149338   431 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0625 17:10:34.149358   431 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0625 17:10:34.149363   431 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0625 17:10:34.149379   431 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0625 17:10:34.149529   431 net.cpp:150] Setting up pool5_2_conv4_relu
I0625 17:10:34.149536   431 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:10:34.149538   431 net.cpp:165] Memory required for data: 1441446856
I0625 17:10:34.149540   431 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0625 17:10:34.149544   431 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0625 17:10:34.149546   431 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0625 17:10:34.149549   431 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0625 17:10:34.149564   431 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0625 17:10:34.149569   431 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0625 17:10:34.149583   431 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0625 17:10:34.149649   431 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0625 17:10:34.149653   431 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:10:34.149657   431 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:10:34.149658   431 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:10:34.149660   431 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:10:34.149662   431 net.cpp:165] Memory required for data: 1448819656
I0625 17:10:34.149663   431 layer_factory.hpp:77] Creating layer query_conv
I0625 17:10:34.149688   431 net.cpp:106] Creating Layer query_conv
I0625 17:10:34.149690   431 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0625 17:10:34.149694   431 net.cpp:411] query_conv -> query_conv
I0625 17:10:34.151491   431 net.cpp:150] Setting up query_conv
I0625 17:10:34.151504   431 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0625 17:10:34.151507   431 net.cpp:165] Memory required for data: 1449050056
I0625 17:10:34.151515   431 layer_factory.hpp:77] Creating layer key_conv
I0625 17:10:34.151527   431 net.cpp:106] Creating Layer key_conv
I0625 17:10:34.151535   431 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0625 17:10:34.151543   431 net.cpp:411] key_conv -> key_conv
I0625 17:10:34.153354   431 net.cpp:150] Setting up key_conv
I0625 17:10:34.153364   431 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0625 17:10:34.153368   431 net.cpp:165] Memory required for data: 1449280456
I0625 17:10:34.153385   431 layer_factory.hpp:77] Creating layer value_conv
I0625 17:10:34.153398   431 net.cpp:106] Creating Layer value_conv
I0625 17:10:34.153403   431 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0625 17:10:34.153410   431 net.cpp:411] value_conv -> value_conv
I0625 17:10:34.165067   431 net.cpp:150] Setting up value_conv
I0625 17:10:34.165086   431 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:10:34.165088   431 net.cpp:165] Memory required for data: 1451123656
I0625 17:10:34.165096   431 layer_factory.hpp:77] Creating layer query_conv_reshape
I0625 17:10:34.165123   431 net.cpp:106] Creating Layer query_conv_reshape
I0625 17:10:34.165129   431 net.cpp:454] query_conv_reshape <- query_conv
I0625 17:10:34.165136   431 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0625 17:10:34.165185   431 net.cpp:150] Setting up query_conv_reshape
I0625 17:10:34.165191   431 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0625 17:10:34.165194   431 net.cpp:165] Memory required for data: 1451354056
I0625 17:10:34.165197   431 layer_factory.hpp:77] Creating layer key_conv_reshape
I0625 17:10:34.165204   431 net.cpp:106] Creating Layer key_conv_reshape
I0625 17:10:34.165243   431 net.cpp:454] key_conv_reshape <- key_conv
I0625 17:10:34.165259   431 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0625 17:10:34.165283   431 net.cpp:150] Setting up key_conv_reshape
I0625 17:10:34.165289   431 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0625 17:10:34.165293   431 net.cpp:165] Memory required for data: 1451584456
I0625 17:10:34.165297   431 layer_factory.hpp:77] Creating layer value_conv_reshape
I0625 17:10:34.165302   431 net.cpp:106] Creating Layer value_conv_reshape
I0625 17:10:34.165304   431 net.cpp:454] value_conv_reshape <- value_conv
I0625 17:10:34.165308   431 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0625 17:10:34.165325   431 net.cpp:150] Setting up value_conv_reshape
I0625 17:10:34.165329   431 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0625 17:10:34.165330   431 net.cpp:165] Memory required for data: 1453427656
I0625 17:10:34.165333   431 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0625 17:10:34.165341   431 net.cpp:106] Creating Layer query_conv_reshape_perm
I0625 17:10:34.165344   431 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0625 17:10:34.165347   431 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0625 17:10:34.165423   431 net.cpp:150] Setting up query_conv_reshape_perm
I0625 17:10:34.165427   431 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0625 17:10:34.165429   431 net.cpp:165] Memory required for data: 1453658056
I0625 17:10:34.165441   431 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0625 17:10:34.165443   431 net.cpp:106] Creating Layer key_conv_reshape_perm
I0625 17:10:34.165446   431 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0625 17:10:34.165449   431 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0625 17:10:34.165515   431 net.cpp:150] Setting up key_conv_reshape_perm
I0625 17:10:34.165519   431 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0625 17:10:34.165521   431 net.cpp:165] Memory required for data: 1453888456
I0625 17:10:34.165532   431 layer_factory.hpp:77] Creating layer energy
I0625 17:10:34.165536   431 net.cpp:106] Creating Layer energy
I0625 17:10:34.165539   431 net.cpp:454] energy <- query_conv_reshape_perm
I0625 17:10:34.165540   431 net.cpp:454] energy <- key_conv_reshape_perm
I0625 17:10:34.165545   431 net.cpp:411] energy -> energy
I0625 17:10:34.165563   431 net.cpp:150] Setting up energy
I0625 17:10:34.165567   431 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0625 17:10:34.165571   431 net.cpp:165] Memory required for data: 1457128456
I0625 17:10:34.165575   431 layer_factory.hpp:77] Creating layer attention
I0625 17:10:34.165581   431 net.cpp:106] Creating Layer attention
I0625 17:10:34.165585   431 net.cpp:454] attention <- energy
I0625 17:10:34.165591   431 net.cpp:411] attention -> attention
I0625 17:10:34.165750   431 net.cpp:150] Setting up attention
I0625 17:10:34.165756   431 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0625 17:10:34.165758   431 net.cpp:165] Memory required for data: 1460368456
I0625 17:10:34.165760   431 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0625 17:10:34.165765   431 net.cpp:106] Creating Layer value_conv_reshape_perm
I0625 17:10:34.165767   431 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0625 17:10:34.165771   431 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0625 17:10:34.165838   431 net.cpp:150] Setting up value_conv_reshape_perm
I0625 17:10:34.165843   431 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0625 17:10:34.165845   431 net.cpp:165] Memory required for data: 1462211656
I0625 17:10:34.165849   431 layer_factory.hpp:77] Creating layer attention_perm
I0625 17:10:34.165854   431 net.cpp:106] Creating Layer attention_perm
I0625 17:10:34.165858   431 net.cpp:454] attention_perm <- attention
I0625 17:10:34.165865   431 net.cpp:411] attention_perm -> attention_perm
I0625 17:10:34.165930   431 net.cpp:150] Setting up attention_perm
I0625 17:10:34.165933   431 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0625 17:10:34.165937   431 net.cpp:165] Memory required for data: 1465451656
I0625 17:10:34.165941   431 layer_factory.hpp:77] Creating layer out
I0625 17:10:34.165947   431 net.cpp:106] Creating Layer out
I0625 17:10:34.165951   431 net.cpp:454] out <- value_conv_reshape_perm
I0625 17:10:34.165954   431 net.cpp:454] out <- attention_perm
I0625 17:10:34.165958   431 net.cpp:411] out -> out
I0625 17:10:34.165974   431 net.cpp:150] Setting up out
I0625 17:10:34.165978   431 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0625 17:10:34.165980   431 net.cpp:165] Memory required for data: 1467294856
I0625 17:10:34.165982   431 layer_factory.hpp:77] Creating layer out_reshape
I0625 17:10:34.165985   431 net.cpp:106] Creating Layer out_reshape
I0625 17:10:34.165988   431 net.cpp:454] out_reshape <- out
I0625 17:10:34.165992   431 net.cpp:411] out_reshape -> out_reshape
I0625 17:10:34.166007   431 net.cpp:150] Setting up out_reshape
I0625 17:10:34.166010   431 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:10:34.166013   431 net.cpp:165] Memory required for data: 1469138056
I0625 17:10:34.166013   431 layer_factory.hpp:77] Creating layer out_reshape_scale
I0625 17:10:34.166020   431 net.cpp:106] Creating Layer out_reshape_scale
I0625 17:10:34.166024   431 net.cpp:454] out_reshape_scale <- out_reshape
I0625 17:10:34.166028   431 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0625 17:10:34.166091   431 net.cpp:150] Setting up out_reshape_scale
I0625 17:10:34.166096   431 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:10:34.166100   431 net.cpp:165] Memory required for data: 1470981256
I0625 17:10:34.166105   431 layer_factory.hpp:77] Creating layer out_x
I0625 17:10:34.166111   431 net.cpp:106] Creating Layer out_x
I0625 17:10:34.166115   431 net.cpp:454] out_x <- out_reshape_scale
I0625 17:10:34.166121   431 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0625 17:10:34.166127   431 net.cpp:411] out_x -> out_x
I0625 17:10:34.166146   431 net.cpp:150] Setting up out_x
I0625 17:10:34.166151   431 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:10:34.166154   431 net.cpp:165] Memory required for data: 1472824456
I0625 17:10:34.166157   431 layer_factory.hpp:77] Creating layer mask_deconv2
I0625 17:10:34.166165   431 net.cpp:106] Creating Layer mask_deconv2
I0625 17:10:34.166168   431 net.cpp:454] mask_deconv2 <- out_x
I0625 17:10:34.166172   431 net.cpp:411] mask_deconv2 -> mask_deconv2
I0625 17:10:34.166970   431 net.cpp:150] Setting up mask_deconv2
I0625 17:10:34.166975   431 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0625 17:10:34.166976   431 net.cpp:165] Memory required for data: 1488065672
I0625 17:10:34.166980   431 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0625 17:10:34.166987   431 net.cpp:106] Creating Layer pool5_2_conv5
I0625 17:10:34.166990   431 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0625 17:10:34.166995   431 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0625 17:10:34.192777   431 net.cpp:150] Setting up pool5_2_conv5
I0625 17:10:34.192795   431 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 17:10:34.192797   431 net.cpp:165] Memory required for data: 1518548104
I0625 17:10:34.192804   431 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0625 17:10:34.192811   431 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0625 17:10:34.192826   431 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0625 17:10:34.192831   431 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0625 17:10:34.192991   431 net.cpp:150] Setting up pool5_2_conv5_relu
I0625 17:10:34.192997   431 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 17:10:34.192999   431 net.cpp:165] Memory required for data: 1549030536
I0625 17:10:34.193001   431 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0625 17:10:34.193009   431 net.cpp:106] Creating Layer pool5_2_conv6
I0625 17:10:34.193011   431 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0625 17:10:34.193017   431 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0625 17:10:34.243136   431 net.cpp:150] Setting up pool5_2_conv6
I0625 17:10:34.243153   431 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 17:10:34.243156   431 net.cpp:165] Memory required for data: 1579512968
I0625 17:10:34.243171   431 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0625 17:10:34.243192   431 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0625 17:10:34.243199   431 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0625 17:10:34.243206   431 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0625 17:10:34.243700   431 net.cpp:150] Setting up pool5_2_conv6_relu
I0625 17:10:34.243707   431 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 17:10:34.243710   431 net.cpp:165] Memory required for data: 1609995400
I0625 17:10:34.243711   431 layer_factory.hpp:77] Creating layer mask_deconv3
I0625 17:10:34.243718   431 net.cpp:106] Creating Layer mask_deconv3
I0625 17:10:34.243721   431 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0625 17:10:34.243727   431 net.cpp:411] mask_deconv3 -> mask_deconv3
I0625 17:10:34.244120   431 net.cpp:150] Setting up mask_deconv3
I0625 17:10:34.244127   431 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0625 17:10:34.244127   431 net.cpp:165] Memory required for data: 1670960264
I0625 17:10:34.244132   431 layer_factory.hpp:77] Creating layer mask_score
I0625 17:10:34.244138   431 net.cpp:106] Creating Layer mask_score
I0625 17:10:34.244140   431 net.cpp:454] mask_score <- mask_deconv3
I0625 17:10:34.244143   431 net.cpp:411] mask_score -> mask_score
I0625 17:10:34.244755   431 net.cpp:150] Setting up mask_score
I0625 17:10:34.244762   431 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:10:34.244765   431 net.cpp:165] Memory required for data: 1672865416
I0625 17:10:34.244767   431 layer_factory.hpp:77] Creating layer prob
I0625 17:10:34.244783   431 net.cpp:106] Creating Layer prob
I0625 17:10:34.244787   431 net.cpp:454] prob <- mask_score
I0625 17:10:34.244804   431 net.cpp:411] prob -> mask_score_softmax
I0625 17:10:34.245354   431 net.cpp:150] Setting up prob
I0625 17:10:34.245362   431 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:10:34.245363   431 net.cpp:165] Memory required for data: 1674770568
I0625 17:10:34.245366   431 layer_factory.hpp:77] Creating layer log
I0625 17:10:34.245369   431 net.cpp:106] Creating Layer log
I0625 17:10:34.245371   431 net.cpp:454] log <- mask_score_softmax
I0625 17:10:34.245375   431 net.cpp:411] log -> log
I0625 17:10:34.245414   431 net.cpp:150] Setting up log
I0625 17:10:34.245419   431 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:10:34.245420   431 net.cpp:165] Memory required for data: 1676675720
I0625 17:10:34.245431   431 layer_factory.hpp:77] Creating layer mult1
I0625 17:10:34.245436   431 net.cpp:106] Creating Layer mult1
I0625 17:10:34.245438   431 net.cpp:454] mult1 <- log
I0625 17:10:34.245450   431 net.cpp:454] mult1 <- mask_targets
I0625 17:10:34.245455   431 net.cpp:411] mult1 -> mult1
I0625 17:10:34.245479   431 net.cpp:150] Setting up mult1
I0625 17:10:34.245482   431 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:10:34.245484   431 net.cpp:165] Memory required for data: 1678580872
I0625 17:10:34.245496   431 layer_factory.hpp:77] Creating layer cross_entropy
I0625 17:10:34.245499   431 net.cpp:106] Creating Layer cross_entropy
I0625 17:10:34.245501   431 net.cpp:454] cross_entropy <- mult1
I0625 17:10:34.245514   431 net.cpp:411] cross_entropy -> cross_entropy
I0625 17:10:34.245540   431 net.cpp:150] Setting up cross_entropy
I0625 17:10:34.245544   431 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:10:34.245556   431 net.cpp:165] Memory required for data: 1680486024
I0625 17:10:34.245558   431 layer_factory.hpp:77] Creating layer ce_sum
I0625 17:10:34.245568   431 net.cpp:106] Creating Layer ce_sum
I0625 17:10:34.245570   431 net.cpp:454] ce_sum <- cross_entropy
I0625 17:10:34.245574   431 net.cpp:411] ce_sum -> cross_entropy_sum
I0625 17:10:34.246760   431 net.cpp:150] Setting up ce_sum
I0625 17:10:34.246768   431 net.cpp:157] Top shape: 1 1 244 244 (59536)
I0625 17:10:34.246770   431 net.cpp:165] Memory required for data: 1680724168
I0625 17:10:34.246773   431 layer_factory.hpp:77] Creating layer ce_mean
I0625 17:10:34.246783   431 net.cpp:106] Creating Layer ce_mean
I0625 17:10:34.246786   431 net.cpp:454] ce_mean <- cross_entropy_sum
I0625 17:10:34.246803   431 net.cpp:411] ce_mean -> cross_entropy_mean
I0625 17:10:34.247427   431 net.cpp:150] Setting up ce_mean
I0625 17:10:34.247436   431 net.cpp:157] Top shape: (1)
I0625 17:10:34.247437   431 net.cpp:160]     with loss weight 1
I0625 17:10:34.247444   431 net.cpp:165] Memory required for data: 1680724172
I0625 17:10:34.247447   431 net.cpp:226] ce_mean needs backward computation.
I0625 17:10:34.247460   431 net.cpp:226] ce_sum needs backward computation.
I0625 17:10:34.247462   431 net.cpp:226] cross_entropy needs backward computation.
I0625 17:10:34.247463   431 net.cpp:226] mult1 needs backward computation.
I0625 17:10:34.247465   431 net.cpp:226] log needs backward computation.
I0625 17:10:34.247467   431 net.cpp:226] prob needs backward computation.
I0625 17:10:34.247469   431 net.cpp:226] mask_score needs backward computation.
I0625 17:10:34.247470   431 net.cpp:226] mask_deconv3 needs backward computation.
I0625 17:10:34.247473   431 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0625 17:10:34.247474   431 net.cpp:226] pool5_2_conv6 needs backward computation.
I0625 17:10:34.247475   431 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0625 17:10:34.247478   431 net.cpp:226] pool5_2_conv5 needs backward computation.
I0625 17:10:34.247480   431 net.cpp:226] mask_deconv2 needs backward computation.
I0625 17:10:34.247481   431 net.cpp:226] out_x needs backward computation.
I0625 17:10:34.247488   431 net.cpp:226] out_reshape_scale needs backward computation.
I0625 17:10:34.247489   431 net.cpp:226] out_reshape needs backward computation.
I0625 17:10:34.247491   431 net.cpp:226] out needs backward computation.
I0625 17:10:34.247493   431 net.cpp:226] attention_perm needs backward computation.
I0625 17:10:34.247496   431 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0625 17:10:34.247506   431 net.cpp:226] attention needs backward computation.
I0625 17:10:34.247509   431 net.cpp:226] energy needs backward computation.
I0625 17:10:34.247511   431 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0625 17:10:34.247514   431 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0625 17:10:34.247525   431 net.cpp:226] value_conv_reshape needs backward computation.
I0625 17:10:34.247529   431 net.cpp:226] key_conv_reshape needs backward computation.
I0625 17:10:34.247530   431 net.cpp:226] query_conv_reshape needs backward computation.
I0625 17:10:34.247534   431 net.cpp:226] value_conv needs backward computation.
I0625 17:10:34.247537   431 net.cpp:226] key_conv needs backward computation.
I0625 17:10:34.247540   431 net.cpp:226] query_conv needs backward computation.
I0625 17:10:34.247542   431 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0625 17:10:34.247545   431 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0625 17:10:34.247555   431 net.cpp:226] pool5_2_conv4 needs backward computation.
I0625 17:10:34.247556   431 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0625 17:10:34.247558   431 net.cpp:226] pool5_2_conv3 needs backward computation.
I0625 17:10:34.247561   431 net.cpp:226] mask_deconv1 needs backward computation.
I0625 17:10:34.247575   431 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0625 17:10:34.247576   431 net.cpp:226] pool5_2_conv2 needs backward computation.
I0625 17:10:34.247578   431 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0625 17:10:34.247582   431 net.cpp:226] pool5_2_conv needs backward computation.
I0625 17:10:34.247586   431 net.cpp:226] roi_pool5_2 needs backward computation.
I0625 17:10:34.247591   431 net.cpp:226] loss_bbox needs backward computation.
I0625 17:10:34.247596   431 net.cpp:226] loss_cls needs backward computation.
I0625 17:10:34.247601   431 net.cpp:226] loss_attribute needs backward computation.
I0625 17:10:34.247606   431 net.cpp:226] bbox_pred needs backward computation.
I0625 17:10:34.247609   431 net.cpp:226] cls_score needs backward computation.
I0625 17:10:34.247613   431 net.cpp:226] attr_score_pos_shift needs backward computation.
I0625 17:10:34.247617   431 net.cpp:226] attr_score_pos needs backward computation.
I0625 17:10:34.247622   431 net.cpp:226] attr_score needs backward computation.
I0625 17:10:34.247625   431 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0625 17:10:34.247629   431 net.cpp:226] relu7 needs backward computation.
I0625 17:10:34.247632   431 net.cpp:226] fc7 needs backward computation.
I0625 17:10:34.247635   431 net.cpp:226] relu6 needs backward computation.
I0625 17:10:34.247638   431 net.cpp:226] fc6 needs backward computation.
I0625 17:10:34.247642   431 net.cpp:226] roi_pool5 needs backward computation.
I0625 17:10:34.247645   431 net.cpp:226] roi-data needs backward computation.
I0625 17:10:34.247651   431 net.cpp:226] proposal needs backward computation.
I0625 17:10:34.247656   431 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0625 17:10:34.247659   431 net.cpp:226] rpn_cls_prob needs backward computation.
I0625 17:10:34.247663   431 net.cpp:226] rpn_loss_bbox needs backward computation.
I0625 17:10:34.247668   431 net.cpp:226] rpn_loss_cls needs backward computation.
I0625 17:10:34.247673   431 net.cpp:226] rpn-data needs backward computation.
I0625 17:10:34.247678   431 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0625 17:10:34.247681   431 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0625 17:10:34.247685   431 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0625 17:10:34.247689   431 net.cpp:226] rpn_bbox_pred needs backward computation.
I0625 17:10:34.247691   431 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0625 17:10:34.247697   431 net.cpp:226] rpn_cls_score needs backward computation.
I0625 17:10:34.247701   431 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0625 17:10:34.247705   431 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0625 17:10:34.247709   431 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0625 17:10:34.247711   431 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0625 17:10:34.247715   431 net.cpp:226] relu5_3 needs backward computation.
I0625 17:10:34.247718   431 net.cpp:226] conv5_3 needs backward computation.
I0625 17:10:34.247721   431 net.cpp:226] relu5_2 needs backward computation.
I0625 17:10:34.247725   431 net.cpp:226] conv5_2 needs backward computation.
I0625 17:10:34.247727   431 net.cpp:226] relu5_1 needs backward computation.
I0625 17:10:34.247730   431 net.cpp:226] conv5_1 needs backward computation.
I0625 17:10:34.247733   431 net.cpp:226] pool4 needs backward computation.
I0625 17:10:34.247737   431 net.cpp:226] relu4_3 needs backward computation.
I0625 17:10:34.247741   431 net.cpp:226] conv4_3 needs backward computation.
I0625 17:10:34.247745   431 net.cpp:226] relu4_2 needs backward computation.
I0625 17:10:34.247748   431 net.cpp:226] conv4_2 needs backward computation.
I0625 17:10:34.247751   431 net.cpp:226] relu4_1 needs backward computation.
I0625 17:10:34.247756   431 net.cpp:226] conv4_1 needs backward computation.
I0625 17:10:34.247758   431 net.cpp:226] pool3 needs backward computation.
I0625 17:10:34.247762   431 net.cpp:226] relu3_3 needs backward computation.
I0625 17:10:34.247766   431 net.cpp:226] conv3_3 needs backward computation.
I0625 17:10:34.247769   431 net.cpp:226] relu3_2 needs backward computation.
I0625 17:10:34.247773   431 net.cpp:226] conv3_2 needs backward computation.
I0625 17:10:34.247776   431 net.cpp:226] relu3_1 needs backward computation.
I0625 17:10:34.247779   431 net.cpp:226] conv3_1 needs backward computation.
I0625 17:10:34.247782   431 net.cpp:228] pool2 does not need backward computation.
I0625 17:10:34.247786   431 net.cpp:228] relu2_2 does not need backward computation.
I0625 17:10:34.247789   431 net.cpp:228] conv2_2 does not need backward computation.
I0625 17:10:34.247793   431 net.cpp:228] relu2_1 does not need backward computation.
I0625 17:10:34.247797   431 net.cpp:228] conv2_1 does not need backward computation.
I0625 17:10:34.247809   431 net.cpp:228] pool1 does not need backward computation.
I0625 17:10:34.247813   431 net.cpp:228] relu1_2 does not need backward computation.
I0625 17:10:34.247817   431 net.cpp:228] conv1_2 does not need backward computation.
I0625 17:10:34.247822   431 net.cpp:228] relu1_1 does not need backward computation.
I0625 17:10:34.247825   431 net.cpp:228] conv1_1 does not need backward computation.
I0625 17:10:34.247829   431 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0625 17:10:34.247833   431 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0625 17:10:34.247838   431 net.cpp:228] data_input-data_0_split does not need backward computation.
I0625 17:10:34.247844   431 net.cpp:228] input-data does not need backward computation.
I0625 17:10:34.247848   431 net.cpp:270] This network produces output cross_entropy_mean
I0625 17:10:34.247850   431 net.cpp:270] This network produces output loss_attribute
I0625 17:10:34.247854   431 net.cpp:270] This network produces output loss_bbox
I0625 17:10:34.247867   431 net.cpp:270] This network produces output loss_cls
I0625 17:10:34.247870   431 net.cpp:270] This network produces output rpn_cls_loss
I0625 17:10:34.247874   431 net.cpp:270] This network produces output rpn_loss_bbox
I0625 17:10:34.247927   431 net.cpp:283] Network initialization done.
I0625 17:10:34.248095   431 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0625 17:10:34.795480   431 net.cpp:816] Ignoring source layer pool5
I0625 17:10:34.858361   431 net.cpp:816] Ignoring source layer drop6
I0625 17:10:34.868443   431 net.cpp:816] Ignoring source layer drop7
I0625 17:10:34.868458   431 net.cpp:816] Ignoring source layer fc8
Solving...
I0625 17:10:35.961835   431 solver.cpp:229] Iteration 0, loss = 5.57038
I0625 17:10:36.015204   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.54325 (* 1 = 1.54325 loss)
I0625 17:10:36.015231   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.304792 (* 1 = 0.304792 loss)
I0625 17:10:36.015238   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.0916567 (* 2 = 0.183313 loss)
I0625 17:10:36.015254   431 solver.cpp:245]     Train net output #3: loss_cls = 0.947394 (* 3 = 2.84218 loss)
I0625 17:10:36.015262   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.73882 (* 1 = 0.73882 loss)
I0625 17:10:36.015269   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0189577 (* 1 = 0.0189577 loss)
I0625 17:10:36.015275   431 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0625 17:10:53.819918   431 solver.cpp:229] Iteration 20, loss = 3.07356
I0625 17:10:53.876727   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.64199 (* 1 = 1.64199 loss)
I0625 17:10:53.876744   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.37301 (* 1 = 0.37301 loss)
I0625 17:10:53.876749   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.364068 (* 2 = 0.728136 loss)
I0625 17:10:53.876752   431 solver.cpp:245]     Train net output #3: loss_cls = 0.127757 (* 3 = 0.38327 loss)
I0625 17:10:53.876757   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.168101 (* 1 = 0.168101 loss)
I0625 17:10:53.876761   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0284442 (* 1 = 0.0284442 loss)
I0625 17:10:53.876766   431 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0625 17:11:19.131338   431 solver.cpp:229] Iteration 40, loss = 2.53946
I0625 17:11:19.186915   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.32397 (* 1 = 1.32397 loss)
I0625 17:11:19.186931   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.310257 (* 1 = 0.310257 loss)
I0625 17:11:19.186935   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.18314 (* 2 = 0.366281 loss)
I0625 17:11:19.186939   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0277677 (* 3 = 0.0833031 loss)
I0625 17:11:19.186944   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.128303 (* 1 = 0.128303 loss)
I0625 17:11:19.186946   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0205821 (* 1 = 0.0205821 loss)
I0625 17:11:19.186961   431 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0625 17:11:48.372936   431 solver.cpp:229] Iteration 60, loss = 2.71183
I0625 17:11:48.431262   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.19292 (* 1 = 1.19292 loss)
I0625 17:11:48.431282   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.120332 (* 1 = 0.120332 loss)
I0625 17:11:48.431288   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.153249 (* 2 = 0.306499 loss)
I0625 17:11:48.431291   431 solver.cpp:245]     Train net output #3: loss_cls = 0.00887024 (* 3 = 0.0266107 loss)
I0625 17:11:48.431295   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0931192 (* 1 = 0.0931192 loss)
I0625 17:11:48.431299   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0123107 (* 1 = 0.0123107 loss)
I0625 17:11:48.431305   431 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0625 17:12:21.113713   431 solver.cpp:229] Iteration 80, loss = 2.18115
I0625 17:12:21.171633   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.07358 (* 1 = 1.07358 loss)
I0625 17:12:21.171649   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.167433 (* 1 = 0.167433 loss)
I0625 17:12:21.171654   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.0855343 (* 2 = 0.171069 loss)
I0625 17:12:21.171659   431 solver.cpp:245]     Train net output #3: loss_cls = 0.105066 (* 3 = 0.315197 loss)
I0625 17:12:21.171663   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0581356 (* 1 = 0.0581356 loss)
I0625 17:12:21.171667   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0829422 (* 1 = 0.0829422 loss)
I0625 17:12:21.171672   431 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0625 17:12:58.840795   431 solver.cpp:229] Iteration 100, loss = 2.40017
I0625 17:12:58.895040   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.12563 (* 1 = 1.12563 loss)
I0625 17:12:58.895056   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.130636 (* 1 = 0.130636 loss)
I0625 17:12:58.895061   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.241166 (* 2 = 0.482333 loss)
I0625 17:12:58.895076   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0687737 (* 3 = 0.206321 loss)
I0625 17:12:58.895081   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0424446 (* 1 = 0.0424446 loss)
I0625 17:12:58.895097   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.144122 (* 1 = 0.144122 loss)
I0625 17:12:58.895102   431 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0625 17:13:37.865828   431 solver.cpp:229] Iteration 120, loss = 2.22142
I0625 17:13:37.920171   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.33526 (* 1 = 1.33526 loss)
I0625 17:13:37.920189   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.160311 (* 1 = 0.160311 loss)
I0625 17:13:37.920194   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.425708 (* 2 = 0.851416 loss)
I0625 17:13:37.920198   431 solver.cpp:245]     Train net output #3: loss_cls = 0.073629 (* 3 = 0.220887 loss)
I0625 17:13:37.920203   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0087875 (* 1 = 0.0087875 loss)
I0625 17:13:37.920207   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0138365 (* 1 = 0.0138365 loss)
I0625 17:13:37.920223   431 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0625 17:14:19.406522   431 solver.cpp:229] Iteration 140, loss = 3.66523
I0625 17:14:19.460312   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.813556 (* 1 = 0.813556 loss)
I0625 17:14:19.460326   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.508975 (* 1 = 0.508975 loss)
I0625 17:14:19.460332   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.433333 (* 2 = 0.866666 loss)
I0625 17:14:19.460340   431 solver.cpp:245]     Train net output #3: loss_cls = 0.20749 (* 3 = 0.622471 loss)
I0625 17:14:19.460346   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.135397 (* 1 = 0.135397 loss)
I0625 17:14:19.460350   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0487467 (* 1 = 0.0487467 loss)
I0625 17:14:19.460356   431 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0625 17:14:58.967244   431 solver.cpp:229] Iteration 160, loss = 1.48888
I0625 17:14:59.023162   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.11871 (* 1 = 1.11871 loss)
I0625 17:14:59.023177   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.0360566 (* 1 = 0.0360566 loss)
I0625 17:14:59.023182   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.096574 (* 2 = 0.193148 loss)
I0625 17:14:59.023186   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0270089 (* 3 = 0.0810267 loss)
I0625 17:14:59.023190   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0312138 (* 1 = 0.0312138 loss)
I0625 17:14:59.023193   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0146506 (* 1 = 0.0146506 loss)
I0625 17:14:59.023209   431 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0625 17:15:38.182801   431 solver.cpp:229] Iteration 180, loss = 2.20803
I0625 17:15:38.239941   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.46406 (* 1 = 1.46406 loss)
I0625 17:15:38.239959   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.196917 (* 1 = 0.196917 loss)
I0625 17:15:38.239964   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.302858 (* 2 = 0.605715 loss)
I0625 17:15:38.239967   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0395617 (* 3 = 0.118685 loss)
I0625 17:15:38.239971   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.017621 (* 1 = 0.017621 loss)
I0625 17:15:38.239976   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0065726 (* 1 = 0.0065726 loss)
I0625 17:15:38.239981   431 sgd_solver.cpp:106] Iteration 180, lr = 0.001
speed: 1.741s / iter
I0625 17:16:25.714831   431 solver.cpp:229] Iteration 200, loss = 3.08964
I0625 17:16:25.769287   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.408272 (* 1 = 0.408272 loss)
I0625 17:16:25.769316   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.715453 (* 1 = 0.715453 loss)
I0625 17:16:25.769321   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.478665 (* 2 = 0.95733 loss)
I0625 17:16:25.769325   431 solver.cpp:245]     Train net output #3: loss_cls = 0.125791 (* 3 = 0.377373 loss)
I0625 17:16:25.769330   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0123481 (* 1 = 0.0123481 loss)
I0625 17:16:25.769343   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0563588 (* 1 = 0.0563588 loss)
I0625 17:16:25.769348   431 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0625 17:17:13.500636   431 solver.cpp:229] Iteration 220, loss = 2.22226
I0625 17:17:13.555127   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.20349 (* 1 = 1.20349 loss)
I0625 17:17:13.555145   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.299689 (* 1 = 0.299689 loss)
I0625 17:17:13.555150   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.22385 (* 2 = 0.447699 loss)
I0625 17:17:13.555153   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0186398 (* 3 = 0.0559195 loss)
I0625 17:17:13.555157   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00555298 (* 1 = 0.00555298 loss)
I0625 17:17:13.555161   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00331531 (* 1 = 0.00331531 loss)
I0625 17:17:13.555177   431 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0625 17:17:58.783834   431 solver.cpp:229] Iteration 240, loss = 2.51617
I0625 17:17:58.838943   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.350531 (* 1 = 0.350531 loss)
I0625 17:17:58.838975   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.703466 (* 1 = 0.703466 loss)
I0625 17:17:58.838981   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.52064 (* 2 = 1.04128 loss)
I0625 17:17:58.838986   431 solver.cpp:245]     Train net output #3: loss_cls = 0.123667 (* 3 = 0.371002 loss)
I0625 17:17:58.839001   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0503215 (* 1 = 0.0503215 loss)
I0625 17:17:58.839009   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.103068 (* 1 = 0.103068 loss)
I0625 17:17:58.839017   431 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0625 17:18:41.037125   431 solver.cpp:229] Iteration 260, loss = 1.78581
I0625 17:18:41.092217   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.03265 (* 1 = 1.03265 loss)
I0625 17:18:41.092232   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.061857 (* 1 = 0.061857 loss)
I0625 17:18:41.092237   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.113137 (* 2 = 0.226274 loss)
I0625 17:18:41.092242   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0570405 (* 3 = 0.171122 loss)
I0625 17:18:41.092247   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00442181 (* 1 = 0.00442181 loss)
I0625 17:18:41.092250   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0131884 (* 1 = 0.0131884 loss)
I0625 17:18:41.092257   431 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0625 17:19:29.925388   431 solver.cpp:229] Iteration 280, loss = 2.75098
I0625 17:19:29.982048   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.507 (* 1 = 1.507 loss)
I0625 17:19:29.982064   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.348281 (* 1 = 0.348281 loss)
I0625 17:19:29.982070   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.555418 (* 2 = 1.11084 loss)
I0625 17:19:29.982075   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0791813 (* 3 = 0.237544 loss)
I0625 17:19:29.982079   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0285098 (* 1 = 0.0285098 loss)
I0625 17:19:29.982084   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00752143 (* 1 = 0.00752143 loss)
I0625 17:19:29.982089   431 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0625 17:20:16.514582   431 solver.cpp:229] Iteration 300, loss = 1.45481
I0625 17:20:16.572016   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.514156 (* 1 = 0.514156 loss)
I0625 17:20:16.572029   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.0556089 (* 1 = 0.0556089 loss)
I0625 17:20:16.572034   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.162698 (* 2 = 0.325396 loss)
I0625 17:20:16.572039   431 solver.cpp:245]     Train net output #3: loss_cls = 0.00703296 (* 3 = 0.0210989 loss)
I0625 17:20:16.572044   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00347647 (* 1 = 0.00347647 loss)
I0625 17:20:16.572048   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0270518 (* 1 = 0.0270518 loss)
I0625 17:20:16.572054   431 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0625 17:21:04.069195   431 solver.cpp:229] Iteration 320, loss = 1.64816
I0625 17:21:04.122983   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.957061 (* 1 = 0.957061 loss)
I0625 17:21:04.123001   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.0715308 (* 1 = 0.0715308 loss)
I0625 17:21:04.123006   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.155093 (* 2 = 0.310186 loss)
I0625 17:21:04.123010   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0544915 (* 3 = 0.163475 loss)
I0625 17:21:04.123014   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00626968 (* 1 = 0.00626968 loss)
I0625 17:21:04.123018   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00227661 (* 1 = 0.00227661 loss)
I0625 17:21:04.123024   431 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0625 17:21:50.559998   431 solver.cpp:229] Iteration 340, loss = 2.34283
I0625 17:21:50.615883   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.1199 (* 1 = 1.1199 loss)
I0625 17:21:50.615900   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.137508 (* 1 = 0.137508 loss)
I0625 17:21:50.615905   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.260512 (* 2 = 0.521024 loss)
I0625 17:21:50.615907   431 solver.cpp:245]     Train net output #3: loss_cls = 0.214039 (* 3 = 0.642116 loss)
I0625 17:21:50.615911   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0400701 (* 1 = 0.0400701 loss)
I0625 17:21:50.615916   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00906375 (* 1 = 0.00906375 loss)
I0625 17:21:50.615921   431 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0625 17:22:40.463917   431 solver.cpp:229] Iteration 360, loss = 1.70181
I0625 17:22:40.516800   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.474474 (* 1 = 0.474474 loss)
I0625 17:22:40.516813   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.44835 (* 1 = 0.44835 loss)
I0625 17:22:40.516818   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.294543 (* 2 = 0.589085 loss)
I0625 17:22:40.516821   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0767901 (* 3 = 0.23037 loss)
I0625 17:22:40.516825   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0363604 (* 1 = 0.0363604 loss)
I0625 17:22:40.516829   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0143418 (* 1 = 0.0143418 loss)
I0625 17:22:40.516844   431 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0625 17:23:32.887106   431 solver.cpp:229] Iteration 380, loss = 2.47086
I0625 17:23:32.941120   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.219744 (* 1 = 0.219744 loss)
I0625 17:23:32.941134   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.675755 (* 1 = 0.675755 loss)
I0625 17:23:32.941141   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.34231 (* 2 = 0.68462 loss)
I0625 17:23:32.941146   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0252262 (* 3 = 0.0756786 loss)
I0625 17:23:32.941152   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00974632 (* 1 = 0.00974632 loss)
I0625 17:23:32.941159   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00488503 (* 1 = 0.00488503 loss)
I0625 17:23:32.941164   431 sgd_solver.cpp:106] Iteration 380, lr = 0.001
speed: 2.067s / iter
I0625 17:24:24.077374   431 solver.cpp:229] Iteration 400, loss = 1.96273
I0625 17:24:24.129616   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.42374 (* 1 = 1.42374 loss)
I0625 17:24:24.129629   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.0686736 (* 1 = 0.0686736 loss)
I0625 17:24:24.129634   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.228897 (* 2 = 0.457794 loss)
I0625 17:24:24.129638   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0643127 (* 3 = 0.192938 loss)
I0625 17:24:24.129642   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00500474 (* 1 = 0.00500474 loss)
I0625 17:24:24.129647   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00253551 (* 1 = 0.00253551 loss)
I0625 17:24:24.129652   431 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0625 17:25:15.406478   431 solver.cpp:229] Iteration 420, loss = 2.49291
I0625 17:25:15.459774   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.707911 (* 1 = 0.707911 loss)
I0625 17:25:15.459790   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.576454 (* 1 = 0.576454 loss)
I0625 17:25:15.459795   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.432645 (* 2 = 0.86529 loss)
I0625 17:25:15.459800   431 solver.cpp:245]     Train net output #3: loss_cls = 0.459309 (* 3 = 1.37793 loss)
I0625 17:25:15.459805   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.06927 (* 1 = 0.06927 loss)
I0625 17:25:15.459808   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0184626 (* 1 = 0.0184626 loss)
I0625 17:25:15.459813   431 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0625 17:26:04.325228   431 solver.cpp:229] Iteration 440, loss = 1.5065
I0625 17:26:04.382153   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.933098 (* 1 = 0.933098 loss)
I0625 17:26:04.382169   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.0119395 (* 1 = 0.0119395 loss)
I0625 17:26:04.382174   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.126743 (* 2 = 0.253486 loss)
I0625 17:26:04.382179   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0637248 (* 3 = 0.191174 loss)
I0625 17:26:04.382185   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.000547937 (* 1 = 0.000547937 loss)
I0625 17:26:04.382192   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00376717 (* 1 = 0.00376717 loss)
I0625 17:26:04.382200   431 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0625 17:26:53.367384   431 solver.cpp:229] Iteration 460, loss = 1.61294
I0625 17:26:53.421023   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.630169 (* 1 = 0.630169 loss)
I0625 17:26:53.421036   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.561818 (* 1 = 0.561818 loss)
I0625 17:26:53.421041   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.260958 (* 2 = 0.521916 loss)
I0625 17:26:53.421046   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0736334 (* 3 = 0.2209 loss)
I0625 17:26:53.421049   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00824005 (* 1 = 0.00824005 loss)
I0625 17:26:53.421054   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00428658 (* 1 = 0.00428658 loss)
I0625 17:26:53.421058   431 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0625 17:27:41.743708   431 solver.cpp:229] Iteration 480, loss = 1.75672
I0625 17:27:41.798804   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.905221 (* 1 = 0.905221 loss)
I0625 17:27:41.798830   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.570936 (* 1 = 0.570936 loss)
I0625 17:27:41.798837   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.157117 (* 2 = 0.314235 loss)
I0625 17:27:41.798844   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0872312 (* 3 = 0.261694 loss)
I0625 17:27:41.798851   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0078967 (* 1 = 0.0078967 loss)
I0625 17:27:41.798857   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00592896 (* 1 = 0.00592896 loss)
I0625 17:27:41.798866   431 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0625 17:28:30.192509   431 solver.cpp:229] Iteration 500, loss = 1.61403
I0625 17:28:30.246009   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.255765 (* 1 = 0.255765 loss)
I0625 17:28:30.246022   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.702089 (* 1 = 0.702089 loss)
I0625 17:28:30.246026   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.225271 (* 2 = 0.450541 loss)
I0625 17:28:30.246031   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0638104 (* 3 = 0.191431 loss)
I0625 17:28:30.246035   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0896275 (* 1 = 0.0896275 loss)
I0625 17:28:30.246039   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0435837 (* 1 = 0.0435837 loss)
I0625 17:28:30.246047   431 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0625 17:29:20.440004   431 solver.cpp:229] Iteration 520, loss = 2.116
I0625 17:29:20.494616   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.22628 (* 1 = 1.22628 loss)
I0625 17:29:20.494632   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.0164486 (* 1 = 0.0164486 loss)
I0625 17:29:20.494637   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.615807 (* 2 = 1.23161 loss)
I0625 17:29:20.494640   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0649967 (* 3 = 0.19499 loss)
I0625 17:29:20.494644   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.000708824 (* 1 = 0.000708824 loss)
I0625 17:29:20.494648   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00823007 (* 1 = 0.00823007 loss)
I0625 17:29:20.494664   431 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0625 17:30:10.864967   431 solver.cpp:229] Iteration 540, loss = 1.39142
I0625 17:30:10.925735   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.421869 (* 1 = 0.421869 loss)
I0625 17:30:10.925762   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.668405 (* 1 = 0.668405 loss)
I0625 17:30:10.925771   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.0866537 (* 2 = 0.173307 loss)
I0625 17:30:10.925781   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0423081 (* 3 = 0.126924 loss)
I0625 17:30:10.925789   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0121559 (* 1 = 0.0121559 loss)
I0625 17:30:10.925798   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0214171 (* 1 = 0.0214171 loss)
I0625 17:30:10.925806   431 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0625 17:31:01.093348   431 solver.cpp:229] Iteration 560, loss = 1.18261
I0625 17:31:01.147219   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.350372 (* 1 = 0.350372 loss)
I0625 17:31:01.147234   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.36264 (* 1 = 0.36264 loss)
I0625 17:31:01.147238   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.0693502 (* 2 = 0.1387 loss)
I0625 17:31:01.147243   431 solver.cpp:245]     Train net output #3: loss_cls = 0.043246 (* 3 = 0.129738 loss)
I0625 17:31:01.147246   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00567952 (* 1 = 0.00567952 loss)
I0625 17:31:01.147250   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0376269 (* 1 = 0.0376269 loss)
I0625 17:31:01.147255   431 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0625 17:31:50.620132   431 solver.cpp:229] Iteration 580, loss = 1.34464
I0625 17:31:50.674813   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.934556 (* 1 = 0.934556 loss)
I0625 17:31:50.674825   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.0145778 (* 1 = 0.0145778 loss)
I0625 17:31:50.674829   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.088463 (* 2 = 0.176926 loss)
I0625 17:31:50.674834   431 solver.cpp:245]     Train net output #3: loss_cls = 0.0725824 (* 3 = 0.217747 loss)
I0625 17:31:50.674839   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00185738 (* 1 = 0.00185738 loss)
I0625 17:31:50.674842   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00308663 (* 1 = 0.00308663 loss)
I0625 17:31:50.674849   431 sgd_solver.cpp:106] Iteration 580, lr = 0.001
speed: 2.206s / iter
I0625 17:32:41.368692   431 solver.cpp:229] Iteration 600, loss = 1.35771
I0625 17:32:41.422665   431 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.55565 (* 1 = 0.55565 loss)
I0625 17:32:41.422677   431 solver.cpp:245]     Train net output #1: loss_attribute = 0.339534 (* 1 = 0.339534 loss)
I0625 17:32:41.422682   431 solver.cpp:245]     Train net output #2: loss_bbox = 0.158599 (* 2 = 0.317198 loss)
I0625 17:32:41.422686   431 solver.cpp:245]     Train net output #3: loss_cls = 0.00576919 (* 3 = 0.0173076 loss)
I0625 17:32:41.422690   431 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00927823 (* 1 = 0.00927823 loss)
I0625 17:32:41.422694   431 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0030068 (* 1 = 0.0030068 loss)
I0625 17:32:41.422699   431 sgd_solver.cpp:106] Iteration 600, lr = 0.001
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:83: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:83: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:85: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:85: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:87: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:87: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:89: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:89: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/rpn/proposal_layer.py:187: RuntimeWarning: invalid value encountered in greater_equal
  keep = np.where((ws >= min_size) & (hs >= min_size))[0]
---- WARNING: filter_boxes() remove ALL proposal.
./experiments/scripts/faster_rcnn_end2end.sh: line 65:   431 Floating point exception/usr/bin/python ./tools/train_net.py --gpu ${GPU_ID} --solver models/${PT_DIR}/${NET}/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb ${TRAIN_IMDB} --iters ${ITERS} --cfg experiments/cfgs/faster_rcnn_end2end.yml ${EXTRA_ARGS}
