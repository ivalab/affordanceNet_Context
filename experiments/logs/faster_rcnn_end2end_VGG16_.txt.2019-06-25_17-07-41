+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-25_17-07-41
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-25_17-07-41
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0625 17:07:54.235363 26308 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0625 17:07:54.235380 26308 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0625 17:07:54.252455 26308 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  top: "attrArray"
  top: "attrArrayInd"
  top: "attrArrayShift"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "attr_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "attr_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "attr_score_pos"
  type: "Eltwise"
  bottom: "attr_score"
  bottom: "attrArrayInd"
  top: "attr_score_pos"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "attr_score_pos_shift"
  type: "Eltwise"
  bottom: "attr_score_pos"
  bottom: "attrArrayShift"
  top: "attr_score_pos_shift"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_attribute"
  type: "SigmoidCrossEntropyLoss"
  bottom: "attr_score_pos_shift"
  bottom: "attrArray"
  top: "loss_attribute"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "mask_score"
  top: "mask_score_softmax"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "log"
  type: "Log"
  bottom: "mask_score_softmax"
  top: "log"
}
layer {
  name: "mult1"
  type: "Eltwise"
  bottom: "log"
  bottom: "mask_targets"
  top: "mult1"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "cross_entropy"
  type: "Power"
  bottom: "mult1"
  top: "cross_entropy"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "ce_sum"
  type: "Convolution"
  bottom: "cross_entropy"
  top: "cross_entropy_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "ce_mean"
  type: "Reduction"
  bottom: "cross_entropy_sum"
  top: "cross_entropy_mean"
  loss_weight: 1
  reduction_param {
    operation: MEAN
    axis: 0
  }
}
I0625 17:07:54.252863 26308 layer_factory.hpp:77] Creating layer input-data
I0625 17:07:54.310143 26308 net.cpp:106] Creating Layer input-data
I0625 17:07:54.310160 26308 net.cpp:411] input-data -> data
I0625 17:07:54.310168 26308 net.cpp:411] input-data -> im_info
I0625 17:07:54.310173 26308 net.cpp:411] input-data -> gt_boxes
I0625 17:07:54.310178 26308 net.cpp:411] input-data -> seg_mask_inds
I0625 17:07:54.310184 26308 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0625 17:07:54.345254 26308 net.cpp:150] Setting up input-data
I0625 17:07:54.345269 26308 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 17:07:54.345273 26308 net.cpp:157] Top shape: 1 3 (3)
I0625 17:07:54.345275 26308 net.cpp:157] Top shape: 1 4 (4)
I0625 17:07:54.345278 26308 net.cpp:157] Top shape: 1 2 (2)
I0625 17:07:54.345279 26308 net.cpp:157] Top shape: 1 1 (1)
I0625 17:07:54.345281 26308 net.cpp:165] Memory required for data: 7200040
I0625 17:07:54.345286 26308 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0625 17:07:54.345299 26308 net.cpp:106] Creating Layer data_input-data_0_split
I0625 17:07:54.345302 26308 net.cpp:454] data_input-data_0_split <- data
I0625 17:07:54.345306 26308 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0625 17:07:54.345312 26308 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0625 17:07:54.345333 26308 net.cpp:150] Setting up data_input-data_0_split
I0625 17:07:54.345337 26308 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 17:07:54.345340 26308 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 17:07:54.345342 26308 net.cpp:165] Memory required for data: 21600040
I0625 17:07:54.345345 26308 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0625 17:07:54.345350 26308 net.cpp:106] Creating Layer im_info_input-data_1_split
I0625 17:07:54.345353 26308 net.cpp:454] im_info_input-data_1_split <- im_info
I0625 17:07:54.345356 26308 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0625 17:07:54.345360 26308 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0625 17:07:54.345367 26308 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0625 17:07:54.345413 26308 net.cpp:150] Setting up im_info_input-data_1_split
I0625 17:07:54.345417 26308 net.cpp:157] Top shape: 1 3 (3)
I0625 17:07:54.345419 26308 net.cpp:157] Top shape: 1 3 (3)
I0625 17:07:54.345422 26308 net.cpp:157] Top shape: 1 3 (3)
I0625 17:07:54.345423 26308 net.cpp:165] Memory required for data: 21600076
I0625 17:07:54.345424 26308 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0625 17:07:54.345427 26308 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0625 17:07:54.345429 26308 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0625 17:07:54.345432 26308 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0625 17:07:54.345448 26308 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0625 17:07:54.345474 26308 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0625 17:07:54.345486 26308 net.cpp:157] Top shape: 1 4 (4)
I0625 17:07:54.345489 26308 net.cpp:157] Top shape: 1 4 (4)
I0625 17:07:54.345491 26308 net.cpp:165] Memory required for data: 21600108
I0625 17:07:54.345504 26308 layer_factory.hpp:77] Creating layer conv1_1
I0625 17:07:54.345525 26308 net.cpp:106] Creating Layer conv1_1
I0625 17:07:54.345527 26308 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0625 17:07:54.345530 26308 net.cpp:411] conv1_1 -> conv1_1
I0625 17:07:54.597201 26308 net.cpp:150] Setting up conv1_1
I0625 17:07:54.597223 26308 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 17:07:54.597224 26308 net.cpp:165] Memory required for data: 175200108
I0625 17:07:54.597235 26308 layer_factory.hpp:77] Creating layer relu1_1
I0625 17:07:54.597254 26308 net.cpp:106] Creating Layer relu1_1
I0625 17:07:54.597257 26308 net.cpp:454] relu1_1 <- conv1_1
I0625 17:07:54.597260 26308 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0625 17:07:54.597399 26308 net.cpp:150] Setting up relu1_1
I0625 17:07:54.597405 26308 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 17:07:54.597407 26308 net.cpp:165] Memory required for data: 328800108
I0625 17:07:54.597409 26308 layer_factory.hpp:77] Creating layer conv1_2
I0625 17:07:54.597415 26308 net.cpp:106] Creating Layer conv1_2
I0625 17:07:54.597417 26308 net.cpp:454] conv1_2 <- conv1_1
I0625 17:07:54.597421 26308 net.cpp:411] conv1_2 -> conv1_2
I0625 17:07:54.599443 26308 net.cpp:150] Setting up conv1_2
I0625 17:07:54.599453 26308 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 17:07:54.599457 26308 net.cpp:165] Memory required for data: 482400108
I0625 17:07:54.599462 26308 layer_factory.hpp:77] Creating layer relu1_2
I0625 17:07:54.599467 26308 net.cpp:106] Creating Layer relu1_2
I0625 17:07:54.599470 26308 net.cpp:454] relu1_2 <- conv1_2
I0625 17:07:54.599475 26308 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0625 17:07:54.599597 26308 net.cpp:150] Setting up relu1_2
I0625 17:07:54.599603 26308 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 17:07:54.599606 26308 net.cpp:165] Memory required for data: 636000108
I0625 17:07:54.599607 26308 layer_factory.hpp:77] Creating layer pool1
I0625 17:07:54.599613 26308 net.cpp:106] Creating Layer pool1
I0625 17:07:54.599615 26308 net.cpp:454] pool1 <- conv1_2
I0625 17:07:54.599630 26308 net.cpp:411] pool1 -> pool1
I0625 17:07:54.599696 26308 net.cpp:150] Setting up pool1
I0625 17:07:54.599701 26308 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0625 17:07:54.599702 26308 net.cpp:165] Memory required for data: 674400108
I0625 17:07:54.599704 26308 layer_factory.hpp:77] Creating layer conv2_1
I0625 17:07:54.599709 26308 net.cpp:106] Creating Layer conv2_1
I0625 17:07:54.599711 26308 net.cpp:454] conv2_1 <- pool1
I0625 17:07:54.599714 26308 net.cpp:411] conv2_1 -> conv2_1
I0625 17:07:54.601406 26308 net.cpp:150] Setting up conv2_1
I0625 17:07:54.601414 26308 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 17:07:54.601416 26308 net.cpp:165] Memory required for data: 751200108
I0625 17:07:54.601423 26308 layer_factory.hpp:77] Creating layer relu2_1
I0625 17:07:54.601426 26308 net.cpp:106] Creating Layer relu2_1
I0625 17:07:54.601428 26308 net.cpp:454] relu2_1 <- conv2_1
I0625 17:07:54.601431 26308 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0625 17:07:54.601899 26308 net.cpp:150] Setting up relu2_1
I0625 17:07:54.601907 26308 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 17:07:54.601908 26308 net.cpp:165] Memory required for data: 828000108
I0625 17:07:54.601910 26308 layer_factory.hpp:77] Creating layer conv2_2
I0625 17:07:54.601915 26308 net.cpp:106] Creating Layer conv2_2
I0625 17:07:54.601917 26308 net.cpp:454] conv2_2 <- conv2_1
I0625 17:07:54.601922 26308 net.cpp:411] conv2_2 -> conv2_2
I0625 17:07:54.603168 26308 net.cpp:150] Setting up conv2_2
I0625 17:07:54.603178 26308 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 17:07:54.603179 26308 net.cpp:165] Memory required for data: 904800108
I0625 17:07:54.603183 26308 layer_factory.hpp:77] Creating layer relu2_2
I0625 17:07:54.603188 26308 net.cpp:106] Creating Layer relu2_2
I0625 17:07:54.603189 26308 net.cpp:454] relu2_2 <- conv2_2
I0625 17:07:54.603193 26308 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0625 17:07:54.603327 26308 net.cpp:150] Setting up relu2_2
I0625 17:07:54.603332 26308 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 17:07:54.603334 26308 net.cpp:165] Memory required for data: 981600108
I0625 17:07:54.603336 26308 layer_factory.hpp:77] Creating layer pool2
I0625 17:07:54.603339 26308 net.cpp:106] Creating Layer pool2
I0625 17:07:54.603341 26308 net.cpp:454] pool2 <- conv2_2
I0625 17:07:54.603344 26308 net.cpp:411] pool2 -> pool2
I0625 17:07:54.603391 26308 net.cpp:150] Setting up pool2
I0625 17:07:54.603404 26308 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0625 17:07:54.603405 26308 net.cpp:165] Memory required for data: 1000800108
I0625 17:07:54.603407 26308 layer_factory.hpp:77] Creating layer conv3_1
I0625 17:07:54.603411 26308 net.cpp:106] Creating Layer conv3_1
I0625 17:07:54.603423 26308 net.cpp:454] conv3_1 <- pool2
I0625 17:07:54.603426 26308 net.cpp:411] conv3_1 -> conv3_1
I0625 17:07:54.605185 26308 net.cpp:150] Setting up conv3_1
I0625 17:07:54.605193 26308 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:07:54.605195 26308 net.cpp:165] Memory required for data: 1039200108
I0625 17:07:54.605201 26308 layer_factory.hpp:77] Creating layer relu3_1
I0625 17:07:54.605206 26308 net.cpp:106] Creating Layer relu3_1
I0625 17:07:54.605207 26308 net.cpp:454] relu3_1 <- conv3_1
I0625 17:07:54.605211 26308 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0625 17:07:54.605341 26308 net.cpp:150] Setting up relu3_1
I0625 17:07:54.605347 26308 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:07:54.605350 26308 net.cpp:165] Memory required for data: 1077600108
I0625 17:07:54.605351 26308 layer_factory.hpp:77] Creating layer conv3_2
I0625 17:07:54.605358 26308 net.cpp:106] Creating Layer conv3_2
I0625 17:07:54.605360 26308 net.cpp:454] conv3_2 <- conv3_1
I0625 17:07:54.605363 26308 net.cpp:411] conv3_2 -> conv3_2
I0625 17:07:54.607308 26308 net.cpp:150] Setting up conv3_2
I0625 17:07:54.607318 26308 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:07:54.607321 26308 net.cpp:165] Memory required for data: 1116000108
I0625 17:07:54.607324 26308 layer_factory.hpp:77] Creating layer relu3_2
I0625 17:07:54.607328 26308 net.cpp:106] Creating Layer relu3_2
I0625 17:07:54.607331 26308 net.cpp:454] relu3_2 <- conv3_2
I0625 17:07:54.607333 26308 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0625 17:07:54.607466 26308 net.cpp:150] Setting up relu3_2
I0625 17:07:54.607472 26308 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:07:54.607475 26308 net.cpp:165] Memory required for data: 1154400108
I0625 17:07:54.607475 26308 layer_factory.hpp:77] Creating layer conv3_3
I0625 17:07:54.607481 26308 net.cpp:106] Creating Layer conv3_3
I0625 17:07:54.607482 26308 net.cpp:454] conv3_3 <- conv3_2
I0625 17:07:54.607499 26308 net.cpp:411] conv3_3 -> conv3_3
I0625 17:07:54.609870 26308 net.cpp:150] Setting up conv3_3
I0625 17:07:54.609894 26308 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:07:54.609897 26308 net.cpp:165] Memory required for data: 1192800108
I0625 17:07:54.609902 26308 layer_factory.hpp:77] Creating layer relu3_3
I0625 17:07:54.609918 26308 net.cpp:106] Creating Layer relu3_3
I0625 17:07:54.609921 26308 net.cpp:454] relu3_3 <- conv3_3
I0625 17:07:54.609925 26308 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0625 17:07:54.610049 26308 net.cpp:150] Setting up relu3_3
I0625 17:07:54.610056 26308 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:07:54.610057 26308 net.cpp:165] Memory required for data: 1231200108
I0625 17:07:54.610059 26308 layer_factory.hpp:77] Creating layer pool3
I0625 17:07:54.610064 26308 net.cpp:106] Creating Layer pool3
I0625 17:07:54.610066 26308 net.cpp:454] pool3 <- conv3_3
I0625 17:07:54.610069 26308 net.cpp:411] pool3 -> pool3
I0625 17:07:54.610107 26308 net.cpp:150] Setting up pool3
I0625 17:07:54.610110 26308 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0625 17:07:54.610112 26308 net.cpp:165] Memory required for data: 1240800108
I0625 17:07:54.610124 26308 layer_factory.hpp:77] Creating layer conv4_1
I0625 17:07:54.610131 26308 net.cpp:106] Creating Layer conv4_1
I0625 17:07:54.610132 26308 net.cpp:454] conv4_1 <- pool3
I0625 17:07:54.610136 26308 net.cpp:411] conv4_1 -> conv4_1
I0625 17:07:54.614231 26308 net.cpp:150] Setting up conv4_1
I0625 17:07:54.614253 26308 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:07:54.614254 26308 net.cpp:165] Memory required for data: 1260000108
I0625 17:07:54.614279 26308 layer_factory.hpp:77] Creating layer relu4_1
I0625 17:07:54.614300 26308 net.cpp:106] Creating Layer relu4_1
I0625 17:07:54.614305 26308 net.cpp:454] relu4_1 <- conv4_1
I0625 17:07:54.614308 26308 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0625 17:07:54.614434 26308 net.cpp:150] Setting up relu4_1
I0625 17:07:54.614440 26308 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:07:54.614442 26308 net.cpp:165] Memory required for data: 1279200108
I0625 17:07:54.614444 26308 layer_factory.hpp:77] Creating layer conv4_2
I0625 17:07:54.614450 26308 net.cpp:106] Creating Layer conv4_2
I0625 17:07:54.614452 26308 net.cpp:454] conv4_2 <- conv4_1
I0625 17:07:54.614456 26308 net.cpp:411] conv4_2 -> conv4_2
I0625 17:07:54.619040 26308 net.cpp:150] Setting up conv4_2
I0625 17:07:54.619060 26308 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:07:54.619061 26308 net.cpp:165] Memory required for data: 1298400108
I0625 17:07:54.619072 26308 layer_factory.hpp:77] Creating layer relu4_2
I0625 17:07:54.619081 26308 net.cpp:106] Creating Layer relu4_2
I0625 17:07:54.619083 26308 net.cpp:454] relu4_2 <- conv4_2
I0625 17:07:54.619088 26308 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0625 17:07:54.619566 26308 net.cpp:150] Setting up relu4_2
I0625 17:07:54.619575 26308 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:07:54.619576 26308 net.cpp:165] Memory required for data: 1317600108
I0625 17:07:54.619578 26308 layer_factory.hpp:77] Creating layer conv4_3
I0625 17:07:54.619585 26308 net.cpp:106] Creating Layer conv4_3
I0625 17:07:54.619587 26308 net.cpp:454] conv4_3 <- conv4_2
I0625 17:07:54.619591 26308 net.cpp:411] conv4_3 -> conv4_3
I0625 17:07:54.623996 26308 net.cpp:150] Setting up conv4_3
I0625 17:07:54.624017 26308 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:07:54.624020 26308 net.cpp:165] Memory required for data: 1336800108
I0625 17:07:54.624037 26308 layer_factory.hpp:77] Creating layer relu4_3
I0625 17:07:54.624056 26308 net.cpp:106] Creating Layer relu4_3
I0625 17:07:54.624060 26308 net.cpp:454] relu4_3 <- conv4_3
I0625 17:07:54.624064 26308 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0625 17:07:54.624202 26308 net.cpp:150] Setting up relu4_3
I0625 17:07:54.624209 26308 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:07:54.624212 26308 net.cpp:165] Memory required for data: 1356000108
I0625 17:07:54.624212 26308 layer_factory.hpp:77] Creating layer pool4
I0625 17:07:54.624217 26308 net.cpp:106] Creating Layer pool4
I0625 17:07:54.624219 26308 net.cpp:454] pool4 <- conv4_3
I0625 17:07:54.624222 26308 net.cpp:411] pool4 -> pool4
I0625 17:07:54.624284 26308 net.cpp:150] Setting up pool4
I0625 17:07:54.624286 26308 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:07:54.624289 26308 net.cpp:165] Memory required for data: 1360903020
I0625 17:07:54.624300 26308 layer_factory.hpp:77] Creating layer conv5_1
I0625 17:07:54.624306 26308 net.cpp:106] Creating Layer conv5_1
I0625 17:07:54.624308 26308 net.cpp:454] conv5_1 <- pool4
I0625 17:07:54.624325 26308 net.cpp:411] conv5_1 -> conv5_1
I0625 17:07:54.629420 26308 net.cpp:150] Setting up conv5_1
I0625 17:07:54.629437 26308 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:07:54.629439 26308 net.cpp:165] Memory required for data: 1365805932
I0625 17:07:54.629446 26308 layer_factory.hpp:77] Creating layer relu5_1
I0625 17:07:54.629454 26308 net.cpp:106] Creating Layer relu5_1
I0625 17:07:54.629458 26308 net.cpp:454] relu5_1 <- conv5_1
I0625 17:07:54.629462 26308 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0625 17:07:54.629577 26308 net.cpp:150] Setting up relu5_1
I0625 17:07:54.629585 26308 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:07:54.629586 26308 net.cpp:165] Memory required for data: 1370708844
I0625 17:07:54.629588 26308 layer_factory.hpp:77] Creating layer conv5_2
I0625 17:07:54.629595 26308 net.cpp:106] Creating Layer conv5_2
I0625 17:07:54.629597 26308 net.cpp:454] conv5_2 <- conv5_1
I0625 17:07:54.629601 26308 net.cpp:411] conv5_2 -> conv5_2
I0625 17:07:54.635725 26308 net.cpp:150] Setting up conv5_2
I0625 17:07:54.635746 26308 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:07:54.635748 26308 net.cpp:165] Memory required for data: 1375611756
I0625 17:07:54.635766 26308 layer_factory.hpp:77] Creating layer relu5_2
I0625 17:07:54.635784 26308 net.cpp:106] Creating Layer relu5_2
I0625 17:07:54.635789 26308 net.cpp:454] relu5_2 <- conv5_2
I0625 17:07:54.635794 26308 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0625 17:07:54.635911 26308 net.cpp:150] Setting up relu5_2
I0625 17:07:54.635917 26308 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:07:54.635920 26308 net.cpp:165] Memory required for data: 1380514668
I0625 17:07:54.635921 26308 layer_factory.hpp:77] Creating layer conv5_3
I0625 17:07:54.635933 26308 net.cpp:106] Creating Layer conv5_3
I0625 17:07:54.635936 26308 net.cpp:454] conv5_3 <- conv5_2
I0625 17:07:54.635941 26308 net.cpp:411] conv5_3 -> conv5_3
I0625 17:07:54.640329 26308 net.cpp:150] Setting up conv5_3
I0625 17:07:54.640349 26308 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:07:54.640352 26308 net.cpp:165] Memory required for data: 1385417580
I0625 17:07:54.640358 26308 layer_factory.hpp:77] Creating layer relu5_3
I0625 17:07:54.640365 26308 net.cpp:106] Creating Layer relu5_3
I0625 17:07:54.640379 26308 net.cpp:454] relu5_3 <- conv5_3
I0625 17:07:54.640385 26308 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0625 17:07:54.640528 26308 net.cpp:150] Setting up relu5_3
I0625 17:07:54.640534 26308 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:07:54.640535 26308 net.cpp:165] Memory required for data: 1390320492
I0625 17:07:54.640537 26308 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0625 17:07:54.640542 26308 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0625 17:07:54.640544 26308 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0625 17:07:54.640547 26308 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0625 17:07:54.640563 26308 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0625 17:07:54.640566 26308 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0625 17:07:54.640609 26308 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0625 17:07:54.640612 26308 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:07:54.640614 26308 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:07:54.640616 26308 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:07:54.640617 26308 net.cpp:165] Memory required for data: 1405029228
I0625 17:07:54.640619 26308 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0625 17:07:54.640626 26308 net.cpp:106] Creating Layer rpn_conv/3x3
I0625 17:07:54.640643 26308 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0625 17:07:54.640647 26308 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0625 17:07:54.690927 26308 net.cpp:150] Setting up rpn_conv/3x3
I0625 17:07:54.690945 26308 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:07:54.690948 26308 net.cpp:165] Memory required for data: 1409932140
I0625 17:07:54.690953 26308 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0625 17:07:54.690961 26308 net.cpp:106] Creating Layer rpn_relu/3x3
I0625 17:07:54.690964 26308 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0625 17:07:54.690977 26308 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0625 17:07:54.691102 26308 net.cpp:150] Setting up rpn_relu/3x3
I0625 17:07:54.691107 26308 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:07:54.691108 26308 net.cpp:165] Memory required for data: 1414835052
I0625 17:07:54.691110 26308 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0625 17:07:54.691113 26308 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0625 17:07:54.691115 26308 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0625 17:07:54.691119 26308 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0625 17:07:54.691123 26308 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0625 17:07:54.691166 26308 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0625 17:07:54.691170 26308 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:07:54.691182 26308 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:07:54.691184 26308 net.cpp:165] Memory required for data: 1424640876
I0625 17:07:54.691186 26308 layer_factory.hpp:77] Creating layer rpn_cls_score
I0625 17:07:54.691193 26308 net.cpp:106] Creating Layer rpn_cls_score
I0625 17:07:54.691195 26308 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0625 17:07:54.691200 26308 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0625 17:07:54.692725 26308 net.cpp:150] Setting up rpn_cls_score
I0625 17:07:54.692734 26308 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 17:07:54.692734 26308 net.cpp:165] Memory required for data: 1424928156
I0625 17:07:54.692739 26308 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0625 17:07:54.692744 26308 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0625 17:07:54.692745 26308 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0625 17:07:54.692749 26308 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0625 17:07:54.692762 26308 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0625 17:07:54.692809 26308 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0625 17:07:54.692813 26308 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 17:07:54.692816 26308 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 17:07:54.692826 26308 net.cpp:165] Memory required for data: 1425502716
I0625 17:07:54.692828 26308 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0625 17:07:54.692834 26308 net.cpp:106] Creating Layer rpn_bbox_pred
I0625 17:07:54.692836 26308 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0625 17:07:54.692849 26308 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0625 17:07:54.694329 26308 net.cpp:150] Setting up rpn_bbox_pred
I0625 17:07:54.694339 26308 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:07:54.694340 26308 net.cpp:165] Memory required for data: 1426077276
I0625 17:07:54.694344 26308 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 17:07:54.694347 26308 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 17:07:54.694350 26308 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0625 17:07:54.694352 26308 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0625 17:07:54.694366 26308 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0625 17:07:54.694401 26308 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 17:07:54.694404 26308 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:07:54.694416 26308 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:07:54.694418 26308 net.cpp:165] Memory required for data: 1427226396
I0625 17:07:54.694419 26308 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0625 17:07:54.694424 26308 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0625 17:07:54.694435 26308 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0625 17:07:54.694438 26308 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0625 17:07:54.694474 26308 net.cpp:150] Setting up rpn_cls_score_reshape
I0625 17:07:54.694478 26308 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 17:07:54.694479 26308 net.cpp:165] Memory required for data: 1427513676
I0625 17:07:54.694481 26308 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 17:07:54.694494 26308 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 17:07:54.694496 26308 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0625 17:07:54.694499 26308 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0625 17:07:54.694502 26308 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0625 17:07:54.694530 26308 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 17:07:54.694535 26308 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 17:07:54.694536 26308 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 17:07:54.694537 26308 net.cpp:165] Memory required for data: 1428088236
I0625 17:07:54.694538 26308 layer_factory.hpp:77] Creating layer rpn-data
I0625 17:07:54.695572 26308 net.cpp:106] Creating Layer rpn-data
I0625 17:07:54.695580 26308 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0625 17:07:54.695585 26308 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0625 17:07:54.695588 26308 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0625 17:07:54.695591 26308 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0625 17:07:54.695595 26308 net.cpp:411] rpn-data -> rpn_labels
I0625 17:07:54.695600 26308 net.cpp:411] rpn-data -> rpn_bbox_targets
I0625 17:07:54.695605 26308 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0625 17:07:54.695608 26308 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0625 17:07:54.696462 26308 net.cpp:150] Setting up rpn-data
I0625 17:07:54.696471 26308 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0625 17:07:54.696473 26308 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:07:54.696475 26308 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:07:54.696477 26308 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:07:54.696480 26308 net.cpp:165] Memory required for data: 1429955556
I0625 17:07:54.696481 26308 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0625 17:07:54.696486 26308 net.cpp:106] Creating Layer rpn_loss_cls
I0625 17:07:54.696489 26308 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0625 17:07:54.696492 26308 net.cpp:454] rpn_loss_cls <- rpn_labels
I0625 17:07:54.696496 26308 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0625 17:07:54.696508 26308 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0625 17:07:54.697154 26308 net.cpp:150] Setting up rpn_loss_cls
I0625 17:07:54.697163 26308 net.cpp:157] Top shape: (1)
I0625 17:07:54.697165 26308 net.cpp:160]     with loss weight 1
I0625 17:07:54.697172 26308 net.cpp:165] Memory required for data: 1429955560
I0625 17:07:54.697175 26308 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0625 17:07:54.697182 26308 net.cpp:106] Creating Layer rpn_loss_bbox
I0625 17:07:54.697186 26308 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0625 17:07:54.697190 26308 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0625 17:07:54.697191 26308 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0625 17:07:54.697193 26308 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0625 17:07:54.697196 26308 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0625 17:07:54.698246 26308 net.cpp:150] Setting up rpn_loss_bbox
I0625 17:07:54.698254 26308 net.cpp:157] Top shape: (1)
I0625 17:07:54.698285 26308 net.cpp:160]     with loss weight 1
I0625 17:07:54.698299 26308 net.cpp:165] Memory required for data: 1429955564
I0625 17:07:54.698302 26308 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0625 17:07:54.698320 26308 net.cpp:106] Creating Layer rpn_cls_prob
I0625 17:07:54.698323 26308 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0625 17:07:54.698326 26308 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0625 17:07:54.698510 26308 net.cpp:150] Setting up rpn_cls_prob
I0625 17:07:54.698516 26308 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 17:07:54.698518 26308 net.cpp:165] Memory required for data: 1430242844
I0625 17:07:54.698520 26308 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0625 17:07:54.698524 26308 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0625 17:07:54.698526 26308 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0625 17:07:54.698541 26308 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0625 17:07:54.698559 26308 net.cpp:150] Setting up rpn_cls_prob_reshape
I0625 17:07:54.698572 26308 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 17:07:54.698575 26308 net.cpp:165] Memory required for data: 1430530124
I0625 17:07:54.698575 26308 layer_factory.hpp:77] Creating layer proposal
I0625 17:07:54.700300 26308 net.cpp:106] Creating Layer proposal
I0625 17:07:54.700309 26308 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0625 17:07:54.700311 26308 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0625 17:07:54.700314 26308 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0625 17:07:54.700317 26308 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0625 17:07:54.701318 26308 net.cpp:150] Setting up proposal
I0625 17:07:54.701328 26308 net.cpp:157] Top shape: 1 5 (5)
I0625 17:07:54.701330 26308 net.cpp:165] Memory required for data: 1430530144
I0625 17:07:54.701333 26308 layer_factory.hpp:77] Creating layer roi-data
I0625 17:07:54.701848 26308 net.cpp:106] Creating Layer roi-data
I0625 17:07:54.701856 26308 net.cpp:454] roi-data <- rpn_rois
I0625 17:07:54.701860 26308 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0625 17:07:54.701864 26308 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0625 17:07:54.701867 26308 net.cpp:454] roi-data <- seg_mask_inds
I0625 17:07:54.701871 26308 net.cpp:454] roi-data <- flipped
I0625 17:07:54.701879 26308 net.cpp:411] roi-data -> rois
I0625 17:07:54.701886 26308 net.cpp:411] roi-data -> labels
I0625 17:07:54.701892 26308 net.cpp:411] roi-data -> bbox_targets
I0625 17:07:54.701898 26308 net.cpp:411] roi-data -> bbox_inside_weights
I0625 17:07:54.701905 26308 net.cpp:411] roi-data -> bbox_outside_weights
I0625 17:07:54.701910 26308 net.cpp:411] roi-data -> mask_targets
I0625 17:07:54.701915 26308 net.cpp:411] roi-data -> rois_pos
I0625 17:07:54.701920 26308 net.cpp:411] roi-data -> attrArray
I0625 17:07:54.701925 26308 net.cpp:411] roi-data -> attrArrayInd
I0625 17:07:54.701931 26308 net.cpp:411] roi-data -> attrArrayShift
I0625 17:07:54.702250 26308 net.cpp:150] Setting up roi-data
I0625 17:07:54.702272 26308 net.cpp:157] Top shape: 1 5 (5)
I0625 17:07:54.702278 26308 net.cpp:157] Top shape: 1 1 (1)
I0625 17:07:54.702281 26308 net.cpp:157] Top shape: 1 8 (8)
I0625 17:07:54.702287 26308 net.cpp:157] Top shape: 1 8 (8)
I0625 17:07:54.702291 26308 net.cpp:157] Top shape: 1 8 (8)
I0625 17:07:54.702294 26308 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:07:54.702298 26308 net.cpp:157] Top shape: 1 5 (5)
I0625 17:07:54.702302 26308 net.cpp:157] Top shape: 1 7 (7)
I0625 17:07:54.702306 26308 net.cpp:157] Top shape: 1 7 (7)
I0625 17:07:54.702311 26308 net.cpp:157] Top shape: 1 7 (7)
I0625 17:07:54.702314 26308 net.cpp:165] Memory required for data: 1432435520
I0625 17:07:54.702319 26308 layer_factory.hpp:77] Creating layer roi_pool5
I0625 17:07:54.702335 26308 net.cpp:106] Creating Layer roi_pool5
I0625 17:07:54.702340 26308 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0625 17:07:54.702345 26308 net.cpp:454] roi_pool5 <- rois
I0625 17:07:54.702352 26308 net.cpp:411] roi_pool5 -> pool5
I0625 17:07:54.702359 26308 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0625 17:07:54.702450 26308 net.cpp:150] Setting up roi_pool5
I0625 17:07:54.702456 26308 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:07:54.702459 26308 net.cpp:165] Memory required for data: 1432535872
I0625 17:07:54.702464 26308 layer_factory.hpp:77] Creating layer fc6
I0625 17:07:54.702472 26308 net.cpp:106] Creating Layer fc6
I0625 17:07:54.702476 26308 net.cpp:454] fc6 <- pool5
I0625 17:07:54.702481 26308 net.cpp:411] fc6 -> fc6
I0625 17:07:54.857070 26308 net.cpp:150] Setting up fc6
I0625 17:07:54.857110 26308 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:07:54.857112 26308 net.cpp:165] Memory required for data: 1432552256
I0625 17:07:54.857138 26308 layer_factory.hpp:77] Creating layer relu6
I0625 17:07:54.857151 26308 net.cpp:106] Creating Layer relu6
I0625 17:07:54.857156 26308 net.cpp:454] relu6 <- fc6
I0625 17:07:54.857161 26308 net.cpp:397] relu6 -> fc6 (in-place)
I0625 17:07:54.857388 26308 net.cpp:150] Setting up relu6
I0625 17:07:54.857406 26308 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:07:54.857409 26308 net.cpp:165] Memory required for data: 1432568640
I0625 17:07:54.857412 26308 layer_factory.hpp:77] Creating layer fc7
I0625 17:07:54.857419 26308 net.cpp:106] Creating Layer fc7
I0625 17:07:54.857434 26308 net.cpp:454] fc7 <- fc6
I0625 17:07:54.857437 26308 net.cpp:411] fc7 -> fc7
I0625 17:07:54.883682 26308 net.cpp:150] Setting up fc7
I0625 17:07:54.883720 26308 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:07:54.883724 26308 net.cpp:165] Memory required for data: 1432585024
I0625 17:07:54.883735 26308 layer_factory.hpp:77] Creating layer relu7
I0625 17:07:54.883745 26308 net.cpp:106] Creating Layer relu7
I0625 17:07:54.883750 26308 net.cpp:454] relu7 <- fc7
I0625 17:07:54.883765 26308 net.cpp:397] relu7 -> fc7 (in-place)
I0625 17:07:54.883986 26308 net.cpp:150] Setting up relu7
I0625 17:07:54.884006 26308 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:07:54.884009 26308 net.cpp:165] Memory required for data: 1432601408
I0625 17:07:54.884012 26308 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0625 17:07:54.884018 26308 net.cpp:106] Creating Layer fc7_relu7_0_split
I0625 17:07:54.884021 26308 net.cpp:454] fc7_relu7_0_split <- fc7
I0625 17:07:54.884027 26308 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0625 17:07:54.884033 26308 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0625 17:07:54.884038 26308 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0625 17:07:54.884099 26308 net.cpp:150] Setting up fc7_relu7_0_split
I0625 17:07:54.884104 26308 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:07:54.884117 26308 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:07:54.884119 26308 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:07:54.884120 26308 net.cpp:165] Memory required for data: 1432650560
I0625 17:07:54.884122 26308 layer_factory.hpp:77] Creating layer attr_score
I0625 17:07:54.884129 26308 net.cpp:106] Creating Layer attr_score
I0625 17:07:54.884130 26308 net.cpp:454] attr_score <- fc7_relu7_0_split_0
I0625 17:07:54.884135 26308 net.cpp:411] attr_score -> attr_score
I0625 17:07:54.884814 26308 net.cpp:150] Setting up attr_score
I0625 17:07:54.884820 26308 net.cpp:157] Top shape: 1 7 (7)
I0625 17:07:54.884832 26308 net.cpp:165] Memory required for data: 1432650588
I0625 17:07:54.884836 26308 layer_factory.hpp:77] Creating layer attr_score_pos
I0625 17:07:54.884852 26308 net.cpp:106] Creating Layer attr_score_pos
I0625 17:07:54.884855 26308 net.cpp:454] attr_score_pos <- attr_score
I0625 17:07:54.884858 26308 net.cpp:454] attr_score_pos <- attrArrayInd
I0625 17:07:54.884861 26308 net.cpp:411] attr_score_pos -> attr_score_pos
I0625 17:07:54.884888 26308 net.cpp:150] Setting up attr_score_pos
I0625 17:07:54.884892 26308 net.cpp:157] Top shape: 1 7 (7)
I0625 17:07:54.884893 26308 net.cpp:165] Memory required for data: 1432650616
I0625 17:07:54.884907 26308 layer_factory.hpp:77] Creating layer attr_score_pos_shift
I0625 17:07:54.884910 26308 net.cpp:106] Creating Layer attr_score_pos_shift
I0625 17:07:54.884912 26308 net.cpp:454] attr_score_pos_shift <- attr_score_pos
I0625 17:07:54.884914 26308 net.cpp:454] attr_score_pos_shift <- attrArrayShift
I0625 17:07:54.884928 26308 net.cpp:411] attr_score_pos_shift -> attr_score_pos_shift
I0625 17:07:54.884951 26308 net.cpp:150] Setting up attr_score_pos_shift
I0625 17:07:54.884955 26308 net.cpp:157] Top shape: 1 7 (7)
I0625 17:07:54.884956 26308 net.cpp:165] Memory required for data: 1432650644
I0625 17:07:54.884958 26308 layer_factory.hpp:77] Creating layer cls_score
I0625 17:07:54.884963 26308 net.cpp:106] Creating Layer cls_score
I0625 17:07:54.884965 26308 net.cpp:454] cls_score <- fc7_relu7_0_split_1
I0625 17:07:54.884969 26308 net.cpp:411] cls_score -> cls_score
I0625 17:07:54.885205 26308 net.cpp:150] Setting up cls_score
I0625 17:07:54.885210 26308 net.cpp:157] Top shape: 1 2 (2)
I0625 17:07:54.885210 26308 net.cpp:165] Memory required for data: 1432650652
I0625 17:07:54.885215 26308 layer_factory.hpp:77] Creating layer bbox_pred
I0625 17:07:54.885219 26308 net.cpp:106] Creating Layer bbox_pred
I0625 17:07:54.885222 26308 net.cpp:454] bbox_pred <- fc7_relu7_0_split_2
I0625 17:07:54.885226 26308 net.cpp:411] bbox_pred -> bbox_pred
I0625 17:07:54.886272 26308 net.cpp:150] Setting up bbox_pred
I0625 17:07:54.886296 26308 net.cpp:157] Top shape: 1 8 (8)
I0625 17:07:54.886308 26308 net.cpp:165] Memory required for data: 1432650684
I0625 17:07:54.886315 26308 layer_factory.hpp:77] Creating layer loss_attribute
I0625 17:07:54.886323 26308 net.cpp:106] Creating Layer loss_attribute
I0625 17:07:54.886327 26308 net.cpp:454] loss_attribute <- attr_score_pos_shift
I0625 17:07:54.886332 26308 net.cpp:454] loss_attribute <- attrArray
I0625 17:07:54.886337 26308 net.cpp:411] loss_attribute -> loss_attribute
I0625 17:07:54.886385 26308 net.cpp:150] Setting up loss_attribute
I0625 17:07:54.886391 26308 net.cpp:157] Top shape: (1)
I0625 17:07:54.886392 26308 net.cpp:160]     with loss weight 1
I0625 17:07:54.886401 26308 net.cpp:165] Memory required for data: 1432650688
I0625 17:07:54.886404 26308 layer_factory.hpp:77] Creating layer loss_cls
I0625 17:07:54.886409 26308 net.cpp:106] Creating Layer loss_cls
I0625 17:07:54.886412 26308 net.cpp:454] loss_cls <- cls_score
I0625 17:07:54.886415 26308 net.cpp:454] loss_cls <- labels
I0625 17:07:54.886418 26308 net.cpp:411] loss_cls -> loss_cls
I0625 17:07:54.886425 26308 layer_factory.hpp:77] Creating layer loss_cls
I0625 17:07:54.887387 26308 net.cpp:150] Setting up loss_cls
I0625 17:07:54.887428 26308 net.cpp:157] Top shape: (1)
I0625 17:07:54.887444 26308 net.cpp:160]     with loss weight 3
I0625 17:07:54.887462 26308 net.cpp:165] Memory required for data: 1432650692
I0625 17:07:54.887475 26308 layer_factory.hpp:77] Creating layer loss_bbox
I0625 17:07:54.887503 26308 net.cpp:106] Creating Layer loss_bbox
I0625 17:07:54.887516 26308 net.cpp:454] loss_bbox <- bbox_pred
I0625 17:07:54.887528 26308 net.cpp:454] loss_bbox <- bbox_targets
I0625 17:07:54.887540 26308 net.cpp:454] loss_bbox <- bbox_inside_weights
I0625 17:07:54.887552 26308 net.cpp:454] loss_bbox <- bbox_outside_weights
I0625 17:07:54.887567 26308 net.cpp:411] loss_bbox -> loss_bbox
I0625 17:07:54.887689 26308 net.cpp:150] Setting up loss_bbox
I0625 17:07:54.887707 26308 net.cpp:157] Top shape: (1)
I0625 17:07:54.887717 26308 net.cpp:160]     with loss weight 2
I0625 17:07:54.887732 26308 net.cpp:165] Memory required for data: 1432650696
I0625 17:07:54.887742 26308 layer_factory.hpp:77] Creating layer roi_pool5_2
I0625 17:07:54.887754 26308 net.cpp:106] Creating Layer roi_pool5_2
I0625 17:07:54.887761 26308 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0625 17:07:54.887768 26308 net.cpp:454] roi_pool5_2 <- rois_pos
I0625 17:07:54.887774 26308 net.cpp:411] roi_pool5_2 -> pool5_2
I0625 17:07:54.887782 26308 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0625 17:07:54.887868 26308 net.cpp:150] Setting up roi_pool5_2
I0625 17:07:54.887874 26308 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:07:54.887878 26308 net.cpp:165] Memory required for data: 1432751048
I0625 17:07:54.887881 26308 layer_factory.hpp:77] Creating layer pool5_2_conv
I0625 17:07:54.887894 26308 net.cpp:106] Creating Layer pool5_2_conv
I0625 17:07:54.887897 26308 net.cpp:454] pool5_2_conv <- pool5_2
I0625 17:07:54.887902 26308 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0625 17:07:54.895299 26308 net.cpp:150] Setting up pool5_2_conv
I0625 17:07:54.895332 26308 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:07:54.895335 26308 net.cpp:165] Memory required for data: 1432851400
I0625 17:07:54.895347 26308 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0625 17:07:54.895359 26308 net.cpp:106] Creating Layer pool5_2_conv_relu
I0625 17:07:54.895365 26308 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0625 17:07:54.895373 26308 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0625 17:07:54.895555 26308 net.cpp:150] Setting up pool5_2_conv_relu
I0625 17:07:54.895575 26308 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:07:54.895576 26308 net.cpp:165] Memory required for data: 1432951752
I0625 17:07:54.895579 26308 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0625 17:07:54.895592 26308 net.cpp:106] Creating Layer pool5_2_conv2
I0625 17:07:54.895597 26308 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0625 17:07:54.895602 26308 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0625 17:07:54.951591 26308 net.cpp:150] Setting up pool5_2_conv2
I0625 17:07:54.951617 26308 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:07:54.951619 26308 net.cpp:165] Memory required for data: 1433052104
I0625 17:07:54.951637 26308 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0625 17:07:54.951645 26308 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0625 17:07:54.951649 26308 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0625 17:07:54.951665 26308 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0625 17:07:54.951834 26308 net.cpp:150] Setting up pool5_2_conv2_relu
I0625 17:07:54.951843 26308 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:07:54.951854 26308 net.cpp:165] Memory required for data: 1433152456
I0625 17:07:54.951858 26308 layer_factory.hpp:77] Creating layer mask_deconv1
I0625 17:07:54.951867 26308 net.cpp:106] Creating Layer mask_deconv1
I0625 17:07:54.951881 26308 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0625 17:07:54.951887 26308 net.cpp:411] mask_deconv1 -> mask_deconv1
I0625 17:07:54.952726 26308 net.cpp:150] Setting up mask_deconv1
I0625 17:07:54.952733 26308 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0625 17:07:54.952734 26308 net.cpp:165] Memory required for data: 1434074056
I0625 17:07:54.952739 26308 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0625 17:07:54.952746 26308 net.cpp:106] Creating Layer pool5_2_conv3
I0625 17:07:54.952749 26308 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0625 17:07:54.952754 26308 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0625 17:07:54.980723 26308 net.cpp:150] Setting up pool5_2_conv3
I0625 17:07:54.980742 26308 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:07:54.980744 26308 net.cpp:165] Memory required for data: 1435917256
I0625 17:07:54.980751 26308 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0625 17:07:54.980758 26308 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0625 17:07:54.980762 26308 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0625 17:07:54.980767 26308 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0625 17:07:54.980918 26308 net.cpp:150] Setting up pool5_2_conv3_relu
I0625 17:07:54.980926 26308 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:07:54.980927 26308 net.cpp:165] Memory required for data: 1437760456
I0625 17:07:54.980929 26308 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0625 17:07:54.980938 26308 net.cpp:106] Creating Layer pool5_2_conv4
I0625 17:07:54.980942 26308 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0625 17:07:54.980947 26308 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0625 17:07:55.030591 26308 net.cpp:150] Setting up pool5_2_conv4
I0625 17:07:55.030608 26308 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:07:55.030611 26308 net.cpp:165] Memory required for data: 1439603656
I0625 17:07:55.030617 26308 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0625 17:07:55.030625 26308 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0625 17:07:55.030630 26308 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0625 17:07:55.030647 26308 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0625 17:07:55.030782 26308 net.cpp:150] Setting up pool5_2_conv4_relu
I0625 17:07:55.030789 26308 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:07:55.030791 26308 net.cpp:165] Memory required for data: 1441446856
I0625 17:07:55.030792 26308 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0625 17:07:55.030797 26308 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0625 17:07:55.030799 26308 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0625 17:07:55.030802 26308 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0625 17:07:55.030808 26308 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0625 17:07:55.030825 26308 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0625 17:07:55.030829 26308 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0625 17:07:55.030880 26308 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0625 17:07:55.030884 26308 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:07:55.030887 26308 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:07:55.030889 26308 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:07:55.030891 26308 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:07:55.030892 26308 net.cpp:165] Memory required for data: 1448819656
I0625 17:07:55.030894 26308 layer_factory.hpp:77] Creating layer query_conv
I0625 17:07:55.030902 26308 net.cpp:106] Creating Layer query_conv
I0625 17:07:55.030916 26308 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0625 17:07:55.030922 26308 net.cpp:411] query_conv -> query_conv
I0625 17:07:55.032423 26308 net.cpp:150] Setting up query_conv
I0625 17:07:55.032431 26308 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0625 17:07:55.032433 26308 net.cpp:165] Memory required for data: 1449050056
I0625 17:07:55.032438 26308 layer_factory.hpp:77] Creating layer key_conv
I0625 17:07:55.032444 26308 net.cpp:106] Creating Layer key_conv
I0625 17:07:55.032447 26308 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0625 17:07:55.032464 26308 net.cpp:411] key_conv -> key_conv
I0625 17:07:55.033954 26308 net.cpp:150] Setting up key_conv
I0625 17:07:55.033962 26308 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0625 17:07:55.033964 26308 net.cpp:165] Memory required for data: 1449280456
I0625 17:07:55.033967 26308 layer_factory.hpp:77] Creating layer value_conv
I0625 17:07:55.033974 26308 net.cpp:106] Creating Layer value_conv
I0625 17:07:55.033977 26308 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0625 17:07:55.033991 26308 net.cpp:411] value_conv -> value_conv
I0625 17:07:55.040715 26308 net.cpp:150] Setting up value_conv
I0625 17:07:55.040736 26308 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:07:55.040738 26308 net.cpp:165] Memory required for data: 1451123656
I0625 17:07:55.040743 26308 layer_factory.hpp:77] Creating layer query_conv_reshape
I0625 17:07:55.040750 26308 net.cpp:106] Creating Layer query_conv_reshape
I0625 17:07:55.040753 26308 net.cpp:454] query_conv_reshape <- query_conv
I0625 17:07:55.040758 26308 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0625 17:07:55.040799 26308 net.cpp:150] Setting up query_conv_reshape
I0625 17:07:55.040803 26308 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0625 17:07:55.040805 26308 net.cpp:165] Memory required for data: 1451354056
I0625 17:07:55.040807 26308 layer_factory.hpp:77] Creating layer key_conv_reshape
I0625 17:07:55.040810 26308 net.cpp:106] Creating Layer key_conv_reshape
I0625 17:07:55.040812 26308 net.cpp:454] key_conv_reshape <- key_conv
I0625 17:07:55.040817 26308 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0625 17:07:55.040833 26308 net.cpp:150] Setting up key_conv_reshape
I0625 17:07:55.040846 26308 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0625 17:07:55.040848 26308 net.cpp:165] Memory required for data: 1451584456
I0625 17:07:55.040849 26308 layer_factory.hpp:77] Creating layer value_conv_reshape
I0625 17:07:55.040864 26308 net.cpp:106] Creating Layer value_conv_reshape
I0625 17:07:55.040866 26308 net.cpp:454] value_conv_reshape <- value_conv
I0625 17:07:55.040869 26308 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0625 17:07:55.040904 26308 net.cpp:150] Setting up value_conv_reshape
I0625 17:07:55.040906 26308 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0625 17:07:55.040908 26308 net.cpp:165] Memory required for data: 1453427656
I0625 17:07:55.040910 26308 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0625 17:07:55.040917 26308 net.cpp:106] Creating Layer query_conv_reshape_perm
I0625 17:07:55.040920 26308 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0625 17:07:55.040925 26308 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0625 17:07:55.041011 26308 net.cpp:150] Setting up query_conv_reshape_perm
I0625 17:07:55.041014 26308 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0625 17:07:55.041016 26308 net.cpp:165] Memory required for data: 1453658056
I0625 17:07:55.041028 26308 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0625 17:07:55.041030 26308 net.cpp:106] Creating Layer key_conv_reshape_perm
I0625 17:07:55.041033 26308 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0625 17:07:55.041035 26308 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0625 17:07:55.041122 26308 net.cpp:150] Setting up key_conv_reshape_perm
I0625 17:07:55.041127 26308 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0625 17:07:55.041129 26308 net.cpp:165] Memory required for data: 1453888456
I0625 17:07:55.041131 26308 layer_factory.hpp:77] Creating layer energy
I0625 17:07:55.041143 26308 net.cpp:106] Creating Layer energy
I0625 17:07:55.041146 26308 net.cpp:454] energy <- query_conv_reshape_perm
I0625 17:07:55.041149 26308 net.cpp:454] energy <- key_conv_reshape_perm
I0625 17:07:55.041152 26308 net.cpp:411] energy -> energy
I0625 17:07:55.041168 26308 net.cpp:150] Setting up energy
I0625 17:07:55.041172 26308 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0625 17:07:55.041173 26308 net.cpp:165] Memory required for data: 1457128456
I0625 17:07:55.041175 26308 layer_factory.hpp:77] Creating layer attention
I0625 17:07:55.041188 26308 net.cpp:106] Creating Layer attention
I0625 17:07:55.041190 26308 net.cpp:454] attention <- energy
I0625 17:07:55.041193 26308 net.cpp:411] attention -> attention
I0625 17:07:55.041357 26308 net.cpp:150] Setting up attention
I0625 17:07:55.041363 26308 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0625 17:07:55.041366 26308 net.cpp:165] Memory required for data: 1460368456
I0625 17:07:55.041368 26308 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0625 17:07:55.041373 26308 net.cpp:106] Creating Layer value_conv_reshape_perm
I0625 17:07:55.041374 26308 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0625 17:07:55.041378 26308 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0625 17:07:55.041448 26308 net.cpp:150] Setting up value_conv_reshape_perm
I0625 17:07:55.041453 26308 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0625 17:07:55.041456 26308 net.cpp:165] Memory required for data: 1462211656
I0625 17:07:55.041460 26308 layer_factory.hpp:77] Creating layer attention_perm
I0625 17:07:55.041465 26308 net.cpp:106] Creating Layer attention_perm
I0625 17:07:55.041468 26308 net.cpp:454] attention_perm <- attention
I0625 17:07:55.041471 26308 net.cpp:411] attention_perm -> attention_perm
I0625 17:07:55.041535 26308 net.cpp:150] Setting up attention_perm
I0625 17:07:55.041539 26308 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0625 17:07:55.041540 26308 net.cpp:165] Memory required for data: 1465451656
I0625 17:07:55.041543 26308 layer_factory.hpp:77] Creating layer out
I0625 17:07:55.041546 26308 net.cpp:106] Creating Layer out
I0625 17:07:55.041548 26308 net.cpp:454] out <- value_conv_reshape_perm
I0625 17:07:55.041550 26308 net.cpp:454] out <- attention_perm
I0625 17:07:55.041553 26308 net.cpp:411] out -> out
I0625 17:07:55.041568 26308 net.cpp:150] Setting up out
I0625 17:07:55.041571 26308 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0625 17:07:55.041573 26308 net.cpp:165] Memory required for data: 1467294856
I0625 17:07:55.041574 26308 layer_factory.hpp:77] Creating layer out_reshape
I0625 17:07:55.041579 26308 net.cpp:106] Creating Layer out_reshape
I0625 17:07:55.041580 26308 net.cpp:454] out_reshape <- out
I0625 17:07:55.041584 26308 net.cpp:411] out_reshape -> out_reshape
I0625 17:07:55.041597 26308 net.cpp:150] Setting up out_reshape
I0625 17:07:55.041601 26308 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:07:55.041604 26308 net.cpp:165] Memory required for data: 1469138056
I0625 17:07:55.041604 26308 layer_factory.hpp:77] Creating layer out_reshape_scale
I0625 17:07:55.041611 26308 net.cpp:106] Creating Layer out_reshape_scale
I0625 17:07:55.041615 26308 net.cpp:454] out_reshape_scale <- out_reshape
I0625 17:07:55.041617 26308 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0625 17:07:55.041677 26308 net.cpp:150] Setting up out_reshape_scale
I0625 17:07:55.041682 26308 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:07:55.041692 26308 net.cpp:165] Memory required for data: 1470981256
I0625 17:07:55.041695 26308 layer_factory.hpp:77] Creating layer out_x
I0625 17:07:55.041699 26308 net.cpp:106] Creating Layer out_x
I0625 17:07:55.041702 26308 net.cpp:454] out_x <- out_reshape_scale
I0625 17:07:55.041704 26308 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0625 17:07:55.041718 26308 net.cpp:411] out_x -> out_x
I0625 17:07:55.041733 26308 net.cpp:150] Setting up out_x
I0625 17:07:55.041738 26308 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:07:55.041740 26308 net.cpp:165] Memory required for data: 1472824456
I0625 17:07:55.041741 26308 layer_factory.hpp:77] Creating layer mask_deconv2
I0625 17:07:55.041746 26308 net.cpp:106] Creating Layer mask_deconv2
I0625 17:07:55.041749 26308 net.cpp:454] mask_deconv2 <- out_x
I0625 17:07:55.041751 26308 net.cpp:411] mask_deconv2 -> mask_deconv2
I0625 17:07:55.042634 26308 net.cpp:150] Setting up mask_deconv2
I0625 17:07:55.042640 26308 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0625 17:07:55.042642 26308 net.cpp:165] Memory required for data: 1488065672
I0625 17:07:55.042645 26308 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0625 17:07:55.042650 26308 net.cpp:106] Creating Layer pool5_2_conv5
I0625 17:07:55.042654 26308 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0625 17:07:55.042659 26308 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0625 17:07:55.068624 26308 net.cpp:150] Setting up pool5_2_conv5
I0625 17:07:55.068641 26308 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 17:07:55.068644 26308 net.cpp:165] Memory required for data: 1518548104
I0625 17:07:55.068650 26308 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0625 17:07:55.068657 26308 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0625 17:07:55.068661 26308 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0625 17:07:55.068667 26308 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0625 17:07:55.068804 26308 net.cpp:150] Setting up pool5_2_conv5_relu
I0625 17:07:55.068810 26308 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 17:07:55.068814 26308 net.cpp:165] Memory required for data: 1549030536
I0625 17:07:55.068819 26308 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0625 17:07:55.068828 26308 net.cpp:106] Creating Layer pool5_2_conv6
I0625 17:07:55.068831 26308 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0625 17:07:55.068837 26308 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0625 17:07:55.120486 26308 net.cpp:150] Setting up pool5_2_conv6
I0625 17:07:55.120504 26308 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 17:07:55.120507 26308 net.cpp:165] Memory required for data: 1579512968
I0625 17:07:55.120523 26308 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0625 17:07:55.120543 26308 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0625 17:07:55.120548 26308 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0625 17:07:55.120553 26308 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0625 17:07:55.121099 26308 net.cpp:150] Setting up pool5_2_conv6_relu
I0625 17:07:55.121109 26308 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 17:07:55.121111 26308 net.cpp:165] Memory required for data: 1609995400
I0625 17:07:55.121114 26308 layer_factory.hpp:77] Creating layer mask_deconv3
I0625 17:07:55.121119 26308 net.cpp:106] Creating Layer mask_deconv3
I0625 17:07:55.121122 26308 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0625 17:07:55.121127 26308 net.cpp:411] mask_deconv3 -> mask_deconv3
I0625 17:07:55.121508 26308 net.cpp:150] Setting up mask_deconv3
I0625 17:07:55.121515 26308 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0625 17:07:55.121516 26308 net.cpp:165] Memory required for data: 1670960264
I0625 17:07:55.121520 26308 layer_factory.hpp:77] Creating layer mask_score
I0625 17:07:55.121526 26308 net.cpp:106] Creating Layer mask_score
I0625 17:07:55.121529 26308 net.cpp:454] mask_score <- mask_deconv3
I0625 17:07:55.121533 26308 net.cpp:411] mask_score -> mask_score
I0625 17:07:55.122131 26308 net.cpp:150] Setting up mask_score
I0625 17:07:55.122138 26308 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:07:55.122140 26308 net.cpp:165] Memory required for data: 1672865416
I0625 17:07:55.122144 26308 layer_factory.hpp:77] Creating layer prob
I0625 17:07:55.122149 26308 net.cpp:106] Creating Layer prob
I0625 17:07:55.122153 26308 net.cpp:454] prob <- mask_score
I0625 17:07:55.122155 26308 net.cpp:411] prob -> mask_score_softmax
I0625 17:07:55.122753 26308 net.cpp:150] Setting up prob
I0625 17:07:55.122761 26308 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:07:55.122763 26308 net.cpp:165] Memory required for data: 1674770568
I0625 17:07:55.122766 26308 layer_factory.hpp:77] Creating layer log
I0625 17:07:55.122769 26308 net.cpp:106] Creating Layer log
I0625 17:07:55.122771 26308 net.cpp:454] log <- mask_score_softmax
I0625 17:07:55.122776 26308 net.cpp:411] log -> log
I0625 17:07:55.122802 26308 net.cpp:150] Setting up log
I0625 17:07:55.122805 26308 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:07:55.122817 26308 net.cpp:165] Memory required for data: 1676675720
I0625 17:07:55.122817 26308 layer_factory.hpp:77] Creating layer mult1
I0625 17:07:55.122822 26308 net.cpp:106] Creating Layer mult1
I0625 17:07:55.122823 26308 net.cpp:454] mult1 <- log
I0625 17:07:55.122836 26308 net.cpp:454] mult1 <- mask_targets
I0625 17:07:55.122839 26308 net.cpp:411] mult1 -> mult1
I0625 17:07:55.122854 26308 net.cpp:150] Setting up mult1
I0625 17:07:55.122859 26308 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:07:55.122859 26308 net.cpp:165] Memory required for data: 1678580872
I0625 17:07:55.122861 26308 layer_factory.hpp:77] Creating layer cross_entropy
I0625 17:07:55.122866 26308 net.cpp:106] Creating Layer cross_entropy
I0625 17:07:55.122869 26308 net.cpp:454] cross_entropy <- mult1
I0625 17:07:55.122871 26308 net.cpp:411] cross_entropy -> cross_entropy
I0625 17:07:55.122889 26308 net.cpp:150] Setting up cross_entropy
I0625 17:07:55.122893 26308 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:07:55.122895 26308 net.cpp:165] Memory required for data: 1680486024
I0625 17:07:55.122896 26308 layer_factory.hpp:77] Creating layer ce_sum
I0625 17:07:55.122901 26308 net.cpp:106] Creating Layer ce_sum
I0625 17:07:55.122905 26308 net.cpp:454] ce_sum <- cross_entropy
I0625 17:07:55.122907 26308 net.cpp:411] ce_sum -> cross_entropy_sum
I0625 17:07:55.124125 26308 net.cpp:150] Setting up ce_sum
I0625 17:07:55.124132 26308 net.cpp:157] Top shape: 1 1 244 244 (59536)
I0625 17:07:55.124136 26308 net.cpp:165] Memory required for data: 1680724168
I0625 17:07:55.124152 26308 layer_factory.hpp:77] Creating layer ce_mean
I0625 17:07:55.124164 26308 net.cpp:106] Creating Layer ce_mean
I0625 17:07:55.124167 26308 net.cpp:454] ce_mean <- cross_entropy_sum
I0625 17:07:55.124172 26308 net.cpp:411] ce_mean -> cross_entropy_mean
I0625 17:07:55.124758 26308 net.cpp:150] Setting up ce_mean
I0625 17:07:55.124766 26308 net.cpp:157] Top shape: (1)
I0625 17:07:55.124770 26308 net.cpp:160]     with loss weight 1
I0625 17:07:55.124779 26308 net.cpp:165] Memory required for data: 1680724172
I0625 17:07:55.124783 26308 net.cpp:226] ce_mean needs backward computation.
I0625 17:07:55.124786 26308 net.cpp:226] ce_sum needs backward computation.
I0625 17:07:55.124789 26308 net.cpp:226] cross_entropy needs backward computation.
I0625 17:07:55.124792 26308 net.cpp:226] mult1 needs backward computation.
I0625 17:07:55.124795 26308 net.cpp:226] log needs backward computation.
I0625 17:07:55.124799 26308 net.cpp:226] prob needs backward computation.
I0625 17:07:55.124801 26308 net.cpp:226] mask_score needs backward computation.
I0625 17:07:55.124804 26308 net.cpp:226] mask_deconv3 needs backward computation.
I0625 17:07:55.124807 26308 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0625 17:07:55.124809 26308 net.cpp:226] pool5_2_conv6 needs backward computation.
I0625 17:07:55.124812 26308 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0625 17:07:55.124816 26308 net.cpp:226] pool5_2_conv5 needs backward computation.
I0625 17:07:55.124819 26308 net.cpp:226] mask_deconv2 needs backward computation.
I0625 17:07:55.124822 26308 net.cpp:226] out_x needs backward computation.
I0625 17:07:55.124826 26308 net.cpp:226] out_reshape_scale needs backward computation.
I0625 17:07:55.124830 26308 net.cpp:226] out_reshape needs backward computation.
I0625 17:07:55.124831 26308 net.cpp:226] out needs backward computation.
I0625 17:07:55.124835 26308 net.cpp:226] attention_perm needs backward computation.
I0625 17:07:55.124840 26308 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0625 17:07:55.124843 26308 net.cpp:226] attention needs backward computation.
I0625 17:07:55.124846 26308 net.cpp:226] energy needs backward computation.
I0625 17:07:55.124850 26308 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0625 17:07:55.124855 26308 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0625 17:07:55.124858 26308 net.cpp:226] value_conv_reshape needs backward computation.
I0625 17:07:55.124861 26308 net.cpp:226] key_conv_reshape needs backward computation.
I0625 17:07:55.124866 26308 net.cpp:226] query_conv_reshape needs backward computation.
I0625 17:07:55.124869 26308 net.cpp:226] value_conv needs backward computation.
I0625 17:07:55.124872 26308 net.cpp:226] key_conv needs backward computation.
I0625 17:07:55.124876 26308 net.cpp:226] query_conv needs backward computation.
I0625 17:07:55.124881 26308 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0625 17:07:55.124884 26308 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0625 17:07:55.124887 26308 net.cpp:226] pool5_2_conv4 needs backward computation.
I0625 17:07:55.124891 26308 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0625 17:07:55.124895 26308 net.cpp:226] pool5_2_conv3 needs backward computation.
I0625 17:07:55.124899 26308 net.cpp:226] mask_deconv1 needs backward computation.
I0625 17:07:55.124902 26308 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0625 17:07:55.124907 26308 net.cpp:226] pool5_2_conv2 needs backward computation.
I0625 17:07:55.124910 26308 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0625 17:07:55.124914 26308 net.cpp:226] pool5_2_conv needs backward computation.
I0625 17:07:55.124917 26308 net.cpp:226] roi_pool5_2 needs backward computation.
I0625 17:07:55.124922 26308 net.cpp:226] loss_bbox needs backward computation.
I0625 17:07:55.124927 26308 net.cpp:226] loss_cls needs backward computation.
I0625 17:07:55.124930 26308 net.cpp:226] loss_attribute needs backward computation.
I0625 17:07:55.124934 26308 net.cpp:226] bbox_pred needs backward computation.
I0625 17:07:55.124938 26308 net.cpp:226] cls_score needs backward computation.
I0625 17:07:55.124944 26308 net.cpp:226] attr_score_pos_shift needs backward computation.
I0625 17:07:55.124948 26308 net.cpp:226] attr_score_pos needs backward computation.
I0625 17:07:55.124953 26308 net.cpp:226] attr_score needs backward computation.
I0625 17:07:55.124956 26308 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0625 17:07:55.124960 26308 net.cpp:226] relu7 needs backward computation.
I0625 17:07:55.124963 26308 net.cpp:226] fc7 needs backward computation.
I0625 17:07:55.124967 26308 net.cpp:226] relu6 needs backward computation.
I0625 17:07:55.124970 26308 net.cpp:226] fc6 needs backward computation.
I0625 17:07:55.124974 26308 net.cpp:226] roi_pool5 needs backward computation.
I0625 17:07:55.124979 26308 net.cpp:226] roi-data needs backward computation.
I0625 17:07:55.124984 26308 net.cpp:226] proposal needs backward computation.
I0625 17:07:55.124989 26308 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0625 17:07:55.124992 26308 net.cpp:226] rpn_cls_prob needs backward computation.
I0625 17:07:55.124996 26308 net.cpp:226] rpn_loss_bbox needs backward computation.
I0625 17:07:55.125001 26308 net.cpp:226] rpn_loss_cls needs backward computation.
I0625 17:07:55.125006 26308 net.cpp:226] rpn-data needs backward computation.
I0625 17:07:55.125012 26308 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0625 17:07:55.125015 26308 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0625 17:07:55.125018 26308 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0625 17:07:55.125022 26308 net.cpp:226] rpn_bbox_pred needs backward computation.
I0625 17:07:55.125026 26308 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0625 17:07:55.125030 26308 net.cpp:226] rpn_cls_score needs backward computation.
I0625 17:07:55.125035 26308 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0625 17:07:55.125038 26308 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0625 17:07:55.125042 26308 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0625 17:07:55.125046 26308 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0625 17:07:55.125061 26308 net.cpp:226] relu5_3 needs backward computation.
I0625 17:07:55.125064 26308 net.cpp:226] conv5_3 needs backward computation.
I0625 17:07:55.125067 26308 net.cpp:226] relu5_2 needs backward computation.
I0625 17:07:55.125072 26308 net.cpp:226] conv5_2 needs backward computation.
I0625 17:07:55.125074 26308 net.cpp:226] relu5_1 needs backward computation.
I0625 17:07:55.125077 26308 net.cpp:226] conv5_1 needs backward computation.
I0625 17:07:55.125080 26308 net.cpp:226] pool4 needs backward computation.
I0625 17:07:55.125083 26308 net.cpp:226] relu4_3 needs backward computation.
I0625 17:07:55.125087 26308 net.cpp:226] conv4_3 needs backward computation.
I0625 17:07:55.125090 26308 net.cpp:226] relu4_2 needs backward computation.
I0625 17:07:55.125093 26308 net.cpp:226] conv4_2 needs backward computation.
I0625 17:07:55.125097 26308 net.cpp:226] relu4_1 needs backward computation.
I0625 17:07:55.125099 26308 net.cpp:226] conv4_1 needs backward computation.
I0625 17:07:55.125116 26308 net.cpp:226] pool3 needs backward computation.
I0625 17:07:55.125119 26308 net.cpp:226] relu3_3 needs backward computation.
I0625 17:07:55.125131 26308 net.cpp:226] conv3_3 needs backward computation.
I0625 17:07:55.125134 26308 net.cpp:226] relu3_2 needs backward computation.
I0625 17:07:55.125138 26308 net.cpp:226] conv3_2 needs backward computation.
I0625 17:07:55.125140 26308 net.cpp:226] relu3_1 needs backward computation.
I0625 17:07:55.125144 26308 net.cpp:226] conv3_1 needs backward computation.
I0625 17:07:55.125145 26308 net.cpp:228] pool2 does not need backward computation.
I0625 17:07:55.125149 26308 net.cpp:228] relu2_2 does not need backward computation.
I0625 17:07:55.125152 26308 net.cpp:228] conv2_2 does not need backward computation.
I0625 17:07:55.125155 26308 net.cpp:228] relu2_1 does not need backward computation.
I0625 17:07:55.125159 26308 net.cpp:228] conv2_1 does not need backward computation.
I0625 17:07:55.125162 26308 net.cpp:228] pool1 does not need backward computation.
I0625 17:07:55.125165 26308 net.cpp:228] relu1_2 does not need backward computation.
I0625 17:07:55.125169 26308 net.cpp:228] conv1_2 does not need backward computation.
I0625 17:07:55.125172 26308 net.cpp:228] relu1_1 does not need backward computation.
I0625 17:07:55.125176 26308 net.cpp:228] conv1_1 does not need backward computation.
I0625 17:07:55.125180 26308 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0625 17:07:55.125185 26308 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0625 17:07:55.125188 26308 net.cpp:228] data_input-data_0_split does not need backward computation.
I0625 17:07:55.125192 26308 net.cpp:228] input-data does not need backward computation.
I0625 17:07:55.125195 26308 net.cpp:270] This network produces output cross_entropy_mean
I0625 17:07:55.125198 26308 net.cpp:270] This network produces output loss_attribute
I0625 17:07:55.125202 26308 net.cpp:270] This network produces output loss_bbox
I0625 17:07:55.125205 26308 net.cpp:270] This network produces output loss_cls
I0625 17:07:55.125210 26308 net.cpp:270] This network produces output rpn_cls_loss
I0625 17:07:55.125212 26308 net.cpp:270] This network produces output rpn_loss_bbox
I0625 17:07:55.125267 26308 net.cpp:283] Network initialization done.
I0625 17:07:55.125460 26308 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0625 17:07:56.375883 26308 net.cpp:816] Ignoring source layer pool5
I0625 17:07:56.438715 26308 net.cpp:816] Ignoring source layer drop6
I0625 17:07:56.448947 26308 net.cpp:816] Ignoring source layer drop7
I0625 17:07:56.448969 26308 net.cpp:816] Ignoring source layer fc8
Solving...
I0625 17:07:57.556426 26308 solver.cpp:229] Iteration 0, loss = 5.57038
I0625 17:07:57.616032 26308 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.54325 (* 1 = 1.54325 loss)
I0625 17:07:57.616050 26308 solver.cpp:245]     Train net output #1: loss_attribute = 0.304792 (* 1 = 0.304792 loss)
I0625 17:07:57.616055 26308 solver.cpp:245]     Train net output #2: loss_bbox = 0.0916567 (* 2 = 0.183313 loss)
I0625 17:07:57.616058 26308 solver.cpp:245]     Train net output #3: loss_cls = 0.947394 (* 3 = 2.84218 loss)
I0625 17:07:57.616062 26308 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.73882 (* 1 = 0.73882 loss)
I0625 17:07:57.616066 26308 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0189577 (* 1 = 0.0189577 loss)
I0625 17:07:57.616082 26308 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0625 17:08:14.934049 26308 solver.cpp:229] Iteration 20, loss = 2.57131
I0625 17:08:14.986833 26308 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.91193 (* 1 = 1.91193 loss)
I0625 17:08:14.986846 26308 solver.cpp:245]     Train net output #1: loss_attribute = 0.0768466 (* 1 = 0.0768466 loss)
I0625 17:08:14.986850 26308 solver.cpp:245]     Train net output #2: loss_bbox = 0.00271047 (* 2 = 0.00542093 loss)
I0625 17:08:14.986855 26308 solver.cpp:245]     Train net output #3: loss_cls = 0.126429 (* 3 = 0.379286 loss)
I0625 17:08:14.986857 26308 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.292362 (* 1 = 0.292362 loss)
I0625 17:08:14.986861 26308 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0276353 (* 1 = 0.0276353 loss)
I0625 17:08:14.986865 26308 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0625 17:08:32.459918 26308 solver.cpp:229] Iteration 40, loss = 3.06435
I0625 17:08:32.511723 26308 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.78103 (* 1 = 1.78103 loss)
I0625 17:08:32.511739 26308 solver.cpp:245]     Train net output #1: loss_attribute = 0.0713726 (* 1 = 0.0713726 loss)
I0625 17:08:32.511744 26308 solver.cpp:245]     Train net output #2: loss_bbox = 0.00203746 (* 2 = 0.00407492 loss)
I0625 17:08:32.511747 26308 solver.cpp:245]     Train net output #3: loss_cls = 0.143235 (* 3 = 0.429705 loss)
I0625 17:08:32.511750 26308 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0914944 (* 1 = 0.0914944 loss)
I0625 17:08:32.511754 26308 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0835982 (* 1 = 0.0835982 loss)
I0625 17:08:32.511768 26308 sgd_solver.cpp:106] Iteration 40, lr = 0.001
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:62: RuntimeWarning: overflow encountered in exp
  pred_w = np.exp(dw) * widths[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:62: RuntimeWarning: overflow encountered in multiply
  pred_w = np.exp(dw) * widths[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:63: RuntimeWarning: overflow encountered in exp
  pred_h = np.exp(dh) * heights[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:63: RuntimeWarning: overflow encountered in multiply
  pred_h = np.exp(dh) * heights[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:83: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:83: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:85: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:85: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:87: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:87: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:89: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:89: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/rpn/proposal_layer.py:187: RuntimeWarning: invalid value encountered in greater_equal
  keep = np.where((ws >= min_size) & (hs >= min_size))[0]
---- WARNING: filter_boxes() remove ALL proposal.
./experiments/scripts/faster_rcnn_end2end.sh: line 65: 26308 Floating point exception/usr/bin/python ./tools/train_net.py --gpu ${GPU_ID} --solver models/${PT_DIR}/${NET}/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb ${TRAIN_IMDB} --iters ${ITERS} --cfg experiments/cfgs/faster_rcnn_end2end.yml ${EXTRA_ARGS}
