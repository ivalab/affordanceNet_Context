+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-25_16-06-40
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-25_16-06-40
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0625 16:06:48.457053  5526 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0625 16:06:48.457070  5526 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0625 16:06:48.458232  5526 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "pool5_2_conv4_relu"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "mask_score"
  top: "mask_score_softmax"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "log"
  type: "Log"
  bottom: "mask_score_softmax"
  top: "log"
}
layer {
  name: "mult1"
  type: "Eltwise"
  bottom: "log"
  bottom: "mask_targets"
  top: "mult1"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "cross_entropy"
  type: "Power"
  bottom: "mult1"
  top: "cross_entropy"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "ce_sum"
  type: "Convolution"
  bottom: "cross_entropy"
  top: "cross_entropy_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "ce_mean"
  type: "Reduction"
  bottom: "cross_entropy_sum"
  top: "cross_entropy_mean"
  loss_weight: 1
  reduction_param {
    operation: MEAN
    axis: 0
  }
}
I0625 16:06:48.458622  5526 layer_factory.hpp:77] Creating layer input-data
I0625 16:06:48.489979  5526 net.cpp:106] Creating Layer input-data
I0625 16:06:48.489998  5526 net.cpp:411] input-data -> data
I0625 16:06:48.490008  5526 net.cpp:411] input-data -> im_info
I0625 16:06:48.490015  5526 net.cpp:411] input-data -> gt_boxes
I0625 16:06:48.490021  5526 net.cpp:411] input-data -> seg_mask_inds
I0625 16:06:48.490026  5526 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0625 16:06:48.501109  5526 net.cpp:150] Setting up input-data
I0625 16:06:48.501127  5526 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 16:06:48.501133  5526 net.cpp:157] Top shape: 1 3 (3)
I0625 16:06:48.501139  5526 net.cpp:157] Top shape: 1 4 (4)
I0625 16:06:48.501143  5526 net.cpp:157] Top shape: 1 2 (2)
I0625 16:06:48.501147  5526 net.cpp:157] Top shape: 1 1 (1)
I0625 16:06:48.501150  5526 net.cpp:165] Memory required for data: 7200040
I0625 16:06:48.501157  5526 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0625 16:06:48.501181  5526 net.cpp:106] Creating Layer data_input-data_0_split
I0625 16:06:48.501186  5526 net.cpp:454] data_input-data_0_split <- data
I0625 16:06:48.501193  5526 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0625 16:06:48.501210  5526 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0625 16:06:48.501263  5526 net.cpp:150] Setting up data_input-data_0_split
I0625 16:06:48.501269  5526 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 16:06:48.501273  5526 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 16:06:48.501276  5526 net.cpp:165] Memory required for data: 21600040
I0625 16:06:48.501281  5526 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0625 16:06:48.501286  5526 net.cpp:106] Creating Layer im_info_input-data_1_split
I0625 16:06:48.501291  5526 net.cpp:454] im_info_input-data_1_split <- im_info
I0625 16:06:48.501296  5526 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0625 16:06:48.501302  5526 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0625 16:06:48.501308  5526 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0625 16:06:48.501333  5526 net.cpp:150] Setting up im_info_input-data_1_split
I0625 16:06:48.501338  5526 net.cpp:157] Top shape: 1 3 (3)
I0625 16:06:48.501343  5526 net.cpp:157] Top shape: 1 3 (3)
I0625 16:06:48.501348  5526 net.cpp:157] Top shape: 1 3 (3)
I0625 16:06:48.501350  5526 net.cpp:165] Memory required for data: 21600076
I0625 16:06:48.501354  5526 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0625 16:06:48.501359  5526 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0625 16:06:48.501363  5526 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0625 16:06:48.501368  5526 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0625 16:06:48.501374  5526 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0625 16:06:48.501394  5526 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0625 16:06:48.501397  5526 net.cpp:157] Top shape: 1 4 (4)
I0625 16:06:48.501401  5526 net.cpp:157] Top shape: 1 4 (4)
I0625 16:06:48.501405  5526 net.cpp:165] Memory required for data: 21600108
I0625 16:06:48.501408  5526 layer_factory.hpp:77] Creating layer conv1_1
I0625 16:06:48.501418  5526 net.cpp:106] Creating Layer conv1_1
I0625 16:06:48.501422  5526 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0625 16:06:48.501427  5526 net.cpp:411] conv1_1 -> conv1_1
I0625 16:06:48.711730  5526 net.cpp:150] Setting up conv1_1
I0625 16:06:48.711751  5526 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 16:06:48.711755  5526 net.cpp:165] Memory required for data: 175200108
I0625 16:06:48.711769  5526 layer_factory.hpp:77] Creating layer relu1_1
I0625 16:06:48.711789  5526 net.cpp:106] Creating Layer relu1_1
I0625 16:06:48.711796  5526 net.cpp:454] relu1_1 <- conv1_1
I0625 16:06:48.711812  5526 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0625 16:06:48.711968  5526 net.cpp:150] Setting up relu1_1
I0625 16:06:48.711975  5526 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 16:06:48.711978  5526 net.cpp:165] Memory required for data: 328800108
I0625 16:06:48.711982  5526 layer_factory.hpp:77] Creating layer conv1_2
I0625 16:06:48.711992  5526 net.cpp:106] Creating Layer conv1_2
I0625 16:06:48.711997  5526 net.cpp:454] conv1_2 <- conv1_1
I0625 16:06:48.712011  5526 net.cpp:411] conv1_2 -> conv1_2
I0625 16:06:48.714026  5526 net.cpp:150] Setting up conv1_2
I0625 16:06:48.714038  5526 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 16:06:48.714041  5526 net.cpp:165] Memory required for data: 482400108
I0625 16:06:48.714051  5526 layer_factory.hpp:77] Creating layer relu1_2
I0625 16:06:48.714071  5526 net.cpp:106] Creating Layer relu1_2
I0625 16:06:48.714076  5526 net.cpp:454] relu1_2 <- conv1_2
I0625 16:06:48.714090  5526 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0625 16:06:48.714243  5526 net.cpp:150] Setting up relu1_2
I0625 16:06:48.714251  5526 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 16:06:48.714252  5526 net.cpp:165] Memory required for data: 636000108
I0625 16:06:48.714272  5526 layer_factory.hpp:77] Creating layer pool1
I0625 16:06:48.714303  5526 net.cpp:106] Creating Layer pool1
I0625 16:06:48.714308  5526 net.cpp:454] pool1 <- conv1_2
I0625 16:06:48.714323  5526 net.cpp:411] pool1 -> pool1
I0625 16:06:48.714370  5526 net.cpp:150] Setting up pool1
I0625 16:06:48.714385  5526 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0625 16:06:48.714386  5526 net.cpp:165] Memory required for data: 674400108
I0625 16:06:48.714390  5526 layer_factory.hpp:77] Creating layer conv2_1
I0625 16:06:48.714407  5526 net.cpp:106] Creating Layer conv2_1
I0625 16:06:48.714411  5526 net.cpp:454] conv2_1 <- pool1
I0625 16:06:48.714417  5526 net.cpp:411] conv2_1 -> conv2_1
I0625 16:06:48.716202  5526 net.cpp:150] Setting up conv2_1
I0625 16:06:48.716212  5526 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 16:06:48.716215  5526 net.cpp:165] Memory required for data: 751200108
I0625 16:06:48.716238  5526 layer_factory.hpp:77] Creating layer relu2_1
I0625 16:06:48.716253  5526 net.cpp:106] Creating Layer relu2_1
I0625 16:06:48.716259  5526 net.cpp:454] relu2_1 <- conv2_1
I0625 16:06:48.716277  5526 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0625 16:06:48.716791  5526 net.cpp:150] Setting up relu2_1
I0625 16:06:48.716800  5526 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 16:06:48.716804  5526 net.cpp:165] Memory required for data: 828000108
I0625 16:06:48.716807  5526 layer_factory.hpp:77] Creating layer conv2_2
I0625 16:06:48.716816  5526 net.cpp:106] Creating Layer conv2_2
I0625 16:06:48.716820  5526 net.cpp:454] conv2_2 <- conv2_1
I0625 16:06:48.716835  5526 net.cpp:411] conv2_2 -> conv2_2
I0625 16:06:48.718217  5526 net.cpp:150] Setting up conv2_2
I0625 16:06:48.718228  5526 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 16:06:48.718232  5526 net.cpp:165] Memory required for data: 904800108
I0625 16:06:48.718240  5526 layer_factory.hpp:77] Creating layer relu2_2
I0625 16:06:48.718246  5526 net.cpp:106] Creating Layer relu2_2
I0625 16:06:48.718251  5526 net.cpp:454] relu2_2 <- conv2_2
I0625 16:06:48.718262  5526 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0625 16:06:48.718392  5526 net.cpp:150] Setting up relu2_2
I0625 16:06:48.718400  5526 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 16:06:48.718402  5526 net.cpp:165] Memory required for data: 981600108
I0625 16:06:48.718405  5526 layer_factory.hpp:77] Creating layer pool2
I0625 16:06:48.718412  5526 net.cpp:106] Creating Layer pool2
I0625 16:06:48.718416  5526 net.cpp:454] pool2 <- conv2_2
I0625 16:06:48.718421  5526 net.cpp:411] pool2 -> pool2
I0625 16:06:48.718452  5526 net.cpp:150] Setting up pool2
I0625 16:06:48.718457  5526 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0625 16:06:48.718461  5526 net.cpp:165] Memory required for data: 1000800108
I0625 16:06:48.718463  5526 layer_factory.hpp:77] Creating layer conv3_1
I0625 16:06:48.718472  5526 net.cpp:106] Creating Layer conv3_1
I0625 16:06:48.718474  5526 net.cpp:454] conv3_1 <- pool2
I0625 16:06:48.718482  5526 net.cpp:411] conv3_1 -> conv3_1
I0625 16:06:48.720252  5526 net.cpp:150] Setting up conv3_1
I0625 16:06:48.720261  5526 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 16:06:48.720264  5526 net.cpp:165] Memory required for data: 1039200108
I0625 16:06:48.720274  5526 layer_factory.hpp:77] Creating layer relu3_1
I0625 16:06:48.720281  5526 net.cpp:106] Creating Layer relu3_1
I0625 16:06:48.720285  5526 net.cpp:454] relu3_1 <- conv3_1
I0625 16:06:48.720290  5526 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0625 16:06:48.720402  5526 net.cpp:150] Setting up relu3_1
I0625 16:06:48.720410  5526 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 16:06:48.720412  5526 net.cpp:165] Memory required for data: 1077600108
I0625 16:06:48.720417  5526 layer_factory.hpp:77] Creating layer conv3_2
I0625 16:06:48.720425  5526 net.cpp:106] Creating Layer conv3_2
I0625 16:06:48.720429  5526 net.cpp:454] conv3_2 <- conv3_1
I0625 16:06:48.720434  5526 net.cpp:411] conv3_2 -> conv3_2
I0625 16:06:48.722357  5526 net.cpp:150] Setting up conv3_2
I0625 16:06:48.722367  5526 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 16:06:48.722369  5526 net.cpp:165] Memory required for data: 1116000108
I0625 16:06:48.722376  5526 layer_factory.hpp:77] Creating layer relu3_2
I0625 16:06:48.722383  5526 net.cpp:106] Creating Layer relu3_2
I0625 16:06:48.722388  5526 net.cpp:454] relu3_2 <- conv3_2
I0625 16:06:48.722393  5526 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0625 16:06:48.722529  5526 net.cpp:150] Setting up relu3_2
I0625 16:06:48.722537  5526 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 16:06:48.722538  5526 net.cpp:165] Memory required for data: 1154400108
I0625 16:06:48.722551  5526 layer_factory.hpp:77] Creating layer conv3_3
I0625 16:06:48.722561  5526 net.cpp:106] Creating Layer conv3_3
I0625 16:06:48.722564  5526 net.cpp:454] conv3_3 <- conv3_2
I0625 16:06:48.722579  5526 net.cpp:411] conv3_3 -> conv3_3
I0625 16:06:48.724494  5526 net.cpp:150] Setting up conv3_3
I0625 16:06:48.724504  5526 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 16:06:48.724509  5526 net.cpp:165] Memory required for data: 1192800108
I0625 16:06:48.724515  5526 layer_factory.hpp:77] Creating layer relu3_3
I0625 16:06:48.724522  5526 net.cpp:106] Creating Layer relu3_3
I0625 16:06:48.724526  5526 net.cpp:454] relu3_3 <- conv3_3
I0625 16:06:48.724544  5526 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0625 16:06:48.724704  5526 net.cpp:150] Setting up relu3_3
I0625 16:06:48.724711  5526 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 16:06:48.724714  5526 net.cpp:165] Memory required for data: 1231200108
I0625 16:06:48.724716  5526 layer_factory.hpp:77] Creating layer pool3
I0625 16:06:48.724723  5526 net.cpp:106] Creating Layer pool3
I0625 16:06:48.724727  5526 net.cpp:454] pool3 <- conv3_3
I0625 16:06:48.724743  5526 net.cpp:411] pool3 -> pool3
I0625 16:06:48.724784  5526 net.cpp:150] Setting up pool3
I0625 16:06:48.724790  5526 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0625 16:06:48.724793  5526 net.cpp:165] Memory required for data: 1240800108
I0625 16:06:48.724797  5526 layer_factory.hpp:77] Creating layer conv4_1
I0625 16:06:48.724802  5526 net.cpp:106] Creating Layer conv4_1
I0625 16:06:48.724805  5526 net.cpp:454] conv4_1 <- pool3
I0625 16:06:48.724812  5526 net.cpp:411] conv4_1 -> conv4_1
I0625 16:06:48.728399  5526 net.cpp:150] Setting up conv4_1
I0625 16:06:48.728418  5526 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 16:06:48.728421  5526 net.cpp:165] Memory required for data: 1260000108
I0625 16:06:48.728430  5526 layer_factory.hpp:77] Creating layer relu4_1
I0625 16:06:48.728440  5526 net.cpp:106] Creating Layer relu4_1
I0625 16:06:48.728446  5526 net.cpp:454] relu4_1 <- conv4_1
I0625 16:06:48.728454  5526 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0625 16:06:48.728574  5526 net.cpp:150] Setting up relu4_1
I0625 16:06:48.728581  5526 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 16:06:48.728583  5526 net.cpp:165] Memory required for data: 1279200108
I0625 16:06:48.728587  5526 layer_factory.hpp:77] Creating layer conv4_2
I0625 16:06:48.728610  5526 net.cpp:106] Creating Layer conv4_2
I0625 16:06:48.728613  5526 net.cpp:454] conv4_2 <- conv4_1
I0625 16:06:48.728629  5526 net.cpp:411] conv4_2 -> conv4_2
I0625 16:06:48.742116  5526 net.cpp:150] Setting up conv4_2
I0625 16:06:48.742139  5526 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 16:06:48.742143  5526 net.cpp:165] Memory required for data: 1298400108
I0625 16:06:48.742157  5526 layer_factory.hpp:77] Creating layer relu4_2
I0625 16:06:48.742168  5526 net.cpp:106] Creating Layer relu4_2
I0625 16:06:48.742199  5526 net.cpp:454] relu4_2 <- conv4_2
I0625 16:06:48.742215  5526 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0625 16:06:48.742877  5526 net.cpp:150] Setting up relu4_2
I0625 16:06:48.742900  5526 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 16:06:48.742911  5526 net.cpp:165] Memory required for data: 1317600108
I0625 16:06:48.742921  5526 layer_factory.hpp:77] Creating layer conv4_3
I0625 16:06:48.742939  5526 net.cpp:106] Creating Layer conv4_3
I0625 16:06:48.742950  5526 net.cpp:454] conv4_3 <- conv4_2
I0625 16:06:48.742969  5526 net.cpp:411] conv4_3 -> conv4_3
I0625 16:06:48.750463  5526 net.cpp:150] Setting up conv4_3
I0625 16:06:48.750530  5526 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 16:06:48.750545  5526 net.cpp:165] Memory required for data: 1336800108
I0625 16:06:48.750566  5526 layer_factory.hpp:77] Creating layer relu4_3
I0625 16:06:48.750586  5526 net.cpp:106] Creating Layer relu4_3
I0625 16:06:48.750602  5526 net.cpp:454] relu4_3 <- conv4_3
I0625 16:06:48.750617  5526 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0625 16:06:48.750828  5526 net.cpp:150] Setting up relu4_3
I0625 16:06:48.750849  5526 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 16:06:48.750859  5526 net.cpp:165] Memory required for data: 1356000108
I0625 16:06:48.750869  5526 layer_factory.hpp:77] Creating layer pool4
I0625 16:06:48.750885  5526 net.cpp:106] Creating Layer pool4
I0625 16:06:48.750895  5526 net.cpp:454] pool4 <- conv4_3
I0625 16:06:48.750907  5526 net.cpp:411] pool4 -> pool4
I0625 16:06:48.750958  5526 net.cpp:150] Setting up pool4
I0625 16:06:48.750972  5526 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:06:48.750982  5526 net.cpp:165] Memory required for data: 1360903020
I0625 16:06:48.750991  5526 layer_factory.hpp:77] Creating layer conv5_1
I0625 16:06:48.751009  5526 net.cpp:106] Creating Layer conv5_1
I0625 16:06:48.751019  5526 net.cpp:454] conv5_1 <- pool4
I0625 16:06:48.751032  5526 net.cpp:411] conv5_1 -> conv5_1
I0625 16:06:48.758255  5526 net.cpp:150] Setting up conv5_1
I0625 16:06:48.758327  5526 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:06:48.758344  5526 net.cpp:165] Memory required for data: 1365805932
I0625 16:06:48.758368  5526 layer_factory.hpp:77] Creating layer relu5_1
I0625 16:06:48.758389  5526 net.cpp:106] Creating Layer relu5_1
I0625 16:06:48.758402  5526 net.cpp:454] relu5_1 <- conv5_1
I0625 16:06:48.758416  5526 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0625 16:06:48.758630  5526 net.cpp:150] Setting up relu5_1
I0625 16:06:48.758654  5526 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:06:48.758664  5526 net.cpp:165] Memory required for data: 1370708844
I0625 16:06:48.758674  5526 layer_factory.hpp:77] Creating layer conv5_2
I0625 16:06:48.758693  5526 net.cpp:106] Creating Layer conv5_2
I0625 16:06:48.758703  5526 net.cpp:454] conv5_2 <- conv5_1
I0625 16:06:48.758716  5526 net.cpp:411] conv5_2 -> conv5_2
I0625 16:06:48.765748  5526 net.cpp:150] Setting up conv5_2
I0625 16:06:48.765813  5526 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:06:48.765836  5526 net.cpp:165] Memory required for data: 1375611756
I0625 16:06:48.765858  5526 layer_factory.hpp:77] Creating layer relu5_2
I0625 16:06:48.765878  5526 net.cpp:106] Creating Layer relu5_2
I0625 16:06:48.765892  5526 net.cpp:454] relu5_2 <- conv5_2
I0625 16:06:48.765906  5526 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0625 16:06:48.766132  5526 net.cpp:150] Setting up relu5_2
I0625 16:06:48.766155  5526 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:06:48.766167  5526 net.cpp:165] Memory required for data: 1380514668
I0625 16:06:48.766185  5526 layer_factory.hpp:77] Creating layer conv5_3
I0625 16:06:48.766211  5526 net.cpp:106] Creating Layer conv5_3
I0625 16:06:48.766223  5526 net.cpp:454] conv5_3 <- conv5_2
I0625 16:06:48.766237  5526 net.cpp:411] conv5_3 -> conv5_3
I0625 16:06:48.777128  5526 net.cpp:150] Setting up conv5_3
I0625 16:06:48.777215  5526 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:06:48.777248  5526 net.cpp:165] Memory required for data: 1385417580
I0625 16:06:48.777278  5526 layer_factory.hpp:77] Creating layer relu5_3
I0625 16:06:48.777304  5526 net.cpp:106] Creating Layer relu5_3
I0625 16:06:48.777324  5526 net.cpp:454] relu5_3 <- conv5_3
I0625 16:06:48.777348  5526 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0625 16:06:48.777740  5526 net.cpp:150] Setting up relu5_3
I0625 16:06:48.777776  5526 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:06:48.777796  5526 net.cpp:165] Memory required for data: 1390320492
I0625 16:06:48.777815  5526 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0625 16:06:48.777842  5526 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0625 16:06:48.777855  5526 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0625 16:06:48.777873  5526 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0625 16:06:48.777894  5526 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0625 16:06:48.777915  5526 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0625 16:06:48.778062  5526 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0625 16:06:48.778095  5526 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:06:48.778113  5526 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:06:48.778128  5526 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:06:48.778142  5526 net.cpp:165] Memory required for data: 1405029228
I0625 16:06:48.778156  5526 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0625 16:06:48.778182  5526 net.cpp:106] Creating Layer rpn_conv/3x3
I0625 16:06:48.778193  5526 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0625 16:06:48.778215  5526 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0625 16:06:48.844436  5526 net.cpp:150] Setting up rpn_conv/3x3
I0625 16:06:48.844467  5526 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:06:48.844470  5526 net.cpp:165] Memory required for data: 1409932140
I0625 16:06:48.844478  5526 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0625 16:06:48.844486  5526 net.cpp:106] Creating Layer rpn_relu/3x3
I0625 16:06:48.844492  5526 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0625 16:06:48.844497  5526 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0625 16:06:48.844636  5526 net.cpp:150] Setting up rpn_relu/3x3
I0625 16:06:48.844645  5526 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:06:48.844656  5526 net.cpp:165] Memory required for data: 1414835052
I0625 16:06:48.844658  5526 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0625 16:06:48.844663  5526 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0625 16:06:48.844666  5526 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0625 16:06:48.844669  5526 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0625 16:06:48.844673  5526 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0625 16:06:48.844718  5526 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0625 16:06:48.844722  5526 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:06:48.844724  5526 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 16:06:48.844736  5526 net.cpp:165] Memory required for data: 1424640876
I0625 16:06:48.844738  5526 layer_factory.hpp:77] Creating layer rpn_cls_score
I0625 16:06:48.844746  5526 net.cpp:106] Creating Layer rpn_cls_score
I0625 16:06:48.844748  5526 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0625 16:06:48.844753  5526 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0625 16:06:48.846530  5526 net.cpp:150] Setting up rpn_cls_score
I0625 16:06:48.846551  5526 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 16:06:48.846554  5526 net.cpp:165] Memory required for data: 1424928156
I0625 16:06:48.846559  5526 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0625 16:06:48.846572  5526 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0625 16:06:48.846575  5526 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0625 16:06:48.846578  5526 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0625 16:06:48.846582  5526 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0625 16:06:48.846627  5526 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0625 16:06:48.846632  5526 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 16:06:48.846633  5526 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 16:06:48.846634  5526 net.cpp:165] Memory required for data: 1425502716
I0625 16:06:48.846637  5526 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0625 16:06:48.846642  5526 net.cpp:106] Creating Layer rpn_bbox_pred
I0625 16:06:48.846644  5526 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0625 16:06:48.846648  5526 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0625 16:06:48.848156  5526 net.cpp:150] Setting up rpn_bbox_pred
I0625 16:06:48.848165  5526 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 16:06:48.848176  5526 net.cpp:165] Memory required for data: 1426077276
I0625 16:06:48.848181  5526 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 16:06:48.848186  5526 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 16:06:48.848187  5526 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0625 16:06:48.848191  5526 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0625 16:06:48.848196  5526 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0625 16:06:48.848242  5526 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 16:06:48.848258  5526 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 16:06:48.848259  5526 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 16:06:48.848260  5526 net.cpp:165] Memory required for data: 1427226396
I0625 16:06:48.848263  5526 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0625 16:06:48.848266  5526 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0625 16:06:48.848268  5526 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0625 16:06:48.848271  5526 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0625 16:06:48.848311  5526 net.cpp:150] Setting up rpn_cls_score_reshape
I0625 16:06:48.848315  5526 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 16:06:48.848316  5526 net.cpp:165] Memory required for data: 1427513676
I0625 16:06:48.848327  5526 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 16:06:48.848331  5526 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 16:06:48.848332  5526 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0625 16:06:48.848335  5526 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0625 16:06:48.848348  5526 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0625 16:06:48.848378  5526 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 16:06:48.848392  5526 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 16:06:48.848393  5526 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 16:06:48.848394  5526 net.cpp:165] Memory required for data: 1428088236
I0625 16:06:48.848397  5526 layer_factory.hpp:77] Creating layer rpn-data
I0625 16:06:48.848768  5526 net.cpp:106] Creating Layer rpn-data
I0625 16:06:48.848775  5526 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0625 16:06:48.848779  5526 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0625 16:06:48.848781  5526 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0625 16:06:48.848784  5526 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0625 16:06:48.848788  5526 net.cpp:411] rpn-data -> rpn_labels
I0625 16:06:48.848791  5526 net.cpp:411] rpn-data -> rpn_bbox_targets
I0625 16:06:48.848805  5526 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0625 16:06:48.848809  5526 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0625 16:06:48.849668  5526 net.cpp:150] Setting up rpn-data
I0625 16:06:48.849676  5526 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0625 16:06:48.849678  5526 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 16:06:48.849680  5526 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 16:06:48.849683  5526 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 16:06:48.849684  5526 net.cpp:165] Memory required for data: 1429955556
I0625 16:06:48.849686  5526 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0625 16:06:48.849702  5526 net.cpp:106] Creating Layer rpn_loss_cls
I0625 16:06:48.849705  5526 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0625 16:06:48.849709  5526 net.cpp:454] rpn_loss_cls <- rpn_labels
I0625 16:06:48.849725  5526 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0625 16:06:48.849746  5526 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0625 16:06:48.850414  5526 net.cpp:150] Setting up rpn_loss_cls
I0625 16:06:48.850421  5526 net.cpp:157] Top shape: (1)
I0625 16:06:48.850423  5526 net.cpp:160]     with loss weight 1
I0625 16:06:48.850430  5526 net.cpp:165] Memory required for data: 1429955560
I0625 16:06:48.850432  5526 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0625 16:06:48.850450  5526 net.cpp:106] Creating Layer rpn_loss_bbox
I0625 16:06:48.850452  5526 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0625 16:06:48.850466  5526 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0625 16:06:48.850468  5526 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0625 16:06:48.850471  5526 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0625 16:06:48.850482  5526 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0625 16:06:48.851634  5526 net.cpp:150] Setting up rpn_loss_bbox
I0625 16:06:48.851641  5526 net.cpp:157] Top shape: (1)
I0625 16:06:48.851644  5526 net.cpp:160]     with loss weight 1
I0625 16:06:48.851646  5526 net.cpp:165] Memory required for data: 1429955564
I0625 16:06:48.851649  5526 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0625 16:06:48.851652  5526 net.cpp:106] Creating Layer rpn_cls_prob
I0625 16:06:48.851655  5526 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0625 16:06:48.851657  5526 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0625 16:06:48.851845  5526 net.cpp:150] Setting up rpn_cls_prob
I0625 16:06:48.851851  5526 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 16:06:48.851853  5526 net.cpp:165] Memory required for data: 1430242844
I0625 16:06:48.851855  5526 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0625 16:06:48.851860  5526 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0625 16:06:48.851861  5526 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0625 16:06:48.851864  5526 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0625 16:06:48.851905  5526 net.cpp:150] Setting up rpn_cls_prob_reshape
I0625 16:06:48.851909  5526 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 16:06:48.851910  5526 net.cpp:165] Memory required for data: 1430530124
I0625 16:06:48.851922  5526 layer_factory.hpp:77] Creating layer proposal
I0625 16:06:48.852948  5526 net.cpp:106] Creating Layer proposal
I0625 16:06:48.852957  5526 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0625 16:06:48.852959  5526 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0625 16:06:48.852962  5526 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0625 16:06:48.852965  5526 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0625 16:06:48.853840  5526 net.cpp:150] Setting up proposal
I0625 16:06:48.853849  5526 net.cpp:157] Top shape: 1 5 (5)
I0625 16:06:48.853852  5526 net.cpp:165] Memory required for data: 1430530144
I0625 16:06:48.853853  5526 layer_factory.hpp:77] Creating layer roi-data
I0625 16:06:48.856256  5526 net.cpp:106] Creating Layer roi-data
I0625 16:06:48.856263  5526 net.cpp:454] roi-data <- rpn_rois
I0625 16:06:48.856266  5526 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0625 16:06:48.856269  5526 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0625 16:06:48.856271  5526 net.cpp:454] roi-data <- seg_mask_inds
I0625 16:06:48.856273  5526 net.cpp:454] roi-data <- flipped
I0625 16:06:48.856277  5526 net.cpp:411] roi-data -> rois
I0625 16:06:48.856282  5526 net.cpp:411] roi-data -> labels
I0625 16:06:48.856295  5526 net.cpp:411] roi-data -> bbox_targets
I0625 16:06:48.856300  5526 net.cpp:411] roi-data -> bbox_inside_weights
I0625 16:06:48.856313  5526 net.cpp:411] roi-data -> bbox_outside_weights
I0625 16:06:48.856318  5526 net.cpp:411] roi-data -> mask_targets
I0625 16:06:48.856333  5526 net.cpp:411] roi-data -> rois_pos
I0625 16:06:48.856622  5526 net.cpp:150] Setting up roi-data
I0625 16:06:48.856629  5526 net.cpp:157] Top shape: 1 5 (5)
I0625 16:06:48.856642  5526 net.cpp:157] Top shape: 1 1 (1)
I0625 16:06:48.856644  5526 net.cpp:157] Top shape: 1 8 (8)
I0625 16:06:48.856645  5526 net.cpp:157] Top shape: 1 8 (8)
I0625 16:06:48.856647  5526 net.cpp:157] Top shape: 1 8 (8)
I0625 16:06:48.856649  5526 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 16:06:48.856652  5526 net.cpp:157] Top shape: 1 5 (5)
I0625 16:06:48.856653  5526 net.cpp:165] Memory required for data: 1432435436
I0625 16:06:48.856655  5526 layer_factory.hpp:77] Creating layer roi_pool5
I0625 16:06:48.856674  5526 net.cpp:106] Creating Layer roi_pool5
I0625 16:06:48.856678  5526 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0625 16:06:48.856680  5526 net.cpp:454] roi_pool5 <- rois
I0625 16:06:48.856683  5526 net.cpp:411] roi_pool5 -> pool5
I0625 16:06:48.856688  5526 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0625 16:06:48.856779  5526 net.cpp:150] Setting up roi_pool5
I0625 16:06:48.856783  5526 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 16:06:48.856786  5526 net.cpp:165] Memory required for data: 1432535788
I0625 16:06:48.856787  5526 layer_factory.hpp:77] Creating layer fc6
I0625 16:06:48.856802  5526 net.cpp:106] Creating Layer fc6
I0625 16:06:48.856804  5526 net.cpp:454] fc6 <- pool5
I0625 16:06:48.856807  5526 net.cpp:411] fc6 -> fc6
I0625 16:06:48.997362  5526 net.cpp:150] Setting up fc6
I0625 16:06:48.997385  5526 net.cpp:157] Top shape: 1 4096 (4096)
I0625 16:06:48.997387  5526 net.cpp:165] Memory required for data: 1432552172
I0625 16:06:48.997401  5526 layer_factory.hpp:77] Creating layer relu6
I0625 16:06:48.997421  5526 net.cpp:106] Creating Layer relu6
I0625 16:06:48.997424  5526 net.cpp:454] relu6 <- fc6
I0625 16:06:48.997439  5526 net.cpp:397] relu6 -> fc6 (in-place)
I0625 16:06:48.997642  5526 net.cpp:150] Setting up relu6
I0625 16:06:48.997649  5526 net.cpp:157] Top shape: 1 4096 (4096)
I0625 16:06:48.997651  5526 net.cpp:165] Memory required for data: 1432568556
I0625 16:06:48.997653  5526 layer_factory.hpp:77] Creating layer fc7
I0625 16:06:48.997658  5526 net.cpp:106] Creating Layer fc7
I0625 16:06:48.997661  5526 net.cpp:454] fc7 <- fc6
I0625 16:06:48.997664  5526 net.cpp:411] fc7 -> fc7
I0625 16:06:49.025853  5526 net.cpp:150] Setting up fc7
I0625 16:06:49.025877  5526 net.cpp:157] Top shape: 1 4096 (4096)
I0625 16:06:49.025880  5526 net.cpp:165] Memory required for data: 1432584940
I0625 16:06:49.025890  5526 layer_factory.hpp:77] Creating layer relu7
I0625 16:06:49.025909  5526 net.cpp:106] Creating Layer relu7
I0625 16:06:49.025914  5526 net.cpp:454] relu7 <- fc7
I0625 16:06:49.025919  5526 net.cpp:397] relu7 -> fc7 (in-place)
I0625 16:06:49.026105  5526 net.cpp:150] Setting up relu7
I0625 16:06:49.026113  5526 net.cpp:157] Top shape: 1 4096 (4096)
I0625 16:06:49.026115  5526 net.cpp:165] Memory required for data: 1432601324
I0625 16:06:49.026118  5526 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0625 16:06:49.026121  5526 net.cpp:106] Creating Layer fc7_relu7_0_split
I0625 16:06:49.026124  5526 net.cpp:454] fc7_relu7_0_split <- fc7
I0625 16:06:49.026139  5526 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0625 16:06:49.026144  5526 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0625 16:06:49.026183  5526 net.cpp:150] Setting up fc7_relu7_0_split
I0625 16:06:49.026187  5526 net.cpp:157] Top shape: 1 4096 (4096)
I0625 16:06:49.026190  5526 net.cpp:157] Top shape: 1 4096 (4096)
I0625 16:06:49.026192  5526 net.cpp:165] Memory required for data: 1432634092
I0625 16:06:49.026194  5526 layer_factory.hpp:77] Creating layer cls_score
I0625 16:06:49.026201  5526 net.cpp:106] Creating Layer cls_score
I0625 16:06:49.026213  5526 net.cpp:454] cls_score <- fc7_relu7_0_split_0
I0625 16:06:49.026216  5526 net.cpp:411] cls_score -> cls_score
I0625 16:06:49.026471  5526 net.cpp:150] Setting up cls_score
I0625 16:06:49.026476  5526 net.cpp:157] Top shape: 1 2 (2)
I0625 16:06:49.026479  5526 net.cpp:165] Memory required for data: 1432634100
I0625 16:06:49.026494  5526 layer_factory.hpp:77] Creating layer bbox_pred
I0625 16:06:49.026497  5526 net.cpp:106] Creating Layer bbox_pred
I0625 16:06:49.026500  5526 net.cpp:454] bbox_pred <- fc7_relu7_0_split_1
I0625 16:06:49.026504  5526 net.cpp:411] bbox_pred -> bbox_pred
I0625 16:06:49.027271  5526 net.cpp:150] Setting up bbox_pred
I0625 16:06:49.027276  5526 net.cpp:157] Top shape: 1 8 (8)
I0625 16:06:49.027277  5526 net.cpp:165] Memory required for data: 1432634132
I0625 16:06:49.027281  5526 layer_factory.hpp:77] Creating layer loss_cls
I0625 16:06:49.027285  5526 net.cpp:106] Creating Layer loss_cls
I0625 16:06:49.027288  5526 net.cpp:454] loss_cls <- cls_score
I0625 16:06:49.027292  5526 net.cpp:454] loss_cls <- labels
I0625 16:06:49.027294  5526 net.cpp:411] loss_cls -> loss_cls
I0625 16:06:49.027299  5526 layer_factory.hpp:77] Creating layer loss_cls
I0625 16:06:49.027951  5526 net.cpp:150] Setting up loss_cls
I0625 16:06:49.027961  5526 net.cpp:157] Top shape: (1)
I0625 16:06:49.027962  5526 net.cpp:160]     with loss weight 3
I0625 16:06:49.027971  5526 net.cpp:165] Memory required for data: 1432634136
I0625 16:06:49.027973  5526 layer_factory.hpp:77] Creating layer loss_bbox
I0625 16:06:49.027977  5526 net.cpp:106] Creating Layer loss_bbox
I0625 16:06:49.027981  5526 net.cpp:454] loss_bbox <- bbox_pred
I0625 16:06:49.027993  5526 net.cpp:454] loss_bbox <- bbox_targets
I0625 16:06:49.027997  5526 net.cpp:454] loss_bbox <- bbox_inside_weights
I0625 16:06:49.027999  5526 net.cpp:454] loss_bbox <- bbox_outside_weights
I0625 16:06:49.028002  5526 net.cpp:411] loss_bbox -> loss_bbox
I0625 16:06:49.028084  5526 net.cpp:150] Setting up loss_bbox
I0625 16:06:49.028090  5526 net.cpp:157] Top shape: (1)
I0625 16:06:49.028093  5526 net.cpp:160]     with loss weight 2
I0625 16:06:49.028098  5526 net.cpp:165] Memory required for data: 1432634140
I0625 16:06:49.028101  5526 layer_factory.hpp:77] Creating layer roi_pool5_2
I0625 16:06:49.028118  5526 net.cpp:106] Creating Layer roi_pool5_2
I0625 16:06:49.028121  5526 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0625 16:06:49.028125  5526 net.cpp:454] roi_pool5_2 <- rois_pos
I0625 16:06:49.028128  5526 net.cpp:411] roi_pool5_2 -> pool5_2
I0625 16:06:49.028133  5526 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0625 16:06:49.028193  5526 net.cpp:150] Setting up roi_pool5_2
I0625 16:06:49.028198  5526 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 16:06:49.028200  5526 net.cpp:165] Memory required for data: 1432734492
I0625 16:06:49.028201  5526 layer_factory.hpp:77] Creating layer pool5_2_conv
I0625 16:06:49.028208  5526 net.cpp:106] Creating Layer pool5_2_conv
I0625 16:06:49.028211  5526 net.cpp:454] pool5_2_conv <- pool5_2
I0625 16:06:49.028214  5526 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0625 16:06:49.035567  5526 net.cpp:150] Setting up pool5_2_conv
I0625 16:06:49.035576  5526 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 16:06:49.035578  5526 net.cpp:165] Memory required for data: 1432834844
I0625 16:06:49.035583  5526 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0625 16:06:49.035588  5526 net.cpp:106] Creating Layer pool5_2_conv_relu
I0625 16:06:49.035601  5526 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0625 16:06:49.035605  5526 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0625 16:06:49.035768  5526 net.cpp:150] Setting up pool5_2_conv_relu
I0625 16:06:49.035774  5526 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 16:06:49.035776  5526 net.cpp:165] Memory required for data: 1432935196
I0625 16:06:49.035778  5526 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0625 16:06:49.035790  5526 net.cpp:106] Creating Layer pool5_2_conv2
I0625 16:06:49.035802  5526 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0625 16:06:49.035806  5526 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0625 16:06:49.087146  5526 net.cpp:150] Setting up pool5_2_conv2
I0625 16:06:49.087165  5526 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 16:06:49.087168  5526 net.cpp:165] Memory required for data: 1433035548
I0625 16:06:49.087177  5526 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0625 16:06:49.087194  5526 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0625 16:06:49.087198  5526 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0625 16:06:49.087203  5526 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0625 16:06:49.087373  5526 net.cpp:150] Setting up pool5_2_conv2_relu
I0625 16:06:49.087379  5526 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 16:06:49.087381  5526 net.cpp:165] Memory required for data: 1433135900
I0625 16:06:49.087383  5526 layer_factory.hpp:77] Creating layer mask_deconv1
I0625 16:06:49.087391  5526 net.cpp:106] Creating Layer mask_deconv1
I0625 16:06:49.087393  5526 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0625 16:06:49.087397  5526 net.cpp:411] mask_deconv1 -> mask_deconv1
I0625 16:06:49.088181  5526 net.cpp:150] Setting up mask_deconv1
I0625 16:06:49.088186  5526 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0625 16:06:49.088187  5526 net.cpp:165] Memory required for data: 1434057500
I0625 16:06:49.088191  5526 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0625 16:06:49.088198  5526 net.cpp:106] Creating Layer pool5_2_conv3
I0625 16:06:49.088201  5526 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0625 16:06:49.088203  5526 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0625 16:06:49.114364  5526 net.cpp:150] Setting up pool5_2_conv3
I0625 16:06:49.114393  5526 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 16:06:49.114395  5526 net.cpp:165] Memory required for data: 1435900700
I0625 16:06:49.114403  5526 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0625 16:06:49.114411  5526 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0625 16:06:49.114415  5526 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0625 16:06:49.114420  5526 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0625 16:06:49.114565  5526 net.cpp:150] Setting up pool5_2_conv3_relu
I0625 16:06:49.114572  5526 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 16:06:49.114583  5526 net.cpp:165] Memory required for data: 1437743900
I0625 16:06:49.114585  5526 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0625 16:06:49.114595  5526 net.cpp:106] Creating Layer pool5_2_conv4
I0625 16:06:49.114609  5526 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0625 16:06:49.114612  5526 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0625 16:06:49.166867  5526 net.cpp:150] Setting up pool5_2_conv4
I0625 16:06:49.166908  5526 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 16:06:49.166910  5526 net.cpp:165] Memory required for data: 1439587100
I0625 16:06:49.166929  5526 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0625 16:06:49.166936  5526 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0625 16:06:49.166941  5526 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0625 16:06:49.166947  5526 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0625 16:06:49.167115  5526 net.cpp:150] Setting up pool5_2_conv4_relu
I0625 16:06:49.167122  5526 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 16:06:49.167134  5526 net.cpp:165] Memory required for data: 1441430300
I0625 16:06:49.167135  5526 layer_factory.hpp:77] Creating layer mask_deconv2
I0625 16:06:49.167145  5526 net.cpp:106] Creating Layer mask_deconv2
I0625 16:06:49.167146  5526 net.cpp:454] mask_deconv2 <- pool5_2_conv4_relu
I0625 16:06:49.167151  5526 net.cpp:411] mask_deconv2 -> mask_deconv2
I0625 16:06:49.167989  5526 net.cpp:150] Setting up mask_deconv2
I0625 16:06:49.167994  5526 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0625 16:06:49.167995  5526 net.cpp:165] Memory required for data: 1456671516
I0625 16:06:49.168009  5526 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0625 16:06:49.168016  5526 net.cpp:106] Creating Layer pool5_2_conv5
I0625 16:06:49.168018  5526 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0625 16:06:49.168022  5526 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0625 16:06:49.194265  5526 net.cpp:150] Setting up pool5_2_conv5
I0625 16:06:49.194283  5526 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 16:06:49.194284  5526 net.cpp:165] Memory required for data: 1487153948
I0625 16:06:49.194290  5526 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0625 16:06:49.194308  5526 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0625 16:06:49.194312  5526 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0625 16:06:49.194316  5526 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0625 16:06:49.194456  5526 net.cpp:150] Setting up pool5_2_conv5_relu
I0625 16:06:49.194463  5526 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 16:06:49.194464  5526 net.cpp:165] Memory required for data: 1517636380
I0625 16:06:49.194466  5526 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0625 16:06:49.194474  5526 net.cpp:106] Creating Layer pool5_2_conv6
I0625 16:06:49.194476  5526 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0625 16:06:49.194479  5526 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0625 16:06:49.244897  5526 net.cpp:150] Setting up pool5_2_conv6
I0625 16:06:49.244915  5526 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 16:06:49.244918  5526 net.cpp:165] Memory required for data: 1548118812
I0625 16:06:49.244925  5526 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0625 16:06:49.244933  5526 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0625 16:06:49.244937  5526 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0625 16:06:49.244953  5526 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0625 16:06:49.245497  5526 net.cpp:150] Setting up pool5_2_conv6_relu
I0625 16:06:49.245507  5526 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 16:06:49.245508  5526 net.cpp:165] Memory required for data: 1578601244
I0625 16:06:49.245512  5526 layer_factory.hpp:77] Creating layer mask_deconv3
I0625 16:06:49.245519  5526 net.cpp:106] Creating Layer mask_deconv3
I0625 16:06:49.245522  5526 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0625 16:06:49.245527  5526 net.cpp:411] mask_deconv3 -> mask_deconv3
I0625 16:06:49.245898  5526 net.cpp:150] Setting up mask_deconv3
I0625 16:06:49.245903  5526 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0625 16:06:49.245905  5526 net.cpp:165] Memory required for data: 1639566108
I0625 16:06:49.245909  5526 layer_factory.hpp:77] Creating layer mask_score
I0625 16:06:49.245915  5526 net.cpp:106] Creating Layer mask_score
I0625 16:06:49.245918  5526 net.cpp:454] mask_score <- mask_deconv3
I0625 16:06:49.245921  5526 net.cpp:411] mask_score -> mask_score
I0625 16:06:49.246953  5526 net.cpp:150] Setting up mask_score
I0625 16:06:49.246960  5526 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 16:06:49.246963  5526 net.cpp:165] Memory required for data: 1641471260
I0625 16:06:49.246966  5526 layer_factory.hpp:77] Creating layer prob
I0625 16:06:49.246973  5526 net.cpp:106] Creating Layer prob
I0625 16:06:49.246974  5526 net.cpp:454] prob <- mask_score
I0625 16:06:49.246978  5526 net.cpp:411] prob -> mask_score_softmax
I0625 16:06:49.247151  5526 net.cpp:150] Setting up prob
I0625 16:06:49.247156  5526 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 16:06:49.247159  5526 net.cpp:165] Memory required for data: 1643376412
I0625 16:06:49.247160  5526 layer_factory.hpp:77] Creating layer log
I0625 16:06:49.247164  5526 net.cpp:106] Creating Layer log
I0625 16:06:49.247165  5526 net.cpp:454] log <- mask_score_softmax
I0625 16:06:49.247169  5526 net.cpp:411] log -> log
I0625 16:06:49.247195  5526 net.cpp:150] Setting up log
I0625 16:06:49.247212  5526 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 16:06:49.247215  5526 net.cpp:165] Memory required for data: 1645281564
I0625 16:06:49.247215  5526 layer_factory.hpp:77] Creating layer mult1
I0625 16:06:49.247229  5526 net.cpp:106] Creating Layer mult1
I0625 16:06:49.247232  5526 net.cpp:454] mult1 <- log
I0625 16:06:49.247234  5526 net.cpp:454] mult1 <- mask_targets
I0625 16:06:49.247237  5526 net.cpp:411] mult1 -> mult1
I0625 16:06:49.247277  5526 net.cpp:150] Setting up mult1
I0625 16:06:49.247280  5526 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 16:06:49.247282  5526 net.cpp:165] Memory required for data: 1647186716
I0625 16:06:49.247283  5526 layer_factory.hpp:77] Creating layer cross_entropy
I0625 16:06:49.247287  5526 net.cpp:106] Creating Layer cross_entropy
I0625 16:06:49.247288  5526 net.cpp:454] cross_entropy <- mult1
I0625 16:06:49.247292  5526 net.cpp:411] cross_entropy -> cross_entropy
I0625 16:06:49.247316  5526 net.cpp:150] Setting up cross_entropy
I0625 16:06:49.247319  5526 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 16:06:49.247321  5526 net.cpp:165] Memory required for data: 1649091868
I0625 16:06:49.247323  5526 layer_factory.hpp:77] Creating layer ce_sum
I0625 16:06:49.247328  5526 net.cpp:106] Creating Layer ce_sum
I0625 16:06:49.247330  5526 net.cpp:454] ce_sum <- cross_entropy
I0625 16:06:49.247334  5526 net.cpp:411] ce_sum -> cross_entropy_sum
I0625 16:06:49.248574  5526 net.cpp:150] Setting up ce_sum
I0625 16:06:49.248581  5526 net.cpp:157] Top shape: 1 1 244 244 (59536)
I0625 16:06:49.248584  5526 net.cpp:165] Memory required for data: 1649330012
I0625 16:06:49.248586  5526 layer_factory.hpp:77] Creating layer ce_mean
I0625 16:06:49.248590  5526 net.cpp:106] Creating Layer ce_mean
I0625 16:06:49.248594  5526 net.cpp:454] ce_mean <- cross_entropy_sum
I0625 16:06:49.248597  5526 net.cpp:411] ce_mean -> cross_entropy_mean
I0625 16:06:49.248713  5526 net.cpp:150] Setting up ce_mean
I0625 16:06:49.248718  5526 net.cpp:157] Top shape: (1)
I0625 16:06:49.248719  5526 net.cpp:160]     with loss weight 1
I0625 16:06:49.248726  5526 net.cpp:165] Memory required for data: 1649330016
I0625 16:06:49.248728  5526 net.cpp:226] ce_mean needs backward computation.
I0625 16:06:49.248729  5526 net.cpp:226] ce_sum needs backward computation.
I0625 16:06:49.248731  5526 net.cpp:226] cross_entropy needs backward computation.
I0625 16:06:49.248733  5526 net.cpp:226] mult1 needs backward computation.
I0625 16:06:49.248734  5526 net.cpp:226] log needs backward computation.
I0625 16:06:49.248736  5526 net.cpp:226] prob needs backward computation.
I0625 16:06:49.248749  5526 net.cpp:226] mask_score needs backward computation.
I0625 16:06:49.248749  5526 net.cpp:226] mask_deconv3 needs backward computation.
I0625 16:06:49.248751  5526 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0625 16:06:49.248752  5526 net.cpp:226] pool5_2_conv6 needs backward computation.
I0625 16:06:49.248754  5526 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0625 16:06:49.248756  5526 net.cpp:226] pool5_2_conv5 needs backward computation.
I0625 16:06:49.248769  5526 net.cpp:226] mask_deconv2 needs backward computation.
I0625 16:06:49.248771  5526 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0625 16:06:49.248773  5526 net.cpp:226] pool5_2_conv4 needs backward computation.
I0625 16:06:49.248775  5526 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0625 16:06:49.248777  5526 net.cpp:226] pool5_2_conv3 needs backward computation.
I0625 16:06:49.248780  5526 net.cpp:226] mask_deconv1 needs backward computation.
I0625 16:06:49.248782  5526 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0625 16:06:49.248785  5526 net.cpp:226] pool5_2_conv2 needs backward computation.
I0625 16:06:49.248785  5526 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0625 16:06:49.248787  5526 net.cpp:226] pool5_2_conv needs backward computation.
I0625 16:06:49.248790  5526 net.cpp:226] roi_pool5_2 needs backward computation.
I0625 16:06:49.248792  5526 net.cpp:226] loss_bbox needs backward computation.
I0625 16:06:49.248795  5526 net.cpp:226] loss_cls needs backward computation.
I0625 16:06:49.248797  5526 net.cpp:226] bbox_pred needs backward computation.
I0625 16:06:49.248800  5526 net.cpp:226] cls_score needs backward computation.
I0625 16:06:49.248801  5526 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0625 16:06:49.248803  5526 net.cpp:226] relu7 needs backward computation.
I0625 16:06:49.248805  5526 net.cpp:226] fc7 needs backward computation.
I0625 16:06:49.248807  5526 net.cpp:226] relu6 needs backward computation.
I0625 16:06:49.248808  5526 net.cpp:226] fc6 needs backward computation.
I0625 16:06:49.248811  5526 net.cpp:226] roi_pool5 needs backward computation.
I0625 16:06:49.248813  5526 net.cpp:226] roi-data needs backward computation.
I0625 16:06:49.248816  5526 net.cpp:226] proposal needs backward computation.
I0625 16:06:49.248821  5526 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0625 16:06:49.248824  5526 net.cpp:226] rpn_cls_prob needs backward computation.
I0625 16:06:49.248826  5526 net.cpp:226] rpn_loss_bbox needs backward computation.
I0625 16:06:49.248829  5526 net.cpp:226] rpn_loss_cls needs backward computation.
I0625 16:06:49.248832  5526 net.cpp:226] rpn-data needs backward computation.
I0625 16:06:49.248837  5526 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0625 16:06:49.248842  5526 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0625 16:06:49.248845  5526 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0625 16:06:49.248847  5526 net.cpp:226] rpn_bbox_pred needs backward computation.
I0625 16:06:49.248849  5526 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0625 16:06:49.248852  5526 net.cpp:226] rpn_cls_score needs backward computation.
I0625 16:06:49.248854  5526 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0625 16:06:49.248857  5526 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0625 16:06:49.248858  5526 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0625 16:06:49.248862  5526 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0625 16:06:49.248863  5526 net.cpp:226] relu5_3 needs backward computation.
I0625 16:06:49.248865  5526 net.cpp:226] conv5_3 needs backward computation.
I0625 16:06:49.248867  5526 net.cpp:226] relu5_2 needs backward computation.
I0625 16:06:49.248869  5526 net.cpp:226] conv5_2 needs backward computation.
I0625 16:06:49.248870  5526 net.cpp:226] relu5_1 needs backward computation.
I0625 16:06:49.248872  5526 net.cpp:226] conv5_1 needs backward computation.
I0625 16:06:49.248874  5526 net.cpp:226] pool4 needs backward computation.
I0625 16:06:49.248877  5526 net.cpp:226] relu4_3 needs backward computation.
I0625 16:06:49.248878  5526 net.cpp:226] conv4_3 needs backward computation.
I0625 16:06:49.248880  5526 net.cpp:226] relu4_2 needs backward computation.
I0625 16:06:49.248883  5526 net.cpp:226] conv4_2 needs backward computation.
I0625 16:06:49.248884  5526 net.cpp:226] relu4_1 needs backward computation.
I0625 16:06:49.248885  5526 net.cpp:226] conv4_1 needs backward computation.
I0625 16:06:49.248888  5526 net.cpp:226] pool3 needs backward computation.
I0625 16:06:49.248889  5526 net.cpp:226] relu3_3 needs backward computation.
I0625 16:06:49.248891  5526 net.cpp:226] conv3_3 needs backward computation.
I0625 16:06:49.248893  5526 net.cpp:226] relu3_2 needs backward computation.
I0625 16:06:49.248895  5526 net.cpp:226] conv3_2 needs backward computation.
I0625 16:06:49.248896  5526 net.cpp:226] relu3_1 needs backward computation.
I0625 16:06:49.248898  5526 net.cpp:226] conv3_1 needs backward computation.
I0625 16:06:49.248900  5526 net.cpp:228] pool2 does not need backward computation.
I0625 16:06:49.248903  5526 net.cpp:228] relu2_2 does not need backward computation.
I0625 16:06:49.248904  5526 net.cpp:228] conv2_2 does not need backward computation.
I0625 16:06:49.248908  5526 net.cpp:228] relu2_1 does not need backward computation.
I0625 16:06:49.248908  5526 net.cpp:228] conv2_1 does not need backward computation.
I0625 16:06:49.248911  5526 net.cpp:228] pool1 does not need backward computation.
I0625 16:06:49.248914  5526 net.cpp:228] relu1_2 does not need backward computation.
I0625 16:06:49.248915  5526 net.cpp:228] conv1_2 does not need backward computation.
I0625 16:06:49.248917  5526 net.cpp:228] relu1_1 does not need backward computation.
I0625 16:06:49.248919  5526 net.cpp:228] conv1_1 does not need backward computation.
I0625 16:06:49.248921  5526 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0625 16:06:49.248924  5526 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0625 16:06:49.248929  5526 net.cpp:228] data_input-data_0_split does not need backward computation.
I0625 16:06:49.248932  5526 net.cpp:228] input-data does not need backward computation.
I0625 16:06:49.248934  5526 net.cpp:270] This network produces output cross_entropy_mean
I0625 16:06:49.248936  5526 net.cpp:270] This network produces output loss_bbox
I0625 16:06:49.248939  5526 net.cpp:270] This network produces output loss_cls
I0625 16:06:49.248940  5526 net.cpp:270] This network produces output rpn_cls_loss
I0625 16:06:49.248942  5526 net.cpp:270] This network produces output rpn_loss_bbox
I0625 16:06:49.248983  5526 net.cpp:283] Network initialization done.
I0625 16:06:49.249140  5526 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0625 16:07:18.144425  5526 net.cpp:816] Ignoring source layer pool5
I0625 16:07:18.218499  5526 net.cpp:816] Ignoring source layer drop6
I0625 16:07:18.229773  5526 net.cpp:816] Ignoring source layer drop7
I0625 16:07:18.229789  5526 net.cpp:816] Ignoring source layer fc8
Solving...
Traceback (most recent call last):
  File "./tools/train_net.py", line 116, in <module>
    max_iters=args.max_iters)
  File "/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/train.py", line 171, in train_net
    model_paths = sw.train_model(max_iters)
  File "/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/train.py", line 110, in train_model
    self.solver.step(1)
  File "/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/rpn/proposal_target_layer.py", line 395, in forward
    roi_mask_kl = singleLabel2dist(roi_mask)
NameError: global name 'singleLabel2dist' is not defined
