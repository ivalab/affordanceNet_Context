+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-11_16-51-00
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-11_16-51-00
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0611 16:51:07.812768   741 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0611 16:51:07.812798   741 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0611 16:51:07.814198   741 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  top: "attrArray"
  top: "attrArrayInd"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "attr_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "attr_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "attr_score_pos"
  type: "Eltwise"
  bottom: "attr_score"
  bottom: "attrArrayInd"
  top: "attr_score_pos"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_attribute"
  type: "SigmoidCrossEntropyLoss"
  bottom: "attr_score_pos"
  bottom: "attrArray"
  top: "loss_attribute"
  loss_weight: 2
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_mask"
  type: "SoftmaxWithLoss"
  bottom: "mask_score"
  bottom: "mask_targets"
  top: "loss_mask"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
I0611 16:51:07.814539   741 layer_factory.hpp:77] Creating layer input-data
I0611 16:51:07.853399   741 net.cpp:106] Creating Layer input-data
I0611 16:51:07.853449   741 net.cpp:411] input-data -> data
I0611 16:51:07.853471   741 net.cpp:411] input-data -> im_info
I0611 16:51:07.853479   741 net.cpp:411] input-data -> gt_boxes
I0611 16:51:07.853495   741 net.cpp:411] input-data -> seg_mask_inds
I0611 16:51:07.853513   741 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0611 16:51:07.865392   741 net.cpp:150] Setting up input-data
I0611 16:51:07.865428   741 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 16:51:07.865440   741 net.cpp:157] Top shape: 1 3 (3)
I0611 16:51:07.865445   741 net.cpp:157] Top shape: 1 4 (4)
I0611 16:51:07.865459   741 net.cpp:157] Top shape: 1 2 (2)
I0611 16:51:07.865463   741 net.cpp:157] Top shape: 1 1 (1)
I0611 16:51:07.865466   741 net.cpp:165] Memory required for data: 7200040
I0611 16:51:07.865473   741 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0611 16:51:07.865489   741 net.cpp:106] Creating Layer data_input-data_0_split
I0611 16:51:07.865495   741 net.cpp:454] data_input-data_0_split <- data
I0611 16:51:07.865511   741 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0611 16:51:07.865530   741 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0611 16:51:07.865556   741 net.cpp:150] Setting up data_input-data_0_split
I0611 16:51:07.865571   741 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 16:51:07.865576   741 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 16:51:07.865590   741 net.cpp:165] Memory required for data: 21600040
I0611 16:51:07.865594   741 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0611 16:51:07.865602   741 net.cpp:106] Creating Layer im_info_input-data_1_split
I0611 16:51:07.865605   741 net.cpp:454] im_info_input-data_1_split <- im_info
I0611 16:51:07.865622   741 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0611 16:51:07.865629   741 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0611 16:51:07.865639   741 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0611 16:51:07.865684   741 net.cpp:150] Setting up im_info_input-data_1_split
I0611 16:51:07.865689   741 net.cpp:157] Top shape: 1 3 (3)
I0611 16:51:07.865692   741 net.cpp:157] Top shape: 1 3 (3)
I0611 16:51:07.865694   741 net.cpp:157] Top shape: 1 3 (3)
I0611 16:51:07.865700   741 net.cpp:165] Memory required for data: 21600076
I0611 16:51:07.865703   741 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0611 16:51:07.865708   741 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0611 16:51:07.865713   741 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0611 16:51:07.865720   741 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0611 16:51:07.865726   741 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0611 16:51:07.865752   741 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0611 16:51:07.865759   741 net.cpp:157] Top shape: 1 4 (4)
I0611 16:51:07.865762   741 net.cpp:157] Top shape: 1 4 (4)
I0611 16:51:07.865767   741 net.cpp:165] Memory required for data: 21600108
I0611 16:51:07.865772   741 layer_factory.hpp:77] Creating layer conv1_1
I0611 16:51:07.865783   741 net.cpp:106] Creating Layer conv1_1
I0611 16:51:07.865788   741 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0611 16:51:07.865793   741 net.cpp:411] conv1_1 -> conv1_1
I0611 16:51:08.065563   741 net.cpp:150] Setting up conv1_1
I0611 16:51:08.065583   741 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 16:51:08.065587   741 net.cpp:165] Memory required for data: 175200108
I0611 16:51:08.065599   741 layer_factory.hpp:77] Creating layer relu1_1
I0611 16:51:08.065611   741 net.cpp:106] Creating Layer relu1_1
I0611 16:51:08.065616   741 net.cpp:454] relu1_1 <- conv1_1
I0611 16:51:08.065623   741 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0611 16:51:08.065749   741 net.cpp:150] Setting up relu1_1
I0611 16:51:08.065757   741 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 16:51:08.065760   741 net.cpp:165] Memory required for data: 328800108
I0611 16:51:08.065763   741 layer_factory.hpp:77] Creating layer conv1_2
I0611 16:51:08.065771   741 net.cpp:106] Creating Layer conv1_2
I0611 16:51:08.065773   741 net.cpp:454] conv1_2 <- conv1_1
I0611 16:51:08.065778   741 net.cpp:411] conv1_2 -> conv1_2
I0611 16:51:08.068071   741 net.cpp:150] Setting up conv1_2
I0611 16:51:08.068091   741 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 16:51:08.068094   741 net.cpp:165] Memory required for data: 482400108
I0611 16:51:08.068102   741 layer_factory.hpp:77] Creating layer relu1_2
I0611 16:51:08.068109   741 net.cpp:106] Creating Layer relu1_2
I0611 16:51:08.068114   741 net.cpp:454] relu1_2 <- conv1_2
I0611 16:51:08.068120   741 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0611 16:51:08.068235   741 net.cpp:150] Setting up relu1_2
I0611 16:51:08.068243   741 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 16:51:08.068245   741 net.cpp:165] Memory required for data: 636000108
I0611 16:51:08.068249   741 layer_factory.hpp:77] Creating layer pool1
I0611 16:51:08.068259   741 net.cpp:106] Creating Layer pool1
I0611 16:51:08.068264   741 net.cpp:454] pool1 <- conv1_2
I0611 16:51:08.068269   741 net.cpp:411] pool1 -> pool1
I0611 16:51:08.068323   741 net.cpp:150] Setting up pool1
I0611 16:51:08.068328   741 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0611 16:51:08.068341   741 net.cpp:165] Memory required for data: 674400108
I0611 16:51:08.068343   741 layer_factory.hpp:77] Creating layer conv2_1
I0611 16:51:08.068351   741 net.cpp:106] Creating Layer conv2_1
I0611 16:51:08.068356   741 net.cpp:454] conv2_1 <- pool1
I0611 16:51:08.068361   741 net.cpp:411] conv2_1 -> conv2_1
I0611 16:51:08.070222   741 net.cpp:150] Setting up conv2_1
I0611 16:51:08.070231   741 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 16:51:08.070235   741 net.cpp:165] Memory required for data: 751200108
I0611 16:51:08.070245   741 layer_factory.hpp:77] Creating layer relu2_1
I0611 16:51:08.070252   741 net.cpp:106] Creating Layer relu2_1
I0611 16:51:08.070258   741 net.cpp:454] relu2_1 <- conv2_1
I0611 16:51:08.070264   741 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0611 16:51:08.070746   741 net.cpp:150] Setting up relu2_1
I0611 16:51:08.070755   741 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 16:51:08.070757   741 net.cpp:165] Memory required for data: 828000108
I0611 16:51:08.070761   741 layer_factory.hpp:77] Creating layer conv2_2
I0611 16:51:08.070782   741 net.cpp:106] Creating Layer conv2_2
I0611 16:51:08.070787   741 net.cpp:454] conv2_2 <- conv2_1
I0611 16:51:08.070793   741 net.cpp:411] conv2_2 -> conv2_2
I0611 16:51:08.072158   741 net.cpp:150] Setting up conv2_2
I0611 16:51:08.072167   741 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 16:51:08.072181   741 net.cpp:165] Memory required for data: 904800108
I0611 16:51:08.072187   741 layer_factory.hpp:77] Creating layer relu2_2
I0611 16:51:08.072194   741 net.cpp:106] Creating Layer relu2_2
I0611 16:51:08.072201   741 net.cpp:454] relu2_2 <- conv2_2
I0611 16:51:08.072208   741 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0611 16:51:08.072338   741 net.cpp:150] Setting up relu2_2
I0611 16:51:08.072345   741 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 16:51:08.072347   741 net.cpp:165] Memory required for data: 981600108
I0611 16:51:08.072350   741 layer_factory.hpp:77] Creating layer pool2
I0611 16:51:08.072366   741 net.cpp:106] Creating Layer pool2
I0611 16:51:08.072372   741 net.cpp:454] pool2 <- conv2_2
I0611 16:51:08.072379   741 net.cpp:411] pool2 -> pool2
I0611 16:51:08.072420   741 net.cpp:150] Setting up pool2
I0611 16:51:08.072427   741 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0611 16:51:08.072429   741 net.cpp:165] Memory required for data: 1000800108
I0611 16:51:08.072433   741 layer_factory.hpp:77] Creating layer conv3_1
I0611 16:51:08.072441   741 net.cpp:106] Creating Layer conv3_1
I0611 16:51:08.072446   741 net.cpp:454] conv3_1 <- pool2
I0611 16:51:08.072453   741 net.cpp:411] conv3_1 -> conv3_1
I0611 16:51:08.074307   741 net.cpp:150] Setting up conv3_1
I0611 16:51:08.074316   741 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 16:51:08.074319   741 net.cpp:165] Memory required for data: 1039200108
I0611 16:51:08.074331   741 layer_factory.hpp:77] Creating layer relu3_1
I0611 16:51:08.074339   741 net.cpp:106] Creating Layer relu3_1
I0611 16:51:08.074343   741 net.cpp:454] relu3_1 <- conv3_1
I0611 16:51:08.074348   741 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0611 16:51:08.074512   741 net.cpp:150] Setting up relu3_1
I0611 16:51:08.074520   741 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 16:51:08.074532   741 net.cpp:165] Memory required for data: 1077600108
I0611 16:51:08.074537   741 layer_factory.hpp:77] Creating layer conv3_2
I0611 16:51:08.074548   741 net.cpp:106] Creating Layer conv3_2
I0611 16:51:08.074551   741 net.cpp:454] conv3_2 <- conv3_1
I0611 16:51:08.074558   741 net.cpp:411] conv3_2 -> conv3_2
I0611 16:51:08.076951   741 net.cpp:150] Setting up conv3_2
I0611 16:51:08.076963   741 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 16:51:08.076967   741 net.cpp:165] Memory required for data: 1116000108
I0611 16:51:08.076973   741 layer_factory.hpp:77] Creating layer relu3_2
I0611 16:51:08.076982   741 net.cpp:106] Creating Layer relu3_2
I0611 16:51:08.076987   741 net.cpp:454] relu3_2 <- conv3_2
I0611 16:51:08.077004   741 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0611 16:51:08.077145   741 net.cpp:150] Setting up relu3_2
I0611 16:51:08.077152   741 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 16:51:08.077154   741 net.cpp:165] Memory required for data: 1154400108
I0611 16:51:08.077168   741 layer_factory.hpp:77] Creating layer conv3_3
I0611 16:51:08.077177   741 net.cpp:106] Creating Layer conv3_3
I0611 16:51:08.077181   741 net.cpp:454] conv3_3 <- conv3_2
I0611 16:51:08.077188   741 net.cpp:411] conv3_3 -> conv3_3
I0611 16:51:08.079293   741 net.cpp:150] Setting up conv3_3
I0611 16:51:08.079306   741 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 16:51:08.079309   741 net.cpp:165] Memory required for data: 1192800108
I0611 16:51:08.079319   741 layer_factory.hpp:77] Creating layer relu3_3
I0611 16:51:08.079326   741 net.cpp:106] Creating Layer relu3_3
I0611 16:51:08.079332   741 net.cpp:454] relu3_3 <- conv3_3
I0611 16:51:08.079337   741 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0611 16:51:08.079463   741 net.cpp:150] Setting up relu3_3
I0611 16:51:08.079473   741 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 16:51:08.079475   741 net.cpp:165] Memory required for data: 1231200108
I0611 16:51:08.079478   741 layer_factory.hpp:77] Creating layer pool3
I0611 16:51:08.079486   741 net.cpp:106] Creating Layer pool3
I0611 16:51:08.079489   741 net.cpp:454] pool3 <- conv3_3
I0611 16:51:08.079494   741 net.cpp:411] pool3 -> pool3
I0611 16:51:08.079536   741 net.cpp:150] Setting up pool3
I0611 16:51:08.079542   741 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0611 16:51:08.079545   741 net.cpp:165] Memory required for data: 1240800108
I0611 16:51:08.079548   741 layer_factory.hpp:77] Creating layer conv4_1
I0611 16:51:08.079560   741 net.cpp:106] Creating Layer conv4_1
I0611 16:51:08.079566   741 net.cpp:454] conv4_1 <- pool3
I0611 16:51:08.079574   741 net.cpp:411] conv4_1 -> conv4_1
I0611 16:51:08.083390   741 net.cpp:150] Setting up conv4_1
I0611 16:51:08.083410   741 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 16:51:08.083412   741 net.cpp:165] Memory required for data: 1260000108
I0611 16:51:08.083421   741 layer_factory.hpp:77] Creating layer relu4_1
I0611 16:51:08.083433   741 net.cpp:106] Creating Layer relu4_1
I0611 16:51:08.083439   741 net.cpp:454] relu4_1 <- conv4_1
I0611 16:51:08.083446   741 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0611 16:51:08.083577   741 net.cpp:150] Setting up relu4_1
I0611 16:51:08.083585   741 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 16:51:08.083587   741 net.cpp:165] Memory required for data: 1279200108
I0611 16:51:08.083591   741 layer_factory.hpp:77] Creating layer conv4_2
I0611 16:51:08.083602   741 net.cpp:106] Creating Layer conv4_2
I0611 16:51:08.083606   741 net.cpp:454] conv4_2 <- conv4_1
I0611 16:51:08.083612   741 net.cpp:411] conv4_2 -> conv4_2
I0611 16:51:08.088284   741 net.cpp:150] Setting up conv4_2
I0611 16:51:08.088313   741 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 16:51:08.088316   741 net.cpp:165] Memory required for data: 1298400108
I0611 16:51:08.088330   741 layer_factory.hpp:77] Creating layer relu4_2
I0611 16:51:08.088338   741 net.cpp:106] Creating Layer relu4_2
I0611 16:51:08.088344   741 net.cpp:454] relu4_2 <- conv4_2
I0611 16:51:08.088351   741 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0611 16:51:08.088841   741 net.cpp:150] Setting up relu4_2
I0611 16:51:08.088850   741 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 16:51:08.088861   741 net.cpp:165] Memory required for data: 1317600108
I0611 16:51:08.088863   741 layer_factory.hpp:77] Creating layer conv4_3
I0611 16:51:08.088871   741 net.cpp:106] Creating Layer conv4_3
I0611 16:51:08.088876   741 net.cpp:454] conv4_3 <- conv4_2
I0611 16:51:08.088883   741 net.cpp:411] conv4_3 -> conv4_3
I0611 16:51:08.093183   741 net.cpp:150] Setting up conv4_3
I0611 16:51:08.093215   741 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 16:51:08.093219   741 net.cpp:165] Memory required for data: 1336800108
I0611 16:51:08.093225   741 layer_factory.hpp:77] Creating layer relu4_3
I0611 16:51:08.093235   741 net.cpp:106] Creating Layer relu4_3
I0611 16:51:08.093240   741 net.cpp:454] relu4_3 <- conv4_3
I0611 16:51:08.093245   741 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0611 16:51:08.093376   741 net.cpp:150] Setting up relu4_3
I0611 16:51:08.093384   741 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 16:51:08.093385   741 net.cpp:165] Memory required for data: 1356000108
I0611 16:51:08.093389   741 layer_factory.hpp:77] Creating layer pool4
I0611 16:51:08.093396   741 net.cpp:106] Creating Layer pool4
I0611 16:51:08.093401   741 net.cpp:454] pool4 <- conv4_3
I0611 16:51:08.093407   741 net.cpp:411] pool4 -> pool4
I0611 16:51:08.093488   741 net.cpp:150] Setting up pool4
I0611 16:51:08.093497   741 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:51:08.093502   741 net.cpp:165] Memory required for data: 1360903020
I0611 16:51:08.093506   741 layer_factory.hpp:77] Creating layer conv5_1
I0611 16:51:08.093519   741 net.cpp:106] Creating Layer conv5_1
I0611 16:51:08.093525   741 net.cpp:454] conv5_1 <- pool4
I0611 16:51:08.093533   741 net.cpp:411] conv5_1 -> conv5_1
I0611 16:51:08.098371   741 net.cpp:150] Setting up conv5_1
I0611 16:51:08.098402   741 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:51:08.098404   741 net.cpp:165] Memory required for data: 1365805932
I0611 16:51:08.098412   741 layer_factory.hpp:77] Creating layer relu5_1
I0611 16:51:08.098423   741 net.cpp:106] Creating Layer relu5_1
I0611 16:51:08.098429   741 net.cpp:454] relu5_1 <- conv5_1
I0611 16:51:08.098436   741 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0611 16:51:08.098590   741 net.cpp:150] Setting up relu5_1
I0611 16:51:08.098596   741 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:51:08.098609   741 net.cpp:165] Memory required for data: 1370708844
I0611 16:51:08.098613   741 layer_factory.hpp:77] Creating layer conv5_2
I0611 16:51:08.098620   741 net.cpp:106] Creating Layer conv5_2
I0611 16:51:08.098635   741 net.cpp:454] conv5_2 <- conv5_1
I0611 16:51:08.098642   741 net.cpp:411] conv5_2 -> conv5_2
I0611 16:51:08.103240   741 net.cpp:150] Setting up conv5_2
I0611 16:51:08.103271   741 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:51:08.103273   741 net.cpp:165] Memory required for data: 1375611756
I0611 16:51:08.103281   741 layer_factory.hpp:77] Creating layer relu5_2
I0611 16:51:08.103288   741 net.cpp:106] Creating Layer relu5_2
I0611 16:51:08.103292   741 net.cpp:454] relu5_2 <- conv5_2
I0611 16:51:08.103302   741 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0611 16:51:08.103446   741 net.cpp:150] Setting up relu5_2
I0611 16:51:08.103451   741 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:51:08.103464   741 net.cpp:165] Memory required for data: 1380514668
I0611 16:51:08.103466   741 layer_factory.hpp:77] Creating layer conv5_3
I0611 16:51:08.103478   741 net.cpp:106] Creating Layer conv5_3
I0611 16:51:08.103482   741 net.cpp:454] conv5_3 <- conv5_2
I0611 16:51:08.103488   741 net.cpp:411] conv5_3 -> conv5_3
I0611 16:51:08.108762   741 net.cpp:150] Setting up conv5_3
I0611 16:51:08.108790   741 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:51:08.108793   741 net.cpp:165] Memory required for data: 1385417580
I0611 16:51:08.108800   741 layer_factory.hpp:77] Creating layer relu5_3
I0611 16:51:08.108810   741 net.cpp:106] Creating Layer relu5_3
I0611 16:51:08.108814   741 net.cpp:454] relu5_3 <- conv5_3
I0611 16:51:08.108822   741 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0611 16:51:08.108960   741 net.cpp:150] Setting up relu5_3
I0611 16:51:08.108968   741 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:51:08.108979   741 net.cpp:165] Memory required for data: 1390320492
I0611 16:51:08.108983   741 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0611 16:51:08.108988   741 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0611 16:51:08.109001   741 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0611 16:51:08.109009   741 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0611 16:51:08.109019   741 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0611 16:51:08.109028   741 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0611 16:51:08.109074   741 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0611 16:51:08.109081   741 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:51:08.109084   741 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:51:08.109086   741 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:51:08.109091   741 net.cpp:165] Memory required for data: 1405029228
I0611 16:51:08.109093   741 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0611 16:51:08.109104   741 net.cpp:106] Creating Layer rpn_conv/3x3
I0611 16:51:08.109108   741 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0611 16:51:08.109117   741 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0611 16:51:08.160233   741 net.cpp:150] Setting up rpn_conv/3x3
I0611 16:51:08.160253   741 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:51:08.160255   741 net.cpp:165] Memory required for data: 1409932140
I0611 16:51:08.160264   741 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0611 16:51:08.160274   741 net.cpp:106] Creating Layer rpn_relu/3x3
I0611 16:51:08.160279   741 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0611 16:51:08.160287   741 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0611 16:51:08.160437   741 net.cpp:150] Setting up rpn_relu/3x3
I0611 16:51:08.160444   741 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:51:08.160447   741 net.cpp:165] Memory required for data: 1414835052
I0611 16:51:08.160459   741 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0611 16:51:08.160465   741 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0611 16:51:08.160470   741 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0611 16:51:08.160486   741 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0611 16:51:08.160504   741 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0611 16:51:08.160542   741 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0611 16:51:08.160548   741 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:51:08.160553   741 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 16:51:08.160558   741 net.cpp:165] Memory required for data: 1424640876
I0611 16:51:08.160562   741 layer_factory.hpp:77] Creating layer rpn_cls_score
I0611 16:51:08.160578   741 net.cpp:106] Creating Layer rpn_cls_score
I0611 16:51:08.160583   741 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0611 16:51:08.160591   741 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0611 16:51:08.162217   741 net.cpp:150] Setting up rpn_cls_score
I0611 16:51:08.162226   741 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 16:51:08.162230   741 net.cpp:165] Memory required for data: 1424928156
I0611 16:51:08.162237   741 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0611 16:51:08.162254   741 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0611 16:51:08.162261   741 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0611 16:51:08.162268   741 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0611 16:51:08.162288   741 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0611 16:51:08.162339   741 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0611 16:51:08.162345   741 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 16:51:08.162349   741 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 16:51:08.162361   741 net.cpp:165] Memory required for data: 1425502716
I0611 16:51:08.162364   741 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0611 16:51:08.162376   741 net.cpp:106] Creating Layer rpn_bbox_pred
I0611 16:51:08.162381   741 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0611 16:51:08.162398   741 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0611 16:51:08.163914   741 net.cpp:150] Setting up rpn_bbox_pred
I0611 16:51:08.163924   741 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 16:51:08.163938   741 net.cpp:165] Memory required for data: 1426077276
I0611 16:51:08.163942   741 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 16:51:08.163949   741 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 16:51:08.163954   741 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0611 16:51:08.163962   741 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0611 16:51:08.163971   741 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0611 16:51:08.164011   741 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 16:51:08.164016   741 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 16:51:08.164021   741 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 16:51:08.164026   741 net.cpp:165] Memory required for data: 1427226396
I0611 16:51:08.164029   741 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0611 16:51:08.164043   741 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0611 16:51:08.164049   741 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0611 16:51:08.164058   741 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0611 16:51:08.164088   741 net.cpp:150] Setting up rpn_cls_score_reshape
I0611 16:51:08.164093   741 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 16:51:08.164095   741 net.cpp:165] Memory required for data: 1427513676
I0611 16:51:08.164101   741 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 16:51:08.164108   741 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 16:51:08.164113   741 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0611 16:51:08.164119   741 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0611 16:51:08.164129   741 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0611 16:51:08.164163   741 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 16:51:08.164168   741 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 16:51:08.164171   741 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 16:51:08.164176   741 net.cpp:165] Memory required for data: 1428088236
I0611 16:51:08.164180   741 layer_factory.hpp:77] Creating layer rpn-data
I0611 16:51:08.164506   741 net.cpp:106] Creating Layer rpn-data
I0611 16:51:08.164513   741 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0611 16:51:08.164520   741 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0611 16:51:08.164526   741 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0611 16:51:08.164533   741 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0611 16:51:08.164541   741 net.cpp:411] rpn-data -> rpn_labels
I0611 16:51:08.164553   741 net.cpp:411] rpn-data -> rpn_bbox_targets
I0611 16:51:08.164562   741 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0611 16:51:08.164572   741 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0611 16:51:08.165410   741 net.cpp:150] Setting up rpn-data
I0611 16:51:08.165433   741 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0611 16:51:08.165437   741 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 16:51:08.165444   741 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 16:51:08.165448   741 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 16:51:08.165453   741 net.cpp:165] Memory required for data: 1429955556
I0611 16:51:08.165458   741 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0611 16:51:08.165467   741 net.cpp:106] Creating Layer rpn_loss_cls
I0611 16:51:08.165473   741 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0611 16:51:08.165482   741 net.cpp:454] rpn_loss_cls <- rpn_labels
I0611 16:51:08.165489   741 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0611 16:51:08.165504   741 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0611 16:51:08.166124   741 net.cpp:150] Setting up rpn_loss_cls
I0611 16:51:08.166133   741 net.cpp:157] Top shape: (1)
I0611 16:51:08.166137   741 net.cpp:160]     with loss weight 1
I0611 16:51:08.166148   741 net.cpp:165] Memory required for data: 1429955560
I0611 16:51:08.166152   741 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0611 16:51:08.166162   741 net.cpp:106] Creating Layer rpn_loss_bbox
I0611 16:51:08.166168   741 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0611 16:51:08.166177   741 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0611 16:51:08.166184   741 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0611 16:51:08.166190   741 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0611 16:51:08.166199   741 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0611 16:51:08.167271   741 net.cpp:150] Setting up rpn_loss_bbox
I0611 16:51:08.167280   741 net.cpp:157] Top shape: (1)
I0611 16:51:08.167282   741 net.cpp:160]     with loss weight 1
I0611 16:51:08.167290   741 net.cpp:165] Memory required for data: 1429955564
I0611 16:51:08.167294   741 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0611 16:51:08.167302   741 net.cpp:106] Creating Layer rpn_cls_prob
I0611 16:51:08.167307   741 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0611 16:51:08.167313   741 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0611 16:51:08.167524   741 net.cpp:150] Setting up rpn_cls_prob
I0611 16:51:08.167536   741 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 16:51:08.167541   741 net.cpp:165] Memory required for data: 1430242844
I0611 16:51:08.167544   741 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0611 16:51:08.167552   741 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0611 16:51:08.167557   741 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0611 16:51:08.167567   741 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0611 16:51:08.167593   741 net.cpp:150] Setting up rpn_cls_prob_reshape
I0611 16:51:08.167600   741 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 16:51:08.167605   741 net.cpp:165] Memory required for data: 1430530124
I0611 16:51:08.167609   741 layer_factory.hpp:77] Creating layer proposal
I0611 16:51:08.168203   741 net.cpp:106] Creating Layer proposal
I0611 16:51:08.168215   741 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0611 16:51:08.168221   741 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0611 16:51:08.168227   741 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0611 16:51:08.168234   741 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0611 16:51:08.169683   741 net.cpp:150] Setting up proposal
I0611 16:51:08.169692   741 net.cpp:157] Top shape: 1 5 (5)
I0611 16:51:08.169704   741 net.cpp:165] Memory required for data: 1430530144
I0611 16:51:08.169708   741 layer_factory.hpp:77] Creating layer roi-data
I0611 16:51:08.169920   741 net.cpp:106] Creating Layer roi-data
I0611 16:51:08.169927   741 net.cpp:454] roi-data <- rpn_rois
I0611 16:51:08.169941   741 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0611 16:51:08.169945   741 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0611 16:51:08.169948   741 net.cpp:454] roi-data <- seg_mask_inds
I0611 16:51:08.169952   741 net.cpp:454] roi-data <- flipped
I0611 16:51:08.169960   741 net.cpp:411] roi-data -> rois
I0611 16:51:08.169970   741 net.cpp:411] roi-data -> labels
I0611 16:51:08.169978   741 net.cpp:411] roi-data -> bbox_targets
I0611 16:51:08.169987   741 net.cpp:411] roi-data -> bbox_inside_weights
I0611 16:51:08.169996   741 net.cpp:411] roi-data -> bbox_outside_weights
I0611 16:51:08.170006   741 net.cpp:411] roi-data -> mask_targets
I0611 16:51:08.170014   741 net.cpp:411] roi-data -> rois_pos
I0611 16:51:08.170022   741 net.cpp:411] roi-data -> attrArray
I0611 16:51:08.170030   741 net.cpp:411] roi-data -> attrArrayInd
I0611 16:51:08.170326   741 net.cpp:150] Setting up roi-data
I0611 16:51:08.170336   741 net.cpp:157] Top shape: 1 5 (5)
I0611 16:51:08.170341   741 net.cpp:157] Top shape: 1 1 (1)
I0611 16:51:08.170344   741 net.cpp:157] Top shape: 1 8 (8)
I0611 16:51:08.170351   741 net.cpp:157] Top shape: 1 8 (8)
I0611 16:51:08.170356   741 net.cpp:157] Top shape: 1 8 (8)
I0611 16:51:08.170361   741 net.cpp:157] Top shape: 1 244 244 (59536)
I0611 16:51:08.170367   741 net.cpp:157] Top shape: 1 5 (5)
I0611 16:51:08.170373   741 net.cpp:157] Top shape: 1 7 (7)
I0611 16:51:08.170377   741 net.cpp:157] Top shape: 1 7 (7)
I0611 16:51:08.170382   741 net.cpp:165] Memory required for data: 1430768484
I0611 16:51:08.170387   741 layer_factory.hpp:77] Creating layer roi_pool5
I0611 16:51:08.170395   741 net.cpp:106] Creating Layer roi_pool5
I0611 16:51:08.170403   741 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0611 16:51:08.170409   741 net.cpp:454] roi_pool5 <- rois
I0611 16:51:08.170415   741 net.cpp:411] roi_pool5 -> pool5
I0611 16:51:08.170429   741 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0611 16:51:08.170516   741 net.cpp:150] Setting up roi_pool5
I0611 16:51:08.170521   741 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 16:51:08.170523   741 net.cpp:165] Memory required for data: 1430868836
I0611 16:51:08.170527   741 layer_factory.hpp:77] Creating layer fc6
I0611 16:51:08.170536   741 net.cpp:106] Creating Layer fc6
I0611 16:51:08.170542   741 net.cpp:454] fc6 <- pool5
I0611 16:51:08.170549   741 net.cpp:411] fc6 -> fc6
I0611 16:51:08.320494   741 net.cpp:150] Setting up fc6
I0611 16:51:08.320529   741 net.cpp:157] Top shape: 1 4096 (4096)
I0611 16:51:08.320533   741 net.cpp:165] Memory required for data: 1430885220
I0611 16:51:08.320546   741 layer_factory.hpp:77] Creating layer relu6
I0611 16:51:08.320554   741 net.cpp:106] Creating Layer relu6
I0611 16:51:08.320559   741 net.cpp:454] relu6 <- fc6
I0611 16:51:08.320565   741 net.cpp:397] relu6 -> fc6 (in-place)
I0611 16:51:08.320813   741 net.cpp:150] Setting up relu6
I0611 16:51:08.320821   741 net.cpp:157] Top shape: 1 4096 (4096)
I0611 16:51:08.320833   741 net.cpp:165] Memory required for data: 1430901604
I0611 16:51:08.320837   741 layer_factory.hpp:77] Creating layer fc7
I0611 16:51:08.320842   741 net.cpp:106] Creating Layer fc7
I0611 16:51:08.320844   741 net.cpp:454] fc7 <- fc6
I0611 16:51:08.320850   741 net.cpp:411] fc7 -> fc7
I0611 16:51:08.345546   741 net.cpp:150] Setting up fc7
I0611 16:51:08.345579   741 net.cpp:157] Top shape: 1 4096 (4096)
I0611 16:51:08.345582   741 net.cpp:165] Memory required for data: 1430917988
I0611 16:51:08.345590   741 layer_factory.hpp:77] Creating layer relu7
I0611 16:51:08.345598   741 net.cpp:106] Creating Layer relu7
I0611 16:51:08.345603   741 net.cpp:454] relu7 <- fc7
I0611 16:51:08.345611   741 net.cpp:397] relu7 -> fc7 (in-place)
I0611 16:51:08.345808   741 net.cpp:150] Setting up relu7
I0611 16:51:08.345813   741 net.cpp:157] Top shape: 1 4096 (4096)
I0611 16:51:08.345826   741 net.cpp:165] Memory required for data: 1430934372
I0611 16:51:08.345829   741 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0611 16:51:08.345834   741 net.cpp:106] Creating Layer fc7_relu7_0_split
I0611 16:51:08.345835   741 net.cpp:454] fc7_relu7_0_split <- fc7
I0611 16:51:08.345841   741 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0611 16:51:08.345849   741 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0611 16:51:08.345854   741 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0611 16:51:08.345934   741 net.cpp:150] Setting up fc7_relu7_0_split
I0611 16:51:08.345940   741 net.cpp:157] Top shape: 1 4096 (4096)
I0611 16:51:08.345953   741 net.cpp:157] Top shape: 1 4096 (4096)
I0611 16:51:08.345955   741 net.cpp:157] Top shape: 1 4096 (4096)
I0611 16:51:08.345957   741 net.cpp:165] Memory required for data: 1430983524
I0611 16:51:08.345959   741 layer_factory.hpp:77] Creating layer attr_score
I0611 16:51:08.345978   741 net.cpp:106] Creating Layer attr_score
I0611 16:51:08.345981   741 net.cpp:454] attr_score <- fc7_relu7_0_split_0
I0611 16:51:08.345988   741 net.cpp:411] attr_score -> attr_score
I0611 16:51:08.346660   741 net.cpp:150] Setting up attr_score
I0611 16:51:08.346665   741 net.cpp:157] Top shape: 1 7 (7)
I0611 16:51:08.346678   741 net.cpp:165] Memory required for data: 1430983552
I0611 16:51:08.346683   741 layer_factory.hpp:77] Creating layer attr_score_pos
I0611 16:51:08.346698   741 net.cpp:106] Creating Layer attr_score_pos
I0611 16:51:08.346700   741 net.cpp:454] attr_score_pos <- attr_score
I0611 16:51:08.346704   741 net.cpp:454] attr_score_pos <- attrArrayInd
I0611 16:51:08.346709   741 net.cpp:411] attr_score_pos -> attr_score_pos
I0611 16:51:08.346745   741 net.cpp:150] Setting up attr_score_pos
I0611 16:51:08.346751   741 net.cpp:157] Top shape: 1 7 (7)
I0611 16:51:08.346766   741 net.cpp:165] Memory required for data: 1430983580
I0611 16:51:08.346771   741 layer_factory.hpp:77] Creating layer cls_score
I0611 16:51:08.346779   741 net.cpp:106] Creating Layer cls_score
I0611 16:51:08.346786   741 net.cpp:454] cls_score <- fc7_relu7_0_split_1
I0611 16:51:08.346793   741 net.cpp:411] cls_score -> cls_score
I0611 16:51:08.347043   741 net.cpp:150] Setting up cls_score
I0611 16:51:08.347049   741 net.cpp:157] Top shape: 1 2 (2)
I0611 16:51:08.347051   741 net.cpp:165] Memory required for data: 1430983588
I0611 16:51:08.347059   741 layer_factory.hpp:77] Creating layer bbox_pred
I0611 16:51:08.347067   741 net.cpp:106] Creating Layer bbox_pred
I0611 16:51:08.347074   741 net.cpp:454] bbox_pred <- fc7_relu7_0_split_2
I0611 16:51:08.347081   741 net.cpp:411] bbox_pred -> bbox_pred
I0611 16:51:08.347841   741 net.cpp:150] Setting up bbox_pred
I0611 16:51:08.347846   741 net.cpp:157] Top shape: 1 8 (8)
I0611 16:51:08.347847   741 net.cpp:165] Memory required for data: 1430983620
I0611 16:51:08.347851   741 layer_factory.hpp:77] Creating layer loss_attribute
I0611 16:51:08.347860   741 net.cpp:106] Creating Layer loss_attribute
I0611 16:51:08.347865   741 net.cpp:454] loss_attribute <- attr_score_pos
I0611 16:51:08.347870   741 net.cpp:454] loss_attribute <- attrArray
I0611 16:51:08.347878   741 net.cpp:411] loss_attribute -> loss_attribute
I0611 16:51:08.347930   741 net.cpp:150] Setting up loss_attribute
I0611 16:51:08.347935   741 net.cpp:157] Top shape: (1)
I0611 16:51:08.347937   741 net.cpp:160]     with loss weight 2
I0611 16:51:08.347951   741 net.cpp:165] Memory required for data: 1430983624
I0611 16:51:08.347955   741 layer_factory.hpp:77] Creating layer loss_cls
I0611 16:51:08.347965   741 net.cpp:106] Creating Layer loss_cls
I0611 16:51:08.347970   741 net.cpp:454] loss_cls <- cls_score
I0611 16:51:08.347975   741 net.cpp:454] loss_cls <- labels
I0611 16:51:08.347983   741 net.cpp:411] loss_cls -> loss_cls
I0611 16:51:08.347995   741 layer_factory.hpp:77] Creating layer loss_cls
I0611 16:51:08.348651   741 net.cpp:150] Setting up loss_cls
I0611 16:51:08.348659   741 net.cpp:157] Top shape: (1)
I0611 16:51:08.348662   741 net.cpp:160]     with loss weight 3
I0611 16:51:08.348666   741 net.cpp:165] Memory required for data: 1430983628
I0611 16:51:08.348670   741 layer_factory.hpp:77] Creating layer loss_bbox
I0611 16:51:08.348675   741 net.cpp:106] Creating Layer loss_bbox
I0611 16:51:08.348680   741 net.cpp:454] loss_bbox <- bbox_pred
I0611 16:51:08.348682   741 net.cpp:454] loss_bbox <- bbox_targets
I0611 16:51:08.348685   741 net.cpp:454] loss_bbox <- bbox_inside_weights
I0611 16:51:08.348688   741 net.cpp:454] loss_bbox <- bbox_outside_weights
I0611 16:51:08.348691   741 net.cpp:411] loss_bbox -> loss_bbox
I0611 16:51:08.348752   741 net.cpp:150] Setting up loss_bbox
I0611 16:51:08.348758   741 net.cpp:157] Top shape: (1)
I0611 16:51:08.348760   741 net.cpp:160]     with loss weight 2
I0611 16:51:08.348763   741 net.cpp:165] Memory required for data: 1430983632
I0611 16:51:08.348767   741 layer_factory.hpp:77] Creating layer roi_pool5_2
I0611 16:51:08.348780   741 net.cpp:106] Creating Layer roi_pool5_2
I0611 16:51:08.348784   741 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0611 16:51:08.348788   741 net.cpp:454] roi_pool5_2 <- rois_pos
I0611 16:51:08.348791   741 net.cpp:411] roi_pool5_2 -> pool5_2
I0611 16:51:08.348796   741 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0611 16:51:08.348863   741 net.cpp:150] Setting up roi_pool5_2
I0611 16:51:08.348868   741 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 16:51:08.348870   741 net.cpp:165] Memory required for data: 1431083984
I0611 16:51:08.348873   741 layer_factory.hpp:77] Creating layer pool5_2_conv
I0611 16:51:08.348881   741 net.cpp:106] Creating Layer pool5_2_conv
I0611 16:51:08.348886   741 net.cpp:454] pool5_2_conv <- pool5_2
I0611 16:51:08.348889   741 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0611 16:51:08.355729   741 net.cpp:150] Setting up pool5_2_conv
I0611 16:51:08.355747   741 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 16:51:08.355749   741 net.cpp:165] Memory required for data: 1431184336
I0611 16:51:08.355757   741 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0611 16:51:08.355765   741 net.cpp:106] Creating Layer pool5_2_conv_relu
I0611 16:51:08.355772   741 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0611 16:51:08.355775   741 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0611 16:51:08.355912   741 net.cpp:150] Setting up pool5_2_conv_relu
I0611 16:51:08.355918   741 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 16:51:08.355921   741 net.cpp:165] Memory required for data: 1431284688
I0611 16:51:08.355923   741 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0611 16:51:08.355933   741 net.cpp:106] Creating Layer pool5_2_conv2
I0611 16:51:08.355937   741 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0611 16:51:08.355942   741 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0611 16:51:08.408015   741 net.cpp:150] Setting up pool5_2_conv2
I0611 16:51:08.408044   741 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 16:51:08.408047   741 net.cpp:165] Memory required for data: 1431385040
I0611 16:51:08.408054   741 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0611 16:51:08.408062   741 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0611 16:51:08.408067   741 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0611 16:51:08.408077   741 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0611 16:51:08.408242   741 net.cpp:150] Setting up pool5_2_conv2_relu
I0611 16:51:08.408259   741 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 16:51:08.408262   741 net.cpp:165] Memory required for data: 1431485392
I0611 16:51:08.408263   741 layer_factory.hpp:77] Creating layer mask_deconv1
I0611 16:51:08.408282   741 net.cpp:106] Creating Layer mask_deconv1
I0611 16:51:08.408283   741 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0611 16:51:08.408288   741 net.cpp:411] mask_deconv1 -> mask_deconv1
I0611 16:51:08.409090   741 net.cpp:150] Setting up mask_deconv1
I0611 16:51:08.409096   741 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0611 16:51:08.409108   741 net.cpp:165] Memory required for data: 1432406992
I0611 16:51:08.409112   741 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0611 16:51:08.409130   741 net.cpp:106] Creating Layer pool5_2_conv3
I0611 16:51:08.409137   741 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0611 16:51:08.409143   741 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0611 16:51:08.435721   741 net.cpp:150] Setting up pool5_2_conv3
I0611 16:51:08.435741   741 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:51:08.435744   741 net.cpp:165] Memory required for data: 1434250192
I0611 16:51:08.435761   741 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0611 16:51:08.435770   741 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0611 16:51:08.435775   741 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0611 16:51:08.435784   741 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0611 16:51:08.435962   741 net.cpp:150] Setting up pool5_2_conv3_relu
I0611 16:51:08.435969   741 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:51:08.435972   741 net.cpp:165] Memory required for data: 1436093392
I0611 16:51:08.435984   741 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0611 16:51:08.435997   741 net.cpp:106] Creating Layer pool5_2_conv4
I0611 16:51:08.436002   741 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0611 16:51:08.436018   741 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0611 16:51:08.488610   741 net.cpp:150] Setting up pool5_2_conv4
I0611 16:51:08.488636   741 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:51:08.488639   741 net.cpp:165] Memory required for data: 1437936592
I0611 16:51:08.488647   741 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0611 16:51:08.488656   741 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0611 16:51:08.488662   741 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0611 16:51:08.488668   741 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0611 16:51:08.488831   741 net.cpp:150] Setting up pool5_2_conv4_relu
I0611 16:51:08.488849   741 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:51:08.488852   741 net.cpp:165] Memory required for data: 1439779792
I0611 16:51:08.488853   741 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 16:51:08.488868   741 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 16:51:08.488871   741 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0611 16:51:08.488874   741 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0611 16:51:08.488880   741 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0611 16:51:08.488888   741 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0611 16:51:08.488896   741 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0611 16:51:08.489001   741 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 16:51:08.489009   741 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:51:08.489023   741 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:51:08.489027   741 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:51:08.489043   741 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:51:08.489049   741 net.cpp:165] Memory required for data: 1447152592
I0611 16:51:08.489053   741 layer_factory.hpp:77] Creating layer query_conv
I0611 16:51:08.489069   741 net.cpp:106] Creating Layer query_conv
I0611 16:51:08.489075   741 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0611 16:51:08.489085   741 net.cpp:411] query_conv -> query_conv
I0611 16:51:08.490707   741 net.cpp:150] Setting up query_conv
I0611 16:51:08.490716   741 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0611 16:51:08.490718   741 net.cpp:165] Memory required for data: 1447382992
I0611 16:51:08.490727   741 layer_factory.hpp:77] Creating layer key_conv
I0611 16:51:08.490741   741 net.cpp:106] Creating Layer key_conv
I0611 16:51:08.490747   741 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0611 16:51:08.490756   741 net.cpp:411] key_conv -> key_conv
I0611 16:51:08.492337   741 net.cpp:150] Setting up key_conv
I0611 16:51:08.492347   741 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0611 16:51:08.492350   741 net.cpp:165] Memory required for data: 1447613392
I0611 16:51:08.492357   741 layer_factory.hpp:77] Creating layer value_conv
I0611 16:51:08.492370   741 net.cpp:106] Creating Layer value_conv
I0611 16:51:08.492377   741 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0611 16:51:08.492388   741 net.cpp:411] value_conv -> value_conv
I0611 16:51:08.499121   741 net.cpp:150] Setting up value_conv
I0611 16:51:08.499131   741 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:51:08.499133   741 net.cpp:165] Memory required for data: 1449456592
I0611 16:51:08.499140   741 layer_factory.hpp:77] Creating layer query_conv_reshape
I0611 16:51:08.499148   741 net.cpp:106] Creating Layer query_conv_reshape
I0611 16:51:08.499153   741 net.cpp:454] query_conv_reshape <- query_conv
I0611 16:51:08.499161   741 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0611 16:51:08.499189   741 net.cpp:150] Setting up query_conv_reshape
I0611 16:51:08.499197   741 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0611 16:51:08.499202   741 net.cpp:165] Memory required for data: 1449686992
I0611 16:51:08.499205   741 layer_factory.hpp:77] Creating layer key_conv_reshape
I0611 16:51:08.499212   741 net.cpp:106] Creating Layer key_conv_reshape
I0611 16:51:08.499217   741 net.cpp:454] key_conv_reshape <- key_conv
I0611 16:51:08.499222   741 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0611 16:51:08.499248   741 net.cpp:150] Setting up key_conv_reshape
I0611 16:51:08.499254   741 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0611 16:51:08.499258   741 net.cpp:165] Memory required for data: 1449917392
I0611 16:51:08.499263   741 layer_factory.hpp:77] Creating layer value_conv_reshape
I0611 16:51:08.499270   741 net.cpp:106] Creating Layer value_conv_reshape
I0611 16:51:08.499274   741 net.cpp:454] value_conv_reshape <- value_conv
I0611 16:51:08.499280   741 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0611 16:51:08.499302   741 net.cpp:150] Setting up value_conv_reshape
I0611 16:51:08.499310   741 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0611 16:51:08.499313   741 net.cpp:165] Memory required for data: 1451760592
I0611 16:51:08.499317   741 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0611 16:51:08.499322   741 net.cpp:106] Creating Layer query_conv_reshape_perm
I0611 16:51:08.499327   741 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0611 16:51:08.499333   741 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0611 16:51:08.499428   741 net.cpp:150] Setting up query_conv_reshape_perm
I0611 16:51:08.499436   741 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0611 16:51:08.499440   741 net.cpp:165] Memory required for data: 1451990992
I0611 16:51:08.499444   741 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0611 16:51:08.499450   741 net.cpp:106] Creating Layer key_conv_reshape_perm
I0611 16:51:08.499455   741 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0611 16:51:08.499460   741 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0611 16:51:08.499548   741 net.cpp:150] Setting up key_conv_reshape_perm
I0611 16:51:08.499557   741 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0611 16:51:08.499560   741 net.cpp:165] Memory required for data: 1452221392
I0611 16:51:08.499563   741 layer_factory.hpp:77] Creating layer energy
I0611 16:51:08.499569   741 net.cpp:106] Creating Layer energy
I0611 16:51:08.499573   741 net.cpp:454] energy <- query_conv_reshape_perm
I0611 16:51:08.499578   741 net.cpp:454] energy <- key_conv_reshape_perm
I0611 16:51:08.499585   741 net.cpp:411] energy -> energy
I0611 16:51:08.499608   741 net.cpp:150] Setting up energy
I0611 16:51:08.499614   741 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 16:51:08.499619   741 net.cpp:165] Memory required for data: 1455461392
I0611 16:51:08.499621   741 layer_factory.hpp:77] Creating layer attention
I0611 16:51:08.499629   741 net.cpp:106] Creating Layer attention
I0611 16:51:08.499632   741 net.cpp:454] attention <- energy
I0611 16:51:08.499639   741 net.cpp:411] attention -> attention
I0611 16:51:08.499861   741 net.cpp:150] Setting up attention
I0611 16:51:08.499872   741 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 16:51:08.499876   741 net.cpp:165] Memory required for data: 1458701392
I0611 16:51:08.499881   741 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0611 16:51:08.499888   741 net.cpp:106] Creating Layer value_conv_reshape_perm
I0611 16:51:08.499894   741 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0611 16:51:08.499902   741 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0611 16:51:08.499996   741 net.cpp:150] Setting up value_conv_reshape_perm
I0611 16:51:08.500003   741 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0611 16:51:08.500005   741 net.cpp:165] Memory required for data: 1460544592
I0611 16:51:08.500007   741 layer_factory.hpp:77] Creating layer attention_perm
I0611 16:51:08.500012   741 net.cpp:106] Creating Layer attention_perm
I0611 16:51:08.500033   741 net.cpp:454] attention_perm <- attention
I0611 16:51:08.500053   741 net.cpp:411] attention_perm -> attention_perm
I0611 16:51:08.500149   741 net.cpp:150] Setting up attention_perm
I0611 16:51:08.500156   741 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 16:51:08.500159   741 net.cpp:165] Memory required for data: 1463784592
I0611 16:51:08.500160   741 layer_factory.hpp:77] Creating layer out
I0611 16:51:08.500166   741 net.cpp:106] Creating Layer out
I0611 16:51:08.500170   741 net.cpp:454] out <- value_conv_reshape_perm
I0611 16:51:08.500175   741 net.cpp:454] out <- attention_perm
I0611 16:51:08.500182   741 net.cpp:411] out -> out
I0611 16:51:08.500211   741 net.cpp:150] Setting up out
I0611 16:51:08.500221   741 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0611 16:51:08.500226   741 net.cpp:165] Memory required for data: 1465627792
I0611 16:51:08.500228   741 layer_factory.hpp:77] Creating layer out_reshape
I0611 16:51:08.500236   741 net.cpp:106] Creating Layer out_reshape
I0611 16:51:08.500241   741 net.cpp:454] out_reshape <- out
I0611 16:51:08.500249   741 net.cpp:411] out_reshape -> out_reshape
I0611 16:51:08.500277   741 net.cpp:150] Setting up out_reshape
I0611 16:51:08.500283   741 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:51:08.500284   741 net.cpp:165] Memory required for data: 1467470992
I0611 16:51:08.500289   741 layer_factory.hpp:77] Creating layer out_reshape_scale
I0611 16:51:08.500299   741 net.cpp:106] Creating Layer out_reshape_scale
I0611 16:51:08.500304   741 net.cpp:454] out_reshape_scale <- out_reshape
I0611 16:51:08.500316   741 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0611 16:51:08.500393   741 net.cpp:150] Setting up out_reshape_scale
I0611 16:51:08.500399   741 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:51:08.500401   741 net.cpp:165] Memory required for data: 1469314192
I0611 16:51:08.500408   741 layer_factory.hpp:77] Creating layer out_x
I0611 16:51:08.500421   741 net.cpp:106] Creating Layer out_x
I0611 16:51:08.500427   741 net.cpp:454] out_x <- out_reshape_scale
I0611 16:51:08.500434   741 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0611 16:51:08.500442   741 net.cpp:411] out_x -> out_x
I0611 16:51:08.500471   741 net.cpp:150] Setting up out_x
I0611 16:51:08.500478   741 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 16:51:08.500481   741 net.cpp:165] Memory required for data: 1471157392
I0611 16:51:08.500485   741 layer_factory.hpp:77] Creating layer mask_deconv2
I0611 16:51:08.500494   741 net.cpp:106] Creating Layer mask_deconv2
I0611 16:51:08.500500   741 net.cpp:454] mask_deconv2 <- out_x
I0611 16:51:08.500510   741 net.cpp:411] mask_deconv2 -> mask_deconv2
I0611 16:51:08.501332   741 net.cpp:150] Setting up mask_deconv2
I0611 16:51:08.501339   741 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0611 16:51:08.501341   741 net.cpp:165] Memory required for data: 1486398608
I0611 16:51:08.501346   741 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0611 16:51:08.501355   741 net.cpp:106] Creating Layer pool5_2_conv5
I0611 16:51:08.501361   741 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0611 16:51:08.501369   741 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0611 16:51:08.528218   741 net.cpp:150] Setting up pool5_2_conv5
I0611 16:51:08.528244   741 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 16:51:08.528246   741 net.cpp:165] Memory required for data: 1516881040
I0611 16:51:08.528254   741 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0611 16:51:08.528264   741 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0611 16:51:08.528270   741 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0611 16:51:08.528277   741 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0611 16:51:08.528432   741 net.cpp:150] Setting up pool5_2_conv5_relu
I0611 16:51:08.528439   741 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 16:51:08.528451   741 net.cpp:165] Memory required for data: 1547363472
I0611 16:51:08.528455   741 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0611 16:51:08.528465   741 net.cpp:106] Creating Layer pool5_2_conv6
I0611 16:51:08.528470   741 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0611 16:51:08.528479   741 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0611 16:51:08.579075   741 net.cpp:150] Setting up pool5_2_conv6
I0611 16:51:08.579093   741 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 16:51:08.579097   741 net.cpp:165] Memory required for data: 1577845904
I0611 16:51:08.579123   741 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0611 16:51:08.579136   741 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0611 16:51:08.579152   741 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0611 16:51:08.579159   741 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0611 16:51:08.579720   741 net.cpp:150] Setting up pool5_2_conv6_relu
I0611 16:51:08.579730   741 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 16:51:08.579731   741 net.cpp:165] Memory required for data: 1608328336
I0611 16:51:08.579738   741 layer_factory.hpp:77] Creating layer mask_deconv3
I0611 16:51:08.579748   741 net.cpp:106] Creating Layer mask_deconv3
I0611 16:51:08.579754   741 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0611 16:51:08.579762   741 net.cpp:411] mask_deconv3 -> mask_deconv3
I0611 16:51:08.580139   741 net.cpp:150] Setting up mask_deconv3
I0611 16:51:08.580145   741 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0611 16:51:08.580147   741 net.cpp:165] Memory required for data: 1669293200
I0611 16:51:08.580153   741 layer_factory.hpp:77] Creating layer mask_score
I0611 16:51:08.580164   741 net.cpp:106] Creating Layer mask_score
I0611 16:51:08.580170   741 net.cpp:454] mask_score <- mask_deconv3
I0611 16:51:08.580178   741 net.cpp:411] mask_score -> mask_score
I0611 16:51:08.580776   741 net.cpp:150] Setting up mask_score
I0611 16:51:08.580785   741 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0611 16:51:08.580787   741 net.cpp:165] Memory required for data: 1671198352
I0611 16:51:08.580796   741 layer_factory.hpp:77] Creating layer loss_mask
I0611 16:51:08.580804   741 net.cpp:106] Creating Layer loss_mask
I0611 16:51:08.580811   741 net.cpp:454] loss_mask <- mask_score
I0611 16:51:08.580816   741 net.cpp:454] loss_mask <- mask_targets
I0611 16:51:08.580826   741 net.cpp:411] loss_mask -> loss_mask
I0611 16:51:08.580838   741 layer_factory.hpp:77] Creating layer loss_mask
I0611 16:51:08.582120   741 net.cpp:150] Setting up loss_mask
I0611 16:51:08.582129   741 net.cpp:157] Top shape: (1)
I0611 16:51:08.582131   741 net.cpp:160]     with loss weight 3
I0611 16:51:08.582154   741 net.cpp:165] Memory required for data: 1671198356
I0611 16:51:08.582159   741 net.cpp:226] loss_mask needs backward computation.
I0611 16:51:08.582165   741 net.cpp:226] mask_score needs backward computation.
I0611 16:51:08.582170   741 net.cpp:226] mask_deconv3 needs backward computation.
I0611 16:51:08.582175   741 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0611 16:51:08.582178   741 net.cpp:226] pool5_2_conv6 needs backward computation.
I0611 16:51:08.582185   741 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0611 16:51:08.582190   741 net.cpp:226] pool5_2_conv5 needs backward computation.
I0611 16:51:08.582192   741 net.cpp:226] mask_deconv2 needs backward computation.
I0611 16:51:08.582196   741 net.cpp:226] out_x needs backward computation.
I0611 16:51:08.582211   741 net.cpp:226] out_reshape_scale needs backward computation.
I0611 16:51:08.582216   741 net.cpp:226] out_reshape needs backward computation.
I0611 16:51:08.582221   741 net.cpp:226] out needs backward computation.
I0611 16:51:08.582226   741 net.cpp:226] attention_perm needs backward computation.
I0611 16:51:08.582231   741 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0611 16:51:08.582235   741 net.cpp:226] attention needs backward computation.
I0611 16:51:08.582239   741 net.cpp:226] energy needs backward computation.
I0611 16:51:08.582257   741 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0611 16:51:08.582262   741 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0611 16:51:08.582268   741 net.cpp:226] value_conv_reshape needs backward computation.
I0611 16:51:08.582276   741 net.cpp:226] key_conv_reshape needs backward computation.
I0611 16:51:08.582293   741 net.cpp:226] query_conv_reshape needs backward computation.
I0611 16:51:08.582307   741 net.cpp:226] value_conv needs backward computation.
I0611 16:51:08.582312   741 net.cpp:226] key_conv needs backward computation.
I0611 16:51:08.582319   741 net.cpp:226] query_conv needs backward computation.
I0611 16:51:08.582321   741 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0611 16:51:08.582327   741 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0611 16:51:08.582329   741 net.cpp:226] pool5_2_conv4 needs backward computation.
I0611 16:51:08.582332   741 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0611 16:51:08.582336   741 net.cpp:226] pool5_2_conv3 needs backward computation.
I0611 16:51:08.582339   741 net.cpp:226] mask_deconv1 needs backward computation.
I0611 16:51:08.582341   741 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0611 16:51:08.582345   741 net.cpp:226] pool5_2_conv2 needs backward computation.
I0611 16:51:08.582347   741 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0611 16:51:08.582350   741 net.cpp:226] pool5_2_conv needs backward computation.
I0611 16:51:08.582353   741 net.cpp:226] roi_pool5_2 needs backward computation.
I0611 16:51:08.582356   741 net.cpp:226] loss_bbox needs backward computation.
I0611 16:51:08.582361   741 net.cpp:226] loss_cls needs backward computation.
I0611 16:51:08.582363   741 net.cpp:226] loss_attribute needs backward computation.
I0611 16:51:08.582367   741 net.cpp:226] bbox_pred needs backward computation.
I0611 16:51:08.582370   741 net.cpp:226] cls_score needs backward computation.
I0611 16:51:08.582373   741 net.cpp:226] attr_score_pos needs backward computation.
I0611 16:51:08.582376   741 net.cpp:226] attr_score needs backward computation.
I0611 16:51:08.582381   741 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0611 16:51:08.582382   741 net.cpp:226] relu7 needs backward computation.
I0611 16:51:08.582386   741 net.cpp:226] fc7 needs backward computation.
I0611 16:51:08.582388   741 net.cpp:226] relu6 needs backward computation.
I0611 16:51:08.582391   741 net.cpp:226] fc6 needs backward computation.
I0611 16:51:08.582393   741 net.cpp:226] roi_pool5 needs backward computation.
I0611 16:51:08.582399   741 net.cpp:226] roi-data needs backward computation.
I0611 16:51:08.582403   741 net.cpp:226] proposal needs backward computation.
I0611 16:51:08.582408   741 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0611 16:51:08.582410   741 net.cpp:226] rpn_cls_prob needs backward computation.
I0611 16:51:08.582414   741 net.cpp:226] rpn_loss_bbox needs backward computation.
I0611 16:51:08.582417   741 net.cpp:226] rpn_loss_cls needs backward computation.
I0611 16:51:08.582422   741 net.cpp:226] rpn-data needs backward computation.
I0611 16:51:08.582427   741 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0611 16:51:08.582430   741 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0611 16:51:08.582433   741 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0611 16:51:08.582437   741 net.cpp:226] rpn_bbox_pred needs backward computation.
I0611 16:51:08.582440   741 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0611 16:51:08.582444   741 net.cpp:226] rpn_cls_score needs backward computation.
I0611 16:51:08.582448   741 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0611 16:51:08.582450   741 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0611 16:51:08.582453   741 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0611 16:51:08.582456   741 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0611 16:51:08.582459   741 net.cpp:226] relu5_3 needs backward computation.
I0611 16:51:08.582463   741 net.cpp:226] conv5_3 needs backward computation.
I0611 16:51:08.582465   741 net.cpp:226] relu5_2 needs backward computation.
I0611 16:51:08.582468   741 net.cpp:226] conv5_2 needs backward computation.
I0611 16:51:08.582471   741 net.cpp:226] relu5_1 needs backward computation.
I0611 16:51:08.582474   741 net.cpp:226] conv5_1 needs backward computation.
I0611 16:51:08.582476   741 net.cpp:226] pool4 needs backward computation.
I0611 16:51:08.582480   741 net.cpp:226] relu4_3 needs backward computation.
I0611 16:51:08.582482   741 net.cpp:226] conv4_3 needs backward computation.
I0611 16:51:08.582485   741 net.cpp:226] relu4_2 needs backward computation.
I0611 16:51:08.582489   741 net.cpp:226] conv4_2 needs backward computation.
I0611 16:51:08.582491   741 net.cpp:226] relu4_1 needs backward computation.
I0611 16:51:08.582494   741 net.cpp:226] conv4_1 needs backward computation.
I0611 16:51:08.582496   741 net.cpp:226] pool3 needs backward computation.
I0611 16:51:08.582499   741 net.cpp:226] relu3_3 needs backward computation.
I0611 16:51:08.582501   741 net.cpp:226] conv3_3 needs backward computation.
I0611 16:51:08.582504   741 net.cpp:226] relu3_2 needs backward computation.
I0611 16:51:08.582506   741 net.cpp:226] conv3_2 needs backward computation.
I0611 16:51:08.582509   741 net.cpp:226] relu3_1 needs backward computation.
I0611 16:51:08.582511   741 net.cpp:226] conv3_1 needs backward computation.
I0611 16:51:08.582515   741 net.cpp:228] pool2 does not need backward computation.
I0611 16:51:08.582518   741 net.cpp:228] relu2_2 does not need backward computation.
I0611 16:51:08.582520   741 net.cpp:228] conv2_2 does not need backward computation.
I0611 16:51:08.582523   741 net.cpp:228] relu2_1 does not need backward computation.
I0611 16:51:08.582527   741 net.cpp:228] conv2_1 does not need backward computation.
I0611 16:51:08.582530   741 net.cpp:228] pool1 does not need backward computation.
I0611 16:51:08.582532   741 net.cpp:228] relu1_2 does not need backward computation.
I0611 16:51:08.582535   741 net.cpp:228] conv1_2 does not need backward computation.
I0611 16:51:08.582538   741 net.cpp:228] relu1_1 does not need backward computation.
I0611 16:51:08.582540   741 net.cpp:228] conv1_1 does not need backward computation.
I0611 16:51:08.582545   741 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0611 16:51:08.582547   741 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0611 16:51:08.582551   741 net.cpp:228] data_input-data_0_split does not need backward computation.
I0611 16:51:08.582556   741 net.cpp:228] input-data does not need backward computation.
I0611 16:51:08.582558   741 net.cpp:270] This network produces output loss_attribute
I0611 16:51:08.582561   741 net.cpp:270] This network produces output loss_bbox
I0611 16:51:08.582564   741 net.cpp:270] This network produces output loss_cls
I0611 16:51:08.582566   741 net.cpp:270] This network produces output loss_mask
I0611 16:51:08.582569   741 net.cpp:270] This network produces output rpn_cls_loss
I0611 16:51:08.582571   741 net.cpp:270] This network produces output rpn_loss_bbox
I0611 16:51:08.582623   741 net.cpp:283] Network initialization done.
I0611 16:51:08.582790   741 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0611 16:51:10.843381   741 net.cpp:816] Ignoring source layer pool5
I0611 16:51:10.908571   741 net.cpp:816] Ignoring source layer drop6
I0611 16:51:10.919536   741 net.cpp:816] Ignoring source layer drop7
I0611 16:51:10.919550   741 net.cpp:816] Ignoring source layer fc8
I0611 16:51:10.919564   741 net.cpp:816] Ignoring source layer prob
Solving...
I0611 16:51:12.221187   741 solver.cpp:229] Iteration 0, loss = 19.6042
I0611 16:51:12.221215   741 solver.cpp:245]     Train net output #0: loss_attribute = 4.85356 (* 2 = 9.70712 loss)
I0611 16:51:12.221220   741 solver.cpp:245]     Train net output #1: loss_bbox = 0.0916567 (* 2 = 0.183313 loss)
I0611 16:51:12.221223   741 solver.cpp:245]     Train net output #2: loss_cls = 0.947394 (* 3 = 2.84218 loss)
I0611 16:51:12.221227   741 solver.cpp:245]     Train net output #3: loss_mask = 2.08166 (* 3 = 6.24497 loss)
I0611 16:51:12.221230   741 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.73882 (* 1 = 0.73882 loss)
I0611 16:51:12.221235   741 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0189577 (* 1 = 0.0189577 loss)
I0611 16:51:12.221249   741 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0611 16:51:31.697921   741 solver.cpp:229] Iteration 20, loss = 16.1477
I0611 16:51:31.697947   741 solver.cpp:245]     Train net output #0: loss_attribute = 4.70432 (* 2 = 9.40865 loss)
I0611 16:51:31.697953   741 solver.cpp:245]     Train net output #1: loss_bbox = 0.264587 (* 2 = 0.529175 loss)
I0611 16:51:31.697957   741 solver.cpp:245]     Train net output #2: loss_cls = 0.0559769 (* 3 = 0.167931 loss)
I0611 16:51:31.697962   741 solver.cpp:245]     Train net output #3: loss_mask = 1.81584 (* 3 = 5.44752 loss)
I0611 16:51:31.697965   741 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.290205 (* 1 = 0.290205 loss)
I0611 16:51:31.697970   741 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0248102 (* 1 = 0.0248102 loss)
I0611 16:51:31.697975   741 sgd_solver.cpp:106] Iteration 20, lr = 0.001
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:62: RuntimeWarning: overflow encountered in exp
  pred_w = np.exp(dw) * widths[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:62: RuntimeWarning: overflow encountered in multiply
  pred_w = np.exp(dw) * widths[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:63: RuntimeWarning: overflow encountered in multiply
  pred_h = np.exp(dh) * heights[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:63: RuntimeWarning: overflow encountered in exp
  pred_h = np.exp(dh) * heights[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:47: RuntimeWarning: overflow encountered in multiply
  pred_ctr_x = dx * widths[:, np.newaxis] + ctr_x[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:48: RuntimeWarning: overflow encountered in multiply
  pred_ctr_y = dy * heights[:, np.newaxis] + ctr_y[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:67: RuntimeWarning: invalid value encountered in subtract
  pred_boxes[:, 0::4] = pred_ctr_x - 0.5 * pred_w
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:69: RuntimeWarning: invalid value encountered in subtract
  pred_boxes[:, 1::4] = pred_ctr_y - 0.5 * pred_h
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:71: RuntimeWarning: invalid value encountered in add
  pred_boxes[:, 2::4] = pred_ctr_x + 0.5 * pred_w
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:83: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:83: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:85: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:85: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:87: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:87: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/rpn/proposal_layer.py:187: RuntimeWarning: invalid value encountered in greater_equal
  keep = np.where((ws >= min_size) & (hs >= min_size))[0]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:89: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:89: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0)
---- WARNING: filter_boxes() remove ALL proposal.
./experiments/scripts/faster_rcnn_end2end.sh: line 65:   741 Floating point exception/usr/bin/python ./tools/train_net.py --gpu ${GPU_ID} --solver models/${PT_DIR}/${NET}/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb ${TRAIN_IMDB} --iters ${ITERS} --cfg experiments/cfgs/faster_rcnn_end2end.yml ${EXTRA_ARGS}
