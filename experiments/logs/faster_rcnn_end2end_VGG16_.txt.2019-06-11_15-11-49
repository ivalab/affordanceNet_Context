+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-11_15-11-49
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-11_15-11-49
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0611 15:11:56.968816 26535 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0611 15:11:56.968835 26535 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0611 15:11:56.970190 26535 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  top: "attrArray"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "attr_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "attr_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_attribute"
  type: "SigmoidCrossEntropyLoss"
  bottom: "attr_score"
  bottom: "attrArray"
  top: "loss_attribute"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_mask"
  type: "SoftmaxWithLoss"
  bottom: "mask_score"
  bottom: "mask_targets"
  top: "loss_mask"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
I0611 15:11:56.970510 26535 layer_factory.hpp:77] Creating layer input-data
I0611 15:11:56.987838 26535 net.cpp:106] Creating Layer input-data
I0611 15:11:56.987864 26535 net.cpp:411] input-data -> data
I0611 15:11:56.987872 26535 net.cpp:411] input-data -> im_info
I0611 15:11:56.987879 26535 net.cpp:411] input-data -> gt_boxes
I0611 15:11:56.987882 26535 net.cpp:411] input-data -> seg_mask_inds
I0611 15:11:56.987886 26535 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0611 15:11:57.000526 26535 net.cpp:150] Setting up input-data
I0611 15:11:57.000551 26535 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 15:11:57.000555 26535 net.cpp:157] Top shape: 1 3 (3)
I0611 15:11:57.000567 26535 net.cpp:157] Top shape: 1 4 (4)
I0611 15:11:57.000571 26535 net.cpp:157] Top shape: 1 2 (2)
I0611 15:11:57.000573 26535 net.cpp:157] Top shape: 1 1 (1)
I0611 15:11:57.000576 26535 net.cpp:165] Memory required for data: 7200040
I0611 15:11:57.000581 26535 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0611 15:11:57.000594 26535 net.cpp:106] Creating Layer data_input-data_0_split
I0611 15:11:57.000599 26535 net.cpp:454] data_input-data_0_split <- data
I0611 15:11:57.000607 26535 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0611 15:11:57.000624 26535 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0611 15:11:57.000650 26535 net.cpp:150] Setting up data_input-data_0_split
I0611 15:11:57.000665 26535 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 15:11:57.000669 26535 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 15:11:57.000671 26535 net.cpp:165] Memory required for data: 21600040
I0611 15:11:57.000674 26535 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0611 15:11:57.000689 26535 net.cpp:106] Creating Layer im_info_input-data_1_split
I0611 15:11:57.000694 26535 net.cpp:454] im_info_input-data_1_split <- im_info
I0611 15:11:57.000696 26535 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0611 15:11:57.000710 26535 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0611 15:11:57.000717 26535 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0611 15:11:57.000766 26535 net.cpp:150] Setting up im_info_input-data_1_split
I0611 15:11:57.000771 26535 net.cpp:157] Top shape: 1 3 (3)
I0611 15:11:57.000774 26535 net.cpp:157] Top shape: 1 3 (3)
I0611 15:11:57.000777 26535 net.cpp:157] Top shape: 1 3 (3)
I0611 15:11:57.000789 26535 net.cpp:165] Memory required for data: 21600076
I0611 15:11:57.000792 26535 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0611 15:11:57.000797 26535 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0611 15:11:57.000799 26535 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0611 15:11:57.000803 26535 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0611 15:11:57.000809 26535 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0611 15:11:57.000831 26535 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0611 15:11:57.000835 26535 net.cpp:157] Top shape: 1 4 (4)
I0611 15:11:57.000838 26535 net.cpp:157] Top shape: 1 4 (4)
I0611 15:11:57.000841 26535 net.cpp:165] Memory required for data: 21600108
I0611 15:11:57.000845 26535 layer_factory.hpp:77] Creating layer conv1_1
I0611 15:11:57.000854 26535 net.cpp:106] Creating Layer conv1_1
I0611 15:11:57.000856 26535 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0611 15:11:57.000861 26535 net.cpp:411] conv1_1 -> conv1_1
I0611 15:11:57.200789 26535 net.cpp:150] Setting up conv1_1
I0611 15:11:57.200820 26535 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 15:11:57.200824 26535 net.cpp:165] Memory required for data: 175200108
I0611 15:11:57.200847 26535 layer_factory.hpp:77] Creating layer relu1_1
I0611 15:11:57.200858 26535 net.cpp:106] Creating Layer relu1_1
I0611 15:11:57.200863 26535 net.cpp:454] relu1_1 <- conv1_1
I0611 15:11:57.200868 26535 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0611 15:11:57.201007 26535 net.cpp:150] Setting up relu1_1
I0611 15:11:57.201014 26535 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 15:11:57.201026 26535 net.cpp:165] Memory required for data: 328800108
I0611 15:11:57.201030 26535 layer_factory.hpp:77] Creating layer conv1_2
I0611 15:11:57.201050 26535 net.cpp:106] Creating Layer conv1_2
I0611 15:11:57.201052 26535 net.cpp:454] conv1_2 <- conv1_1
I0611 15:11:57.201058 26535 net.cpp:411] conv1_2 -> conv1_2
I0611 15:11:57.203529 26535 net.cpp:150] Setting up conv1_2
I0611 15:11:57.203550 26535 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 15:11:57.203553 26535 net.cpp:165] Memory required for data: 482400108
I0611 15:11:57.203564 26535 layer_factory.hpp:77] Creating layer relu1_2
I0611 15:11:57.203582 26535 net.cpp:106] Creating Layer relu1_2
I0611 15:11:57.203585 26535 net.cpp:454] relu1_2 <- conv1_2
I0611 15:11:57.203588 26535 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0611 15:11:57.203722 26535 net.cpp:150] Setting up relu1_2
I0611 15:11:57.203729 26535 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 15:11:57.203742 26535 net.cpp:165] Memory required for data: 636000108
I0611 15:11:57.203743 26535 layer_factory.hpp:77] Creating layer pool1
I0611 15:11:57.203760 26535 net.cpp:106] Creating Layer pool1
I0611 15:11:57.203763 26535 net.cpp:454] pool1 <- conv1_2
I0611 15:11:57.203768 26535 net.cpp:411] pool1 -> pool1
I0611 15:11:57.203824 26535 net.cpp:150] Setting up pool1
I0611 15:11:57.203827 26535 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0611 15:11:57.203840 26535 net.cpp:165] Memory required for data: 674400108
I0611 15:11:57.203841 26535 layer_factory.hpp:77] Creating layer conv2_1
I0611 15:11:57.203848 26535 net.cpp:106] Creating Layer conv2_1
I0611 15:11:57.203860 26535 net.cpp:454] conv2_1 <- pool1
I0611 15:11:57.203866 26535 net.cpp:411] conv2_1 -> conv2_1
I0611 15:11:57.206086 26535 net.cpp:150] Setting up conv2_1
I0611 15:11:57.206095 26535 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 15:11:57.206107 26535 net.cpp:165] Memory required for data: 751200108
I0611 15:11:57.206115 26535 layer_factory.hpp:77] Creating layer relu2_1
I0611 15:11:57.206121 26535 net.cpp:106] Creating Layer relu2_1
I0611 15:11:57.206125 26535 net.cpp:454] relu2_1 <- conv2_1
I0611 15:11:57.206130 26535 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0611 15:11:57.208282 26535 net.cpp:150] Setting up relu2_1
I0611 15:11:57.208302 26535 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 15:11:57.208304 26535 net.cpp:165] Memory required for data: 828000108
I0611 15:11:57.208307 26535 layer_factory.hpp:77] Creating layer conv2_2
I0611 15:11:57.208312 26535 net.cpp:106] Creating Layer conv2_2
I0611 15:11:57.208324 26535 net.cpp:454] conv2_2 <- conv2_1
I0611 15:11:57.208330 26535 net.cpp:411] conv2_2 -> conv2_2
I0611 15:11:57.213125 26535 net.cpp:150] Setting up conv2_2
I0611 15:11:57.213157 26535 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 15:11:57.213161 26535 net.cpp:165] Memory required for data: 904800108
I0611 15:11:57.213182 26535 layer_factory.hpp:77] Creating layer relu2_2
I0611 15:11:57.213194 26535 net.cpp:106] Creating Layer relu2_2
I0611 15:11:57.213201 26535 net.cpp:454] relu2_2 <- conv2_2
I0611 15:11:57.213205 26535 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0611 15:11:57.213346 26535 net.cpp:150] Setting up relu2_2
I0611 15:11:57.213354 26535 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 15:11:57.213356 26535 net.cpp:165] Memory required for data: 981600108
I0611 15:11:57.213361 26535 layer_factory.hpp:77] Creating layer pool2
I0611 15:11:57.213369 26535 net.cpp:106] Creating Layer pool2
I0611 15:11:57.213373 26535 net.cpp:454] pool2 <- conv2_2
I0611 15:11:57.213380 26535 net.cpp:411] pool2 -> pool2
I0611 15:11:57.213438 26535 net.cpp:150] Setting up pool2
I0611 15:11:57.213444 26535 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0611 15:11:57.213446 26535 net.cpp:165] Memory required for data: 1000800108
I0611 15:11:57.213449 26535 layer_factory.hpp:77] Creating layer conv3_1
I0611 15:11:57.213459 26535 net.cpp:106] Creating Layer conv3_1
I0611 15:11:57.213462 26535 net.cpp:454] conv3_1 <- pool2
I0611 15:11:57.213467 26535 net.cpp:411] conv3_1 -> conv3_1
I0611 15:11:57.215628 26535 net.cpp:150] Setting up conv3_1
I0611 15:11:57.215638 26535 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 15:11:57.215641 26535 net.cpp:165] Memory required for data: 1039200108
I0611 15:11:57.215651 26535 layer_factory.hpp:77] Creating layer relu3_1
I0611 15:11:57.215658 26535 net.cpp:106] Creating Layer relu3_1
I0611 15:11:57.215663 26535 net.cpp:454] relu3_1 <- conv3_1
I0611 15:11:57.215667 26535 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0611 15:11:57.215806 26535 net.cpp:150] Setting up relu3_1
I0611 15:11:57.215813 26535 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 15:11:57.215816 26535 net.cpp:165] Memory required for data: 1077600108
I0611 15:11:57.215818 26535 layer_factory.hpp:77] Creating layer conv3_2
I0611 15:11:57.215838 26535 net.cpp:106] Creating Layer conv3_2
I0611 15:11:57.215842 26535 net.cpp:454] conv3_2 <- conv3_1
I0611 15:11:57.215847 26535 net.cpp:411] conv3_2 -> conv3_2
I0611 15:11:57.218062 26535 net.cpp:150] Setting up conv3_2
I0611 15:11:57.218073 26535 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 15:11:57.218076 26535 net.cpp:165] Memory required for data: 1116000108
I0611 15:11:57.218093 26535 layer_factory.hpp:77] Creating layer relu3_2
I0611 15:11:57.218101 26535 net.cpp:106] Creating Layer relu3_2
I0611 15:11:57.218106 26535 net.cpp:454] relu3_2 <- conv3_2
I0611 15:11:57.218109 26535 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0611 15:11:57.218235 26535 net.cpp:150] Setting up relu3_2
I0611 15:11:57.218240 26535 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 15:11:57.218243 26535 net.cpp:165] Memory required for data: 1154400108
I0611 15:11:57.218256 26535 layer_factory.hpp:77] Creating layer conv3_3
I0611 15:11:57.218264 26535 net.cpp:106] Creating Layer conv3_3
I0611 15:11:57.218267 26535 net.cpp:454] conv3_3 <- conv3_2
I0611 15:11:57.218272 26535 net.cpp:411] conv3_3 -> conv3_3
I0611 15:11:57.220244 26535 net.cpp:150] Setting up conv3_3
I0611 15:11:57.220263 26535 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 15:11:57.220266 26535 net.cpp:165] Memory required for data: 1192800108
I0611 15:11:57.220270 26535 layer_factory.hpp:77] Creating layer relu3_3
I0611 15:11:57.220285 26535 net.cpp:106] Creating Layer relu3_3
I0611 15:11:57.220289 26535 net.cpp:454] relu3_3 <- conv3_3
I0611 15:11:57.220293 26535 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0611 15:11:57.220423 26535 net.cpp:150] Setting up relu3_3
I0611 15:11:57.220429 26535 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 15:11:57.220443 26535 net.cpp:165] Memory required for data: 1231200108
I0611 15:11:57.220444 26535 layer_factory.hpp:77] Creating layer pool3
I0611 15:11:57.220449 26535 net.cpp:106] Creating Layer pool3
I0611 15:11:57.220453 26535 net.cpp:454] pool3 <- conv3_3
I0611 15:11:57.220468 26535 net.cpp:411] pool3 -> pool3
I0611 15:11:57.220510 26535 net.cpp:150] Setting up pool3
I0611 15:11:57.220513 26535 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0611 15:11:57.220515 26535 net.cpp:165] Memory required for data: 1240800108
I0611 15:11:57.220527 26535 layer_factory.hpp:77] Creating layer conv4_1
I0611 15:11:57.220532 26535 net.cpp:106] Creating Layer conv4_1
I0611 15:11:57.220546 26535 net.cpp:454] conv4_1 <- pool3
I0611 15:11:57.220551 26535 net.cpp:411] conv4_1 -> conv4_1
I0611 15:11:57.224205 26535 net.cpp:150] Setting up conv4_1
I0611 15:11:57.224236 26535 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 15:11:57.224238 26535 net.cpp:165] Memory required for data: 1260000108
I0611 15:11:57.224257 26535 layer_factory.hpp:77] Creating layer relu4_1
I0611 15:11:57.224265 26535 net.cpp:106] Creating Layer relu4_1
I0611 15:11:57.224270 26535 net.cpp:454] relu4_1 <- conv4_1
I0611 15:11:57.224275 26535 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0611 15:11:57.224412 26535 net.cpp:150] Setting up relu4_1
I0611 15:11:57.224418 26535 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 15:11:57.224431 26535 net.cpp:165] Memory required for data: 1279200108
I0611 15:11:57.224433 26535 layer_factory.hpp:77] Creating layer conv4_2
I0611 15:11:57.224449 26535 net.cpp:106] Creating Layer conv4_2
I0611 15:11:57.224452 26535 net.cpp:454] conv4_2 <- conv4_1
I0611 15:11:57.224457 26535 net.cpp:411] conv4_2 -> conv4_2
I0611 15:11:57.229663 26535 net.cpp:150] Setting up conv4_2
I0611 15:11:57.229689 26535 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 15:11:57.229693 26535 net.cpp:165] Memory required for data: 1298400108
I0611 15:11:57.229717 26535 layer_factory.hpp:77] Creating layer relu4_2
I0611 15:11:57.229732 26535 net.cpp:106] Creating Layer relu4_2
I0611 15:11:57.229739 26535 net.cpp:454] relu4_2 <- conv4_2
I0611 15:11:57.229771 26535 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0611 15:11:57.230355 26535 net.cpp:150] Setting up relu4_2
I0611 15:11:57.230363 26535 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 15:11:57.230376 26535 net.cpp:165] Memory required for data: 1317600108
I0611 15:11:57.230379 26535 layer_factory.hpp:77] Creating layer conv4_3
I0611 15:11:57.230387 26535 net.cpp:106] Creating Layer conv4_3
I0611 15:11:57.230391 26535 net.cpp:454] conv4_3 <- conv4_2
I0611 15:11:57.230408 26535 net.cpp:411] conv4_3 -> conv4_3
I0611 15:11:57.235198 26535 net.cpp:150] Setting up conv4_3
I0611 15:11:57.235237 26535 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 15:11:57.235241 26535 net.cpp:165] Memory required for data: 1336800108
I0611 15:11:57.235249 26535 layer_factory.hpp:77] Creating layer relu4_3
I0611 15:11:57.235260 26535 net.cpp:106] Creating Layer relu4_3
I0611 15:11:57.235265 26535 net.cpp:454] relu4_3 <- conv4_3
I0611 15:11:57.235271 26535 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0611 15:11:57.235417 26535 net.cpp:150] Setting up relu4_3
I0611 15:11:57.235425 26535 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 15:11:57.235427 26535 net.cpp:165] Memory required for data: 1356000108
I0611 15:11:57.235430 26535 layer_factory.hpp:77] Creating layer pool4
I0611 15:11:57.235435 26535 net.cpp:106] Creating Layer pool4
I0611 15:11:57.235438 26535 net.cpp:454] pool4 <- conv4_3
I0611 15:11:57.235442 26535 net.cpp:411] pool4 -> pool4
I0611 15:11:57.235496 26535 net.cpp:150] Setting up pool4
I0611 15:11:57.235502 26535 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:11:57.235513 26535 net.cpp:165] Memory required for data: 1360903020
I0611 15:11:57.235515 26535 layer_factory.hpp:77] Creating layer conv5_1
I0611 15:11:57.235522 26535 net.cpp:106] Creating Layer conv5_1
I0611 15:11:57.235527 26535 net.cpp:454] conv5_1 <- pool4
I0611 15:11:57.235532 26535 net.cpp:411] conv5_1 -> conv5_1
I0611 15:11:57.240458 26535 net.cpp:150] Setting up conv5_1
I0611 15:11:57.240478 26535 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:11:57.240480 26535 net.cpp:165] Memory required for data: 1365805932
I0611 15:11:57.240487 26535 layer_factory.hpp:77] Creating layer relu5_1
I0611 15:11:57.240497 26535 net.cpp:106] Creating Layer relu5_1
I0611 15:11:57.240504 26535 net.cpp:454] relu5_1 <- conv5_1
I0611 15:11:57.240520 26535 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0611 15:11:57.240675 26535 net.cpp:150] Setting up relu5_1
I0611 15:11:57.240682 26535 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:11:57.240684 26535 net.cpp:165] Memory required for data: 1370708844
I0611 15:11:57.240686 26535 layer_factory.hpp:77] Creating layer conv5_2
I0611 15:11:57.240694 26535 net.cpp:106] Creating Layer conv5_2
I0611 15:11:57.240696 26535 net.cpp:454] conv5_2 <- conv5_1
I0611 15:11:57.240710 26535 net.cpp:411] conv5_2 -> conv5_2
I0611 15:11:57.245306 26535 net.cpp:150] Setting up conv5_2
I0611 15:11:57.245334 26535 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:11:57.245337 26535 net.cpp:165] Memory required for data: 1375611756
I0611 15:11:57.245345 26535 layer_factory.hpp:77] Creating layer relu5_2
I0611 15:11:57.245365 26535 net.cpp:106] Creating Layer relu5_2
I0611 15:11:57.245369 26535 net.cpp:454] relu5_2 <- conv5_2
I0611 15:11:57.245376 26535 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0611 15:11:57.245548 26535 net.cpp:150] Setting up relu5_2
I0611 15:11:57.245556 26535 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:11:57.245569 26535 net.cpp:165] Memory required for data: 1380514668
I0611 15:11:57.245571 26535 layer_factory.hpp:77] Creating layer conv5_3
I0611 15:11:57.245596 26535 net.cpp:106] Creating Layer conv5_3
I0611 15:11:57.245600 26535 net.cpp:454] conv5_3 <- conv5_2
I0611 15:11:57.245616 26535 net.cpp:411] conv5_3 -> conv5_3
I0611 15:11:57.250391 26535 net.cpp:150] Setting up conv5_3
I0611 15:11:57.250412 26535 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:11:57.250416 26535 net.cpp:165] Memory required for data: 1385417580
I0611 15:11:57.250434 26535 layer_factory.hpp:77] Creating layer relu5_3
I0611 15:11:57.250444 26535 net.cpp:106] Creating Layer relu5_3
I0611 15:11:57.250449 26535 net.cpp:454] relu5_3 <- conv5_3
I0611 15:11:57.250454 26535 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0611 15:11:57.250602 26535 net.cpp:150] Setting up relu5_3
I0611 15:11:57.250608 26535 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:11:57.250620 26535 net.cpp:165] Memory required for data: 1390320492
I0611 15:11:57.250623 26535 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0611 15:11:57.250638 26535 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0611 15:11:57.250643 26535 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0611 15:11:57.250648 26535 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0611 15:11:57.250653 26535 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0611 15:11:57.250658 26535 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0611 15:11:57.250725 26535 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0611 15:11:57.250730 26535 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:11:57.250742 26535 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:11:57.250746 26535 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:11:57.250748 26535 net.cpp:165] Memory required for data: 1405029228
I0611 15:11:57.250752 26535 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0611 15:11:57.250777 26535 net.cpp:106] Creating Layer rpn_conv/3x3
I0611 15:11:57.250782 26535 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0611 15:11:57.250795 26535 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0611 15:11:57.302536 26535 net.cpp:150] Setting up rpn_conv/3x3
I0611 15:11:57.302553 26535 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:11:57.302556 26535 net.cpp:165] Memory required for data: 1409932140
I0611 15:11:57.302563 26535 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0611 15:11:57.302573 26535 net.cpp:106] Creating Layer rpn_relu/3x3
I0611 15:11:57.302590 26535 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0611 15:11:57.302599 26535 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0611 15:11:57.302736 26535 net.cpp:150] Setting up rpn_relu/3x3
I0611 15:11:57.302743 26535 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:11:57.302745 26535 net.cpp:165] Memory required for data: 1414835052
I0611 15:11:57.302748 26535 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0611 15:11:57.302753 26535 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0611 15:11:57.302757 26535 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0611 15:11:57.302773 26535 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0611 15:11:57.302783 26535 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0611 15:11:57.302820 26535 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0611 15:11:57.302825 26535 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:11:57.302839 26535 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:11:57.302845 26535 net.cpp:165] Memory required for data: 1424640876
I0611 15:11:57.302857 26535 layer_factory.hpp:77] Creating layer rpn_cls_score
I0611 15:11:57.302870 26535 net.cpp:106] Creating Layer rpn_cls_score
I0611 15:11:57.302875 26535 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0611 15:11:57.302882 26535 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0611 15:11:57.304512 26535 net.cpp:150] Setting up rpn_cls_score
I0611 15:11:57.304520 26535 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 15:11:57.304525 26535 net.cpp:165] Memory required for data: 1424928156
I0611 15:11:57.304544 26535 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0611 15:11:57.304553 26535 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0611 15:11:57.304558 26535 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0611 15:11:57.304561 26535 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0611 15:11:57.304567 26535 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0611 15:11:57.304597 26535 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0611 15:11:57.304602 26535 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 15:11:57.304605 26535 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 15:11:57.304607 26535 net.cpp:165] Memory required for data: 1425502716
I0611 15:11:57.304610 26535 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0611 15:11:57.304616 26535 net.cpp:106] Creating Layer rpn_bbox_pred
I0611 15:11:57.304620 26535 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0611 15:11:57.304625 26535 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0611 15:11:57.306134 26535 net.cpp:150] Setting up rpn_bbox_pred
I0611 15:11:57.306143 26535 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 15:11:57.306145 26535 net.cpp:165] Memory required for data: 1426077276
I0611 15:11:57.306162 26535 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 15:11:57.306167 26535 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 15:11:57.306169 26535 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0611 15:11:57.306174 26535 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0611 15:11:57.306181 26535 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0611 15:11:57.306217 26535 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 15:11:57.306222 26535 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 15:11:57.306226 26535 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 15:11:57.306229 26535 net.cpp:165] Memory required for data: 1427226396
I0611 15:11:57.306232 26535 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0611 15:11:57.306241 26535 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0611 15:11:57.306243 26535 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0611 15:11:57.306247 26535 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0611 15:11:57.306267 26535 net.cpp:150] Setting up rpn_cls_score_reshape
I0611 15:11:57.306272 26535 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 15:11:57.306274 26535 net.cpp:165] Memory required for data: 1427513676
I0611 15:11:57.306277 26535 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 15:11:57.306282 26535 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 15:11:57.306283 26535 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0611 15:11:57.306288 26535 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0611 15:11:57.306293 26535 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0611 15:11:57.306314 26535 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 15:11:57.306318 26535 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 15:11:57.306321 26535 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 15:11:57.306324 26535 net.cpp:165] Memory required for data: 1428088236
I0611 15:11:57.306326 26535 layer_factory.hpp:77] Creating layer rpn-data
I0611 15:11:57.306654 26535 net.cpp:106] Creating Layer rpn-data
I0611 15:11:57.306661 26535 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0611 15:11:57.306670 26535 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0611 15:11:57.306676 26535 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0611 15:11:57.306680 26535 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0611 15:11:57.306685 26535 net.cpp:411] rpn-data -> rpn_labels
I0611 15:11:57.306691 26535 net.cpp:411] rpn-data -> rpn_bbox_targets
I0611 15:11:57.306697 26535 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0611 15:11:57.306702 26535 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0611 15:11:57.307523 26535 net.cpp:150] Setting up rpn-data
I0611 15:11:57.307530 26535 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0611 15:11:57.307534 26535 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 15:11:57.307536 26535 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 15:11:57.307539 26535 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 15:11:57.307543 26535 net.cpp:165] Memory required for data: 1429955556
I0611 15:11:57.307545 26535 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0611 15:11:57.307551 26535 net.cpp:106] Creating Layer rpn_loss_cls
I0611 15:11:57.307556 26535 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0611 15:11:57.307560 26535 net.cpp:454] rpn_loss_cls <- rpn_labels
I0611 15:11:57.307564 26535 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0611 15:11:57.307570 26535 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0611 15:11:57.308179 26535 net.cpp:150] Setting up rpn_loss_cls
I0611 15:11:57.308187 26535 net.cpp:157] Top shape: (1)
I0611 15:11:57.308199 26535 net.cpp:160]     with loss weight 1
I0611 15:11:57.308207 26535 net.cpp:165] Memory required for data: 1429955560
I0611 15:11:57.308210 26535 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0611 15:11:57.308218 26535 net.cpp:106] Creating Layer rpn_loss_bbox
I0611 15:11:57.308221 26535 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0611 15:11:57.308225 26535 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0611 15:11:57.308228 26535 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0611 15:11:57.308231 26535 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0611 15:11:57.308234 26535 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0611 15:11:57.309305 26535 net.cpp:150] Setting up rpn_loss_bbox
I0611 15:11:57.309312 26535 net.cpp:157] Top shape: (1)
I0611 15:11:57.309324 26535 net.cpp:160]     with loss weight 1
I0611 15:11:57.309329 26535 net.cpp:165] Memory required for data: 1429955564
I0611 15:11:57.309332 26535 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0611 15:11:57.309337 26535 net.cpp:106] Creating Layer rpn_cls_prob
I0611 15:11:57.309341 26535 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0611 15:11:57.309345 26535 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0611 15:11:57.309509 26535 net.cpp:150] Setting up rpn_cls_prob
I0611 15:11:57.309516 26535 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 15:11:57.309520 26535 net.cpp:165] Memory required for data: 1430242844
I0611 15:11:57.309522 26535 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0611 15:11:57.309528 26535 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0611 15:11:57.309532 26535 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0611 15:11:57.309536 26535 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0611 15:11:57.309556 26535 net.cpp:150] Setting up rpn_cls_prob_reshape
I0611 15:11:57.309561 26535 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 15:11:57.309562 26535 net.cpp:165] Memory required for data: 1430530124
I0611 15:11:57.309566 26535 layer_factory.hpp:77] Creating layer proposal
I0611 15:11:57.310081 26535 net.cpp:106] Creating Layer proposal
I0611 15:11:57.310098 26535 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0611 15:11:57.310102 26535 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0611 15:11:57.310106 26535 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0611 15:11:57.310111 26535 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0611 15:11:57.311112 26535 net.cpp:150] Setting up proposal
I0611 15:11:57.311131 26535 net.cpp:157] Top shape: 1 5 (5)
I0611 15:11:57.311143 26535 net.cpp:165] Memory required for data: 1430530144
I0611 15:11:57.311146 26535 layer_factory.hpp:77] Creating layer roi-data
I0611 15:11:57.311398 26535 net.cpp:106] Creating Layer roi-data
I0611 15:11:57.311405 26535 net.cpp:454] roi-data <- rpn_rois
I0611 15:11:57.311410 26535 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0611 15:11:57.311414 26535 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0611 15:11:57.311416 26535 net.cpp:454] roi-data <- seg_mask_inds
I0611 15:11:57.311419 26535 net.cpp:454] roi-data <- flipped
I0611 15:11:57.311424 26535 net.cpp:411] roi-data -> rois
I0611 15:11:57.311430 26535 net.cpp:411] roi-data -> labels
I0611 15:11:57.311435 26535 net.cpp:411] roi-data -> bbox_targets
I0611 15:11:57.311439 26535 net.cpp:411] roi-data -> bbox_inside_weights
I0611 15:11:57.311444 26535 net.cpp:411] roi-data -> bbox_outside_weights
I0611 15:11:57.311448 26535 net.cpp:411] roi-data -> mask_targets
I0611 15:11:57.311453 26535 net.cpp:411] roi-data -> rois_pos
I0611 15:11:57.311457 26535 net.cpp:411] roi-data -> attrArray
I0611 15:11:57.311754 26535 net.cpp:150] Setting up roi-data
I0611 15:11:57.311763 26535 net.cpp:157] Top shape: 1 5 (5)
I0611 15:11:57.311765 26535 net.cpp:157] Top shape: 1 1 (1)
I0611 15:11:57.311769 26535 net.cpp:157] Top shape: 1 8 (8)
I0611 15:11:57.311771 26535 net.cpp:157] Top shape: 1 8 (8)
I0611 15:11:57.311775 26535 net.cpp:157] Top shape: 1 8 (8)
I0611 15:11:57.311781 26535 net.cpp:157] Top shape: 1 244 244 (59536)
I0611 15:11:57.311784 26535 net.cpp:157] Top shape: 1 5 (5)
I0611 15:11:57.311789 26535 net.cpp:157] Top shape: 1 7 (7)
I0611 15:11:57.311794 26535 net.cpp:165] Memory required for data: 1430768456
I0611 15:11:57.311797 26535 layer_factory.hpp:77] Creating layer roi_pool5
I0611 15:11:57.311806 26535 net.cpp:106] Creating Layer roi_pool5
I0611 15:11:57.311810 26535 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0611 15:11:57.311815 26535 net.cpp:454] roi_pool5 <- rois
I0611 15:11:57.311821 26535 net.cpp:411] roi_pool5 -> pool5
I0611 15:11:57.311830 26535 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0611 15:11:57.311899 26535 net.cpp:150] Setting up roi_pool5
I0611 15:11:57.311904 26535 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 15:11:57.311908 26535 net.cpp:165] Memory required for data: 1430868808
I0611 15:11:57.311913 26535 layer_factory.hpp:77] Creating layer fc6
I0611 15:11:57.311919 26535 net.cpp:106] Creating Layer fc6
I0611 15:11:57.311923 26535 net.cpp:454] fc6 <- pool5
I0611 15:11:57.311928 26535 net.cpp:411] fc6 -> fc6
I0611 15:11:57.465312 26535 net.cpp:150] Setting up fc6
I0611 15:11:57.465343 26535 net.cpp:157] Top shape: 1 4096 (4096)
I0611 15:11:57.465346 26535 net.cpp:165] Memory required for data: 1430885192
I0611 15:11:57.465375 26535 layer_factory.hpp:77] Creating layer relu6
I0611 15:11:57.465387 26535 net.cpp:106] Creating Layer relu6
I0611 15:11:57.465392 26535 net.cpp:454] relu6 <- fc6
I0611 15:11:57.465399 26535 net.cpp:397] relu6 -> fc6 (in-place)
I0611 15:11:57.465710 26535 net.cpp:150] Setting up relu6
I0611 15:11:57.465718 26535 net.cpp:157] Top shape: 1 4096 (4096)
I0611 15:11:57.465731 26535 net.cpp:165] Memory required for data: 1430901576
I0611 15:11:57.465735 26535 layer_factory.hpp:77] Creating layer fc7
I0611 15:11:57.465745 26535 net.cpp:106] Creating Layer fc7
I0611 15:11:57.465751 26535 net.cpp:454] fc7 <- fc6
I0611 15:11:57.465759 26535 net.cpp:411] fc7 -> fc7
I0611 15:11:57.491322 26535 net.cpp:150] Setting up fc7
I0611 15:11:57.491365 26535 net.cpp:157] Top shape: 1 4096 (4096)
I0611 15:11:57.491369 26535 net.cpp:165] Memory required for data: 1430917960
I0611 15:11:57.491380 26535 layer_factory.hpp:77] Creating layer relu7
I0611 15:11:57.491394 26535 net.cpp:106] Creating Layer relu7
I0611 15:11:57.491402 26535 net.cpp:454] relu7 <- fc7
I0611 15:11:57.491407 26535 net.cpp:397] relu7 -> fc7 (in-place)
I0611 15:11:57.491644 26535 net.cpp:150] Setting up relu7
I0611 15:11:57.491653 26535 net.cpp:157] Top shape: 1 4096 (4096)
I0611 15:11:57.491665 26535 net.cpp:165] Memory required for data: 1430934344
I0611 15:11:57.491669 26535 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0611 15:11:57.491686 26535 net.cpp:106] Creating Layer fc7_relu7_0_split
I0611 15:11:57.491691 26535 net.cpp:454] fc7_relu7_0_split <- fc7
I0611 15:11:57.491711 26535 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0611 15:11:57.491727 26535 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0611 15:11:57.491735 26535 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0611 15:11:57.491808 26535 net.cpp:150] Setting up fc7_relu7_0_split
I0611 15:11:57.491814 26535 net.cpp:157] Top shape: 1 4096 (4096)
I0611 15:11:57.491827 26535 net.cpp:157] Top shape: 1 4096 (4096)
I0611 15:11:57.491829 26535 net.cpp:157] Top shape: 1 4096 (4096)
I0611 15:11:57.491832 26535 net.cpp:165] Memory required for data: 1430983496
I0611 15:11:57.491837 26535 layer_factory.hpp:77] Creating layer attr_score
I0611 15:11:57.491863 26535 net.cpp:106] Creating Layer attr_score
I0611 15:11:57.491866 26535 net.cpp:454] attr_score <- fc7_relu7_0_split_0
I0611 15:11:57.491873 26535 net.cpp:411] attr_score -> attr_score
I0611 15:11:57.492566 26535 net.cpp:150] Setting up attr_score
I0611 15:11:57.492573 26535 net.cpp:157] Top shape: 1 7 (7)
I0611 15:11:57.492578 26535 net.cpp:165] Memory required for data: 1430983524
I0611 15:11:57.492595 26535 layer_factory.hpp:77] Creating layer cls_score
I0611 15:11:57.492614 26535 net.cpp:106] Creating Layer cls_score
I0611 15:11:57.492619 26535 net.cpp:454] cls_score <- fc7_relu7_0_split_1
I0611 15:11:57.492628 26535 net.cpp:411] cls_score -> cls_score
I0611 15:11:57.492882 26535 net.cpp:150] Setting up cls_score
I0611 15:11:57.492888 26535 net.cpp:157] Top shape: 1 2 (2)
I0611 15:11:57.492892 26535 net.cpp:165] Memory required for data: 1430983532
I0611 15:11:57.492911 26535 layer_factory.hpp:77] Creating layer bbox_pred
I0611 15:11:57.492918 26535 net.cpp:106] Creating Layer bbox_pred
I0611 15:11:57.492923 26535 net.cpp:454] bbox_pred <- fc7_relu7_0_split_2
I0611 15:11:57.492929 26535 net.cpp:411] bbox_pred -> bbox_pred
I0611 15:11:57.493665 26535 net.cpp:150] Setting up bbox_pred
I0611 15:11:57.493670 26535 net.cpp:157] Top shape: 1 8 (8)
I0611 15:11:57.493674 26535 net.cpp:165] Memory required for data: 1430983564
I0611 15:11:57.493690 26535 layer_factory.hpp:77] Creating layer loss_attribute
I0611 15:11:57.493700 26535 net.cpp:106] Creating Layer loss_attribute
I0611 15:11:57.493702 26535 net.cpp:454] loss_attribute <- attr_score
I0611 15:11:57.493705 26535 net.cpp:454] loss_attribute <- attrArray
I0611 15:11:57.493712 26535 net.cpp:411] loss_attribute -> loss_attribute
I0611 15:11:57.493762 26535 net.cpp:150] Setting up loss_attribute
I0611 15:11:57.493767 26535 net.cpp:157] Top shape: (1)
I0611 15:11:57.493772 26535 net.cpp:160]     with loss weight 1
I0611 15:11:57.493793 26535 net.cpp:165] Memory required for data: 1430983568
I0611 15:11:57.493795 26535 layer_factory.hpp:77] Creating layer loss_cls
I0611 15:11:57.493800 26535 net.cpp:106] Creating Layer loss_cls
I0611 15:11:57.493803 26535 net.cpp:454] loss_cls <- cls_score
I0611 15:11:57.493805 26535 net.cpp:454] loss_cls <- labels
I0611 15:11:57.493809 26535 net.cpp:411] loss_cls -> loss_cls
I0611 15:11:57.493814 26535 layer_factory.hpp:77] Creating layer loss_cls
I0611 15:11:57.494905 26535 net.cpp:150] Setting up loss_cls
I0611 15:11:57.494925 26535 net.cpp:157] Top shape: (1)
I0611 15:11:57.494937 26535 net.cpp:160]     with loss weight 3
I0611 15:11:57.494942 26535 net.cpp:165] Memory required for data: 1430983572
I0611 15:11:57.494946 26535 layer_factory.hpp:77] Creating layer loss_bbox
I0611 15:11:57.494952 26535 net.cpp:106] Creating Layer loss_bbox
I0611 15:11:57.494956 26535 net.cpp:454] loss_bbox <- bbox_pred
I0611 15:11:57.494958 26535 net.cpp:454] loss_bbox <- bbox_targets
I0611 15:11:57.494961 26535 net.cpp:454] loss_bbox <- bbox_inside_weights
I0611 15:11:57.494964 26535 net.cpp:454] loss_bbox <- bbox_outside_weights
I0611 15:11:57.494969 26535 net.cpp:411] loss_bbox -> loss_bbox
I0611 15:11:57.495048 26535 net.cpp:150] Setting up loss_bbox
I0611 15:11:57.495054 26535 net.cpp:157] Top shape: (1)
I0611 15:11:57.495055 26535 net.cpp:160]     with loss weight 2
I0611 15:11:57.495070 26535 net.cpp:165] Memory required for data: 1430983576
I0611 15:11:57.495074 26535 layer_factory.hpp:77] Creating layer roi_pool5_2
I0611 15:11:57.495079 26535 net.cpp:106] Creating Layer roi_pool5_2
I0611 15:11:57.495085 26535 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0611 15:11:57.495090 26535 net.cpp:454] roi_pool5_2 <- rois_pos
I0611 15:11:57.495095 26535 net.cpp:411] roi_pool5_2 -> pool5_2
I0611 15:11:57.495100 26535 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0611 15:11:57.495179 26535 net.cpp:150] Setting up roi_pool5_2
I0611 15:11:57.495185 26535 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 15:11:57.495188 26535 net.cpp:165] Memory required for data: 1431083928
I0611 15:11:57.495191 26535 layer_factory.hpp:77] Creating layer pool5_2_conv
I0611 15:11:57.495205 26535 net.cpp:106] Creating Layer pool5_2_conv
I0611 15:11:57.495208 26535 net.cpp:454] pool5_2_conv <- pool5_2
I0611 15:11:57.495213 26535 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0611 15:11:57.502542 26535 net.cpp:150] Setting up pool5_2_conv
I0611 15:11:57.502568 26535 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 15:11:57.502569 26535 net.cpp:165] Memory required for data: 1431184280
I0611 15:11:57.502579 26535 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0611 15:11:57.502588 26535 net.cpp:106] Creating Layer pool5_2_conv_relu
I0611 15:11:57.502593 26535 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0611 15:11:57.502598 26535 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0611 15:11:57.502748 26535 net.cpp:150] Setting up pool5_2_conv_relu
I0611 15:11:57.502755 26535 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 15:11:57.502758 26535 net.cpp:165] Memory required for data: 1431284632
I0611 15:11:57.502760 26535 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0611 15:11:57.502768 26535 net.cpp:106] Creating Layer pool5_2_conv2
I0611 15:11:57.502782 26535 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0611 15:11:57.502787 26535 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0611 15:11:57.555858 26535 net.cpp:150] Setting up pool5_2_conv2
I0611 15:11:57.555876 26535 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 15:11:57.555878 26535 net.cpp:165] Memory required for data: 1431384984
I0611 15:11:57.555897 26535 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0611 15:11:57.555919 26535 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0611 15:11:57.555925 26535 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0611 15:11:57.555939 26535 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0611 15:11:57.556113 26535 net.cpp:150] Setting up pool5_2_conv2_relu
I0611 15:11:57.556120 26535 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 15:11:57.556123 26535 net.cpp:165] Memory required for data: 1431485336
I0611 15:11:57.556138 26535 layer_factory.hpp:77] Creating layer mask_deconv1
I0611 15:11:57.556146 26535 net.cpp:106] Creating Layer mask_deconv1
I0611 15:11:57.556162 26535 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0611 15:11:57.556177 26535 net.cpp:411] mask_deconv1 -> mask_deconv1
I0611 15:11:57.556957 26535 net.cpp:150] Setting up mask_deconv1
I0611 15:11:57.556963 26535 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0611 15:11:57.556965 26535 net.cpp:165] Memory required for data: 1432406936
I0611 15:11:57.556969 26535 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0611 15:11:57.556987 26535 net.cpp:106] Creating Layer pool5_2_conv3
I0611 15:11:57.556990 26535 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0611 15:11:57.556995 26535 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0611 15:11:57.584882 26535 net.cpp:150] Setting up pool5_2_conv3
I0611 15:11:57.584902 26535 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:11:57.584905 26535 net.cpp:165] Memory required for data: 1434250136
I0611 15:11:57.584913 26535 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0611 15:11:57.584921 26535 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0611 15:11:57.584928 26535 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0611 15:11:57.584933 26535 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0611 15:11:57.585084 26535 net.cpp:150] Setting up pool5_2_conv3_relu
I0611 15:11:57.585091 26535 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:11:57.585094 26535 net.cpp:165] Memory required for data: 1436093336
I0611 15:11:57.585098 26535 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0611 15:11:57.585106 26535 net.cpp:106] Creating Layer pool5_2_conv4
I0611 15:11:57.585109 26535 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0611 15:11:57.585114 26535 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0611 15:11:57.638072 26535 net.cpp:150] Setting up pool5_2_conv4
I0611 15:11:57.638092 26535 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:11:57.638094 26535 net.cpp:165] Memory required for data: 1437936536
I0611 15:11:57.638103 26535 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0611 15:11:57.638110 26535 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0611 15:11:57.638118 26535 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0611 15:11:57.638123 26535 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0611 15:11:57.638260 26535 net.cpp:150] Setting up pool5_2_conv4_relu
I0611 15:11:57.638267 26535 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:11:57.638270 26535 net.cpp:165] Memory required for data: 1439779736
I0611 15:11:57.638273 26535 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 15:11:57.638278 26535 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 15:11:57.638283 26535 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0611 15:11:57.638288 26535 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0611 15:11:57.638304 26535 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0611 15:11:57.638309 26535 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0611 15:11:57.638314 26535 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0611 15:11:57.638366 26535 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 15:11:57.638371 26535 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:11:57.638375 26535 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:11:57.638377 26535 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:11:57.638381 26535 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:11:57.638383 26535 net.cpp:165] Memory required for data: 1447152536
I0611 15:11:57.638386 26535 layer_factory.hpp:77] Creating layer query_conv
I0611 15:11:57.638406 26535 net.cpp:106] Creating Layer query_conv
I0611 15:11:57.638408 26535 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0611 15:11:57.638412 26535 net.cpp:411] query_conv -> query_conv
I0611 15:11:57.640094 26535 net.cpp:150] Setting up query_conv
I0611 15:11:57.640103 26535 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0611 15:11:57.640106 26535 net.cpp:165] Memory required for data: 1447382936
I0611 15:11:57.640112 26535 layer_factory.hpp:77] Creating layer key_conv
I0611 15:11:57.640122 26535 net.cpp:106] Creating Layer key_conv
I0611 15:11:57.640126 26535 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0611 15:11:57.640131 26535 net.cpp:411] key_conv -> key_conv
I0611 15:11:57.641783 26535 net.cpp:150] Setting up key_conv
I0611 15:11:57.641791 26535 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0611 15:11:57.641804 26535 net.cpp:165] Memory required for data: 1447613336
I0611 15:11:57.641808 26535 layer_factory.hpp:77] Creating layer value_conv
I0611 15:11:57.641827 26535 net.cpp:106] Creating Layer value_conv
I0611 15:11:57.641831 26535 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0611 15:11:57.641836 26535 net.cpp:411] value_conv -> value_conv
I0611 15:11:57.652573 26535 net.cpp:150] Setting up value_conv
I0611 15:11:57.652593 26535 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:11:57.652597 26535 net.cpp:165] Memory required for data: 1449456536
I0611 15:11:57.652606 26535 layer_factory.hpp:77] Creating layer query_conv_reshape
I0611 15:11:57.652616 26535 net.cpp:106] Creating Layer query_conv_reshape
I0611 15:11:57.652621 26535 net.cpp:454] query_conv_reshape <- query_conv
I0611 15:11:57.652627 26535 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0611 15:11:57.652659 26535 net.cpp:150] Setting up query_conv_reshape
I0611 15:11:57.652665 26535 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0611 15:11:57.652667 26535 net.cpp:165] Memory required for data: 1449686936
I0611 15:11:57.652670 26535 layer_factory.hpp:77] Creating layer key_conv_reshape
I0611 15:11:57.652676 26535 net.cpp:106] Creating Layer key_conv_reshape
I0611 15:11:57.652679 26535 net.cpp:454] key_conv_reshape <- key_conv
I0611 15:11:57.652684 26535 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0611 15:11:57.652709 26535 net.cpp:150] Setting up key_conv_reshape
I0611 15:11:57.652714 26535 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0611 15:11:57.652716 26535 net.cpp:165] Memory required for data: 1449917336
I0611 15:11:57.652719 26535 layer_factory.hpp:77] Creating layer value_conv_reshape
I0611 15:11:57.652724 26535 net.cpp:106] Creating Layer value_conv_reshape
I0611 15:11:57.652726 26535 net.cpp:454] value_conv_reshape <- value_conv
I0611 15:11:57.652731 26535 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0611 15:11:57.652751 26535 net.cpp:150] Setting up value_conv_reshape
I0611 15:11:57.652756 26535 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0611 15:11:57.652758 26535 net.cpp:165] Memory required for data: 1451760536
I0611 15:11:57.652760 26535 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0611 15:11:57.652771 26535 net.cpp:106] Creating Layer query_conv_reshape_perm
I0611 15:11:57.652777 26535 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0611 15:11:57.652781 26535 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0611 15:11:57.652863 26535 net.cpp:150] Setting up query_conv_reshape_perm
I0611 15:11:57.652868 26535 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0611 15:11:57.652870 26535 net.cpp:165] Memory required for data: 1451990936
I0611 15:11:57.652873 26535 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0611 15:11:57.652876 26535 net.cpp:106] Creating Layer key_conv_reshape_perm
I0611 15:11:57.652880 26535 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0611 15:11:57.652884 26535 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0611 15:11:57.652956 26535 net.cpp:150] Setting up key_conv_reshape_perm
I0611 15:11:57.652961 26535 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0611 15:11:57.652963 26535 net.cpp:165] Memory required for data: 1452221336
I0611 15:11:57.652966 26535 layer_factory.hpp:77] Creating layer energy
I0611 15:11:57.652969 26535 net.cpp:106] Creating Layer energy
I0611 15:11:57.652973 26535 net.cpp:454] energy <- query_conv_reshape_perm
I0611 15:11:57.652978 26535 net.cpp:454] energy <- key_conv_reshape_perm
I0611 15:11:57.652983 26535 net.cpp:411] energy -> energy
I0611 15:11:57.653002 26535 net.cpp:150] Setting up energy
I0611 15:11:57.653008 26535 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 15:11:57.653010 26535 net.cpp:165] Memory required for data: 1455461336
I0611 15:11:57.653012 26535 layer_factory.hpp:77] Creating layer attention
I0611 15:11:57.653018 26535 net.cpp:106] Creating Layer attention
I0611 15:11:57.653021 26535 net.cpp:454] attention <- energy
I0611 15:11:57.653026 26535 net.cpp:411] attention -> attention
I0611 15:11:57.653219 26535 net.cpp:150] Setting up attention
I0611 15:11:57.653228 26535 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 15:11:57.653229 26535 net.cpp:165] Memory required for data: 1458701336
I0611 15:11:57.653235 26535 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0611 15:11:57.653241 26535 net.cpp:106] Creating Layer value_conv_reshape_perm
I0611 15:11:57.653245 26535 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0611 15:11:57.653250 26535 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0611 15:11:57.653322 26535 net.cpp:150] Setting up value_conv_reshape_perm
I0611 15:11:57.653327 26535 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0611 15:11:57.653329 26535 net.cpp:165] Memory required for data: 1460544536
I0611 15:11:57.653332 26535 layer_factory.hpp:77] Creating layer attention_perm
I0611 15:11:57.653337 26535 net.cpp:106] Creating Layer attention_perm
I0611 15:11:57.653340 26535 net.cpp:454] attention_perm <- attention
I0611 15:11:57.653345 26535 net.cpp:411] attention_perm -> attention_perm
I0611 15:11:57.653434 26535 net.cpp:150] Setting up attention_perm
I0611 15:11:57.653439 26535 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 15:11:57.653442 26535 net.cpp:165] Memory required for data: 1463784536
I0611 15:11:57.653445 26535 layer_factory.hpp:77] Creating layer out
I0611 15:11:57.653450 26535 net.cpp:106] Creating Layer out
I0611 15:11:57.653451 26535 net.cpp:454] out <- value_conv_reshape_perm
I0611 15:11:57.653457 26535 net.cpp:454] out <- attention_perm
I0611 15:11:57.653461 26535 net.cpp:411] out -> out
I0611 15:11:57.653481 26535 net.cpp:150] Setting up out
I0611 15:11:57.653493 26535 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0611 15:11:57.653496 26535 net.cpp:165] Memory required for data: 1465627736
I0611 15:11:57.653497 26535 layer_factory.hpp:77] Creating layer out_reshape
I0611 15:11:57.653514 26535 net.cpp:106] Creating Layer out_reshape
I0611 15:11:57.653517 26535 net.cpp:454] out_reshape <- out
I0611 15:11:57.653529 26535 net.cpp:411] out_reshape -> out_reshape
I0611 15:11:57.653555 26535 net.cpp:150] Setting up out_reshape
I0611 15:11:57.653559 26535 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:11:57.653570 26535 net.cpp:165] Memory required for data: 1467470936
I0611 15:11:57.653573 26535 layer_factory.hpp:77] Creating layer out_reshape_scale
I0611 15:11:57.653590 26535 net.cpp:106] Creating Layer out_reshape_scale
I0611 15:11:57.653594 26535 net.cpp:454] out_reshape_scale <- out_reshape
I0611 15:11:57.653597 26535 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0611 15:11:57.653681 26535 net.cpp:150] Setting up out_reshape_scale
I0611 15:11:57.653686 26535 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:11:57.653697 26535 net.cpp:165] Memory required for data: 1469314136
I0611 15:11:57.653700 26535 layer_factory.hpp:77] Creating layer out_x
I0611 15:11:57.653704 26535 net.cpp:106] Creating Layer out_x
I0611 15:11:57.653707 26535 net.cpp:454] out_x <- out_reshape_scale
I0611 15:11:57.653710 26535 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0611 15:11:57.653725 26535 net.cpp:411] out_x -> out_x
I0611 15:11:57.653744 26535 net.cpp:150] Setting up out_x
I0611 15:11:57.653757 26535 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:11:57.653759 26535 net.cpp:165] Memory required for data: 1471157336
I0611 15:11:57.653761 26535 layer_factory.hpp:77] Creating layer mask_deconv2
I0611 15:11:57.653777 26535 net.cpp:106] Creating Layer mask_deconv2
I0611 15:11:57.653780 26535 net.cpp:454] mask_deconv2 <- out_x
I0611 15:11:57.653786 26535 net.cpp:411] mask_deconv2 -> mask_deconv2
I0611 15:11:57.654573 26535 net.cpp:150] Setting up mask_deconv2
I0611 15:11:57.654578 26535 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0611 15:11:57.654590 26535 net.cpp:165] Memory required for data: 1486398552
I0611 15:11:57.654594 26535 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0611 15:11:57.654611 26535 net.cpp:106] Creating Layer pool5_2_conv5
I0611 15:11:57.654614 26535 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0611 15:11:57.654618 26535 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0611 15:11:57.682695 26535 net.cpp:150] Setting up pool5_2_conv5
I0611 15:11:57.682713 26535 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 15:11:57.682716 26535 net.cpp:165] Memory required for data: 1516880984
I0611 15:11:57.682724 26535 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0611 15:11:57.682732 26535 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0611 15:11:57.682747 26535 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0611 15:11:57.682754 26535 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0611 15:11:57.682929 26535 net.cpp:150] Setting up pool5_2_conv5_relu
I0611 15:11:57.682937 26535 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 15:11:57.682940 26535 net.cpp:165] Memory required for data: 1547363416
I0611 15:11:57.682941 26535 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0611 15:11:57.682950 26535 net.cpp:106] Creating Layer pool5_2_conv6
I0611 15:11:57.682953 26535 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0611 15:11:57.682968 26535 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0611 15:11:57.735857 26535 net.cpp:150] Setting up pool5_2_conv6
I0611 15:11:57.735875 26535 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 15:11:57.735877 26535 net.cpp:165] Memory required for data: 1577845848
I0611 15:11:57.735894 26535 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0611 15:11:57.735903 26535 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0611 15:11:57.735919 26535 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0611 15:11:57.735924 26535 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0611 15:11:57.736589 26535 net.cpp:150] Setting up pool5_2_conv6_relu
I0611 15:11:57.736603 26535 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 15:11:57.736608 26535 net.cpp:165] Memory required for data: 1608328280
I0611 15:11:57.736611 26535 layer_factory.hpp:77] Creating layer mask_deconv3
I0611 15:11:57.736632 26535 net.cpp:106] Creating Layer mask_deconv3
I0611 15:11:57.736649 26535 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0611 15:11:57.736655 26535 net.cpp:411] mask_deconv3 -> mask_deconv3
I0611 15:11:57.737089 26535 net.cpp:150] Setting up mask_deconv3
I0611 15:11:57.737097 26535 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0611 15:11:57.737098 26535 net.cpp:165] Memory required for data: 1669293144
I0611 15:11:57.737103 26535 layer_factory.hpp:77] Creating layer mask_score
I0611 15:11:57.737123 26535 net.cpp:106] Creating Layer mask_score
I0611 15:11:57.737126 26535 net.cpp:454] mask_score <- mask_deconv3
I0611 15:11:57.737141 26535 net.cpp:411] mask_score -> mask_score
I0611 15:11:57.737783 26535 net.cpp:150] Setting up mask_score
I0611 15:11:57.737792 26535 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0611 15:11:57.737794 26535 net.cpp:165] Memory required for data: 1671198296
I0611 15:11:57.737799 26535 layer_factory.hpp:77] Creating layer loss_mask
I0611 15:11:57.737805 26535 net.cpp:106] Creating Layer loss_mask
I0611 15:11:57.737808 26535 net.cpp:454] loss_mask <- mask_score
I0611 15:11:57.737821 26535 net.cpp:454] loss_mask <- mask_targets
I0611 15:11:57.737826 26535 net.cpp:411] loss_mask -> loss_mask
I0611 15:11:57.737843 26535 layer_factory.hpp:77] Creating layer loss_mask
I0611 15:11:57.739300 26535 net.cpp:150] Setting up loss_mask
I0611 15:11:57.739308 26535 net.cpp:157] Top shape: (1)
I0611 15:11:57.739311 26535 net.cpp:160]     with loss weight 3
I0611 15:11:57.739318 26535 net.cpp:165] Memory required for data: 1671198300
I0611 15:11:57.739321 26535 net.cpp:226] loss_mask needs backward computation.
I0611 15:11:57.739325 26535 net.cpp:226] mask_score needs backward computation.
I0611 15:11:57.739327 26535 net.cpp:226] mask_deconv3 needs backward computation.
I0611 15:11:57.739341 26535 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0611 15:11:57.739343 26535 net.cpp:226] pool5_2_conv6 needs backward computation.
I0611 15:11:57.739346 26535 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0611 15:11:57.739349 26535 net.cpp:226] pool5_2_conv5 needs backward computation.
I0611 15:11:57.739352 26535 net.cpp:226] mask_deconv2 needs backward computation.
I0611 15:11:57.739354 26535 net.cpp:226] out_x needs backward computation.
I0611 15:11:57.739357 26535 net.cpp:226] out_reshape_scale needs backward computation.
I0611 15:11:57.739361 26535 net.cpp:226] out_reshape needs backward computation.
I0611 15:11:57.739372 26535 net.cpp:226] out needs backward computation.
I0611 15:11:57.739377 26535 net.cpp:226] attention_perm needs backward computation.
I0611 15:11:57.739378 26535 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0611 15:11:57.739393 26535 net.cpp:226] attention needs backward computation.
I0611 15:11:57.739396 26535 net.cpp:226] energy needs backward computation.
I0611 15:11:57.739403 26535 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0611 15:11:57.739405 26535 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0611 15:11:57.739408 26535 net.cpp:226] value_conv_reshape needs backward computation.
I0611 15:11:57.739411 26535 net.cpp:226] key_conv_reshape needs backward computation.
I0611 15:11:57.739414 26535 net.cpp:226] query_conv_reshape needs backward computation.
I0611 15:11:57.739416 26535 net.cpp:226] value_conv needs backward computation.
I0611 15:11:57.739423 26535 net.cpp:226] key_conv needs backward computation.
I0611 15:11:57.739424 26535 net.cpp:226] query_conv needs backward computation.
I0611 15:11:57.739428 26535 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0611 15:11:57.739430 26535 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0611 15:11:57.739434 26535 net.cpp:226] pool5_2_conv4 needs backward computation.
I0611 15:11:57.739437 26535 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0611 15:11:57.739440 26535 net.cpp:226] pool5_2_conv3 needs backward computation.
I0611 15:11:57.739444 26535 net.cpp:226] mask_deconv1 needs backward computation.
I0611 15:11:57.739446 26535 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0611 15:11:57.739459 26535 net.cpp:226] pool5_2_conv2 needs backward computation.
I0611 15:11:57.739462 26535 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0611 15:11:57.739465 26535 net.cpp:226] pool5_2_conv needs backward computation.
I0611 15:11:57.739478 26535 net.cpp:226] roi_pool5_2 needs backward computation.
I0611 15:11:57.739481 26535 net.cpp:226] loss_bbox needs backward computation.
I0611 15:11:57.739487 26535 net.cpp:226] loss_cls needs backward computation.
I0611 15:11:57.739491 26535 net.cpp:226] loss_attribute needs backward computation.
I0611 15:11:57.739506 26535 net.cpp:226] bbox_pred needs backward computation.
I0611 15:11:57.739511 26535 net.cpp:226] cls_score needs backward computation.
I0611 15:11:57.739512 26535 net.cpp:226] attr_score needs backward computation.
I0611 15:11:57.739516 26535 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0611 15:11:57.739528 26535 net.cpp:226] relu7 needs backward computation.
I0611 15:11:57.739531 26535 net.cpp:226] fc7 needs backward computation.
I0611 15:11:57.739533 26535 net.cpp:226] relu6 needs backward computation.
I0611 15:11:57.739536 26535 net.cpp:226] fc6 needs backward computation.
I0611 15:11:57.739538 26535 net.cpp:226] roi_pool5 needs backward computation.
I0611 15:11:57.739542 26535 net.cpp:226] roi-data needs backward computation.
I0611 15:11:57.739555 26535 net.cpp:226] proposal needs backward computation.
I0611 15:11:57.739560 26535 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0611 15:11:57.739563 26535 net.cpp:226] rpn_cls_prob needs backward computation.
I0611 15:11:57.739567 26535 net.cpp:226] rpn_loss_bbox needs backward computation.
I0611 15:11:57.739570 26535 net.cpp:226] rpn_loss_cls needs backward computation.
I0611 15:11:57.739574 26535 net.cpp:226] rpn-data needs backward computation.
I0611 15:11:57.739580 26535 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0611 15:11:57.739584 26535 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0611 15:11:57.739588 26535 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0611 15:11:57.739590 26535 net.cpp:226] rpn_bbox_pred needs backward computation.
I0611 15:11:57.739593 26535 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0611 15:11:57.739596 26535 net.cpp:226] rpn_cls_score needs backward computation.
I0611 15:11:57.739599 26535 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0611 15:11:57.739603 26535 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0611 15:11:57.739604 26535 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0611 15:11:57.739607 26535 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0611 15:11:57.739610 26535 net.cpp:226] relu5_3 needs backward computation.
I0611 15:11:57.739612 26535 net.cpp:226] conv5_3 needs backward computation.
I0611 15:11:57.739615 26535 net.cpp:226] relu5_2 needs backward computation.
I0611 15:11:57.739617 26535 net.cpp:226] conv5_2 needs backward computation.
I0611 15:11:57.739621 26535 net.cpp:226] relu5_1 needs backward computation.
I0611 15:11:57.739624 26535 net.cpp:226] conv5_1 needs backward computation.
I0611 15:11:57.739625 26535 net.cpp:226] pool4 needs backward computation.
I0611 15:11:57.739629 26535 net.cpp:226] relu4_3 needs backward computation.
I0611 15:11:57.739631 26535 net.cpp:226] conv4_3 needs backward computation.
I0611 15:11:57.739634 26535 net.cpp:226] relu4_2 needs backward computation.
I0611 15:11:57.739635 26535 net.cpp:226] conv4_2 needs backward computation.
I0611 15:11:57.739639 26535 net.cpp:226] relu4_1 needs backward computation.
I0611 15:11:57.739641 26535 net.cpp:226] conv4_1 needs backward computation.
I0611 15:11:57.739643 26535 net.cpp:226] pool3 needs backward computation.
I0611 15:11:57.739646 26535 net.cpp:226] relu3_3 needs backward computation.
I0611 15:11:57.739650 26535 net.cpp:226] conv3_3 needs backward computation.
I0611 15:11:57.739652 26535 net.cpp:226] relu3_2 needs backward computation.
I0611 15:11:57.739655 26535 net.cpp:226] conv3_2 needs backward computation.
I0611 15:11:57.739657 26535 net.cpp:226] relu3_1 needs backward computation.
I0611 15:11:57.739660 26535 net.cpp:226] conv3_1 needs backward computation.
I0611 15:11:57.739666 26535 net.cpp:228] pool2 does not need backward computation.
I0611 15:11:57.739670 26535 net.cpp:228] relu2_2 does not need backward computation.
I0611 15:11:57.739671 26535 net.cpp:228] conv2_2 does not need backward computation.
I0611 15:11:57.739675 26535 net.cpp:228] relu2_1 does not need backward computation.
I0611 15:11:57.739677 26535 net.cpp:228] conv2_1 does not need backward computation.
I0611 15:11:57.739681 26535 net.cpp:228] pool1 does not need backward computation.
I0611 15:11:57.739683 26535 net.cpp:228] relu1_2 does not need backward computation.
I0611 15:11:57.739686 26535 net.cpp:228] conv1_2 does not need backward computation.
I0611 15:11:57.739688 26535 net.cpp:228] relu1_1 does not need backward computation.
I0611 15:11:57.739691 26535 net.cpp:228] conv1_1 does not need backward computation.
I0611 15:11:57.739694 26535 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0611 15:11:57.739698 26535 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0611 15:11:57.739701 26535 net.cpp:228] data_input-data_0_split does not need backward computation.
I0611 15:11:57.739706 26535 net.cpp:228] input-data does not need backward computation.
I0611 15:11:57.739708 26535 net.cpp:270] This network produces output loss_attribute
I0611 15:11:57.739711 26535 net.cpp:270] This network produces output loss_bbox
I0611 15:11:57.739714 26535 net.cpp:270] This network produces output loss_cls
I0611 15:11:57.739717 26535 net.cpp:270] This network produces output loss_mask
I0611 15:11:57.739719 26535 net.cpp:270] This network produces output rpn_cls_loss
I0611 15:11:57.739722 26535 net.cpp:270] This network produces output rpn_loss_bbox
I0611 15:11:57.739771 26535 net.cpp:283] Network initialization done.
I0611 15:11:57.739959 26535 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0611 15:11:59.207080 26535 net.cpp:816] Ignoring source layer pool5
I0611 15:11:59.274786 26535 net.cpp:816] Ignoring source layer drop6
I0611 15:11:59.286310 26535 net.cpp:816] Ignoring source layer drop7
I0611 15:11:59.286329 26535 net.cpp:816] Ignoring source layer fc8
I0611 15:11:59.286332 26535 net.cpp:816] Ignoring source layer prob
Solving...
I0611 15:12:00.497189 26535 solver.cpp:229] Iteration 0, loss = 15.8363
I0611 15:12:00.497227 26535 solver.cpp:245]     Train net output #0: loss_attribute = 6.08711 (* 1 = 6.08711 loss)
I0611 15:12:00.497233 26535 solver.cpp:245]     Train net output #1: loss_bbox = 0.0916567 (* 2 = 0.183313 loss)
I0611 15:12:00.497238 26535 solver.cpp:245]     Train net output #2: loss_cls = 0.947394 (* 3 = 2.84218 loss)
I0611 15:12:00.497243 26535 solver.cpp:245]     Train net output #3: loss_mask = 2.08166 (* 3 = 6.24497 loss)
I0611 15:12:00.497257 26535 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.73882 (* 1 = 0.73882 loss)
I0611 15:12:00.497262 26535 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0189577 (* 1 = 0.0189577 loss)
I0611 15:12:00.497267 26535 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0611 15:12:19.584969 26535 solver.cpp:229] Iteration 20, loss = 7.29119
I0611 15:12:19.584995 26535 solver.cpp:245]     Train net output #0: loss_attribute = 0.164689 (* 1 = 0.164689 loss)
I0611 15:12:19.585001 26535 solver.cpp:245]     Train net output #1: loss_bbox = 0.000590692 (* 2 = 0.00118138 loss)
I0611 15:12:19.585005 26535 solver.cpp:245]     Train net output #2: loss_cls = 0.232833 (* 3 = 0.6985 loss)
I0611 15:12:19.585009 26535 solver.cpp:245]     Train net output #3: loss_mask = 1.83956 (* 3 = 5.51868 loss)
I0611 15:12:19.585023 26535 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.183246 (* 1 = 0.183246 loss)
I0611 15:12:19.585027 26535 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0317713 (* 1 = 0.0317713 loss)
I0611 15:12:19.585033 26535 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0611 15:12:43.657290 26535 solver.cpp:229] Iteration 40, loss = 11.4273
I0611 15:12:43.657320 26535 solver.cpp:245]     Train net output #0: loss_attribute = 0.360067 (* 1 = 0.360067 loss)
I0611 15:12:43.657328 26535 solver.cpp:245]     Train net output #1: loss_bbox = 0.0167857 (* 2 = 0.0335715 loss)
I0611 15:12:43.657332 26535 solver.cpp:245]     Train net output #2: loss_cls = 1.30574 (* 3 = 3.91721 loss)
I0611 15:12:43.657337 26535 solver.cpp:245]     Train net output #3: loss_mask = 1.58464 (* 3 = 4.75393 loss)
I0611 15:12:43.657351 26535 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0398326 (* 1 = 0.0398326 loss)
I0611 15:12:43.657356 26535 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0394272 (* 1 = 0.0394272 loss)
I0611 15:12:43.657362 26535 sgd_solver.cpp:106] Iteration 40, lr = 0.001
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:63: RuntimeWarning: overflow encountered in exp
  pred_h = np.exp(dh) * heights[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:63: RuntimeWarning: overflow encountered in multiply
  pred_h = np.exp(dh) * heights[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:62: RuntimeWarning: overflow encountered in exp
  pred_w = np.exp(dw) * widths[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:62: RuntimeWarning: overflow encountered in multiply
  pred_w = np.exp(dw) * widths[:, np.newaxis]
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:83: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:83: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:85: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:85: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:87: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:87: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:89: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:89: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/rpn/proposal_layer.py:187: RuntimeWarning: invalid value encountered in greater_equal
  keep = np.where((ws >= min_size) & (hs >= min_size))[0]
---- WARNING: filter_boxes() remove ALL proposal.
./experiments/scripts/faster_rcnn_end2end.sh: line 65: 26535 Floating point exception/usr/bin/python ./tools/train_net.py --gpu ${GPU_ID} --solver models/${PT_DIR}/${NET}/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb ${TRAIN_IMDB} --iters ${ITERS} --cfg experiments/cfgs/faster_rcnn_end2end.yml ${EXTRA_ARGS}
