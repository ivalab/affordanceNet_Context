+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-25_17-06-06
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-25_17-06-06
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0625 17:06:17.204087 22418 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0625 17:06:17.204119 22418 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0625 17:06:17.205657 22418 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  top: "attrArray"
  top: "attrArrayInd"
  top: "attrArrayShift"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "attr_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "attr_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "attr_score_pos"
  type: "Eltwise"
  bottom: "attr_score"
  bottom: "attrArrayInd"
  top: "attr_score_pos"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "attr_score_pos_shift"
  type: "Eltwise"
  bottom: "attr_score_pos"
  bottom: "attrArrayShift"
  top: "attr_score_pos_shift"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_attribute"
  type: "SigmoidCrossEntropyLoss"
  bottom: "attr_score_pos_shift"
  bottom: "attrArray"
  top: "loss_attribute"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "mask_score"
  top: "mask_score_softmax"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "log"
  type: "Log"
  bottom: "mask_score_softmax"
  top: "log"
}
layer {
  name: "mult1"
  type: "Eltwise"
  bottom: "log"
  bottom: "mask_targets"
  top: "mult1"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "cross_entropy"
  type: "Power"
  bottom: "mult1"
  top: "cross_entropy"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "ce_sum"
  type: "Convolution"
  bottom: "cross_entropy"
  top: "cross_entropy_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "ce_mean"
  type: "Reduction"
  bottom: "cross_entropy_sum"
  top: "cross_entropy_mean"
  loss_weight: 1
  reduction_param {
    operation: MEAN
    axis: 0
  }
}
I0625 17:06:17.206054 22418 layer_factory.hpp:77] Creating layer input-data
I0625 17:06:17.254958 22418 net.cpp:106] Creating Layer input-data
I0625 17:06:17.254974 22418 net.cpp:411] input-data -> data
I0625 17:06:17.254986 22418 net.cpp:411] input-data -> im_info
I0625 17:06:17.254992 22418 net.cpp:411] input-data -> gt_boxes
I0625 17:06:17.254998 22418 net.cpp:411] input-data -> seg_mask_inds
I0625 17:06:17.255004 22418 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0625 17:06:17.289196 22418 net.cpp:150] Setting up input-data
I0625 17:06:17.289214 22418 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 17:06:17.289222 22418 net.cpp:157] Top shape: 1 3 (3)
I0625 17:06:17.289227 22418 net.cpp:157] Top shape: 1 4 (4)
I0625 17:06:17.289232 22418 net.cpp:157] Top shape: 1 2 (2)
I0625 17:06:17.289238 22418 net.cpp:157] Top shape: 1 1 (1)
I0625 17:06:17.289242 22418 net.cpp:165] Memory required for data: 7200040
I0625 17:06:17.289249 22418 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0625 17:06:17.289265 22418 net.cpp:106] Creating Layer data_input-data_0_split
I0625 17:06:17.289270 22418 net.cpp:454] data_input-data_0_split <- data
I0625 17:06:17.289278 22418 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0625 17:06:17.289285 22418 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0625 17:06:17.289310 22418 net.cpp:150] Setting up data_input-data_0_split
I0625 17:06:17.289316 22418 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 17:06:17.289321 22418 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 17:06:17.289325 22418 net.cpp:165] Memory required for data: 21600040
I0625 17:06:17.289330 22418 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0625 17:06:17.289335 22418 net.cpp:106] Creating Layer im_info_input-data_1_split
I0625 17:06:17.289340 22418 net.cpp:454] im_info_input-data_1_split <- im_info
I0625 17:06:17.289345 22418 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0625 17:06:17.289350 22418 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0625 17:06:17.289358 22418 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0625 17:06:17.289386 22418 net.cpp:150] Setting up im_info_input-data_1_split
I0625 17:06:17.289391 22418 net.cpp:157] Top shape: 1 3 (3)
I0625 17:06:17.289396 22418 net.cpp:157] Top shape: 1 3 (3)
I0625 17:06:17.289400 22418 net.cpp:157] Top shape: 1 3 (3)
I0625 17:06:17.289405 22418 net.cpp:165] Memory required for data: 21600076
I0625 17:06:17.289408 22418 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0625 17:06:17.289414 22418 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0625 17:06:17.289418 22418 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0625 17:06:17.289423 22418 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0625 17:06:17.289429 22418 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0625 17:06:17.289449 22418 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0625 17:06:17.289454 22418 net.cpp:157] Top shape: 1 4 (4)
I0625 17:06:17.289459 22418 net.cpp:157] Top shape: 1 4 (4)
I0625 17:06:17.289463 22418 net.cpp:165] Memory required for data: 21600108
I0625 17:06:17.289466 22418 layer_factory.hpp:77] Creating layer conv1_1
I0625 17:06:17.289475 22418 net.cpp:106] Creating Layer conv1_1
I0625 17:06:17.289479 22418 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0625 17:06:17.289484 22418 net.cpp:411] conv1_1 -> conv1_1
I0625 17:06:17.473894 22418 net.cpp:150] Setting up conv1_1
I0625 17:06:17.473917 22418 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 17:06:17.473922 22418 net.cpp:165] Memory required for data: 175200108
I0625 17:06:17.473963 22418 layer_factory.hpp:77] Creating layer relu1_1
I0625 17:06:17.473984 22418 net.cpp:106] Creating Layer relu1_1
I0625 17:06:17.473990 22418 net.cpp:454] relu1_1 <- conv1_1
I0625 17:06:17.474004 22418 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0625 17:06:17.474159 22418 net.cpp:150] Setting up relu1_1
I0625 17:06:17.474166 22418 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 17:06:17.474169 22418 net.cpp:165] Memory required for data: 328800108
I0625 17:06:17.474174 22418 layer_factory.hpp:77] Creating layer conv1_2
I0625 17:06:17.474184 22418 net.cpp:106] Creating Layer conv1_2
I0625 17:06:17.474187 22418 net.cpp:454] conv1_2 <- conv1_1
I0625 17:06:17.474193 22418 net.cpp:411] conv1_2 -> conv1_2
I0625 17:06:17.476600 22418 net.cpp:150] Setting up conv1_2
I0625 17:06:17.476614 22418 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 17:06:17.476617 22418 net.cpp:165] Memory required for data: 482400108
I0625 17:06:17.476641 22418 layer_factory.hpp:77] Creating layer relu1_2
I0625 17:06:17.476660 22418 net.cpp:106] Creating Layer relu1_2
I0625 17:06:17.476677 22418 net.cpp:454] relu1_2 <- conv1_2
I0625 17:06:17.476682 22418 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0625 17:06:17.476824 22418 net.cpp:150] Setting up relu1_2
I0625 17:06:17.476831 22418 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 17:06:17.476835 22418 net.cpp:165] Memory required for data: 636000108
I0625 17:06:17.476837 22418 layer_factory.hpp:77] Creating layer pool1
I0625 17:06:17.476846 22418 net.cpp:106] Creating Layer pool1
I0625 17:06:17.476861 22418 net.cpp:454] pool1 <- conv1_2
I0625 17:06:17.476867 22418 net.cpp:411] pool1 -> pool1
I0625 17:06:17.476914 22418 net.cpp:150] Setting up pool1
I0625 17:06:17.476919 22418 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0625 17:06:17.476922 22418 net.cpp:165] Memory required for data: 674400108
I0625 17:06:17.476935 22418 layer_factory.hpp:77] Creating layer conv2_1
I0625 17:06:17.476943 22418 net.cpp:106] Creating Layer conv2_1
I0625 17:06:17.476946 22418 net.cpp:454] conv2_1 <- pool1
I0625 17:06:17.476951 22418 net.cpp:411] conv2_1 -> conv2_1
I0625 17:06:17.478694 22418 net.cpp:150] Setting up conv2_1
I0625 17:06:17.478706 22418 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 17:06:17.478709 22418 net.cpp:165] Memory required for data: 751200108
I0625 17:06:17.478729 22418 layer_factory.hpp:77] Creating layer relu2_1
I0625 17:06:17.478761 22418 net.cpp:106] Creating Layer relu2_1
I0625 17:06:17.478776 22418 net.cpp:454] relu2_1 <- conv2_1
I0625 17:06:17.478781 22418 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0625 17:06:17.479370 22418 net.cpp:150] Setting up relu2_1
I0625 17:06:17.479379 22418 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 17:06:17.479391 22418 net.cpp:165] Memory required for data: 828000108
I0625 17:06:17.479394 22418 layer_factory.hpp:77] Creating layer conv2_2
I0625 17:06:17.479400 22418 net.cpp:106] Creating Layer conv2_2
I0625 17:06:17.479403 22418 net.cpp:454] conv2_2 <- conv2_1
I0625 17:06:17.479405 22418 net.cpp:411] conv2_2 -> conv2_2
I0625 17:06:17.480826 22418 net.cpp:150] Setting up conv2_2
I0625 17:06:17.480845 22418 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 17:06:17.480847 22418 net.cpp:165] Memory required for data: 904800108
I0625 17:06:17.480852 22418 layer_factory.hpp:77] Creating layer relu2_2
I0625 17:06:17.480856 22418 net.cpp:106] Creating Layer relu2_2
I0625 17:06:17.480859 22418 net.cpp:454] relu2_2 <- conv2_2
I0625 17:06:17.480862 22418 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0625 17:06:17.480979 22418 net.cpp:150] Setting up relu2_2
I0625 17:06:17.480985 22418 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 17:06:17.480996 22418 net.cpp:165] Memory required for data: 981600108
I0625 17:06:17.480998 22418 layer_factory.hpp:77] Creating layer pool2
I0625 17:06:17.481003 22418 net.cpp:106] Creating Layer pool2
I0625 17:06:17.481004 22418 net.cpp:454] pool2 <- conv2_2
I0625 17:06:17.481009 22418 net.cpp:411] pool2 -> pool2
I0625 17:06:17.481042 22418 net.cpp:150] Setting up pool2
I0625 17:06:17.481046 22418 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0625 17:06:17.481048 22418 net.cpp:165] Memory required for data: 1000800108
I0625 17:06:17.481060 22418 layer_factory.hpp:77] Creating layer conv3_1
I0625 17:06:17.481065 22418 net.cpp:106] Creating Layer conv3_1
I0625 17:06:17.481066 22418 net.cpp:454] conv3_1 <- pool2
I0625 17:06:17.481070 22418 net.cpp:411] conv3_1 -> conv3_1
I0625 17:06:17.483016 22418 net.cpp:150] Setting up conv3_1
I0625 17:06:17.483037 22418 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:06:17.483039 22418 net.cpp:165] Memory required for data: 1039200108
I0625 17:06:17.483047 22418 layer_factory.hpp:77] Creating layer relu3_1
I0625 17:06:17.483052 22418 net.cpp:106] Creating Layer relu3_1
I0625 17:06:17.483063 22418 net.cpp:454] relu3_1 <- conv3_1
I0625 17:06:17.483067 22418 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0625 17:06:17.483189 22418 net.cpp:150] Setting up relu3_1
I0625 17:06:17.483194 22418 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:06:17.483196 22418 net.cpp:165] Memory required for data: 1077600108
I0625 17:06:17.483198 22418 layer_factory.hpp:77] Creating layer conv3_2
I0625 17:06:17.483217 22418 net.cpp:106] Creating Layer conv3_2
I0625 17:06:17.483219 22418 net.cpp:454] conv3_2 <- conv3_1
I0625 17:06:17.483223 22418 net.cpp:411] conv3_2 -> conv3_2
I0625 17:06:17.485229 22418 net.cpp:150] Setting up conv3_2
I0625 17:06:17.485237 22418 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:06:17.485239 22418 net.cpp:165] Memory required for data: 1116000108
I0625 17:06:17.485244 22418 layer_factory.hpp:77] Creating layer relu3_2
I0625 17:06:17.485247 22418 net.cpp:106] Creating Layer relu3_2
I0625 17:06:17.485249 22418 net.cpp:454] relu3_2 <- conv3_2
I0625 17:06:17.485253 22418 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0625 17:06:17.485383 22418 net.cpp:150] Setting up relu3_2
I0625 17:06:17.485389 22418 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:06:17.485390 22418 net.cpp:165] Memory required for data: 1154400108
I0625 17:06:17.485393 22418 layer_factory.hpp:77] Creating layer conv3_3
I0625 17:06:17.485397 22418 net.cpp:106] Creating Layer conv3_3
I0625 17:06:17.485399 22418 net.cpp:454] conv3_3 <- conv3_2
I0625 17:06:17.485404 22418 net.cpp:411] conv3_3 -> conv3_3
I0625 17:06:17.487386 22418 net.cpp:150] Setting up conv3_3
I0625 17:06:17.487395 22418 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:06:17.487396 22418 net.cpp:165] Memory required for data: 1192800108
I0625 17:06:17.487401 22418 layer_factory.hpp:77] Creating layer relu3_3
I0625 17:06:17.487404 22418 net.cpp:106] Creating Layer relu3_3
I0625 17:06:17.487407 22418 net.cpp:454] relu3_3 <- conv3_3
I0625 17:06:17.487411 22418 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0625 17:06:17.487537 22418 net.cpp:150] Setting up relu3_3
I0625 17:06:17.487542 22418 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 17:06:17.487545 22418 net.cpp:165] Memory required for data: 1231200108
I0625 17:06:17.487546 22418 layer_factory.hpp:77] Creating layer pool3
I0625 17:06:17.487550 22418 net.cpp:106] Creating Layer pool3
I0625 17:06:17.487551 22418 net.cpp:454] pool3 <- conv3_3
I0625 17:06:17.487555 22418 net.cpp:411] pool3 -> pool3
I0625 17:06:17.487603 22418 net.cpp:150] Setting up pool3
I0625 17:06:17.487607 22418 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0625 17:06:17.487608 22418 net.cpp:165] Memory required for data: 1240800108
I0625 17:06:17.487620 22418 layer_factory.hpp:77] Creating layer conv4_1
I0625 17:06:17.487625 22418 net.cpp:106] Creating Layer conv4_1
I0625 17:06:17.487627 22418 net.cpp:454] conv4_1 <- pool3
I0625 17:06:17.487630 22418 net.cpp:411] conv4_1 -> conv4_1
I0625 17:06:17.491257 22418 net.cpp:150] Setting up conv4_1
I0625 17:06:17.491286 22418 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:06:17.491288 22418 net.cpp:165] Memory required for data: 1260000108
I0625 17:06:17.491295 22418 layer_factory.hpp:77] Creating layer relu4_1
I0625 17:06:17.491305 22418 net.cpp:106] Creating Layer relu4_1
I0625 17:06:17.491309 22418 net.cpp:454] relu4_1 <- conv4_1
I0625 17:06:17.491314 22418 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0625 17:06:17.491468 22418 net.cpp:150] Setting up relu4_1
I0625 17:06:17.491474 22418 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:06:17.491487 22418 net.cpp:165] Memory required for data: 1279200108
I0625 17:06:17.491488 22418 layer_factory.hpp:77] Creating layer conv4_2
I0625 17:06:17.491495 22418 net.cpp:106] Creating Layer conv4_2
I0625 17:06:17.491497 22418 net.cpp:454] conv4_2 <- conv4_1
I0625 17:06:17.491502 22418 net.cpp:411] conv4_2 -> conv4_2
I0625 17:06:17.496419 22418 net.cpp:150] Setting up conv4_2
I0625 17:06:17.496448 22418 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:06:17.496451 22418 net.cpp:165] Memory required for data: 1298400108
I0625 17:06:17.496462 22418 layer_factory.hpp:77] Creating layer relu4_2
I0625 17:06:17.496470 22418 net.cpp:106] Creating Layer relu4_2
I0625 17:06:17.496484 22418 net.cpp:454] relu4_2 <- conv4_2
I0625 17:06:17.496489 22418 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0625 17:06:17.496973 22418 net.cpp:150] Setting up relu4_2
I0625 17:06:17.496979 22418 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:06:17.496981 22418 net.cpp:165] Memory required for data: 1317600108
I0625 17:06:17.496984 22418 layer_factory.hpp:77] Creating layer conv4_3
I0625 17:06:17.496990 22418 net.cpp:106] Creating Layer conv4_3
I0625 17:06:17.496992 22418 net.cpp:454] conv4_3 <- conv4_2
I0625 17:06:17.496996 22418 net.cpp:411] conv4_3 -> conv4_3
I0625 17:06:17.501222 22418 net.cpp:150] Setting up conv4_3
I0625 17:06:17.501242 22418 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:06:17.501245 22418 net.cpp:165] Memory required for data: 1336800108
I0625 17:06:17.501250 22418 layer_factory.hpp:77] Creating layer relu4_3
I0625 17:06:17.501258 22418 net.cpp:106] Creating Layer relu4_3
I0625 17:06:17.501261 22418 net.cpp:454] relu4_3 <- conv4_3
I0625 17:06:17.501266 22418 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0625 17:06:17.501396 22418 net.cpp:150] Setting up relu4_3
I0625 17:06:17.501401 22418 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 17:06:17.501404 22418 net.cpp:165] Memory required for data: 1356000108
I0625 17:06:17.501405 22418 layer_factory.hpp:77] Creating layer pool4
I0625 17:06:17.501410 22418 net.cpp:106] Creating Layer pool4
I0625 17:06:17.501411 22418 net.cpp:454] pool4 <- conv4_3
I0625 17:06:17.501415 22418 net.cpp:411] pool4 -> pool4
I0625 17:06:17.501461 22418 net.cpp:150] Setting up pool4
I0625 17:06:17.501464 22418 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:06:17.501466 22418 net.cpp:165] Memory required for data: 1360903020
I0625 17:06:17.501477 22418 layer_factory.hpp:77] Creating layer conv5_1
I0625 17:06:17.501484 22418 net.cpp:106] Creating Layer conv5_1
I0625 17:06:17.501487 22418 net.cpp:454] conv5_1 <- pool4
I0625 17:06:17.501488 22418 net.cpp:411] conv5_1 -> conv5_1
I0625 17:06:17.505650 22418 net.cpp:150] Setting up conv5_1
I0625 17:06:17.505672 22418 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:06:17.505674 22418 net.cpp:165] Memory required for data: 1365805932
I0625 17:06:17.505681 22418 layer_factory.hpp:77] Creating layer relu5_1
I0625 17:06:17.505698 22418 net.cpp:106] Creating Layer relu5_1
I0625 17:06:17.505702 22418 net.cpp:454] relu5_1 <- conv5_1
I0625 17:06:17.505707 22418 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0625 17:06:17.505829 22418 net.cpp:150] Setting up relu5_1
I0625 17:06:17.505834 22418 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:06:17.505836 22418 net.cpp:165] Memory required for data: 1370708844
I0625 17:06:17.505838 22418 layer_factory.hpp:77] Creating layer conv5_2
I0625 17:06:17.505854 22418 net.cpp:106] Creating Layer conv5_2
I0625 17:06:17.505857 22418 net.cpp:454] conv5_2 <- conv5_1
I0625 17:06:17.505861 22418 net.cpp:411] conv5_2 -> conv5_2
I0625 17:06:17.509948 22418 net.cpp:150] Setting up conv5_2
I0625 17:06:17.509969 22418 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:06:17.509971 22418 net.cpp:165] Memory required for data: 1375611756
I0625 17:06:17.509979 22418 layer_factory.hpp:77] Creating layer relu5_2
I0625 17:06:17.509985 22418 net.cpp:106] Creating Layer relu5_2
I0625 17:06:17.509989 22418 net.cpp:454] relu5_2 <- conv5_2
I0625 17:06:17.509994 22418 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0625 17:06:17.510124 22418 net.cpp:150] Setting up relu5_2
I0625 17:06:17.510129 22418 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:06:17.510131 22418 net.cpp:165] Memory required for data: 1380514668
I0625 17:06:17.510133 22418 layer_factory.hpp:77] Creating layer conv5_3
I0625 17:06:17.510152 22418 net.cpp:106] Creating Layer conv5_3
I0625 17:06:17.510155 22418 net.cpp:454] conv5_3 <- conv5_2
I0625 17:06:17.510169 22418 net.cpp:411] conv5_3 -> conv5_3
I0625 17:06:17.514384 22418 net.cpp:150] Setting up conv5_3
I0625 17:06:17.514402 22418 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:06:17.514405 22418 net.cpp:165] Memory required for data: 1385417580
I0625 17:06:17.514411 22418 layer_factory.hpp:77] Creating layer relu5_3
I0625 17:06:17.514428 22418 net.cpp:106] Creating Layer relu5_3
I0625 17:06:17.514431 22418 net.cpp:454] relu5_3 <- conv5_3
I0625 17:06:17.514436 22418 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0625 17:06:17.514571 22418 net.cpp:150] Setting up relu5_3
I0625 17:06:17.514576 22418 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:06:17.514578 22418 net.cpp:165] Memory required for data: 1390320492
I0625 17:06:17.514580 22418 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0625 17:06:17.514583 22418 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0625 17:06:17.514585 22418 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0625 17:06:17.514590 22418 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0625 17:06:17.514593 22418 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0625 17:06:17.514596 22418 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0625 17:06:17.514652 22418 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0625 17:06:17.514655 22418 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:06:17.514657 22418 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:06:17.514659 22418 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:06:17.514662 22418 net.cpp:165] Memory required for data: 1405029228
I0625 17:06:17.514663 22418 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0625 17:06:17.514672 22418 net.cpp:106] Creating Layer rpn_conv/3x3
I0625 17:06:17.514673 22418 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0625 17:06:17.514677 22418 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0625 17:06:17.563925 22418 net.cpp:150] Setting up rpn_conv/3x3
I0625 17:06:17.563942 22418 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:06:17.563944 22418 net.cpp:165] Memory required for data: 1409932140
I0625 17:06:17.563951 22418 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0625 17:06:17.563958 22418 net.cpp:106] Creating Layer rpn_relu/3x3
I0625 17:06:17.563971 22418 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0625 17:06:17.563975 22418 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0625 17:06:17.564116 22418 net.cpp:150] Setting up rpn_relu/3x3
I0625 17:06:17.564121 22418 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:06:17.564122 22418 net.cpp:165] Memory required for data: 1414835052
I0625 17:06:17.564124 22418 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0625 17:06:17.564128 22418 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0625 17:06:17.564131 22418 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0625 17:06:17.564134 22418 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0625 17:06:17.564138 22418 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0625 17:06:17.564182 22418 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0625 17:06:17.564185 22418 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:06:17.564198 22418 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 17:06:17.564199 22418 net.cpp:165] Memory required for data: 1424640876
I0625 17:06:17.564200 22418 layer_factory.hpp:77] Creating layer rpn_cls_score
I0625 17:06:17.564208 22418 net.cpp:106] Creating Layer rpn_cls_score
I0625 17:06:17.564219 22418 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0625 17:06:17.564222 22418 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0625 17:06:17.565826 22418 net.cpp:150] Setting up rpn_cls_score
I0625 17:06:17.565834 22418 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 17:06:17.565836 22418 net.cpp:165] Memory required for data: 1424928156
I0625 17:06:17.565840 22418 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0625 17:06:17.565855 22418 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0625 17:06:17.565858 22418 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0625 17:06:17.565872 22418 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0625 17:06:17.565876 22418 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0625 17:06:17.565910 22418 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0625 17:06:17.565914 22418 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 17:06:17.565917 22418 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 17:06:17.565918 22418 net.cpp:165] Memory required for data: 1425502716
I0625 17:06:17.565929 22418 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0625 17:06:17.565951 22418 net.cpp:106] Creating Layer rpn_bbox_pred
I0625 17:06:17.565955 22418 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0625 17:06:17.565971 22418 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0625 17:06:17.567627 22418 net.cpp:150] Setting up rpn_bbox_pred
I0625 17:06:17.567636 22418 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:06:17.567637 22418 net.cpp:165] Memory required for data: 1426077276
I0625 17:06:17.567641 22418 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 17:06:17.567656 22418 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 17:06:17.567659 22418 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0625 17:06:17.567673 22418 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0625 17:06:17.567677 22418 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0625 17:06:17.567713 22418 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 17:06:17.567716 22418 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:06:17.567718 22418 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:06:17.567720 22418 net.cpp:165] Memory required for data: 1427226396
I0625 17:06:17.567734 22418 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0625 17:06:17.567739 22418 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0625 17:06:17.567750 22418 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0625 17:06:17.567754 22418 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0625 17:06:17.567781 22418 net.cpp:150] Setting up rpn_cls_score_reshape
I0625 17:06:17.567785 22418 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 17:06:17.567786 22418 net.cpp:165] Memory required for data: 1427513676
I0625 17:06:17.567788 22418 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 17:06:17.567792 22418 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 17:06:17.567795 22418 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0625 17:06:17.567796 22418 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0625 17:06:17.567800 22418 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0625 17:06:17.567829 22418 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 17:06:17.567832 22418 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 17:06:17.567836 22418 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 17:06:17.567836 22418 net.cpp:165] Memory required for data: 1428088236
I0625 17:06:17.567838 22418 layer_factory.hpp:77] Creating layer rpn-data
I0625 17:06:17.568924 22418 net.cpp:106] Creating Layer rpn-data
I0625 17:06:17.568934 22418 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0625 17:06:17.568939 22418 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0625 17:06:17.568944 22418 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0625 17:06:17.568949 22418 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0625 17:06:17.568954 22418 net.cpp:411] rpn-data -> rpn_labels
I0625 17:06:17.568962 22418 net.cpp:411] rpn-data -> rpn_bbox_targets
I0625 17:06:17.568969 22418 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0625 17:06:17.568976 22418 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0625 17:06:17.570291 22418 net.cpp:150] Setting up rpn-data
I0625 17:06:17.570302 22418 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0625 17:06:17.570307 22418 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:06:17.570312 22418 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:06:17.570317 22418 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 17:06:17.570320 22418 net.cpp:165] Memory required for data: 1429955556
I0625 17:06:17.570323 22418 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0625 17:06:17.570330 22418 net.cpp:106] Creating Layer rpn_loss_cls
I0625 17:06:17.570335 22418 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0625 17:06:17.570339 22418 net.cpp:454] rpn_loss_cls <- rpn_labels
I0625 17:06:17.570345 22418 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0625 17:06:17.570354 22418 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0625 17:06:17.572288 22418 net.cpp:150] Setting up rpn_loss_cls
I0625 17:06:17.572296 22418 net.cpp:157] Top shape: (1)
I0625 17:06:17.572299 22418 net.cpp:160]     with loss weight 1
I0625 17:06:17.572304 22418 net.cpp:165] Memory required for data: 1429955560
I0625 17:06:17.572306 22418 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0625 17:06:17.572311 22418 net.cpp:106] Creating Layer rpn_loss_bbox
I0625 17:06:17.572314 22418 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0625 17:06:17.572317 22418 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0625 17:06:17.572320 22418 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0625 17:06:17.572322 22418 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0625 17:06:17.572325 22418 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0625 17:06:17.573596 22418 net.cpp:150] Setting up rpn_loss_bbox
I0625 17:06:17.573604 22418 net.cpp:157] Top shape: (1)
I0625 17:06:17.573606 22418 net.cpp:160]     with loss weight 1
I0625 17:06:17.573611 22418 net.cpp:165] Memory required for data: 1429955564
I0625 17:06:17.573612 22418 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0625 17:06:17.573616 22418 net.cpp:106] Creating Layer rpn_cls_prob
I0625 17:06:17.573619 22418 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0625 17:06:17.573623 22418 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0625 17:06:17.573809 22418 net.cpp:150] Setting up rpn_cls_prob
I0625 17:06:17.573815 22418 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 17:06:17.573827 22418 net.cpp:165] Memory required for data: 1430242844
I0625 17:06:17.573829 22418 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0625 17:06:17.573834 22418 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0625 17:06:17.573837 22418 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0625 17:06:17.573841 22418 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0625 17:06:17.573866 22418 net.cpp:150] Setting up rpn_cls_prob_reshape
I0625 17:06:17.573869 22418 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 17:06:17.573871 22418 net.cpp:165] Memory required for data: 1430530124
I0625 17:06:17.573873 22418 layer_factory.hpp:77] Creating layer proposal
I0625 17:06:17.575428 22418 net.cpp:106] Creating Layer proposal
I0625 17:06:17.575435 22418 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0625 17:06:17.575438 22418 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0625 17:06:17.575441 22418 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0625 17:06:17.575445 22418 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0625 17:06:17.576776 22418 net.cpp:150] Setting up proposal
I0625 17:06:17.576786 22418 net.cpp:157] Top shape: 1 5 (5)
I0625 17:06:17.576789 22418 net.cpp:165] Memory required for data: 1430530144
I0625 17:06:17.576793 22418 layer_factory.hpp:77] Creating layer roi-data
I0625 17:06:17.579723 22418 net.cpp:106] Creating Layer roi-data
I0625 17:06:17.579733 22418 net.cpp:454] roi-data <- rpn_rois
I0625 17:06:17.579740 22418 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0625 17:06:17.579744 22418 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0625 17:06:17.579749 22418 net.cpp:454] roi-data <- seg_mask_inds
I0625 17:06:17.579753 22418 net.cpp:454] roi-data <- flipped
I0625 17:06:17.579771 22418 net.cpp:411] roi-data -> rois
I0625 17:06:17.579780 22418 net.cpp:411] roi-data -> labels
I0625 17:06:17.579787 22418 net.cpp:411] roi-data -> bbox_targets
I0625 17:06:17.579795 22418 net.cpp:411] roi-data -> bbox_inside_weights
I0625 17:06:17.579802 22418 net.cpp:411] roi-data -> bbox_outside_weights
I0625 17:06:17.579808 22418 net.cpp:411] roi-data -> mask_targets
I0625 17:06:17.579825 22418 net.cpp:411] roi-data -> rois_pos
I0625 17:06:17.579831 22418 net.cpp:411] roi-data -> attrArray
I0625 17:06:17.579838 22418 net.cpp:411] roi-data -> attrArrayInd
I0625 17:06:17.579845 22418 net.cpp:411] roi-data -> attrArrayShift
I0625 17:06:17.580193 22418 net.cpp:150] Setting up roi-data
I0625 17:06:17.580202 22418 net.cpp:157] Top shape: 1 5 (5)
I0625 17:06:17.580207 22418 net.cpp:157] Top shape: 1 1 (1)
I0625 17:06:17.580212 22418 net.cpp:157] Top shape: 1 8 (8)
I0625 17:06:17.580217 22418 net.cpp:157] Top shape: 1 8 (8)
I0625 17:06:17.580222 22418 net.cpp:157] Top shape: 1 8 (8)
I0625 17:06:17.580227 22418 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:06:17.580231 22418 net.cpp:157] Top shape: 1 5 (5)
I0625 17:06:17.580236 22418 net.cpp:157] Top shape: 1 7 (7)
I0625 17:06:17.580241 22418 net.cpp:157] Top shape: 1 7 (7)
I0625 17:06:17.580255 22418 net.cpp:157] Top shape: 1 7 (7)
I0625 17:06:17.580258 22418 net.cpp:165] Memory required for data: 1432435520
I0625 17:06:17.580262 22418 layer_factory.hpp:77] Creating layer roi_pool5
I0625 17:06:17.580271 22418 net.cpp:106] Creating Layer roi_pool5
I0625 17:06:17.580274 22418 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0625 17:06:17.580279 22418 net.cpp:454] roi_pool5 <- rois
I0625 17:06:17.580284 22418 net.cpp:411] roi_pool5 -> pool5
I0625 17:06:17.580292 22418 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0625 17:06:17.580360 22418 net.cpp:150] Setting up roi_pool5
I0625 17:06:17.580366 22418 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:06:17.580370 22418 net.cpp:165] Memory required for data: 1432535872
I0625 17:06:17.580374 22418 layer_factory.hpp:77] Creating layer fc6
I0625 17:06:17.580381 22418 net.cpp:106] Creating Layer fc6
I0625 17:06:17.580384 22418 net.cpp:454] fc6 <- pool5
I0625 17:06:17.580389 22418 net.cpp:411] fc6 -> fc6
I0625 17:06:17.723512 22418 net.cpp:150] Setting up fc6
I0625 17:06:17.723541 22418 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:06:17.723544 22418 net.cpp:165] Memory required for data: 1432552256
I0625 17:06:17.723574 22418 layer_factory.hpp:77] Creating layer relu6
I0625 17:06:17.723587 22418 net.cpp:106] Creating Layer relu6
I0625 17:06:17.723592 22418 net.cpp:454] relu6 <- fc6
I0625 17:06:17.723598 22418 net.cpp:397] relu6 -> fc6 (in-place)
I0625 17:06:17.723819 22418 net.cpp:150] Setting up relu6
I0625 17:06:17.723826 22418 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:06:17.723829 22418 net.cpp:165] Memory required for data: 1432568640
I0625 17:06:17.723832 22418 layer_factory.hpp:77] Creating layer fc7
I0625 17:06:17.723839 22418 net.cpp:106] Creating Layer fc7
I0625 17:06:17.723841 22418 net.cpp:454] fc7 <- fc6
I0625 17:06:17.723856 22418 net.cpp:411] fc7 -> fc7
I0625 17:06:17.758682 22418 net.cpp:150] Setting up fc7
I0625 17:06:17.758713 22418 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:06:17.758716 22418 net.cpp:165] Memory required for data: 1432585024
I0625 17:06:17.758728 22418 layer_factory.hpp:77] Creating layer relu7
I0625 17:06:17.758738 22418 net.cpp:106] Creating Layer relu7
I0625 17:06:17.758744 22418 net.cpp:454] relu7 <- fc7
I0625 17:06:17.758752 22418 net.cpp:397] relu7 -> fc7 (in-place)
I0625 17:06:17.758940 22418 net.cpp:150] Setting up relu7
I0625 17:06:17.758947 22418 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:06:17.758950 22418 net.cpp:165] Memory required for data: 1432601408
I0625 17:06:17.758954 22418 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0625 17:06:17.758960 22418 net.cpp:106] Creating Layer fc7_relu7_0_split
I0625 17:06:17.758963 22418 net.cpp:454] fc7_relu7_0_split <- fc7
I0625 17:06:17.758970 22418 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0625 17:06:17.758977 22418 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0625 17:06:17.758988 22418 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0625 17:06:17.759030 22418 net.cpp:150] Setting up fc7_relu7_0_split
I0625 17:06:17.759037 22418 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:06:17.759039 22418 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:06:17.759043 22418 net.cpp:157] Top shape: 1 4096 (4096)
I0625 17:06:17.759047 22418 net.cpp:165] Memory required for data: 1432650560
I0625 17:06:17.759049 22418 layer_factory.hpp:77] Creating layer attr_score
I0625 17:06:17.759058 22418 net.cpp:106] Creating Layer attr_score
I0625 17:06:17.759063 22418 net.cpp:454] attr_score <- fc7_relu7_0_split_0
I0625 17:06:17.759073 22418 net.cpp:411] attr_score -> attr_score
I0625 17:06:17.759752 22418 net.cpp:150] Setting up attr_score
I0625 17:06:17.759759 22418 net.cpp:157] Top shape: 1 7 (7)
I0625 17:06:17.759763 22418 net.cpp:165] Memory required for data: 1432650588
I0625 17:06:17.759769 22418 layer_factory.hpp:77] Creating layer attr_score_pos
I0625 17:06:17.759789 22418 net.cpp:106] Creating Layer attr_score_pos
I0625 17:06:17.759794 22418 net.cpp:454] attr_score_pos <- attr_score
I0625 17:06:17.759799 22418 net.cpp:454] attr_score_pos <- attrArrayInd
I0625 17:06:17.759804 22418 net.cpp:411] attr_score_pos -> attr_score_pos
I0625 17:06:17.759829 22418 net.cpp:150] Setting up attr_score_pos
I0625 17:06:17.759835 22418 net.cpp:157] Top shape: 1 7 (7)
I0625 17:06:17.759837 22418 net.cpp:165] Memory required for data: 1432650616
I0625 17:06:17.759840 22418 layer_factory.hpp:77] Creating layer attr_score_pos_shift
I0625 17:06:17.759845 22418 net.cpp:106] Creating Layer attr_score_pos_shift
I0625 17:06:17.759860 22418 net.cpp:454] attr_score_pos_shift <- attr_score_pos
I0625 17:06:17.759873 22418 net.cpp:454] attr_score_pos_shift <- attrArrayShift
I0625 17:06:17.759886 22418 net.cpp:411] attr_score_pos_shift -> attr_score_pos_shift
I0625 17:06:17.759920 22418 net.cpp:150] Setting up attr_score_pos_shift
I0625 17:06:17.759935 22418 net.cpp:157] Top shape: 1 7 (7)
I0625 17:06:17.759945 22418 net.cpp:165] Memory required for data: 1432650644
I0625 17:06:17.759950 22418 layer_factory.hpp:77] Creating layer cls_score
I0625 17:06:17.759958 22418 net.cpp:106] Creating Layer cls_score
I0625 17:06:17.759961 22418 net.cpp:454] cls_score <- fc7_relu7_0_split_1
I0625 17:06:17.759968 22418 net.cpp:411] cls_score -> cls_score
I0625 17:06:17.760210 22418 net.cpp:150] Setting up cls_score
I0625 17:06:17.760216 22418 net.cpp:157] Top shape: 1 2 (2)
I0625 17:06:17.760219 22418 net.cpp:165] Memory required for data: 1432650652
I0625 17:06:17.760234 22418 layer_factory.hpp:77] Creating layer bbox_pred
I0625 17:06:17.760241 22418 net.cpp:106] Creating Layer bbox_pred
I0625 17:06:17.760246 22418 net.cpp:454] bbox_pred <- fc7_relu7_0_split_2
I0625 17:06:17.760251 22418 net.cpp:411] bbox_pred -> bbox_pred
I0625 17:06:17.761008 22418 net.cpp:150] Setting up bbox_pred
I0625 17:06:17.761015 22418 net.cpp:157] Top shape: 1 8 (8)
I0625 17:06:17.761018 22418 net.cpp:165] Memory required for data: 1432650684
I0625 17:06:17.761024 22418 layer_factory.hpp:77] Creating layer loss_attribute
I0625 17:06:17.761034 22418 net.cpp:106] Creating Layer loss_attribute
I0625 17:06:17.761037 22418 net.cpp:454] loss_attribute <- attr_score_pos_shift
I0625 17:06:17.761041 22418 net.cpp:454] loss_attribute <- attrArray
I0625 17:06:17.761047 22418 net.cpp:411] loss_attribute -> loss_attribute
I0625 17:06:17.761086 22418 net.cpp:150] Setting up loss_attribute
I0625 17:06:17.761092 22418 net.cpp:157] Top shape: (1)
I0625 17:06:17.761096 22418 net.cpp:160]     with loss weight 1
I0625 17:06:17.761109 22418 net.cpp:165] Memory required for data: 1432650688
I0625 17:06:17.761112 22418 layer_factory.hpp:77] Creating layer loss_cls
I0625 17:06:17.761121 22418 net.cpp:106] Creating Layer loss_cls
I0625 17:06:17.761124 22418 net.cpp:454] loss_cls <- cls_score
I0625 17:06:17.761129 22418 net.cpp:454] loss_cls <- labels
I0625 17:06:17.761134 22418 net.cpp:411] loss_cls -> loss_cls
I0625 17:06:17.761142 22418 layer_factory.hpp:77] Creating layer loss_cls
I0625 17:06:17.761828 22418 net.cpp:150] Setting up loss_cls
I0625 17:06:17.761837 22418 net.cpp:157] Top shape: (1)
I0625 17:06:17.761842 22418 net.cpp:160]     with loss weight 3
I0625 17:06:17.761857 22418 net.cpp:165] Memory required for data: 1432650692
I0625 17:06:17.761860 22418 layer_factory.hpp:77] Creating layer loss_bbox
I0625 17:06:17.761873 22418 net.cpp:106] Creating Layer loss_bbox
I0625 17:06:17.761878 22418 net.cpp:454] loss_bbox <- bbox_pred
I0625 17:06:17.761883 22418 net.cpp:454] loss_bbox <- bbox_targets
I0625 17:06:17.761888 22418 net.cpp:454] loss_bbox <- bbox_inside_weights
I0625 17:06:17.761893 22418 net.cpp:454] loss_bbox <- bbox_outside_weights
I0625 17:06:17.761898 22418 net.cpp:411] loss_bbox -> loss_bbox
I0625 17:06:17.761981 22418 net.cpp:150] Setting up loss_bbox
I0625 17:06:17.761987 22418 net.cpp:157] Top shape: (1)
I0625 17:06:17.761998 22418 net.cpp:160]     with loss weight 2
I0625 17:06:17.762001 22418 net.cpp:165] Memory required for data: 1432650696
I0625 17:06:17.762004 22418 layer_factory.hpp:77] Creating layer roi_pool5_2
I0625 17:06:17.762012 22418 net.cpp:106] Creating Layer roi_pool5_2
I0625 17:06:17.762014 22418 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0625 17:06:17.762020 22418 net.cpp:454] roi_pool5_2 <- rois_pos
I0625 17:06:17.762024 22418 net.cpp:411] roi_pool5_2 -> pool5_2
I0625 17:06:17.762032 22418 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0625 17:06:17.762095 22418 net.cpp:150] Setting up roi_pool5_2
I0625 17:06:17.762099 22418 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:06:17.762102 22418 net.cpp:165] Memory required for data: 1432751048
I0625 17:06:17.762105 22418 layer_factory.hpp:77] Creating layer pool5_2_conv
I0625 17:06:17.762115 22418 net.cpp:106] Creating Layer pool5_2_conv
I0625 17:06:17.762120 22418 net.cpp:454] pool5_2_conv <- pool5_2
I0625 17:06:17.762126 22418 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0625 17:06:17.769089 22418 net.cpp:150] Setting up pool5_2_conv
I0625 17:06:17.769110 22418 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:06:17.769112 22418 net.cpp:165] Memory required for data: 1432851400
I0625 17:06:17.769121 22418 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0625 17:06:17.769130 22418 net.cpp:106] Creating Layer pool5_2_conv_relu
I0625 17:06:17.769134 22418 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0625 17:06:17.769140 22418 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0625 17:06:17.769299 22418 net.cpp:150] Setting up pool5_2_conv_relu
I0625 17:06:17.769306 22418 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:06:17.769309 22418 net.cpp:165] Memory required for data: 1432951752
I0625 17:06:17.769311 22418 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0625 17:06:17.769323 22418 net.cpp:106] Creating Layer pool5_2_conv2
I0625 17:06:17.769327 22418 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0625 17:06:17.769335 22418 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0625 17:06:17.824072 22418 net.cpp:150] Setting up pool5_2_conv2
I0625 17:06:17.824090 22418 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:06:17.824092 22418 net.cpp:165] Memory required for data: 1433052104
I0625 17:06:17.824100 22418 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0625 17:06:17.824107 22418 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0625 17:06:17.824112 22418 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0625 17:06:17.824128 22418 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0625 17:06:17.824275 22418 net.cpp:150] Setting up pool5_2_conv2_relu
I0625 17:06:17.824281 22418 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 17:06:17.824285 22418 net.cpp:165] Memory required for data: 1433152456
I0625 17:06:17.824286 22418 layer_factory.hpp:77] Creating layer mask_deconv1
I0625 17:06:17.824291 22418 net.cpp:106] Creating Layer mask_deconv1
I0625 17:06:17.824295 22418 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0625 17:06:17.824299 22418 net.cpp:411] mask_deconv1 -> mask_deconv1
I0625 17:06:17.825073 22418 net.cpp:150] Setting up mask_deconv1
I0625 17:06:17.825078 22418 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0625 17:06:17.825079 22418 net.cpp:165] Memory required for data: 1434074056
I0625 17:06:17.825083 22418 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0625 17:06:17.825088 22418 net.cpp:106] Creating Layer pool5_2_conv3
I0625 17:06:17.825090 22418 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0625 17:06:17.825095 22418 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0625 17:06:17.851095 22418 net.cpp:150] Setting up pool5_2_conv3
I0625 17:06:17.851115 22418 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:06:17.851119 22418 net.cpp:165] Memory required for data: 1435917256
I0625 17:06:17.851136 22418 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0625 17:06:17.851147 22418 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0625 17:06:17.851152 22418 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0625 17:06:17.851158 22418 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0625 17:06:17.851303 22418 net.cpp:150] Setting up pool5_2_conv3_relu
I0625 17:06:17.851310 22418 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:06:17.851313 22418 net.cpp:165] Memory required for data: 1437760456
I0625 17:06:17.851327 22418 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0625 17:06:17.851338 22418 net.cpp:106] Creating Layer pool5_2_conv4
I0625 17:06:17.851341 22418 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0625 17:06:17.851346 22418 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0625 17:06:17.902079 22418 net.cpp:150] Setting up pool5_2_conv4
I0625 17:06:17.902107 22418 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:06:17.902109 22418 net.cpp:165] Memory required for data: 1439603656
I0625 17:06:17.902117 22418 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0625 17:06:17.902127 22418 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0625 17:06:17.902132 22418 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0625 17:06:17.902138 22418 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0625 17:06:17.902314 22418 net.cpp:150] Setting up pool5_2_conv4_relu
I0625 17:06:17.902321 22418 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:06:17.902333 22418 net.cpp:165] Memory required for data: 1441446856
I0625 17:06:17.902335 22418 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0625 17:06:17.902340 22418 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0625 17:06:17.902343 22418 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0625 17:06:17.902348 22418 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0625 17:06:17.902354 22418 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0625 17:06:17.902359 22418 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0625 17:06:17.902364 22418 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0625 17:06:17.902413 22418 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0625 17:06:17.902420 22418 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:06:17.902422 22418 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:06:17.902427 22418 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:06:17.902431 22418 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:06:17.902436 22418 net.cpp:165] Memory required for data: 1448819656
I0625 17:06:17.902438 22418 layer_factory.hpp:77] Creating layer query_conv
I0625 17:06:17.902449 22418 net.cpp:106] Creating Layer query_conv
I0625 17:06:17.902454 22418 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0625 17:06:17.902460 22418 net.cpp:411] query_conv -> query_conv
I0625 17:06:17.904139 22418 net.cpp:150] Setting up query_conv
I0625 17:06:17.904146 22418 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0625 17:06:17.904148 22418 net.cpp:165] Memory required for data: 1449050056
I0625 17:06:17.904155 22418 layer_factory.hpp:77] Creating layer key_conv
I0625 17:06:17.904166 22418 net.cpp:106] Creating Layer key_conv
I0625 17:06:17.904172 22418 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0625 17:06:17.904181 22418 net.cpp:411] key_conv -> key_conv
I0625 17:06:17.905747 22418 net.cpp:150] Setting up key_conv
I0625 17:06:17.905755 22418 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0625 17:06:17.905757 22418 net.cpp:165] Memory required for data: 1449280456
I0625 17:06:17.905766 22418 layer_factory.hpp:77] Creating layer value_conv
I0625 17:06:17.905776 22418 net.cpp:106] Creating Layer value_conv
I0625 17:06:17.905781 22418 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0625 17:06:17.905789 22418 net.cpp:411] value_conv -> value_conv
I0625 17:06:17.912688 22418 net.cpp:150] Setting up value_conv
I0625 17:06:17.912698 22418 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:06:17.912700 22418 net.cpp:165] Memory required for data: 1451123656
I0625 17:06:17.912705 22418 layer_factory.hpp:77] Creating layer query_conv_reshape
I0625 17:06:17.912715 22418 net.cpp:106] Creating Layer query_conv_reshape
I0625 17:06:17.912720 22418 net.cpp:454] query_conv_reshape <- query_conv
I0625 17:06:17.912725 22418 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0625 17:06:17.912753 22418 net.cpp:150] Setting up query_conv_reshape
I0625 17:06:17.912758 22418 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0625 17:06:17.912760 22418 net.cpp:165] Memory required for data: 1451354056
I0625 17:06:17.912761 22418 layer_factory.hpp:77] Creating layer key_conv_reshape
I0625 17:06:17.912765 22418 net.cpp:106] Creating Layer key_conv_reshape
I0625 17:06:17.912766 22418 net.cpp:454] key_conv_reshape <- key_conv
I0625 17:06:17.912770 22418 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0625 17:06:17.912811 22418 net.cpp:150] Setting up key_conv_reshape
I0625 17:06:17.912817 22418 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0625 17:06:17.912830 22418 net.cpp:165] Memory required for data: 1451584456
I0625 17:06:17.912832 22418 layer_factory.hpp:77] Creating layer value_conv_reshape
I0625 17:06:17.912837 22418 net.cpp:106] Creating Layer value_conv_reshape
I0625 17:06:17.912840 22418 net.cpp:454] value_conv_reshape <- value_conv
I0625 17:06:17.912847 22418 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0625 17:06:17.912879 22418 net.cpp:150] Setting up value_conv_reshape
I0625 17:06:17.912885 22418 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0625 17:06:17.912887 22418 net.cpp:165] Memory required for data: 1453427656
I0625 17:06:17.912899 22418 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0625 17:06:17.912909 22418 net.cpp:106] Creating Layer query_conv_reshape_perm
I0625 17:06:17.912914 22418 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0625 17:06:17.912927 22418 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0625 17:06:17.913024 22418 net.cpp:150] Setting up query_conv_reshape_perm
I0625 17:06:17.913028 22418 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0625 17:06:17.913031 22418 net.cpp:165] Memory required for data: 1453658056
I0625 17:06:17.913043 22418 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0625 17:06:17.913046 22418 net.cpp:106] Creating Layer key_conv_reshape_perm
I0625 17:06:17.913050 22418 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0625 17:06:17.913056 22418 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0625 17:06:17.913125 22418 net.cpp:150] Setting up key_conv_reshape_perm
I0625 17:06:17.913130 22418 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0625 17:06:17.913132 22418 net.cpp:165] Memory required for data: 1453888456
I0625 17:06:17.913136 22418 layer_factory.hpp:77] Creating layer energy
I0625 17:06:17.913141 22418 net.cpp:106] Creating Layer energy
I0625 17:06:17.913146 22418 net.cpp:454] energy <- query_conv_reshape_perm
I0625 17:06:17.913151 22418 net.cpp:454] energy <- key_conv_reshape_perm
I0625 17:06:17.913156 22418 net.cpp:411] energy -> energy
I0625 17:06:17.913182 22418 net.cpp:150] Setting up energy
I0625 17:06:17.913185 22418 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0625 17:06:17.913188 22418 net.cpp:165] Memory required for data: 1457128456
I0625 17:06:17.913192 22418 layer_factory.hpp:77] Creating layer attention
I0625 17:06:17.913198 22418 net.cpp:106] Creating Layer attention
I0625 17:06:17.913203 22418 net.cpp:454] attention <- energy
I0625 17:06:17.913208 22418 net.cpp:411] attention -> attention
I0625 17:06:17.913373 22418 net.cpp:150] Setting up attention
I0625 17:06:17.913379 22418 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0625 17:06:17.913383 22418 net.cpp:165] Memory required for data: 1460368456
I0625 17:06:17.913386 22418 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0625 17:06:17.913393 22418 net.cpp:106] Creating Layer value_conv_reshape_perm
I0625 17:06:17.913398 22418 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0625 17:06:17.913403 22418 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0625 17:06:17.913477 22418 net.cpp:150] Setting up value_conv_reshape_perm
I0625 17:06:17.913482 22418 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0625 17:06:17.913486 22418 net.cpp:165] Memory required for data: 1462211656
I0625 17:06:17.913489 22418 layer_factory.hpp:77] Creating layer attention_perm
I0625 17:06:17.913494 22418 net.cpp:106] Creating Layer attention_perm
I0625 17:06:17.913498 22418 net.cpp:454] attention_perm <- attention
I0625 17:06:17.913504 22418 net.cpp:411] attention_perm -> attention_perm
I0625 17:06:17.913576 22418 net.cpp:150] Setting up attention_perm
I0625 17:06:17.913581 22418 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0625 17:06:17.913584 22418 net.cpp:165] Memory required for data: 1465451656
I0625 17:06:17.913589 22418 layer_factory.hpp:77] Creating layer out
I0625 17:06:17.913594 22418 net.cpp:106] Creating Layer out
I0625 17:06:17.913599 22418 net.cpp:454] out <- value_conv_reshape_perm
I0625 17:06:17.913604 22418 net.cpp:454] out <- attention_perm
I0625 17:06:17.913609 22418 net.cpp:411] out -> out
I0625 17:06:17.913630 22418 net.cpp:150] Setting up out
I0625 17:06:17.913635 22418 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0625 17:06:17.913637 22418 net.cpp:165] Memory required for data: 1467294856
I0625 17:06:17.913641 22418 layer_factory.hpp:77] Creating layer out_reshape
I0625 17:06:17.913648 22418 net.cpp:106] Creating Layer out_reshape
I0625 17:06:17.913652 22418 net.cpp:454] out_reshape <- out
I0625 17:06:17.913658 22418 net.cpp:411] out_reshape -> out_reshape
I0625 17:06:17.913681 22418 net.cpp:150] Setting up out_reshape
I0625 17:06:17.913686 22418 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:06:17.913688 22418 net.cpp:165] Memory required for data: 1469138056
I0625 17:06:17.913692 22418 layer_factory.hpp:77] Creating layer out_reshape_scale
I0625 17:06:17.913702 22418 net.cpp:106] Creating Layer out_reshape_scale
I0625 17:06:17.913707 22418 net.cpp:454] out_reshape_scale <- out_reshape
I0625 17:06:17.913712 22418 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0625 17:06:17.913780 22418 net.cpp:150] Setting up out_reshape_scale
I0625 17:06:17.913784 22418 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:06:17.913787 22418 net.cpp:165] Memory required for data: 1470981256
I0625 17:06:17.913792 22418 layer_factory.hpp:77] Creating layer out_x
I0625 17:06:17.913800 22418 net.cpp:106] Creating Layer out_x
I0625 17:06:17.913803 22418 net.cpp:454] out_x <- out_reshape_scale
I0625 17:06:17.913808 22418 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0625 17:06:17.913815 22418 net.cpp:411] out_x -> out_x
I0625 17:06:17.913839 22418 net.cpp:150] Setting up out_x
I0625 17:06:17.913844 22418 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 17:06:17.913848 22418 net.cpp:165] Memory required for data: 1472824456
I0625 17:06:17.913851 22418 layer_factory.hpp:77] Creating layer mask_deconv2
I0625 17:06:17.913857 22418 net.cpp:106] Creating Layer mask_deconv2
I0625 17:06:17.913861 22418 net.cpp:454] mask_deconv2 <- out_x
I0625 17:06:17.913868 22418 net.cpp:411] mask_deconv2 -> mask_deconv2
I0625 17:06:17.914675 22418 net.cpp:150] Setting up mask_deconv2
I0625 17:06:17.914681 22418 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0625 17:06:17.914683 22418 net.cpp:165] Memory required for data: 1488065672
I0625 17:06:17.914688 22418 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0625 17:06:17.914698 22418 net.cpp:106] Creating Layer pool5_2_conv5
I0625 17:06:17.914703 22418 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0625 17:06:17.914710 22418 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0625 17:06:17.941253 22418 net.cpp:150] Setting up pool5_2_conv5
I0625 17:06:17.941282 22418 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 17:06:17.941284 22418 net.cpp:165] Memory required for data: 1518548104
I0625 17:06:17.941292 22418 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0625 17:06:17.941308 22418 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0625 17:06:17.941313 22418 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0625 17:06:17.941316 22418 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0625 17:06:17.941483 22418 net.cpp:150] Setting up pool5_2_conv5_relu
I0625 17:06:17.941488 22418 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 17:06:17.941500 22418 net.cpp:165] Memory required for data: 1549030536
I0625 17:06:17.941504 22418 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0625 17:06:17.941512 22418 net.cpp:106] Creating Layer pool5_2_conv6
I0625 17:06:17.941515 22418 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0625 17:06:17.941521 22418 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0625 17:06:17.994210 22418 net.cpp:150] Setting up pool5_2_conv6
I0625 17:06:17.994240 22418 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 17:06:17.994241 22418 net.cpp:165] Memory required for data: 1579512968
I0625 17:06:17.994271 22418 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0625 17:06:17.994282 22418 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0625 17:06:17.994287 22418 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0625 17:06:17.994304 22418 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0625 17:06:17.994814 22418 net.cpp:150] Setting up pool5_2_conv6_relu
I0625 17:06:17.994832 22418 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 17:06:17.994834 22418 net.cpp:165] Memory required for data: 1609995400
I0625 17:06:17.994837 22418 layer_factory.hpp:77] Creating layer mask_deconv3
I0625 17:06:17.994844 22418 net.cpp:106] Creating Layer mask_deconv3
I0625 17:06:17.994848 22418 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0625 17:06:17.994854 22418 net.cpp:411] mask_deconv3 -> mask_deconv3
I0625 17:06:17.995291 22418 net.cpp:150] Setting up mask_deconv3
I0625 17:06:17.995297 22418 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0625 17:06:17.995299 22418 net.cpp:165] Memory required for data: 1670960264
I0625 17:06:17.995303 22418 layer_factory.hpp:77] Creating layer mask_score
I0625 17:06:17.995309 22418 net.cpp:106] Creating Layer mask_score
I0625 17:06:17.995312 22418 net.cpp:454] mask_score <- mask_deconv3
I0625 17:06:17.995316 22418 net.cpp:411] mask_score -> mask_score
I0625 17:06:17.995900 22418 net.cpp:150] Setting up mask_score
I0625 17:06:17.995908 22418 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:06:17.995909 22418 net.cpp:165] Memory required for data: 1672865416
I0625 17:06:17.995913 22418 layer_factory.hpp:77] Creating layer prob
I0625 17:06:17.995918 22418 net.cpp:106] Creating Layer prob
I0625 17:06:17.995920 22418 net.cpp:454] prob <- mask_score
I0625 17:06:17.995923 22418 net.cpp:411] prob -> mask_score_softmax
I0625 17:06:17.996490 22418 net.cpp:150] Setting up prob
I0625 17:06:17.996497 22418 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:06:17.996500 22418 net.cpp:165] Memory required for data: 1674770568
I0625 17:06:17.996501 22418 layer_factory.hpp:77] Creating layer log
I0625 17:06:17.996505 22418 net.cpp:106] Creating Layer log
I0625 17:06:17.996506 22418 net.cpp:454] log <- mask_score_softmax
I0625 17:06:17.996511 22418 net.cpp:411] log -> log
I0625 17:06:17.996549 22418 net.cpp:150] Setting up log
I0625 17:06:17.996556 22418 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:06:17.996558 22418 net.cpp:165] Memory required for data: 1676675720
I0625 17:06:17.996562 22418 layer_factory.hpp:77] Creating layer mult1
I0625 17:06:17.996567 22418 net.cpp:106] Creating Layer mult1
I0625 17:06:17.996569 22418 net.cpp:454] mult1 <- log
I0625 17:06:17.996584 22418 net.cpp:454] mult1 <- mask_targets
I0625 17:06:17.996587 22418 net.cpp:411] mult1 -> mult1
I0625 17:06:17.996620 22418 net.cpp:150] Setting up mult1
I0625 17:06:17.996628 22418 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:06:17.996628 22418 net.cpp:165] Memory required for data: 1678580872
I0625 17:06:17.996630 22418 layer_factory.hpp:77] Creating layer cross_entropy
I0625 17:06:17.996636 22418 net.cpp:106] Creating Layer cross_entropy
I0625 17:06:17.996639 22418 net.cpp:454] cross_entropy <- mult1
I0625 17:06:17.996641 22418 net.cpp:411] cross_entropy -> cross_entropy
I0625 17:06:17.996680 22418 net.cpp:150] Setting up cross_entropy
I0625 17:06:17.996685 22418 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 17:06:17.996688 22418 net.cpp:165] Memory required for data: 1680486024
I0625 17:06:17.996691 22418 layer_factory.hpp:77] Creating layer ce_sum
I0625 17:06:17.996698 22418 net.cpp:106] Creating Layer ce_sum
I0625 17:06:17.996701 22418 net.cpp:454] ce_sum <- cross_entropy
I0625 17:06:17.996714 22418 net.cpp:411] ce_sum -> cross_entropy_sum
I0625 17:06:17.997887 22418 net.cpp:150] Setting up ce_sum
I0625 17:06:17.997895 22418 net.cpp:157] Top shape: 1 1 244 244 (59536)
I0625 17:06:17.997897 22418 net.cpp:165] Memory required for data: 1680724168
I0625 17:06:17.997900 22418 layer_factory.hpp:77] Creating layer ce_mean
I0625 17:06:17.997908 22418 net.cpp:106] Creating Layer ce_mean
I0625 17:06:17.997910 22418 net.cpp:454] ce_mean <- cross_entropy_sum
I0625 17:06:17.997915 22418 net.cpp:411] ce_mean -> cross_entropy_mean
I0625 17:06:17.999132 22418 net.cpp:150] Setting up ce_mean
I0625 17:06:17.999141 22418 net.cpp:157] Top shape: (1)
I0625 17:06:17.999143 22418 net.cpp:160]     with loss weight 1
I0625 17:06:17.999150 22418 net.cpp:165] Memory required for data: 1680724172
I0625 17:06:17.999153 22418 net.cpp:226] ce_mean needs backward computation.
I0625 17:06:17.999155 22418 net.cpp:226] ce_sum needs backward computation.
I0625 17:06:17.999156 22418 net.cpp:226] cross_entropy needs backward computation.
I0625 17:06:17.999158 22418 net.cpp:226] mult1 needs backward computation.
I0625 17:06:17.999161 22418 net.cpp:226] log needs backward computation.
I0625 17:06:17.999162 22418 net.cpp:226] prob needs backward computation.
I0625 17:06:17.999164 22418 net.cpp:226] mask_score needs backward computation.
I0625 17:06:17.999166 22418 net.cpp:226] mask_deconv3 needs backward computation.
I0625 17:06:17.999167 22418 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0625 17:06:17.999169 22418 net.cpp:226] pool5_2_conv6 needs backward computation.
I0625 17:06:17.999171 22418 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0625 17:06:17.999173 22418 net.cpp:226] pool5_2_conv5 needs backward computation.
I0625 17:06:17.999176 22418 net.cpp:226] mask_deconv2 needs backward computation.
I0625 17:06:17.999177 22418 net.cpp:226] out_x needs backward computation.
I0625 17:06:17.999179 22418 net.cpp:226] out_reshape_scale needs backward computation.
I0625 17:06:17.999181 22418 net.cpp:226] out_reshape needs backward computation.
I0625 17:06:17.999183 22418 net.cpp:226] out needs backward computation.
I0625 17:06:17.999186 22418 net.cpp:226] attention_perm needs backward computation.
I0625 17:06:17.999187 22418 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0625 17:06:17.999189 22418 net.cpp:226] attention needs backward computation.
I0625 17:06:17.999191 22418 net.cpp:226] energy needs backward computation.
I0625 17:06:17.999193 22418 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0625 17:06:17.999195 22418 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0625 17:06:17.999197 22418 net.cpp:226] value_conv_reshape needs backward computation.
I0625 17:06:17.999200 22418 net.cpp:226] key_conv_reshape needs backward computation.
I0625 17:06:17.999202 22418 net.cpp:226] query_conv_reshape needs backward computation.
I0625 17:06:17.999204 22418 net.cpp:226] value_conv needs backward computation.
I0625 17:06:17.999207 22418 net.cpp:226] key_conv needs backward computation.
I0625 17:06:17.999208 22418 net.cpp:226] query_conv needs backward computation.
I0625 17:06:17.999210 22418 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0625 17:06:17.999212 22418 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0625 17:06:17.999214 22418 net.cpp:226] pool5_2_conv4 needs backward computation.
I0625 17:06:17.999217 22418 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0625 17:06:17.999218 22418 net.cpp:226] pool5_2_conv3 needs backward computation.
I0625 17:06:17.999220 22418 net.cpp:226] mask_deconv1 needs backward computation.
I0625 17:06:17.999222 22418 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0625 17:06:17.999224 22418 net.cpp:226] pool5_2_conv2 needs backward computation.
I0625 17:06:17.999227 22418 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0625 17:06:17.999228 22418 net.cpp:226] pool5_2_conv needs backward computation.
I0625 17:06:17.999230 22418 net.cpp:226] roi_pool5_2 needs backward computation.
I0625 17:06:17.999233 22418 net.cpp:226] loss_bbox needs backward computation.
I0625 17:06:17.999235 22418 net.cpp:226] loss_cls needs backward computation.
I0625 17:06:17.999238 22418 net.cpp:226] loss_attribute needs backward computation.
I0625 17:06:17.999241 22418 net.cpp:226] bbox_pred needs backward computation.
I0625 17:06:17.999243 22418 net.cpp:226] cls_score needs backward computation.
I0625 17:06:17.999246 22418 net.cpp:226] attr_score_pos_shift needs backward computation.
I0625 17:06:17.999248 22418 net.cpp:226] attr_score_pos needs backward computation.
I0625 17:06:17.999251 22418 net.cpp:226] attr_score needs backward computation.
I0625 17:06:17.999253 22418 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0625 17:06:17.999254 22418 net.cpp:226] relu7 needs backward computation.
I0625 17:06:17.999256 22418 net.cpp:226] fc7 needs backward computation.
I0625 17:06:17.999258 22418 net.cpp:226] relu6 needs backward computation.
I0625 17:06:17.999260 22418 net.cpp:226] fc6 needs backward computation.
I0625 17:06:17.999263 22418 net.cpp:226] roi_pool5 needs backward computation.
I0625 17:06:17.999265 22418 net.cpp:226] roi-data needs backward computation.
I0625 17:06:17.999269 22418 net.cpp:226] proposal needs backward computation.
I0625 17:06:17.999274 22418 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0625 17:06:17.999275 22418 net.cpp:226] rpn_cls_prob needs backward computation.
I0625 17:06:17.999277 22418 net.cpp:226] rpn_loss_bbox needs backward computation.
I0625 17:06:17.999280 22418 net.cpp:226] rpn_loss_cls needs backward computation.
I0625 17:06:17.999286 22418 net.cpp:226] rpn-data needs backward computation.
I0625 17:06:17.999294 22418 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0625 17:06:17.999297 22418 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0625 17:06:17.999300 22418 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0625 17:06:17.999305 22418 net.cpp:226] rpn_bbox_pred needs backward computation.
I0625 17:06:17.999307 22418 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0625 17:06:17.999311 22418 net.cpp:226] rpn_cls_score needs backward computation.
I0625 17:06:17.999315 22418 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0625 17:06:17.999320 22418 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0625 17:06:17.999323 22418 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0625 17:06:17.999327 22418 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0625 17:06:17.999332 22418 net.cpp:226] relu5_3 needs backward computation.
I0625 17:06:17.999336 22418 net.cpp:226] conv5_3 needs backward computation.
I0625 17:06:17.999339 22418 net.cpp:226] relu5_2 needs backward computation.
I0625 17:06:17.999343 22418 net.cpp:226] conv5_2 needs backward computation.
I0625 17:06:17.999346 22418 net.cpp:226] relu5_1 needs backward computation.
I0625 17:06:17.999351 22418 net.cpp:226] conv5_1 needs backward computation.
I0625 17:06:17.999354 22418 net.cpp:226] pool4 needs backward computation.
I0625 17:06:17.999358 22418 net.cpp:226] relu4_3 needs backward computation.
I0625 17:06:17.999363 22418 net.cpp:226] conv4_3 needs backward computation.
I0625 17:06:17.999366 22418 net.cpp:226] relu4_2 needs backward computation.
I0625 17:06:17.999370 22418 net.cpp:226] conv4_2 needs backward computation.
I0625 17:06:17.999373 22418 net.cpp:226] relu4_1 needs backward computation.
I0625 17:06:17.999377 22418 net.cpp:226] conv4_1 needs backward computation.
I0625 17:06:17.999388 22418 net.cpp:226] pool3 needs backward computation.
I0625 17:06:17.999392 22418 net.cpp:226] relu3_3 needs backward computation.
I0625 17:06:17.999395 22418 net.cpp:226] conv3_3 needs backward computation.
I0625 17:06:17.999398 22418 net.cpp:226] relu3_2 needs backward computation.
I0625 17:06:17.999402 22418 net.cpp:226] conv3_2 needs backward computation.
I0625 17:06:17.999405 22418 net.cpp:226] relu3_1 needs backward computation.
I0625 17:06:17.999408 22418 net.cpp:226] conv3_1 needs backward computation.
I0625 17:06:17.999411 22418 net.cpp:228] pool2 does not need backward computation.
I0625 17:06:17.999415 22418 net.cpp:228] relu2_2 does not need backward computation.
I0625 17:06:17.999419 22418 net.cpp:228] conv2_2 does not need backward computation.
I0625 17:06:17.999423 22418 net.cpp:228] relu2_1 does not need backward computation.
I0625 17:06:17.999428 22418 net.cpp:228] conv2_1 does not need backward computation.
I0625 17:06:17.999430 22418 net.cpp:228] pool1 does not need backward computation.
I0625 17:06:17.999434 22418 net.cpp:228] relu1_2 does not need backward computation.
I0625 17:06:17.999439 22418 net.cpp:228] conv1_2 does not need backward computation.
I0625 17:06:17.999441 22418 net.cpp:228] relu1_1 does not need backward computation.
I0625 17:06:17.999445 22418 net.cpp:228] conv1_1 does not need backward computation.
I0625 17:06:17.999449 22418 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0625 17:06:17.999454 22418 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0625 17:06:17.999459 22418 net.cpp:228] data_input-data_0_split does not need backward computation.
I0625 17:06:17.999464 22418 net.cpp:228] input-data does not need backward computation.
I0625 17:06:17.999466 22418 net.cpp:270] This network produces output cross_entropy_mean
I0625 17:06:17.999470 22418 net.cpp:270] This network produces output loss_attribute
I0625 17:06:17.999475 22418 net.cpp:270] This network produces output loss_bbox
I0625 17:06:17.999478 22418 net.cpp:270] This network produces output loss_cls
I0625 17:06:17.999480 22418 net.cpp:270] This network produces output rpn_cls_loss
I0625 17:06:17.999485 22418 net.cpp:270] This network produces output rpn_loss_bbox
I0625 17:06:17.999539 22418 net.cpp:283] Network initialization done.
I0625 17:06:17.999717 22418 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0625 17:06:44.365768 22418 net.cpp:816] Ignoring source layer pool5
I0625 17:06:44.435720 22418 net.cpp:816] Ignoring source layer drop6
I0625 17:06:44.446386 22418 net.cpp:816] Ignoring source layer drop7
I0625 17:06:44.446398 22418 net.cpp:816] Ignoring source layer fc8
Solving...
I0625 17:06:45.690603 22418 solver.cpp:229] Iteration 0, loss = 5.57038
I0625 17:06:45.743551 22418 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.54325 (* 1 = 1.54325 loss)
I0625 17:06:45.743584 22418 solver.cpp:245]     Train net output #1: loss_attribute = 0.304792 (* 1 = 0.304792 loss)
I0625 17:06:45.743594 22418 solver.cpp:245]     Train net output #2: loss_bbox = 0.0916567 (* 2 = 0.183313 loss)
I0625 17:06:45.743602 22418 solver.cpp:245]     Train net output #3: loss_cls = 0.947394 (* 3 = 2.84218 loss)
I0625 17:06:45.743614 22418 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.73882 (* 1 = 0.73882 loss)
I0625 17:06:45.743623 22418 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0189577 (* 1 = 0.0189577 loss)
I0625 17:06:45.743630 22418 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0625 17:07:04.160461 22418 solver.cpp:229] Iteration 20, loss = 2.94432
I0625 17:07:04.213549 22418 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.9084 (* 1 = 1.9084 loss)
I0625 17:07:04.213574 22418 solver.cpp:245]     Train net output #1: loss_attribute = 0.157866 (* 1 = 0.157866 loss)
I0625 17:07:04.213578 22418 solver.cpp:245]     Train net output #2: loss_bbox = 0.10908 (* 2 = 0.21816 loss)
I0625 17:07:04.213583 22418 solver.cpp:245]     Train net output #3: loss_cls = 0.221416 (* 3 = 0.664248 loss)
I0625 17:07:04.213589 22418 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.206376 (* 1 = 0.206376 loss)
I0625 17:07:04.213603 22418 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0175029 (* 1 = 0.0175029 loss)
I0625 17:07:04.213608 22418 sgd_solver.cpp:106] Iteration 20, lr = 0.001
F0625 17:07:05.467209 22418 syncedmem.cpp:56] Check failed: error == cudaSuccess (2 vs. 0)  out of memory
*** Check failure stack trace: ***
./experiments/scripts/faster_rcnn_end2end.sh: line 65: 22418 Aborted                 /usr/bin/python ./tools/train_net.py --gpu ${GPU_ID} --solver models/${PT_DIR}/${NET}/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb ${TRAIN_IMDB} --iters ${ITERS} --cfg experiments/cfgs/faster_rcnn_end2end.yml ${EXTRA_ARGS}
