+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-25_20-55-34
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-25_20-55-34
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 32,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0625 20:55:42.037673 26920 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.0001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0625 20:55:42.037700 26920 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0625 20:55:42.039147 26920 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  top: "attrArray"
  top: "attrArrayInd"
  top: "attrArrayShift"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "attr_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "attr_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "attr_score_pos"
  type: "Eltwise"
  bottom: "attr_score"
  bottom: "attrArrayInd"
  top: "attr_score_pos"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "attr_score_pos_shift"
  type: "Eltwise"
  bottom: "attr_score_pos"
  bottom: "attrArrayShift"
  top: "attr_score_pos_shift"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_attribute"
  type: "SigmoidCrossEntropyLoss"
  bottom: "attr_score_pos_shift"
  bottom: "attrArray"
  top: "loss_attribute"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "mask_score"
  top: "mask_score_softmax"
  softmax_param {
    axis: 1
  }
}
layer {
  name: "log"
  type: "Log"
  bottom: "mask_score_softmax"
  top: "log"
}
layer {
  name: "mult1"
  type: "Eltwise"
  bottom: "log"
  bottom: "mask_targets"
  top: "mult1"
  eltwise_param {
    operation: PROD
  }
}
layer {
  name: "cross_entropy"
  type: "Power"
  bottom: "mult1"
  top: "cross_entropy"
  power_param {
    power: 1
    scale: -1
    shift: 0
  }
}
layer {
  name: "ce_sum"
  type: "Convolution"
  bottom: "cross_entropy"
  top: "cross_entropy_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 1
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "ce_mean"
  type: "Reduction"
  bottom: "cross_entropy_sum"
  top: "cross_entropy_mean"
  loss_weight: 1
  reduction_param {
    operation: MEAN
    axis: 0
  }
}
I0625 20:55:42.039489 26920 layer_factory.hpp:77] Creating layer input-data
I0625 20:55:42.051496 26920 net.cpp:106] Creating Layer input-data
I0625 20:55:42.051512 26920 net.cpp:411] input-data -> data
I0625 20:55:42.051522 26920 net.cpp:411] input-data -> im_info
I0625 20:55:42.051528 26920 net.cpp:411] input-data -> gt_boxes
I0625 20:55:42.051534 26920 net.cpp:411] input-data -> seg_mask_inds
I0625 20:55:42.051551 26920 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0625 20:55:42.062114 26920 net.cpp:150] Setting up input-data
I0625 20:55:42.062139 26920 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 20:55:42.062142 26920 net.cpp:157] Top shape: 1 3 (3)
I0625 20:55:42.062144 26920 net.cpp:157] Top shape: 1 4 (4)
I0625 20:55:42.062146 26920 net.cpp:157] Top shape: 1 2 (2)
I0625 20:55:42.062150 26920 net.cpp:157] Top shape: 1 1 (1)
I0625 20:55:42.062151 26920 net.cpp:165] Memory required for data: 7200040
I0625 20:55:42.062155 26920 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0625 20:55:42.062167 26920 net.cpp:106] Creating Layer data_input-data_0_split
I0625 20:55:42.062171 26920 net.cpp:454] data_input-data_0_split <- data
I0625 20:55:42.062175 26920 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0625 20:55:42.062182 26920 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0625 20:55:42.062202 26920 net.cpp:150] Setting up data_input-data_0_split
I0625 20:55:42.062206 26920 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 20:55:42.062209 26920 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0625 20:55:42.062212 26920 net.cpp:165] Memory required for data: 21600040
I0625 20:55:42.062214 26920 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0625 20:55:42.062217 26920 net.cpp:106] Creating Layer im_info_input-data_1_split
I0625 20:55:42.062219 26920 net.cpp:454] im_info_input-data_1_split <- im_info
I0625 20:55:42.062222 26920 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0625 20:55:42.062225 26920 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0625 20:55:42.062229 26920 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0625 20:55:42.062253 26920 net.cpp:150] Setting up im_info_input-data_1_split
I0625 20:55:42.062263 26920 net.cpp:157] Top shape: 1 3 (3)
I0625 20:55:42.062264 26920 net.cpp:157] Top shape: 1 3 (3)
I0625 20:55:42.062266 26920 net.cpp:157] Top shape: 1 3 (3)
I0625 20:55:42.062268 26920 net.cpp:165] Memory required for data: 21600076
I0625 20:55:42.062270 26920 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0625 20:55:42.062273 26920 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0625 20:55:42.062275 26920 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0625 20:55:42.062278 26920 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0625 20:55:42.062281 26920 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0625 20:55:42.062299 26920 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0625 20:55:42.062304 26920 net.cpp:157] Top shape: 1 4 (4)
I0625 20:55:42.062305 26920 net.cpp:157] Top shape: 1 4 (4)
I0625 20:55:42.062307 26920 net.cpp:165] Memory required for data: 21600108
I0625 20:55:42.062309 26920 layer_factory.hpp:77] Creating layer conv1_1
I0625 20:55:42.062316 26920 net.cpp:106] Creating Layer conv1_1
I0625 20:55:42.062319 26920 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0625 20:55:42.062322 26920 net.cpp:411] conv1_1 -> conv1_1
I0625 20:55:42.265622 26920 net.cpp:150] Setting up conv1_1
I0625 20:55:42.265650 26920 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 20:55:42.265653 26920 net.cpp:165] Memory required for data: 175200108
I0625 20:55:42.265664 26920 layer_factory.hpp:77] Creating layer relu1_1
I0625 20:55:42.265683 26920 net.cpp:106] Creating Layer relu1_1
I0625 20:55:42.265688 26920 net.cpp:454] relu1_1 <- conv1_1
I0625 20:55:42.265691 26920 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0625 20:55:42.265821 26920 net.cpp:150] Setting up relu1_1
I0625 20:55:42.265827 26920 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 20:55:42.265830 26920 net.cpp:165] Memory required for data: 328800108
I0625 20:55:42.265831 26920 layer_factory.hpp:77] Creating layer conv1_2
I0625 20:55:42.265849 26920 net.cpp:106] Creating Layer conv1_2
I0625 20:55:42.265851 26920 net.cpp:454] conv1_2 <- conv1_1
I0625 20:55:42.265856 26920 net.cpp:411] conv1_2 -> conv1_2
I0625 20:55:42.267979 26920 net.cpp:150] Setting up conv1_2
I0625 20:55:42.267992 26920 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 20:55:42.267993 26920 net.cpp:165] Memory required for data: 482400108
I0625 20:55:42.268002 26920 layer_factory.hpp:77] Creating layer relu1_2
I0625 20:55:42.268007 26920 net.cpp:106] Creating Layer relu1_2
I0625 20:55:42.268010 26920 net.cpp:454] relu1_2 <- conv1_2
I0625 20:55:42.268013 26920 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0625 20:55:42.268138 26920 net.cpp:150] Setting up relu1_2
I0625 20:55:42.268143 26920 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0625 20:55:42.268146 26920 net.cpp:165] Memory required for data: 636000108
I0625 20:55:42.268147 26920 layer_factory.hpp:77] Creating layer pool1
I0625 20:55:42.268153 26920 net.cpp:106] Creating Layer pool1
I0625 20:55:42.268155 26920 net.cpp:454] pool1 <- conv1_2
I0625 20:55:42.268159 26920 net.cpp:411] pool1 -> pool1
I0625 20:55:42.268210 26920 net.cpp:150] Setting up pool1
I0625 20:55:42.268214 26920 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0625 20:55:42.268215 26920 net.cpp:165] Memory required for data: 674400108
I0625 20:55:42.268227 26920 layer_factory.hpp:77] Creating layer conv2_1
I0625 20:55:42.268234 26920 net.cpp:106] Creating Layer conv2_1
I0625 20:55:42.268244 26920 net.cpp:454] conv2_1 <- pool1
I0625 20:55:42.268247 26920 net.cpp:411] conv2_1 -> conv2_1
I0625 20:55:42.270036 26920 net.cpp:150] Setting up conv2_1
I0625 20:55:42.270045 26920 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 20:55:42.270047 26920 net.cpp:165] Memory required for data: 751200108
I0625 20:55:42.270066 26920 layer_factory.hpp:77] Creating layer relu2_1
I0625 20:55:42.270071 26920 net.cpp:106] Creating Layer relu2_1
I0625 20:55:42.270074 26920 net.cpp:454] relu2_1 <- conv2_1
I0625 20:55:42.270076 26920 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0625 20:55:42.270578 26920 net.cpp:150] Setting up relu2_1
I0625 20:55:42.270586 26920 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 20:55:42.270587 26920 net.cpp:165] Memory required for data: 828000108
I0625 20:55:42.270589 26920 layer_factory.hpp:77] Creating layer conv2_2
I0625 20:55:42.270596 26920 net.cpp:106] Creating Layer conv2_2
I0625 20:55:42.270597 26920 net.cpp:454] conv2_2 <- conv2_1
I0625 20:55:42.270601 26920 net.cpp:411] conv2_2 -> conv2_2
I0625 20:55:42.271873 26920 net.cpp:150] Setting up conv2_2
I0625 20:55:42.271883 26920 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 20:55:42.271884 26920 net.cpp:165] Memory required for data: 904800108
I0625 20:55:42.271888 26920 layer_factory.hpp:77] Creating layer relu2_2
I0625 20:55:42.271893 26920 net.cpp:106] Creating Layer relu2_2
I0625 20:55:42.271894 26920 net.cpp:454] relu2_2 <- conv2_2
I0625 20:55:42.271898 26920 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0625 20:55:42.272038 26920 net.cpp:150] Setting up relu2_2
I0625 20:55:42.272043 26920 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0625 20:55:42.272045 26920 net.cpp:165] Memory required for data: 981600108
I0625 20:55:42.272047 26920 layer_factory.hpp:77] Creating layer pool2
I0625 20:55:42.272051 26920 net.cpp:106] Creating Layer pool2
I0625 20:55:42.272053 26920 net.cpp:454] pool2 <- conv2_2
I0625 20:55:42.272055 26920 net.cpp:411] pool2 -> pool2
I0625 20:55:42.272114 26920 net.cpp:150] Setting up pool2
I0625 20:55:42.272117 26920 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0625 20:55:42.272119 26920 net.cpp:165] Memory required for data: 1000800108
I0625 20:55:42.272120 26920 layer_factory.hpp:77] Creating layer conv3_1
I0625 20:55:42.272135 26920 net.cpp:106] Creating Layer conv3_1
I0625 20:55:42.272137 26920 net.cpp:454] conv3_1 <- pool2
I0625 20:55:42.272142 26920 net.cpp:411] conv3_1 -> conv3_1
I0625 20:55:42.273895 26920 net.cpp:150] Setting up conv3_1
I0625 20:55:42.273902 26920 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 20:55:42.273905 26920 net.cpp:165] Memory required for data: 1039200108
I0625 20:55:42.273910 26920 layer_factory.hpp:77] Creating layer relu3_1
I0625 20:55:42.273916 26920 net.cpp:106] Creating Layer relu3_1
I0625 20:55:42.273917 26920 net.cpp:454] relu3_1 <- conv3_1
I0625 20:55:42.273919 26920 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0625 20:55:42.274045 26920 net.cpp:150] Setting up relu3_1
I0625 20:55:42.274051 26920 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 20:55:42.274052 26920 net.cpp:165] Memory required for data: 1077600108
I0625 20:55:42.274055 26920 layer_factory.hpp:77] Creating layer conv3_2
I0625 20:55:42.274072 26920 net.cpp:106] Creating Layer conv3_2
I0625 20:55:42.274075 26920 net.cpp:454] conv3_2 <- conv3_1
I0625 20:55:42.274078 26920 net.cpp:411] conv3_2 -> conv3_2
I0625 20:55:42.276043 26920 net.cpp:150] Setting up conv3_2
I0625 20:55:42.276052 26920 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 20:55:42.276054 26920 net.cpp:165] Memory required for data: 1116000108
I0625 20:55:42.276059 26920 layer_factory.hpp:77] Creating layer relu3_2
I0625 20:55:42.276064 26920 net.cpp:106] Creating Layer relu3_2
I0625 20:55:42.276067 26920 net.cpp:454] relu3_2 <- conv3_2
I0625 20:55:42.276070 26920 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0625 20:55:42.276185 26920 net.cpp:150] Setting up relu3_2
I0625 20:55:42.276190 26920 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 20:55:42.276191 26920 net.cpp:165] Memory required for data: 1154400108
I0625 20:55:42.276193 26920 layer_factory.hpp:77] Creating layer conv3_3
I0625 20:55:42.276199 26920 net.cpp:106] Creating Layer conv3_3
I0625 20:55:42.276201 26920 net.cpp:454] conv3_3 <- conv3_2
I0625 20:55:42.276204 26920 net.cpp:411] conv3_3 -> conv3_3
I0625 20:55:42.278182 26920 net.cpp:150] Setting up conv3_3
I0625 20:55:42.278192 26920 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 20:55:42.278193 26920 net.cpp:165] Memory required for data: 1192800108
I0625 20:55:42.278208 26920 layer_factory.hpp:77] Creating layer relu3_3
I0625 20:55:42.278213 26920 net.cpp:106] Creating Layer relu3_3
I0625 20:55:42.278216 26920 net.cpp:454] relu3_3 <- conv3_3
I0625 20:55:42.278219 26920 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0625 20:55:42.278367 26920 net.cpp:150] Setting up relu3_3
I0625 20:55:42.278371 26920 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0625 20:55:42.278373 26920 net.cpp:165] Memory required for data: 1231200108
I0625 20:55:42.278375 26920 layer_factory.hpp:77] Creating layer pool3
I0625 20:55:42.278389 26920 net.cpp:106] Creating Layer pool3
I0625 20:55:42.278393 26920 net.cpp:454] pool3 <- conv3_3
I0625 20:55:42.278396 26920 net.cpp:411] pool3 -> pool3
I0625 20:55:42.278424 26920 net.cpp:150] Setting up pool3
I0625 20:55:42.278439 26920 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0625 20:55:42.278441 26920 net.cpp:165] Memory required for data: 1240800108
I0625 20:55:42.278442 26920 layer_factory.hpp:77] Creating layer conv4_1
I0625 20:55:42.278457 26920 net.cpp:106] Creating Layer conv4_1
I0625 20:55:42.278460 26920 net.cpp:454] conv4_1 <- pool3
I0625 20:55:42.278463 26920 net.cpp:411] conv4_1 -> conv4_1
I0625 20:55:42.282315 26920 net.cpp:150] Setting up conv4_1
I0625 20:55:42.282351 26920 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 20:55:42.282354 26920 net.cpp:165] Memory required for data: 1260000108
I0625 20:55:42.282361 26920 layer_factory.hpp:77] Creating layer relu4_1
I0625 20:55:42.282378 26920 net.cpp:106] Creating Layer relu4_1
I0625 20:55:42.282382 26920 net.cpp:454] relu4_1 <- conv4_1
I0625 20:55:42.282387 26920 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0625 20:55:42.282516 26920 net.cpp:150] Setting up relu4_1
I0625 20:55:42.282522 26920 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 20:55:42.282524 26920 net.cpp:165] Memory required for data: 1279200108
I0625 20:55:42.282537 26920 layer_factory.hpp:77] Creating layer conv4_2
I0625 20:55:42.282543 26920 net.cpp:106] Creating Layer conv4_2
I0625 20:55:42.282546 26920 net.cpp:454] conv4_2 <- conv4_1
I0625 20:55:42.282549 26920 net.cpp:411] conv4_2 -> conv4_2
I0625 20:55:42.287369 26920 net.cpp:150] Setting up conv4_2
I0625 20:55:42.287397 26920 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 20:55:42.287400 26920 net.cpp:165] Memory required for data: 1298400108
I0625 20:55:42.287410 26920 layer_factory.hpp:77] Creating layer relu4_2
I0625 20:55:42.287428 26920 net.cpp:106] Creating Layer relu4_2
I0625 20:55:42.287432 26920 net.cpp:454] relu4_2 <- conv4_2
I0625 20:55:42.287436 26920 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0625 20:55:42.287925 26920 net.cpp:150] Setting up relu4_2
I0625 20:55:42.287932 26920 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 20:55:42.287935 26920 net.cpp:165] Memory required for data: 1317600108
I0625 20:55:42.287936 26920 layer_factory.hpp:77] Creating layer conv4_3
I0625 20:55:42.287942 26920 net.cpp:106] Creating Layer conv4_3
I0625 20:55:42.287945 26920 net.cpp:454] conv4_3 <- conv4_2
I0625 20:55:42.287959 26920 net.cpp:411] conv4_3 -> conv4_3
I0625 20:55:42.292230 26920 net.cpp:150] Setting up conv4_3
I0625 20:55:42.292251 26920 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 20:55:42.292253 26920 net.cpp:165] Memory required for data: 1336800108
I0625 20:55:42.292270 26920 layer_factory.hpp:77] Creating layer relu4_3
I0625 20:55:42.292279 26920 net.cpp:106] Creating Layer relu4_3
I0625 20:55:42.292294 26920 net.cpp:454] relu4_3 <- conv4_3
I0625 20:55:42.292299 26920 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0625 20:55:42.292448 26920 net.cpp:150] Setting up relu4_3
I0625 20:55:42.292452 26920 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0625 20:55:42.292454 26920 net.cpp:165] Memory required for data: 1356000108
I0625 20:55:42.292456 26920 layer_factory.hpp:77] Creating layer pool4
I0625 20:55:42.292461 26920 net.cpp:106] Creating Layer pool4
I0625 20:55:42.292464 26920 net.cpp:454] pool4 <- conv4_3
I0625 20:55:42.292467 26920 net.cpp:411] pool4 -> pool4
I0625 20:55:42.292527 26920 net.cpp:150] Setting up pool4
I0625 20:55:42.292531 26920 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 20:55:42.292532 26920 net.cpp:165] Memory required for data: 1360903020
I0625 20:55:42.292544 26920 layer_factory.hpp:77] Creating layer conv5_1
I0625 20:55:42.292549 26920 net.cpp:106] Creating Layer conv5_1
I0625 20:55:42.292567 26920 net.cpp:454] conv5_1 <- pool4
I0625 20:55:42.292570 26920 net.cpp:411] conv5_1 -> conv5_1
I0625 20:55:42.296664 26920 net.cpp:150] Setting up conv5_1
I0625 20:55:42.296682 26920 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 20:55:42.296695 26920 net.cpp:165] Memory required for data: 1365805932
I0625 20:55:42.296702 26920 layer_factory.hpp:77] Creating layer relu5_1
I0625 20:55:42.296721 26920 net.cpp:106] Creating Layer relu5_1
I0625 20:55:42.296725 26920 net.cpp:454] relu5_1 <- conv5_1
I0625 20:55:42.296730 26920 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0625 20:55:42.296867 26920 net.cpp:150] Setting up relu5_1
I0625 20:55:42.296875 26920 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 20:55:42.296886 26920 net.cpp:165] Memory required for data: 1370708844
I0625 20:55:42.296888 26920 layer_factory.hpp:77] Creating layer conv5_2
I0625 20:55:42.296896 26920 net.cpp:106] Creating Layer conv5_2
I0625 20:55:42.296898 26920 net.cpp:454] conv5_2 <- conv5_1
I0625 20:55:42.296902 26920 net.cpp:411] conv5_2 -> conv5_2
I0625 20:55:42.301637 26920 net.cpp:150] Setting up conv5_2
I0625 20:55:42.301656 26920 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 20:55:42.301659 26920 net.cpp:165] Memory required for data: 1375611756
I0625 20:55:42.301666 26920 layer_factory.hpp:77] Creating layer relu5_2
I0625 20:55:42.301672 26920 net.cpp:106] Creating Layer relu5_2
I0625 20:55:42.301686 26920 net.cpp:454] relu5_2 <- conv5_2
I0625 20:55:42.301690 26920 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0625 20:55:42.301841 26920 net.cpp:150] Setting up relu5_2
I0625 20:55:42.301846 26920 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 20:55:42.301847 26920 net.cpp:165] Memory required for data: 1380514668
I0625 20:55:42.301849 26920 layer_factory.hpp:77] Creating layer conv5_3
I0625 20:55:42.301858 26920 net.cpp:106] Creating Layer conv5_3
I0625 20:55:42.301861 26920 net.cpp:454] conv5_3 <- conv5_2
I0625 20:55:42.301864 26920 net.cpp:411] conv5_3 -> conv5_3
I0625 20:55:42.306095 26920 net.cpp:150] Setting up conv5_3
I0625 20:55:42.306115 26920 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 20:55:42.306118 26920 net.cpp:165] Memory required for data: 1385417580
I0625 20:55:42.306124 26920 layer_factory.hpp:77] Creating layer relu5_3
I0625 20:55:42.306133 26920 net.cpp:106] Creating Layer relu5_3
I0625 20:55:42.306146 26920 net.cpp:454] relu5_3 <- conv5_3
I0625 20:55:42.306151 26920 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0625 20:55:42.306308 26920 net.cpp:150] Setting up relu5_3
I0625 20:55:42.306314 26920 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 20:55:42.306315 26920 net.cpp:165] Memory required for data: 1390320492
I0625 20:55:42.306318 26920 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0625 20:55:42.306322 26920 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0625 20:55:42.306324 26920 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0625 20:55:42.306327 26920 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0625 20:55:42.306332 26920 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0625 20:55:42.306335 26920 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0625 20:55:42.306392 26920 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0625 20:55:42.306396 26920 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 20:55:42.306411 26920 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 20:55:42.306412 26920 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 20:55:42.306414 26920 net.cpp:165] Memory required for data: 1405029228
I0625 20:55:42.306416 26920 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0625 20:55:42.306432 26920 net.cpp:106] Creating Layer rpn_conv/3x3
I0625 20:55:42.306434 26920 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0625 20:55:42.306448 26920 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0625 20:55:42.356305 26920 net.cpp:150] Setting up rpn_conv/3x3
I0625 20:55:42.356321 26920 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 20:55:42.356324 26920 net.cpp:165] Memory required for data: 1409932140
I0625 20:55:42.356330 26920 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0625 20:55:42.356338 26920 net.cpp:106] Creating Layer rpn_relu/3x3
I0625 20:55:42.356340 26920 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0625 20:55:42.356355 26920 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0625 20:55:42.356477 26920 net.cpp:150] Setting up rpn_relu/3x3
I0625 20:55:42.356482 26920 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 20:55:42.356484 26920 net.cpp:165] Memory required for data: 1414835052
I0625 20:55:42.356487 26920 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0625 20:55:42.356490 26920 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0625 20:55:42.356492 26920 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0625 20:55:42.356495 26920 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0625 20:55:42.356498 26920 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0625 20:55:42.356544 26920 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0625 20:55:42.356547 26920 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 20:55:42.356560 26920 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0625 20:55:42.356561 26920 net.cpp:165] Memory required for data: 1424640876
I0625 20:55:42.356564 26920 layer_factory.hpp:77] Creating layer rpn_cls_score
I0625 20:55:42.356570 26920 net.cpp:106] Creating Layer rpn_cls_score
I0625 20:55:42.356572 26920 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0625 20:55:42.356576 26920 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0625 20:55:42.358076 26920 net.cpp:150] Setting up rpn_cls_score
I0625 20:55:42.358084 26920 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 20:55:42.358086 26920 net.cpp:165] Memory required for data: 1424928156
I0625 20:55:42.358100 26920 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0625 20:55:42.358106 26920 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0625 20:55:42.358108 26920 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0625 20:55:42.358111 26920 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0625 20:55:42.358115 26920 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0625 20:55:42.358165 26920 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0625 20:55:42.358177 26920 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 20:55:42.358180 26920 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 20:55:42.358181 26920 net.cpp:165] Memory required for data: 1425502716
I0625 20:55:42.358183 26920 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0625 20:55:42.358201 26920 net.cpp:106] Creating Layer rpn_bbox_pred
I0625 20:55:42.358202 26920 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0625 20:55:42.358222 26920 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0625 20:55:42.359766 26920 net.cpp:150] Setting up rpn_bbox_pred
I0625 20:55:42.359773 26920 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 20:55:42.359776 26920 net.cpp:165] Memory required for data: 1426077276
I0625 20:55:42.359779 26920 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 20:55:42.359793 26920 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 20:55:42.359796 26920 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0625 20:55:42.359809 26920 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0625 20:55:42.359814 26920 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0625 20:55:42.359849 26920 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0625 20:55:42.359853 26920 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 20:55:42.359866 26920 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 20:55:42.359867 26920 net.cpp:165] Memory required for data: 1427226396
I0625 20:55:42.359869 26920 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0625 20:55:42.359874 26920 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0625 20:55:42.359886 26920 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0625 20:55:42.359889 26920 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0625 20:55:42.359905 26920 net.cpp:150] Setting up rpn_cls_score_reshape
I0625 20:55:42.359908 26920 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 20:55:42.359910 26920 net.cpp:165] Memory required for data: 1427513676
I0625 20:55:42.359911 26920 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 20:55:42.359915 26920 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 20:55:42.359916 26920 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0625 20:55:42.359920 26920 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0625 20:55:42.359923 26920 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0625 20:55:42.359944 26920 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0625 20:55:42.359948 26920 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 20:55:42.359951 26920 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 20:55:42.359951 26920 net.cpp:165] Memory required for data: 1428088236
I0625 20:55:42.359953 26920 layer_factory.hpp:77] Creating layer rpn-data
I0625 20:55:42.360285 26920 net.cpp:106] Creating Layer rpn-data
I0625 20:55:42.360291 26920 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0625 20:55:42.360296 26920 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0625 20:55:42.360298 26920 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0625 20:55:42.360301 26920 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0625 20:55:42.360304 26920 net.cpp:411] rpn-data -> rpn_labels
I0625 20:55:42.360308 26920 net.cpp:411] rpn-data -> rpn_bbox_targets
I0625 20:55:42.360312 26920 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0625 20:55:42.360316 26920 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0625 20:55:42.361119 26920 net.cpp:150] Setting up rpn-data
I0625 20:55:42.361126 26920 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0625 20:55:42.361129 26920 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 20:55:42.361131 26920 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 20:55:42.361133 26920 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0625 20:55:42.361135 26920 net.cpp:165] Memory required for data: 1429955556
I0625 20:55:42.361137 26920 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0625 20:55:42.361142 26920 net.cpp:106] Creating Layer rpn_loss_cls
I0625 20:55:42.361145 26920 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0625 20:55:42.361148 26920 net.cpp:454] rpn_loss_cls <- rpn_labels
I0625 20:55:42.361151 26920 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0625 20:55:42.361177 26920 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0625 20:55:42.363587 26920 net.cpp:150] Setting up rpn_loss_cls
I0625 20:55:42.363595 26920 net.cpp:157] Top shape: (1)
I0625 20:55:42.363597 26920 net.cpp:160]     with loss weight 1
I0625 20:55:42.363612 26920 net.cpp:165] Memory required for data: 1429955560
I0625 20:55:42.363615 26920 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0625 20:55:42.363623 26920 net.cpp:106] Creating Layer rpn_loss_bbox
I0625 20:55:42.363626 26920 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0625 20:55:42.363629 26920 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0625 20:55:42.363632 26920 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0625 20:55:42.363634 26920 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0625 20:55:42.363636 26920 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0625 20:55:42.364805 26920 net.cpp:150] Setting up rpn_loss_bbox
I0625 20:55:42.364815 26920 net.cpp:157] Top shape: (1)
I0625 20:55:42.364817 26920 net.cpp:160]     with loss weight 1
I0625 20:55:42.364821 26920 net.cpp:165] Memory required for data: 1429955564
I0625 20:55:42.364825 26920 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0625 20:55:42.364828 26920 net.cpp:106] Creating Layer rpn_cls_prob
I0625 20:55:42.364830 26920 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0625 20:55:42.364835 26920 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0625 20:55:42.365000 26920 net.cpp:150] Setting up rpn_cls_prob
I0625 20:55:42.365005 26920 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0625 20:55:42.365007 26920 net.cpp:165] Memory required for data: 1430242844
I0625 20:55:42.365010 26920 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0625 20:55:42.365025 26920 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0625 20:55:42.365027 26920 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0625 20:55:42.365032 26920 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0625 20:55:42.365068 26920 net.cpp:150] Setting up rpn_cls_prob_reshape
I0625 20:55:42.365072 26920 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0625 20:55:42.365074 26920 net.cpp:165] Memory required for data: 1430530124
I0625 20:55:42.365075 26920 layer_factory.hpp:77] Creating layer proposal
I0625 20:55:42.365551 26920 net.cpp:106] Creating Layer proposal
I0625 20:55:42.365559 26920 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0625 20:55:42.365562 26920 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0625 20:55:42.365566 26920 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0625 20:55:42.365568 26920 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0625 20:55:42.366416 26920 net.cpp:150] Setting up proposal
I0625 20:55:42.366425 26920 net.cpp:157] Top shape: 1 5 (5)
I0625 20:55:42.366426 26920 net.cpp:165] Memory required for data: 1430530144
I0625 20:55:42.366430 26920 layer_factory.hpp:77] Creating layer roi-data
I0625 20:55:42.366642 26920 net.cpp:106] Creating Layer roi-data
I0625 20:55:42.366649 26920 net.cpp:454] roi-data <- rpn_rois
I0625 20:55:42.366652 26920 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0625 20:55:42.366655 26920 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0625 20:55:42.366667 26920 net.cpp:454] roi-data <- seg_mask_inds
I0625 20:55:42.366669 26920 net.cpp:454] roi-data <- flipped
I0625 20:55:42.366673 26920 net.cpp:411] roi-data -> rois
I0625 20:55:42.366678 26920 net.cpp:411] roi-data -> labels
I0625 20:55:42.366683 26920 net.cpp:411] roi-data -> bbox_targets
I0625 20:55:42.366688 26920 net.cpp:411] roi-data -> bbox_inside_weights
I0625 20:55:42.366700 26920 net.cpp:411] roi-data -> bbox_outside_weights
I0625 20:55:42.366704 26920 net.cpp:411] roi-data -> mask_targets
I0625 20:55:42.366719 26920 net.cpp:411] roi-data -> rois_pos
I0625 20:55:42.366724 26920 net.cpp:411] roi-data -> attrArray
I0625 20:55:42.366726 26920 net.cpp:411] roi-data -> attrArrayInd
I0625 20:55:42.366731 26920 net.cpp:411] roi-data -> attrArrayShift
I0625 20:55:42.367029 26920 net.cpp:150] Setting up roi-data
I0625 20:55:42.367036 26920 net.cpp:157] Top shape: 1 5 (5)
I0625 20:55:42.367039 26920 net.cpp:157] Top shape: 1 1 (1)
I0625 20:55:42.367041 26920 net.cpp:157] Top shape: 1 8 (8)
I0625 20:55:42.367043 26920 net.cpp:157] Top shape: 1 8 (8)
I0625 20:55:42.367045 26920 net.cpp:157] Top shape: 1 8 (8)
I0625 20:55:42.367048 26920 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 20:55:42.367050 26920 net.cpp:157] Top shape: 1 5 (5)
I0625 20:55:42.367053 26920 net.cpp:157] Top shape: 1 7 (7)
I0625 20:55:42.367054 26920 net.cpp:157] Top shape: 1 7 (7)
I0625 20:55:42.367056 26920 net.cpp:157] Top shape: 1 7 (7)
I0625 20:55:42.367058 26920 net.cpp:165] Memory required for data: 1432435520
I0625 20:55:42.367060 26920 layer_factory.hpp:77] Creating layer roi_pool5
I0625 20:55:42.367069 26920 net.cpp:106] Creating Layer roi_pool5
I0625 20:55:42.367072 26920 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0625 20:55:42.367075 26920 net.cpp:454] roi_pool5 <- rois
I0625 20:55:42.367079 26920 net.cpp:411] roi_pool5 -> pool5
I0625 20:55:42.367082 26920 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0625 20:55:42.367148 26920 net.cpp:150] Setting up roi_pool5
I0625 20:55:42.367152 26920 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 20:55:42.367154 26920 net.cpp:165] Memory required for data: 1432535872
I0625 20:55:42.367156 26920 layer_factory.hpp:77] Creating layer fc6
I0625 20:55:42.367163 26920 net.cpp:106] Creating Layer fc6
I0625 20:55:42.367166 26920 net.cpp:454] fc6 <- pool5
I0625 20:55:42.367172 26920 net.cpp:411] fc6 -> fc6
I0625 20:55:42.507046 26920 net.cpp:150] Setting up fc6
I0625 20:55:42.507069 26920 net.cpp:157] Top shape: 1 4096 (4096)
I0625 20:55:42.507071 26920 net.cpp:165] Memory required for data: 1432552256
I0625 20:55:42.507086 26920 layer_factory.hpp:77] Creating layer relu6
I0625 20:55:42.507105 26920 net.cpp:106] Creating Layer relu6
I0625 20:55:42.507109 26920 net.cpp:454] relu6 <- fc6
I0625 20:55:42.507123 26920 net.cpp:397] relu6 -> fc6 (in-place)
I0625 20:55:42.507334 26920 net.cpp:150] Setting up relu6
I0625 20:55:42.507341 26920 net.cpp:157] Top shape: 1 4096 (4096)
I0625 20:55:42.507344 26920 net.cpp:165] Memory required for data: 1432568640
I0625 20:55:42.507346 26920 layer_factory.hpp:77] Creating layer fc7
I0625 20:55:42.507351 26920 net.cpp:106] Creating Layer fc7
I0625 20:55:42.507354 26920 net.cpp:454] fc7 <- fc6
I0625 20:55:42.507357 26920 net.cpp:411] fc7 -> fc7
I0625 20:55:42.530784 26920 net.cpp:150] Setting up fc7
I0625 20:55:42.530807 26920 net.cpp:157] Top shape: 1 4096 (4096)
I0625 20:55:42.530810 26920 net.cpp:165] Memory required for data: 1432585024
I0625 20:55:42.530817 26920 layer_factory.hpp:77] Creating layer relu7
I0625 20:55:42.530825 26920 net.cpp:106] Creating Layer relu7
I0625 20:55:42.530839 26920 net.cpp:454] relu7 <- fc7
I0625 20:55:42.530845 26920 net.cpp:397] relu7 -> fc7 (in-place)
I0625 20:55:42.531047 26920 net.cpp:150] Setting up relu7
I0625 20:55:42.531055 26920 net.cpp:157] Top shape: 1 4096 (4096)
I0625 20:55:42.531057 26920 net.cpp:165] Memory required for data: 1432601408
I0625 20:55:42.531059 26920 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0625 20:55:42.531065 26920 net.cpp:106] Creating Layer fc7_relu7_0_split
I0625 20:55:42.531069 26920 net.cpp:454] fc7_relu7_0_split <- fc7
I0625 20:55:42.531081 26920 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0625 20:55:42.531085 26920 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0625 20:55:42.531090 26920 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0625 20:55:42.531172 26920 net.cpp:150] Setting up fc7_relu7_0_split
I0625 20:55:42.531175 26920 net.cpp:157] Top shape: 1 4096 (4096)
I0625 20:55:42.531188 26920 net.cpp:157] Top shape: 1 4096 (4096)
I0625 20:55:42.531189 26920 net.cpp:157] Top shape: 1 4096 (4096)
I0625 20:55:42.531190 26920 net.cpp:165] Memory required for data: 1432650560
I0625 20:55:42.531193 26920 layer_factory.hpp:77] Creating layer attr_score
I0625 20:55:42.531208 26920 net.cpp:106] Creating Layer attr_score
I0625 20:55:42.531210 26920 net.cpp:454] attr_score <- fc7_relu7_0_split_0
I0625 20:55:42.531224 26920 net.cpp:411] attr_score -> attr_score
I0625 20:55:42.531940 26920 net.cpp:150] Setting up attr_score
I0625 20:55:42.531945 26920 net.cpp:157] Top shape: 1 7 (7)
I0625 20:55:42.531947 26920 net.cpp:165] Memory required for data: 1432650588
I0625 20:55:42.531950 26920 layer_factory.hpp:77] Creating layer attr_score_pos
I0625 20:55:42.531955 26920 net.cpp:106] Creating Layer attr_score_pos
I0625 20:55:42.531957 26920 net.cpp:454] attr_score_pos <- attr_score
I0625 20:55:42.531960 26920 net.cpp:454] attr_score_pos <- attrArrayInd
I0625 20:55:42.531962 26920 net.cpp:411] attr_score_pos -> attr_score_pos
I0625 20:55:42.532003 26920 net.cpp:150] Setting up attr_score_pos
I0625 20:55:42.532016 26920 net.cpp:157] Top shape: 1 7 (7)
I0625 20:55:42.532017 26920 net.cpp:165] Memory required for data: 1432650616
I0625 20:55:42.532019 26920 layer_factory.hpp:77] Creating layer attr_score_pos_shift
I0625 20:55:42.532023 26920 net.cpp:106] Creating Layer attr_score_pos_shift
I0625 20:55:42.532024 26920 net.cpp:454] attr_score_pos_shift <- attr_score_pos
I0625 20:55:42.532037 26920 net.cpp:454] attr_score_pos_shift <- attrArrayShift
I0625 20:55:42.532039 26920 net.cpp:411] attr_score_pos_shift -> attr_score_pos_shift
I0625 20:55:42.532064 26920 net.cpp:150] Setting up attr_score_pos_shift
I0625 20:55:42.532080 26920 net.cpp:157] Top shape: 1 7 (7)
I0625 20:55:42.532081 26920 net.cpp:165] Memory required for data: 1432650644
I0625 20:55:42.532083 26920 layer_factory.hpp:77] Creating layer cls_score
I0625 20:55:42.532088 26920 net.cpp:106] Creating Layer cls_score
I0625 20:55:42.532100 26920 net.cpp:454] cls_score <- fc7_relu7_0_split_1
I0625 20:55:42.532104 26920 net.cpp:411] cls_score -> cls_score
I0625 20:55:42.532389 26920 net.cpp:150] Setting up cls_score
I0625 20:55:42.532393 26920 net.cpp:157] Top shape: 1 2 (2)
I0625 20:55:42.532397 26920 net.cpp:165] Memory required for data: 1432650652
I0625 20:55:42.532409 26920 layer_factory.hpp:77] Creating layer bbox_pred
I0625 20:55:42.532414 26920 net.cpp:106] Creating Layer bbox_pred
I0625 20:55:42.532416 26920 net.cpp:454] bbox_pred <- fc7_relu7_0_split_2
I0625 20:55:42.532433 26920 net.cpp:411] bbox_pred -> bbox_pred
I0625 20:55:42.533193 26920 net.cpp:150] Setting up bbox_pred
I0625 20:55:42.533197 26920 net.cpp:157] Top shape: 1 8 (8)
I0625 20:55:42.533200 26920 net.cpp:165] Memory required for data: 1432650684
I0625 20:55:42.533212 26920 layer_factory.hpp:77] Creating layer loss_attribute
I0625 20:55:42.533217 26920 net.cpp:106] Creating Layer loss_attribute
I0625 20:55:42.533219 26920 net.cpp:454] loss_attribute <- attr_score_pos_shift
I0625 20:55:42.533231 26920 net.cpp:454] loss_attribute <- attrArray
I0625 20:55:42.533234 26920 net.cpp:411] loss_attribute -> loss_attribute
I0625 20:55:42.533288 26920 net.cpp:150] Setting up loss_attribute
I0625 20:55:42.533291 26920 net.cpp:157] Top shape: (1)
I0625 20:55:42.533293 26920 net.cpp:160]     with loss weight 1
I0625 20:55:42.533313 26920 net.cpp:165] Memory required for data: 1432650688
I0625 20:55:42.533314 26920 layer_factory.hpp:77] Creating layer loss_cls
I0625 20:55:42.533329 26920 net.cpp:106] Creating Layer loss_cls
I0625 20:55:42.533331 26920 net.cpp:454] loss_cls <- cls_score
I0625 20:55:42.533334 26920 net.cpp:454] loss_cls <- labels
I0625 20:55:42.533337 26920 net.cpp:411] loss_cls -> loss_cls
I0625 20:55:42.533341 26920 layer_factory.hpp:77] Creating layer loss_cls
I0625 20:55:42.534027 26920 net.cpp:150] Setting up loss_cls
I0625 20:55:42.534034 26920 net.cpp:157] Top shape: (1)
I0625 20:55:42.534046 26920 net.cpp:160]     with loss weight 3
I0625 20:55:42.534051 26920 net.cpp:165] Memory required for data: 1432650692
I0625 20:55:42.534054 26920 layer_factory.hpp:77] Creating layer loss_bbox
I0625 20:55:42.534063 26920 net.cpp:106] Creating Layer loss_bbox
I0625 20:55:42.534066 26920 net.cpp:454] loss_bbox <- bbox_pred
I0625 20:55:42.534070 26920 net.cpp:454] loss_bbox <- bbox_targets
I0625 20:55:42.534071 26920 net.cpp:454] loss_bbox <- bbox_inside_weights
I0625 20:55:42.534075 26920 net.cpp:454] loss_bbox <- bbox_outside_weights
I0625 20:55:42.534076 26920 net.cpp:411] loss_bbox -> loss_bbox
I0625 20:55:42.534145 26920 net.cpp:150] Setting up loss_bbox
I0625 20:55:42.534150 26920 net.cpp:157] Top shape: (1)
I0625 20:55:42.534152 26920 net.cpp:160]     with loss weight 2
I0625 20:55:42.534165 26920 net.cpp:165] Memory required for data: 1432650696
I0625 20:55:42.534168 26920 layer_factory.hpp:77] Creating layer roi_pool5_2
I0625 20:55:42.534173 26920 net.cpp:106] Creating Layer roi_pool5_2
I0625 20:55:42.534174 26920 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0625 20:55:42.534178 26920 net.cpp:454] roi_pool5_2 <- rois_pos
I0625 20:55:42.534180 26920 net.cpp:411] roi_pool5_2 -> pool5_2
I0625 20:55:42.534185 26920 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0625 20:55:42.534263 26920 net.cpp:150] Setting up roi_pool5_2
I0625 20:55:42.534268 26920 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 20:55:42.534270 26920 net.cpp:165] Memory required for data: 1432751048
I0625 20:55:42.534281 26920 layer_factory.hpp:77] Creating layer pool5_2_conv
I0625 20:55:42.534288 26920 net.cpp:106] Creating Layer pool5_2_conv
I0625 20:55:42.534291 26920 net.cpp:454] pool5_2_conv <- pool5_2
I0625 20:55:42.534294 26920 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0625 20:55:42.541076 26920 net.cpp:150] Setting up pool5_2_conv
I0625 20:55:42.541085 26920 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 20:55:42.541087 26920 net.cpp:165] Memory required for data: 1432851400
I0625 20:55:42.541103 26920 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0625 20:55:42.541107 26920 net.cpp:106] Creating Layer pool5_2_conv_relu
I0625 20:55:42.541110 26920 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0625 20:55:42.541115 26920 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0625 20:55:42.541275 26920 net.cpp:150] Setting up pool5_2_conv_relu
I0625 20:55:42.541280 26920 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 20:55:42.541283 26920 net.cpp:165] Memory required for data: 1432951752
I0625 20:55:42.541296 26920 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0625 20:55:42.541302 26920 net.cpp:106] Creating Layer pool5_2_conv2
I0625 20:55:42.541318 26920 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0625 20:55:42.541322 26920 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0625 20:55:42.592485 26920 net.cpp:150] Setting up pool5_2_conv2
I0625 20:55:42.592502 26920 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 20:55:42.592504 26920 net.cpp:165] Memory required for data: 1433052104
I0625 20:55:42.592522 26920 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0625 20:55:42.592538 26920 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0625 20:55:42.592543 26920 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0625 20:55:42.592547 26920 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0625 20:55:42.592718 26920 net.cpp:150] Setting up pool5_2_conv2_relu
I0625 20:55:42.592725 26920 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0625 20:55:42.592727 26920 net.cpp:165] Memory required for data: 1433152456
I0625 20:55:42.592739 26920 layer_factory.hpp:77] Creating layer mask_deconv1
I0625 20:55:42.592746 26920 net.cpp:106] Creating Layer mask_deconv1
I0625 20:55:42.592761 26920 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0625 20:55:42.592764 26920 net.cpp:411] mask_deconv1 -> mask_deconv1
I0625 20:55:42.593554 26920 net.cpp:150] Setting up mask_deconv1
I0625 20:55:42.593559 26920 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0625 20:55:42.593561 26920 net.cpp:165] Memory required for data: 1434074056
I0625 20:55:42.593575 26920 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0625 20:55:42.593593 26920 net.cpp:106] Creating Layer pool5_2_conv3
I0625 20:55:42.593596 26920 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0625 20:55:42.593600 26920 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0625 20:55:42.619328 26920 net.cpp:150] Setting up pool5_2_conv3
I0625 20:55:42.619344 26920 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 20:55:42.619346 26920 net.cpp:165] Memory required for data: 1435917256
I0625 20:55:42.619354 26920 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0625 20:55:42.619360 26920 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0625 20:55:42.619374 26920 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0625 20:55:42.619379 26920 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0625 20:55:42.619526 26920 net.cpp:150] Setting up pool5_2_conv3_relu
I0625 20:55:42.619532 26920 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 20:55:42.619534 26920 net.cpp:165] Memory required for data: 1437760456
I0625 20:55:42.619536 26920 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0625 20:55:42.619544 26920 net.cpp:106] Creating Layer pool5_2_conv4
I0625 20:55:42.619545 26920 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0625 20:55:42.619549 26920 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0625 20:55:42.669776 26920 net.cpp:150] Setting up pool5_2_conv4
I0625 20:55:42.669793 26920 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 20:55:42.669795 26920 net.cpp:165] Memory required for data: 1439603656
I0625 20:55:42.669801 26920 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0625 20:55:42.669808 26920 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0625 20:55:42.669823 26920 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0625 20:55:42.669828 26920 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0625 20:55:42.669978 26920 net.cpp:150] Setting up pool5_2_conv4_relu
I0625 20:55:42.669983 26920 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 20:55:42.669986 26920 net.cpp:165] Memory required for data: 1441446856
I0625 20:55:42.669987 26920 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0625 20:55:42.669991 26920 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0625 20:55:42.669993 26920 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0625 20:55:42.669996 26920 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0625 20:55:42.670001 26920 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0625 20:55:42.670013 26920 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0625 20:55:42.670017 26920 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0625 20:55:42.670085 26920 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0625 20:55:42.670089 26920 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 20:55:42.670091 26920 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 20:55:42.670094 26920 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 20:55:42.670095 26920 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 20:55:42.670097 26920 net.cpp:165] Memory required for data: 1448819656
I0625 20:55:42.670099 26920 layer_factory.hpp:77] Creating layer query_conv
I0625 20:55:42.670123 26920 net.cpp:106] Creating Layer query_conv
I0625 20:55:42.670125 26920 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0625 20:55:42.670140 26920 net.cpp:411] query_conv -> query_conv
I0625 20:55:42.671653 26920 net.cpp:150] Setting up query_conv
I0625 20:55:42.671660 26920 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0625 20:55:42.671663 26920 net.cpp:165] Memory required for data: 1449050056
I0625 20:55:42.671666 26920 layer_factory.hpp:77] Creating layer key_conv
I0625 20:55:42.671674 26920 net.cpp:106] Creating Layer key_conv
I0625 20:55:42.671675 26920 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0625 20:55:42.671691 26920 net.cpp:411] key_conv -> key_conv
I0625 20:55:42.673199 26920 net.cpp:150] Setting up key_conv
I0625 20:55:42.673208 26920 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0625 20:55:42.673210 26920 net.cpp:165] Memory required for data: 1449280456
I0625 20:55:42.673213 26920 layer_factory.hpp:77] Creating layer value_conv
I0625 20:55:42.673220 26920 net.cpp:106] Creating Layer value_conv
I0625 20:55:42.673223 26920 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0625 20:55:42.673236 26920 net.cpp:411] value_conv -> value_conv
I0625 20:55:42.680148 26920 net.cpp:150] Setting up value_conv
I0625 20:55:42.680160 26920 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 20:55:42.680162 26920 net.cpp:165] Memory required for data: 1451123656
I0625 20:55:42.680176 26920 layer_factory.hpp:77] Creating layer query_conv_reshape
I0625 20:55:42.680183 26920 net.cpp:106] Creating Layer query_conv_reshape
I0625 20:55:42.680197 26920 net.cpp:454] query_conv_reshape <- query_conv
I0625 20:55:42.680202 26920 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0625 20:55:42.680233 26920 net.cpp:150] Setting up query_conv_reshape
I0625 20:55:42.680238 26920 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0625 20:55:42.680239 26920 net.cpp:165] Memory required for data: 1451354056
I0625 20:55:42.680241 26920 layer_factory.hpp:77] Creating layer key_conv_reshape
I0625 20:55:42.680255 26920 net.cpp:106] Creating Layer key_conv_reshape
I0625 20:55:42.680258 26920 net.cpp:454] key_conv_reshape <- key_conv
I0625 20:55:42.680263 26920 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0625 20:55:42.680287 26920 net.cpp:150] Setting up key_conv_reshape
I0625 20:55:42.680291 26920 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0625 20:55:42.680294 26920 net.cpp:165] Memory required for data: 1451584456
I0625 20:55:42.680305 26920 layer_factory.hpp:77] Creating layer value_conv_reshape
I0625 20:55:42.680310 26920 net.cpp:106] Creating Layer value_conv_reshape
I0625 20:55:42.680312 26920 net.cpp:454] value_conv_reshape <- value_conv
I0625 20:55:42.680315 26920 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0625 20:55:42.680339 26920 net.cpp:150] Setting up value_conv_reshape
I0625 20:55:42.680343 26920 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0625 20:55:42.680346 26920 net.cpp:165] Memory required for data: 1453427656
I0625 20:55:42.680347 26920 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0625 20:55:42.680351 26920 net.cpp:106] Creating Layer query_conv_reshape_perm
I0625 20:55:42.680364 26920 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0625 20:55:42.680367 26920 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0625 20:55:42.680434 26920 net.cpp:150] Setting up query_conv_reshape_perm
I0625 20:55:42.680439 26920 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0625 20:55:42.680440 26920 net.cpp:165] Memory required for data: 1453658056
I0625 20:55:42.680443 26920 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0625 20:55:42.680446 26920 net.cpp:106] Creating Layer key_conv_reshape_perm
I0625 20:55:42.680449 26920 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0625 20:55:42.680451 26920 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0625 20:55:42.680511 26920 net.cpp:150] Setting up key_conv_reshape_perm
I0625 20:55:42.680516 26920 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0625 20:55:42.680517 26920 net.cpp:165] Memory required for data: 1453888456
I0625 20:55:42.680519 26920 layer_factory.hpp:77] Creating layer energy
I0625 20:55:42.680522 26920 net.cpp:106] Creating Layer energy
I0625 20:55:42.680524 26920 net.cpp:454] energy <- query_conv_reshape_perm
I0625 20:55:42.680527 26920 net.cpp:454] energy <- key_conv_reshape_perm
I0625 20:55:42.680531 26920 net.cpp:411] energy -> energy
I0625 20:55:42.680544 26920 net.cpp:150] Setting up energy
I0625 20:55:42.680548 26920 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0625 20:55:42.680549 26920 net.cpp:165] Memory required for data: 1457128456
I0625 20:55:42.680552 26920 layer_factory.hpp:77] Creating layer attention
I0625 20:55:42.680557 26920 net.cpp:106] Creating Layer attention
I0625 20:55:42.680559 26920 net.cpp:454] attention <- energy
I0625 20:55:42.680562 26920 net.cpp:411] attention -> attention
I0625 20:55:42.680714 26920 net.cpp:150] Setting up attention
I0625 20:55:42.680721 26920 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0625 20:55:42.680723 26920 net.cpp:165] Memory required for data: 1460368456
I0625 20:55:42.680725 26920 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0625 20:55:42.680729 26920 net.cpp:106] Creating Layer value_conv_reshape_perm
I0625 20:55:42.680732 26920 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0625 20:55:42.680737 26920 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0625 20:55:42.680810 26920 net.cpp:150] Setting up value_conv_reshape_perm
I0625 20:55:42.680814 26920 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0625 20:55:42.680816 26920 net.cpp:165] Memory required for data: 1462211656
I0625 20:55:42.680819 26920 layer_factory.hpp:77] Creating layer attention_perm
I0625 20:55:42.680831 26920 net.cpp:106] Creating Layer attention_perm
I0625 20:55:42.680835 26920 net.cpp:454] attention_perm <- attention
I0625 20:55:42.680837 26920 net.cpp:411] attention_perm -> attention_perm
I0625 20:55:42.680899 26920 net.cpp:150] Setting up attention_perm
I0625 20:55:42.680902 26920 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0625 20:55:42.680904 26920 net.cpp:165] Memory required for data: 1465451656
I0625 20:55:42.680907 26920 layer_factory.hpp:77] Creating layer out
I0625 20:55:42.680909 26920 net.cpp:106] Creating Layer out
I0625 20:55:42.680912 26920 net.cpp:454] out <- value_conv_reshape_perm
I0625 20:55:42.680914 26920 net.cpp:454] out <- attention_perm
I0625 20:55:42.680917 26920 net.cpp:411] out -> out
I0625 20:55:42.680932 26920 net.cpp:150] Setting up out
I0625 20:55:42.680935 26920 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0625 20:55:42.680938 26920 net.cpp:165] Memory required for data: 1467294856
I0625 20:55:42.680939 26920 layer_factory.hpp:77] Creating layer out_reshape
I0625 20:55:42.680943 26920 net.cpp:106] Creating Layer out_reshape
I0625 20:55:42.680944 26920 net.cpp:454] out_reshape <- out
I0625 20:55:42.680948 26920 net.cpp:411] out_reshape -> out_reshape
I0625 20:55:42.680961 26920 net.cpp:150] Setting up out_reshape
I0625 20:55:42.680965 26920 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 20:55:42.680966 26920 net.cpp:165] Memory required for data: 1469138056
I0625 20:55:42.680968 26920 layer_factory.hpp:77] Creating layer out_reshape_scale
I0625 20:55:42.680974 26920 net.cpp:106] Creating Layer out_reshape_scale
I0625 20:55:42.680975 26920 net.cpp:454] out_reshape_scale <- out_reshape
I0625 20:55:42.680979 26920 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0625 20:55:42.681038 26920 net.cpp:150] Setting up out_reshape_scale
I0625 20:55:42.681043 26920 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 20:55:42.681046 26920 net.cpp:165] Memory required for data: 1470981256
I0625 20:55:42.681048 26920 layer_factory.hpp:77] Creating layer out_x
I0625 20:55:42.681053 26920 net.cpp:106] Creating Layer out_x
I0625 20:55:42.681056 26920 net.cpp:454] out_x <- out_reshape_scale
I0625 20:55:42.681058 26920 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0625 20:55:42.681061 26920 net.cpp:411] out_x -> out_x
I0625 20:55:42.681078 26920 net.cpp:150] Setting up out_x
I0625 20:55:42.681082 26920 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0625 20:55:42.681083 26920 net.cpp:165] Memory required for data: 1472824456
I0625 20:55:42.681085 26920 layer_factory.hpp:77] Creating layer mask_deconv2
I0625 20:55:42.681090 26920 net.cpp:106] Creating Layer mask_deconv2
I0625 20:55:42.681092 26920 net.cpp:454] mask_deconv2 <- out_x
I0625 20:55:42.681097 26920 net.cpp:411] mask_deconv2 -> mask_deconv2
I0625 20:55:42.681888 26920 net.cpp:150] Setting up mask_deconv2
I0625 20:55:42.681893 26920 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0625 20:55:42.681895 26920 net.cpp:165] Memory required for data: 1488065672
I0625 20:55:42.681900 26920 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0625 20:55:42.681906 26920 net.cpp:106] Creating Layer pool5_2_conv5
I0625 20:55:42.681910 26920 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0625 20:55:42.681912 26920 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0625 20:55:42.708341 26920 net.cpp:150] Setting up pool5_2_conv5
I0625 20:55:42.708359 26920 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 20:55:42.708360 26920 net.cpp:165] Memory required for data: 1518548104
I0625 20:55:42.708369 26920 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0625 20:55:42.708374 26920 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0625 20:55:42.708389 26920 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0625 20:55:42.708393 26920 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0625 20:55:42.708532 26920 net.cpp:150] Setting up pool5_2_conv5_relu
I0625 20:55:42.708539 26920 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 20:55:42.708540 26920 net.cpp:165] Memory required for data: 1549030536
I0625 20:55:42.708542 26920 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0625 20:55:42.708550 26920 net.cpp:106] Creating Layer pool5_2_conv6
I0625 20:55:42.708552 26920 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0625 20:55:42.708556 26920 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0625 20:55:42.763870 26920 net.cpp:150] Setting up pool5_2_conv6
I0625 20:55:42.763896 26920 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 20:55:42.763900 26920 net.cpp:165] Memory required for data: 1579512968
I0625 20:55:42.763924 26920 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0625 20:55:42.763938 26920 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0625 20:55:42.763947 26920 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0625 20:55:42.763954 26920 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0625 20:55:42.764613 26920 net.cpp:150] Setting up pool5_2_conv6_relu
I0625 20:55:42.764626 26920 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0625 20:55:42.764628 26920 net.cpp:165] Memory required for data: 1609995400
I0625 20:55:42.764632 26920 layer_factory.hpp:77] Creating layer mask_deconv3
I0625 20:55:42.764645 26920 net.cpp:106] Creating Layer mask_deconv3
I0625 20:55:42.764664 26920 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0625 20:55:42.764683 26920 net.cpp:411] mask_deconv3 -> mask_deconv3
I0625 20:55:42.765108 26920 net.cpp:150] Setting up mask_deconv3
I0625 20:55:42.765117 26920 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0625 20:55:42.765120 26920 net.cpp:165] Memory required for data: 1670960264
I0625 20:55:42.765127 26920 layer_factory.hpp:77] Creating layer mask_score
I0625 20:55:42.765136 26920 net.cpp:106] Creating Layer mask_score
I0625 20:55:42.765151 26920 net.cpp:454] mask_score <- mask_deconv3
I0625 20:55:42.765168 26920 net.cpp:411] mask_score -> mask_score
I0625 20:55:42.765918 26920 net.cpp:150] Setting up mask_score
I0625 20:55:42.765933 26920 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 20:55:42.765935 26920 net.cpp:165] Memory required for data: 1672865416
I0625 20:55:42.765944 26920 layer_factory.hpp:77] Creating layer prob
I0625 20:55:42.765954 26920 net.cpp:106] Creating Layer prob
I0625 20:55:42.765971 26920 net.cpp:454] prob <- mask_score
I0625 20:55:42.765988 26920 net.cpp:411] prob -> mask_score_softmax
I0625 20:55:42.766722 26920 net.cpp:150] Setting up prob
I0625 20:55:42.766737 26920 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 20:55:42.766742 26920 net.cpp:165] Memory required for data: 1674770568
I0625 20:55:42.766746 26920 layer_factory.hpp:77] Creating layer log
I0625 20:55:42.766753 26920 net.cpp:106] Creating Layer log
I0625 20:55:42.766769 26920 net.cpp:454] log <- mask_score_softmax
I0625 20:55:42.766784 26920 net.cpp:411] log -> log
I0625 20:55:42.766822 26920 net.cpp:150] Setting up log
I0625 20:55:42.766829 26920 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 20:55:42.766832 26920 net.cpp:165] Memory required for data: 1676675720
I0625 20:55:42.766835 26920 layer_factory.hpp:77] Creating layer mult1
I0625 20:55:42.766842 26920 net.cpp:106] Creating Layer mult1
I0625 20:55:42.766855 26920 net.cpp:454] mult1 <- log
I0625 20:55:42.766868 26920 net.cpp:454] mult1 <- mask_targets
I0625 20:55:42.766889 26920 net.cpp:411] mult1 -> mult1
I0625 20:55:42.766924 26920 net.cpp:150] Setting up mult1
I0625 20:55:42.766930 26920 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 20:55:42.766933 26920 net.cpp:165] Memory required for data: 1678580872
I0625 20:55:42.766937 26920 layer_factory.hpp:77] Creating layer cross_entropy
I0625 20:55:42.766945 26920 net.cpp:106] Creating Layer cross_entropy
I0625 20:55:42.766959 26920 net.cpp:454] cross_entropy <- mult1
I0625 20:55:42.766974 26920 net.cpp:411] cross_entropy -> cross_entropy
I0625 20:55:42.767009 26920 net.cpp:150] Setting up cross_entropy
I0625 20:55:42.767014 26920 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0625 20:55:42.767016 26920 net.cpp:165] Memory required for data: 1680486024
I0625 20:55:42.767019 26920 layer_factory.hpp:77] Creating layer ce_sum
I0625 20:55:42.767031 26920 net.cpp:106] Creating Layer ce_sum
I0625 20:55:42.767045 26920 net.cpp:454] ce_sum <- cross_entropy
I0625 20:55:42.767061 26920 net.cpp:411] ce_sum -> cross_entropy_sum
I0625 20:55:42.768487 26920 net.cpp:150] Setting up ce_sum
I0625 20:55:42.768502 26920 net.cpp:157] Top shape: 1 1 244 244 (59536)
I0625 20:55:42.768504 26920 net.cpp:165] Memory required for data: 1680724168
I0625 20:55:42.768512 26920 layer_factory.hpp:77] Creating layer ce_mean
I0625 20:55:42.768522 26920 net.cpp:106] Creating Layer ce_mean
I0625 20:55:42.768527 26920 net.cpp:454] ce_mean <- cross_entropy_sum
I0625 20:55:42.768534 26920 net.cpp:411] ce_mean -> cross_entropy_mean
I0625 20:55:42.769233 26920 net.cpp:150] Setting up ce_mean
I0625 20:55:42.769248 26920 net.cpp:157] Top shape: (1)
I0625 20:55:42.769250 26920 net.cpp:160]     with loss weight 1
I0625 20:55:42.769263 26920 net.cpp:165] Memory required for data: 1680724172
I0625 20:55:42.769266 26920 net.cpp:226] ce_mean needs backward computation.
I0625 20:55:42.769270 26920 net.cpp:226] ce_sum needs backward computation.
I0625 20:55:42.769274 26920 net.cpp:226] cross_entropy needs backward computation.
I0625 20:55:42.769277 26920 net.cpp:226] mult1 needs backward computation.
I0625 20:55:42.769280 26920 net.cpp:226] log needs backward computation.
I0625 20:55:42.769284 26920 net.cpp:226] prob needs backward computation.
I0625 20:55:42.769287 26920 net.cpp:226] mask_score needs backward computation.
I0625 20:55:42.769292 26920 net.cpp:226] mask_deconv3 needs backward computation.
I0625 20:55:42.769295 26920 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0625 20:55:42.769299 26920 net.cpp:226] pool5_2_conv6 needs backward computation.
I0625 20:55:42.769301 26920 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0625 20:55:42.769304 26920 net.cpp:226] pool5_2_conv5 needs backward computation.
I0625 20:55:42.769307 26920 net.cpp:226] mask_deconv2 needs backward computation.
I0625 20:55:42.769309 26920 net.cpp:226] out_x needs backward computation.
I0625 20:55:42.769311 26920 net.cpp:226] out_reshape_scale needs backward computation.
I0625 20:55:42.769313 26920 net.cpp:226] out_reshape needs backward computation.
I0625 20:55:42.769315 26920 net.cpp:226] out needs backward computation.
I0625 20:55:42.769317 26920 net.cpp:226] attention_perm needs backward computation.
I0625 20:55:42.769320 26920 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0625 20:55:42.769322 26920 net.cpp:226] attention needs backward computation.
I0625 20:55:42.769325 26920 net.cpp:226] energy needs backward computation.
I0625 20:55:42.769326 26920 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0625 20:55:42.769328 26920 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0625 20:55:42.769330 26920 net.cpp:226] value_conv_reshape needs backward computation.
I0625 20:55:42.769332 26920 net.cpp:226] key_conv_reshape needs backward computation.
I0625 20:55:42.769335 26920 net.cpp:226] query_conv_reshape needs backward computation.
I0625 20:55:42.769336 26920 net.cpp:226] value_conv needs backward computation.
I0625 20:55:42.769340 26920 net.cpp:226] key_conv needs backward computation.
I0625 20:55:42.769341 26920 net.cpp:226] query_conv needs backward computation.
I0625 20:55:42.769343 26920 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0625 20:55:42.769345 26920 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0625 20:55:42.769347 26920 net.cpp:226] pool5_2_conv4 needs backward computation.
I0625 20:55:42.769351 26920 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0625 20:55:42.769354 26920 net.cpp:226] pool5_2_conv3 needs backward computation.
I0625 20:55:42.769356 26920 net.cpp:226] mask_deconv1 needs backward computation.
I0625 20:55:42.769358 26920 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0625 20:55:42.769361 26920 net.cpp:226] pool5_2_conv2 needs backward computation.
I0625 20:55:42.769362 26920 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0625 20:55:42.769364 26920 net.cpp:226] pool5_2_conv needs backward computation.
I0625 20:55:42.769367 26920 net.cpp:226] roi_pool5_2 needs backward computation.
I0625 20:55:42.769369 26920 net.cpp:226] loss_bbox needs backward computation.
I0625 20:55:42.769372 26920 net.cpp:226] loss_cls needs backward computation.
I0625 20:55:42.769374 26920 net.cpp:226] loss_attribute needs backward computation.
I0625 20:55:42.769377 26920 net.cpp:226] bbox_pred needs backward computation.
I0625 20:55:42.769379 26920 net.cpp:226] cls_score needs backward computation.
I0625 20:55:42.769381 26920 net.cpp:226] attr_score_pos_shift needs backward computation.
I0625 20:55:42.769383 26920 net.cpp:226] attr_score_pos needs backward computation.
I0625 20:55:42.769387 26920 net.cpp:226] attr_score needs backward computation.
I0625 20:55:42.769389 26920 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0625 20:55:42.769392 26920 net.cpp:226] relu7 needs backward computation.
I0625 20:55:42.769393 26920 net.cpp:226] fc7 needs backward computation.
I0625 20:55:42.769395 26920 net.cpp:226] relu6 needs backward computation.
I0625 20:55:42.769397 26920 net.cpp:226] fc6 needs backward computation.
I0625 20:55:42.769399 26920 net.cpp:226] roi_pool5 needs backward computation.
I0625 20:55:42.769402 26920 net.cpp:226] roi-data needs backward computation.
I0625 20:55:42.769405 26920 net.cpp:226] proposal needs backward computation.
I0625 20:55:42.769409 26920 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0625 20:55:42.769412 26920 net.cpp:226] rpn_cls_prob needs backward computation.
I0625 20:55:42.769414 26920 net.cpp:226] rpn_loss_bbox needs backward computation.
I0625 20:55:42.769418 26920 net.cpp:226] rpn_loss_cls needs backward computation.
I0625 20:55:42.769420 26920 net.cpp:226] rpn-data needs backward computation.
I0625 20:55:42.769425 26920 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0625 20:55:42.769428 26920 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0625 20:55:42.769430 26920 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0625 20:55:42.769433 26920 net.cpp:226] rpn_bbox_pred needs backward computation.
I0625 20:55:42.769435 26920 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0625 20:55:42.769438 26920 net.cpp:226] rpn_cls_score needs backward computation.
I0625 20:55:42.769439 26920 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0625 20:55:42.769443 26920 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0625 20:55:42.769444 26920 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0625 20:55:42.769446 26920 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0625 20:55:42.769448 26920 net.cpp:226] relu5_3 needs backward computation.
I0625 20:55:42.769450 26920 net.cpp:226] conv5_3 needs backward computation.
I0625 20:55:42.769452 26920 net.cpp:226] relu5_2 needs backward computation.
I0625 20:55:42.769454 26920 net.cpp:226] conv5_2 needs backward computation.
I0625 20:55:42.769456 26920 net.cpp:226] relu5_1 needs backward computation.
I0625 20:55:42.769459 26920 net.cpp:226] conv5_1 needs backward computation.
I0625 20:55:42.769461 26920 net.cpp:226] pool4 needs backward computation.
I0625 20:55:42.769464 26920 net.cpp:226] relu4_3 needs backward computation.
I0625 20:55:42.769465 26920 net.cpp:226] conv4_3 needs backward computation.
I0625 20:55:42.769467 26920 net.cpp:226] relu4_2 needs backward computation.
I0625 20:55:42.769469 26920 net.cpp:226] conv4_2 needs backward computation.
I0625 20:55:42.769471 26920 net.cpp:226] relu4_1 needs backward computation.
I0625 20:55:42.769472 26920 net.cpp:226] conv4_1 needs backward computation.
I0625 20:55:42.769475 26920 net.cpp:226] pool3 needs backward computation.
I0625 20:55:42.769476 26920 net.cpp:226] relu3_3 needs backward computation.
I0625 20:55:42.769479 26920 net.cpp:226] conv3_3 needs backward computation.
I0625 20:55:42.769480 26920 net.cpp:226] relu3_2 needs backward computation.
I0625 20:55:42.769484 26920 net.cpp:226] conv3_2 needs backward computation.
I0625 20:55:42.769485 26920 net.cpp:226] relu3_1 needs backward computation.
I0625 20:55:42.769487 26920 net.cpp:226] conv3_1 needs backward computation.
I0625 20:55:42.769490 26920 net.cpp:228] pool2 does not need backward computation.
I0625 20:55:42.769492 26920 net.cpp:228] relu2_2 does not need backward computation.
I0625 20:55:42.769495 26920 net.cpp:228] conv2_2 does not need backward computation.
I0625 20:55:42.769497 26920 net.cpp:228] relu2_1 does not need backward computation.
I0625 20:55:42.769500 26920 net.cpp:228] conv2_1 does not need backward computation.
I0625 20:55:42.769502 26920 net.cpp:228] pool1 does not need backward computation.
I0625 20:55:42.769505 26920 net.cpp:228] relu1_2 does not need backward computation.
I0625 20:55:42.769507 26920 net.cpp:228] conv1_2 does not need backward computation.
I0625 20:55:42.769510 26920 net.cpp:228] relu1_1 does not need backward computation.
I0625 20:55:42.769511 26920 net.cpp:228] conv1_1 does not need backward computation.
I0625 20:55:42.769515 26920 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0625 20:55:42.769516 26920 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0625 20:55:42.769520 26920 net.cpp:228] data_input-data_0_split does not need backward computation.
I0625 20:55:42.769523 26920 net.cpp:228] input-data does not need backward computation.
I0625 20:55:42.769526 26920 net.cpp:270] This network produces output cross_entropy_mean
I0625 20:55:42.769528 26920 net.cpp:270] This network produces output loss_attribute
I0625 20:55:42.769531 26920 net.cpp:270] This network produces output loss_bbox
I0625 20:55:42.769533 26920 net.cpp:270] This network produces output loss_cls
I0625 20:55:42.769536 26920 net.cpp:270] This network produces output rpn_cls_loss
I0625 20:55:42.769537 26920 net.cpp:270] This network produces output rpn_loss_bbox
I0625 20:55:42.769595 26920 net.cpp:283] Network initialization done.
I0625 20:55:42.769778 26920 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0625 20:55:43.988636 26920 net.cpp:816] Ignoring source layer pool5
I0625 20:55:44.053107 26920 net.cpp:816] Ignoring source layer drop6
I0625 20:55:44.063099 26920 net.cpp:816] Ignoring source layer drop7
I0625 20:55:44.063114 26920 net.cpp:816] Ignoring source layer fc8
Solving...
I0625 20:55:45.290751 26920 solver.cpp:229] Iteration 0, loss = 5.76212
I0625 20:55:45.346860 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.54325 (* 1 = 1.54325 loss)
I0625 20:55:45.346876 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.457188 (* 1 = 0.457188 loss)
I0625 20:55:45.346879 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.137485 (* 2 = 0.27497 loss)
I0625 20:55:45.346884 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.888849 (* 3 = 2.66655 loss)
I0625 20:55:45.346886 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.73882 (* 1 = 0.73882 loss)
I0625 20:55:45.346890 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0189577 (* 1 = 0.0189577 loss)
I0625 20:55:45.346904 26920 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0625 20:56:06.793365 26920 solver.cpp:229] Iteration 20, loss = 3.40977
I0625 20:56:06.848954 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.76941 (* 1 = 1.76941 loss)
I0625 20:56:06.848970 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.411483 (* 1 = 0.411483 loss)
I0625 20:56:06.848987 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.23481 (* 2 = 0.469619 loss)
I0625 20:56:06.848994 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.152462 (* 3 = 0.457385 loss)
I0625 20:56:06.848999 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.622102 (* 1 = 0.622102 loss)
I0625 20:56:06.849006 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0174302 (* 1 = 0.0174302 loss)
I0625 20:56:06.849014 26920 sgd_solver.cpp:106] Iteration 20, lr = 0.0001
I0625 20:56:26.851200 26920 solver.cpp:229] Iteration 40, loss = 2.75349
I0625 20:56:26.903578 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.91068 (* 1 = 1.91068 loss)
I0625 20:56:26.903592 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.108294 (* 1 = 0.108294 loss)
I0625 20:56:26.903597 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.000696761 (* 2 = 0.00139352 loss)
I0625 20:56:26.903601 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0755869 (* 3 = 0.226761 loss)
I0625 20:56:26.903605 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.464316 (* 1 = 0.464316 loss)
I0625 20:56:26.903609 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0121545 (* 1 = 0.0121545 loss)
I0625 20:56:26.903623 26920 sgd_solver.cpp:106] Iteration 40, lr = 0.0001
I0625 20:56:46.298874 26920 solver.cpp:229] Iteration 60, loss = 3.40628
I0625 20:56:46.356803 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.38531 (* 1 = 1.38531 loss)
I0625 20:56:46.356819 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.380558 (* 1 = 0.380558 loss)
I0625 20:56:46.356824 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.311567 (* 2 = 0.623134 loss)
I0625 20:56:46.356828 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0580353 (* 3 = 0.174106 loss)
I0625 20:56:46.356833 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.174223 (* 1 = 0.174223 loss)
I0625 20:56:46.356837 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0178847 (* 1 = 0.0178847 loss)
I0625 20:56:46.356842 26920 sgd_solver.cpp:106] Iteration 60, lr = 0.0001
I0625 20:57:07.528007 26920 solver.cpp:229] Iteration 80, loss = 3.18299
I0625 20:57:07.587622 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.57618 (* 1 = 1.57618 loss)
I0625 20:57:07.587649 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.25008 (* 1 = 0.25008 loss)
I0625 20:57:07.587656 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.142508 (* 2 = 0.285016 loss)
I0625 20:57:07.587659 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0207137 (* 3 = 0.062141 loss)
I0625 20:57:07.587666 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.182724 (* 1 = 0.182724 loss)
I0625 20:57:07.587672 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.105084 (* 1 = 0.105084 loss)
I0625 20:57:07.587692 26920 sgd_solver.cpp:106] Iteration 80, lr = 0.0001
I0625 20:57:35.989652 26920 solver.cpp:229] Iteration 100, loss = 2.96165
I0625 20:57:36.044667 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.31482 (* 1 = 1.31482 loss)
I0625 20:57:36.044678 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.196423 (* 1 = 0.196423 loss)
I0625 20:57:36.044682 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.324392 (* 2 = 0.648785 loss)
I0625 20:57:36.044687 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0769048 (* 3 = 0.230714 loss)
I0625 20:57:36.044690 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0877337 (* 1 = 0.0877337 loss)
I0625 20:57:36.044694 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.164117 (* 1 = 0.164117 loss)
I0625 20:57:36.044699 26920 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0625 20:58:04.868738 26920 solver.cpp:229] Iteration 120, loss = 2.09658
I0625 20:58:04.926254 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.68944 (* 1 = 1.68944 loss)
I0625 20:58:04.926288 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0459955 (* 1 = 0.0459955 loss)
I0625 20:58:04.926293 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.198464 (* 2 = 0.396927 loss)
I0625 20:58:04.926296 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00864446 (* 3 = 0.0259334 loss)
I0625 20:58:04.926311 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0365919 (* 1 = 0.0365919 loss)
I0625 20:58:04.926314 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0272821 (* 1 = 0.0272821 loss)
I0625 20:58:04.926327 26920 sgd_solver.cpp:106] Iteration 120, lr = 0.0001
I0625 20:58:31.494607 26920 solver.cpp:229] Iteration 140, loss = 3.86868
I0625 20:58:31.554066 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.49674 (* 1 = 1.49674 loss)
I0625 20:58:31.554081 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.534298 (* 1 = 0.534298 loss)
I0625 20:58:31.554086 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.55587 (* 2 = 1.11174 loss)
I0625 20:58:31.554090 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.349125 (* 3 = 1.04737 loss)
I0625 20:58:31.554093 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0548683 (* 1 = 0.0548683 loss)
I0625 20:58:31.554097 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0553146 (* 1 = 0.0553146 loss)
I0625 20:58:31.554111 26920 sgd_solver.cpp:106] Iteration 140, lr = 0.0001
I0625 20:58:59.340843 26920 solver.cpp:229] Iteration 160, loss = 2.87379
I0625 20:58:59.398882 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.47606 (* 1 = 1.47606 loss)
I0625 20:58:59.398898 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0316327 (* 1 = 0.0316327 loss)
I0625 20:58:59.398902 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.238975 (* 2 = 0.47795 loss)
I0625 20:58:59.398906 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00599519 (* 3 = 0.0179856 loss)
I0625 20:58:59.398910 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0170283 (* 1 = 0.0170283 loss)
I0625 20:58:59.398913 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0560969 (* 1 = 0.0560969 loss)
I0625 20:58:59.398918 26920 sgd_solver.cpp:106] Iteration 160, lr = 0.0001
I0625 20:59:26.468178 26920 solver.cpp:229] Iteration 180, loss = 2.28599
I0625 20:59:26.525207 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.43536 (* 1 = 1.43536 loss)
I0625 20:59:26.525231 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0240333 (* 1 = 0.0240333 loss)
I0625 20:59:26.525235 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.326239 (* 2 = 0.652478 loss)
I0625 20:59:26.525239 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0394102 (* 3 = 0.118231 loss)
I0625 20:59:26.525243 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0173019 (* 1 = 0.0173019 loss)
I0625 20:59:26.525257 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0456593 (* 1 = 0.0456593 loss)
I0625 20:59:26.525262 26920 sgd_solver.cpp:106] Iteration 180, lr = 0.0001
speed: 1.234s / iter
I0625 20:59:52.406311 26920 solver.cpp:229] Iteration 200, loss = 3.14661
I0625 20:59:52.462862 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.45289 (* 1 = 1.45289 loss)
I0625 20:59:52.462875 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.383355 (* 1 = 0.383355 loss)
I0625 20:59:52.462879 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.367066 (* 2 = 0.734132 loss)
I0625 20:59:52.462884 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0204832 (* 3 = 0.0614497 loss)
I0625 20:59:52.462888 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0383179 (* 1 = 0.0383179 loss)
I0625 20:59:52.462893 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0869963 (* 1 = 0.0869963 loss)
I0625 20:59:52.462898 26920 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0625 21:00:18.348311 26920 solver.cpp:229] Iteration 220, loss = 1.7565
I0625 21:00:18.406181 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.43074 (* 1 = 1.43074 loss)
I0625 21:00:18.406205 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0221172 (* 1 = 0.0221172 loss)
I0625 21:00:18.406209 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0955121 (* 2 = 0.191024 loss)
I0625 21:00:18.406213 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0184136 (* 3 = 0.0552408 loss)
I0625 21:00:18.406216 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0105748 (* 1 = 0.0105748 loss)
I0625 21:00:18.406220 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00924266 (* 1 = 0.00924266 loss)
I0625 21:00:18.406225 26920 sgd_solver.cpp:106] Iteration 220, lr = 0.0001
I0625 21:00:46.259527 26920 solver.cpp:229] Iteration 240, loss = 2.75675
I0625 21:00:46.315910 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.18798 (* 1 = 1.18798 loss)
I0625 21:00:46.315922 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.442633 (* 1 = 0.442633 loss)
I0625 21:00:46.315927 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.602158 (* 2 = 1.20432 loss)
I0625 21:00:46.315930 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.141547 (* 3 = 0.424641 loss)
I0625 21:00:46.315935 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.121778 (* 1 = 0.121778 loss)
I0625 21:00:46.315939 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.151001 (* 1 = 0.151001 loss)
I0625 21:00:46.315945 26920 sgd_solver.cpp:106] Iteration 240, lr = 0.0001
I0625 21:01:09.943902 26920 solver.cpp:229] Iteration 260, loss = 2.16582
I0625 21:01:10.001664 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.51281 (* 1 = 1.51281 loss)
I0625 21:01:10.001680 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.084306 (* 1 = 0.084306 loss)
I0625 21:01:10.001685 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.31643 (* 2 = 0.632859 loss)
I0625 21:01:10.001689 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0383551 (* 3 = 0.115065 loss)
I0625 21:01:10.001693 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0125257 (* 1 = 0.0125257 loss)
I0625 21:01:10.001698 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0158323 (* 1 = 0.0158323 loss)
I0625 21:01:10.001703 26920 sgd_solver.cpp:106] Iteration 260, lr = 0.0001
I0625 21:01:32.410393 26920 solver.cpp:229] Iteration 280, loss = 1.98381
I0625 21:01:32.466500 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.61681 (* 1 = 1.61681 loss)
I0625 21:01:32.466513 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0299384 (* 1 = 0.0299384 loss)
I0625 21:01:32.466517 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.103868 (* 2 = 0.207735 loss)
I0625 21:01:32.466522 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00572669 (* 3 = 0.0171801 loss)
I0625 21:01:32.466526 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0137216 (* 1 = 0.0137216 loss)
I0625 21:01:32.466529 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0366151 (* 1 = 0.0366151 loss)
I0625 21:01:32.466536 26920 sgd_solver.cpp:106] Iteration 280, lr = 0.0001
I0625 21:01:58.288714 26920 solver.cpp:229] Iteration 300, loss = 1.79794
I0625 21:01:58.345635 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.981176 (* 1 = 0.981176 loss)
I0625 21:01:58.345646 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.170049 (* 1 = 0.170049 loss)
I0625 21:01:58.345650 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.165736 (* 2 = 0.331473 loss)
I0625 21:01:58.345654 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0416668 (* 3 = 0.125 loss)
I0625 21:01:58.345669 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0167764 (* 1 = 0.0167764 loss)
I0625 21:01:58.345672 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0405546 (* 1 = 0.0405546 loss)
I0625 21:01:58.345677 26920 sgd_solver.cpp:106] Iteration 300, lr = 0.0001
I0625 21:02:23.397954 26920 solver.cpp:229] Iteration 320, loss = 1.84194
I0625 21:02:23.450811 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.17137 (* 1 = 1.17137 loss)
I0625 21:02:23.450824 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0591588 (* 1 = 0.0591588 loss)
I0625 21:02:23.450827 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.203237 (* 2 = 0.406473 loss)
I0625 21:02:23.450831 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0097058 (* 3 = 0.0291174 loss)
I0625 21:02:23.450835 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.010934 (* 1 = 0.010934 loss)
I0625 21:02:23.450839 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0117277 (* 1 = 0.0117277 loss)
I0625 21:02:23.450843 26920 sgd_solver.cpp:106] Iteration 320, lr = 0.0001
I0625 21:02:48.940481 26920 solver.cpp:229] Iteration 340, loss = 1.53003
I0625 21:02:48.997829 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.18535 (* 1 = 1.18535 loss)
I0625 21:02:48.997843 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0379255 (* 1 = 0.0379255 loss)
I0625 21:02:48.997846 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.133362 (* 2 = 0.266724 loss)
I0625 21:02:48.997850 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.000887381 (* 3 = 0.00266214 loss)
I0625 21:02:48.997854 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0137388 (* 1 = 0.0137388 loss)
I0625 21:02:48.997858 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0199717 (* 1 = 0.0199717 loss)
I0625 21:02:48.997862 26920 sgd_solver.cpp:106] Iteration 340, lr = 0.0001
I0625 21:03:15.672462 26920 solver.cpp:229] Iteration 360, loss = 1.68583
I0625 21:03:15.726524 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.701886 (* 1 = 0.701886 loss)
I0625 21:03:15.726537 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.468559 (* 1 = 0.468559 loss)
I0625 21:03:15.726541 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.231348 (* 2 = 0.462696 loss)
I0625 21:03:15.726545 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0083132 (* 3 = 0.0249396 loss)
I0625 21:03:15.726549 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0512993 (* 1 = 0.0512993 loss)
I0625 21:03:15.726553 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.056105 (* 1 = 0.056105 loss)
I0625 21:03:15.726568 26920 sgd_solver.cpp:106] Iteration 360, lr = 0.0001
I0625 21:03:40.404383 26920 solver.cpp:229] Iteration 380, loss = 1.26202
I0625 21:03:40.460698 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.422113 (* 1 = 0.422113 loss)
I0625 21:03:40.460709 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.329581 (* 1 = 0.329581 loss)
I0625 21:03:40.460713 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.179228 (* 2 = 0.358456 loss)
I0625 21:03:40.460718 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00978882 (* 3 = 0.0293665 loss)
I0625 21:03:40.460726 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00630257 (* 1 = 0.00630257 loss)
I0625 21:03:40.460739 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0467847 (* 1 = 0.0467847 loss)
I0625 21:03:40.460744 26920 sgd_solver.cpp:106] Iteration 380, lr = 0.0001
speed: 1.259s / iter
I0625 21:04:09.077025 26920 solver.cpp:229] Iteration 400, loss = 1.53989
I0625 21:04:09.133301 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.3127 (* 1 = 1.3127 loss)
I0625 21:04:09.133319 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0519444 (* 1 = 0.0519444 loss)
I0625 21:04:09.133324 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.13453 (* 2 = 0.26906 loss)
I0625 21:04:09.133328 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00836904 (* 3 = 0.0251071 loss)
I0625 21:04:09.133332 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00864638 (* 1 = 0.00864638 loss)
I0625 21:04:09.133337 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0104932 (* 1 = 0.0104932 loss)
I0625 21:04:09.133342 26920 sgd_solver.cpp:106] Iteration 400, lr = 0.0001
I0625 21:04:37.406427 26920 solver.cpp:229] Iteration 420, loss = 1.9574
I0625 21:04:37.460399 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.911057 (* 1 = 0.911057 loss)
I0625 21:04:37.460414 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.501975 (* 1 = 0.501975 loss)
I0625 21:04:37.460419 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.328545 (* 2 = 0.65709 loss)
I0625 21:04:37.460423 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.212515 (* 3 = 0.637544 loss)
I0625 21:04:37.460427 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0544662 (* 1 = 0.0544662 loss)
I0625 21:04:37.460431 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0761458 (* 1 = 0.0761458 loss)
I0625 21:04:37.460436 26920 sgd_solver.cpp:106] Iteration 420, lr = 0.0001
I0625 21:05:03.732069 26920 solver.cpp:229] Iteration 440, loss = 1.7203
I0625 21:05:03.789058 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.51451 (* 1 = 1.51451 loss)
I0625 21:05:03.789131 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0156861 (* 1 = 0.0156861 loss)
I0625 21:05:03.789171 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0343198 (* 2 = 0.0686396 loss)
I0625 21:05:03.789211 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0078951 (* 3 = 0.0236853 loss)
I0625 21:05:03.789244 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0034132 (* 1 = 0.0034132 loss)
I0625 21:05:03.789278 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00581167 (* 1 = 0.00581167 loss)
I0625 21:05:03.789322 26920 sgd_solver.cpp:106] Iteration 440, lr = 0.0001
I0625 21:05:33.876950 26920 solver.cpp:229] Iteration 460, loss = 1.45404
I0625 21:05:33.934247 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.880231 (* 1 = 0.880231 loss)
I0625 21:05:33.934263 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.185018 (* 1 = 0.185018 loss)
I0625 21:05:33.934268 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.228004 (* 2 = 0.456007 loss)
I0625 21:05:33.934273 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0623271 (* 3 = 0.186981 loss)
I0625 21:05:33.934278 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0203464 (* 1 = 0.0203464 loss)
I0625 21:05:33.934283 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0220283 (* 1 = 0.0220283 loss)
I0625 21:05:33.934290 26920 sgd_solver.cpp:106] Iteration 460, lr = 0.0001
I0625 21:06:01.197139 26920 solver.cpp:229] Iteration 480, loss = 1.13248
I0625 21:06:01.254920 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.91383 (* 1 = 0.91383 loss)
I0625 21:06:01.254933 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.104371 (* 1 = 0.104371 loss)
I0625 21:06:01.254937 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.129788 (* 2 = 0.259577 loss)
I0625 21:06:01.254941 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00819431 (* 3 = 0.0245829 loss)
I0625 21:06:01.254945 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0186125 (* 1 = 0.0186125 loss)
I0625 21:06:01.254948 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0118664 (* 1 = 0.0118664 loss)
I0625 21:06:01.254963 26920 sgd_solver.cpp:106] Iteration 480, lr = 0.0001
I0625 21:06:27.661900 26920 solver.cpp:229] Iteration 500, loss = 1.42224
I0625 21:06:27.719540 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.515142 (* 1 = 0.515142 loss)
I0625 21:06:27.719552 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.111623 (* 1 = 0.111623 loss)
I0625 21:06:27.719555 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0539156 (* 2 = 0.107831 loss)
I0625 21:06:27.719559 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0192272 (* 3 = 0.0576815 loss)
I0625 21:06:27.719563 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.152171 (* 1 = 0.152171 loss)
I0625 21:06:27.719566 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.134614 (* 1 = 0.134614 loss)
I0625 21:06:27.719571 26920 sgd_solver.cpp:106] Iteration 500, lr = 0.0001
I0625 21:06:55.263356 26920 solver.cpp:229] Iteration 520, loss = 1.47144
I0625 21:06:55.318084 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.77357 (* 1 = 1.77357 loss)
I0625 21:06:55.318099 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0027703 (* 1 = 0.0027703 loss)
I0625 21:06:55.318104 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.081617 (* 2 = 0.163234 loss)
I0625 21:06:55.318109 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0343274 (* 3 = 0.102982 loss)
I0625 21:06:55.318112 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00108779 (* 1 = 0.00108779 loss)
I0625 21:06:55.318116 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0122332 (* 1 = 0.0122332 loss)
I0625 21:06:55.318121 26920 sgd_solver.cpp:106] Iteration 520, lr = 0.0001
I0625 21:07:22.237382 26920 solver.cpp:229] Iteration 540, loss = 1.74004
I0625 21:07:22.291225 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.530105 (* 1 = 0.530105 loss)
I0625 21:07:22.291235 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.444787 (* 1 = 0.444787 loss)
I0625 21:07:22.291240 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.189644 (* 2 = 0.379287 loss)
I0625 21:07:22.291244 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0997114 (* 3 = 0.299134 loss)
I0625 21:07:22.291249 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.028898 (* 1 = 0.028898 loss)
I0625 21:07:22.291252 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0454696 (* 1 = 0.0454696 loss)
I0625 21:07:22.291257 26920 sgd_solver.cpp:106] Iteration 540, lr = 0.0001
I0625 21:07:50.504590 26920 solver.cpp:229] Iteration 560, loss = 1.25584
I0625 21:07:50.559481 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.532155 (* 1 = 0.532155 loss)
I0625 21:07:50.559499 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.200993 (* 1 = 0.200993 loss)
I0625 21:07:50.559505 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.22413 (* 2 = 0.44826 loss)
I0625 21:07:50.559511 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.109324 (* 3 = 0.327972 loss)
I0625 21:07:50.559517 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00494144 (* 1 = 0.00494144 loss)
I0625 21:07:50.559523 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.101983 (* 1 = 0.101983 loss)
I0625 21:07:50.559531 26920 sgd_solver.cpp:106] Iteration 560, lr = 0.0001
I0625 21:08:20.421527 26920 solver.cpp:229] Iteration 580, loss = 1.43335
I0625 21:08:20.478112 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.40091 (* 1 = 1.40091 loss)
I0625 21:08:20.478127 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.00761048 (* 1 = 0.00761048 loss)
I0625 21:08:20.478134 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0188692 (* 2 = 0.0377385 loss)
I0625 21:08:20.478142 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00860579 (* 3 = 0.0258174 loss)
I0625 21:08:20.478149 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00476483 (* 1 = 0.00476483 loss)
I0625 21:08:20.478157 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00840526 (* 1 = 0.00840526 loss)
I0625 21:08:20.478165 26920 sgd_solver.cpp:106] Iteration 580, lr = 0.0001
speed: 1.303s / iter
I0625 21:08:47.446054 26920 solver.cpp:229] Iteration 600, loss = 1.52359
I0625 21:08:47.503850 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.799441 (* 1 = 0.799441 loss)
I0625 21:08:47.503863 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.034467 (* 1 = 0.034467 loss)
I0625 21:08:47.503867 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0250395 (* 2 = 0.050079 loss)
I0625 21:08:47.503871 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.161563 (* 3 = 0.48469 loss)
I0625 21:08:47.503875 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0240229 (* 1 = 0.0240229 loss)
I0625 21:08:47.503878 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0288408 (* 1 = 0.0288408 loss)
I0625 21:08:47.503883 26920 sgd_solver.cpp:106] Iteration 600, lr = 0.0001
I0625 21:09:16.346894 26920 solver.cpp:229] Iteration 620, loss = 1.10815
I0625 21:09:16.402423 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.935768 (* 1 = 0.935768 loss)
I0625 21:09:16.402434 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0502874 (* 1 = 0.0502874 loss)
I0625 21:09:16.402438 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0920351 (* 2 = 0.18407 loss)
I0625 21:09:16.402442 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00560535 (* 3 = 0.0168161 loss)
I0625 21:09:16.402446 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0149252 (* 1 = 0.0149252 loss)
I0625 21:09:16.402451 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0183527 (* 1 = 0.0183527 loss)
I0625 21:09:16.402457 26920 sgd_solver.cpp:106] Iteration 620, lr = 0.0001
I0625 21:09:44.071554 26920 solver.cpp:229] Iteration 640, loss = 1.86575
I0625 21:09:44.125185 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.30556 (* 1 = 1.30556 loss)
I0625 21:09:44.125213 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0149045 (* 1 = 0.0149045 loss)
I0625 21:09:44.125218 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0307694 (* 2 = 0.0615389 loss)
I0625 21:09:44.125222 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00778493 (* 3 = 0.0233548 loss)
I0625 21:09:44.125226 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0162799 (* 1 = 0.0162799 loss)
I0625 21:09:44.125231 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0925687 (* 1 = 0.0925687 loss)
I0625 21:09:44.125236 26920 sgd_solver.cpp:106] Iteration 640, lr = 0.0001
I0625 21:10:09.697365 26920 solver.cpp:229] Iteration 660, loss = 1.46878
I0625 21:10:09.756548 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.688391 (* 1 = 0.688391 loss)
I0625 21:10:09.756569 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0326206 (* 1 = 0.0326206 loss)
I0625 21:10:09.756577 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.116241 (* 2 = 0.232482 loss)
I0625 21:10:09.756582 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0174375 (* 3 = 0.0523124 loss)
I0625 21:10:09.756587 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0174322 (* 1 = 0.0174322 loss)
I0625 21:10:09.756595 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0529713 (* 1 = 0.0529713 loss)
I0625 21:10:09.756603 26920 sgd_solver.cpp:106] Iteration 660, lr = 0.0001
I0625 21:10:37.233619 26920 solver.cpp:229] Iteration 680, loss = 1.47902
I0625 21:10:37.292953 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.906671 (* 1 = 0.906671 loss)
I0625 21:10:37.292968 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.142373 (* 1 = 0.142373 loss)
I0625 21:10:37.292971 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.176016 (* 2 = 0.352032 loss)
I0625 21:10:37.292975 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0087695 (* 3 = 0.0263085 loss)
I0625 21:10:37.292979 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00184673 (* 1 = 0.00184673 loss)
I0625 21:10:37.292984 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0090995 (* 1 = 0.0090995 loss)
I0625 21:10:37.292989 26920 sgd_solver.cpp:106] Iteration 680, lr = 0.0001
I0625 21:11:04.611634 26920 solver.cpp:229] Iteration 700, loss = 1.30374
I0625 21:11:04.667605 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.799695 (* 1 = 0.799695 loss)
I0625 21:11:04.667616 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.157069 (* 1 = 0.157069 loss)
I0625 21:11:04.667620 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.150141 (* 2 = 0.300281 loss)
I0625 21:11:04.667624 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00315419 (* 3 = 0.00946256 loss)
I0625 21:11:04.667627 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0235265 (* 1 = 0.0235265 loss)
I0625 21:11:04.667631 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00949613 (* 1 = 0.00949613 loss)
I0625 21:11:04.667635 26920 sgd_solver.cpp:106] Iteration 700, lr = 0.0001
I0625 21:11:31.323812 26920 solver.cpp:229] Iteration 720, loss = 1.32623
I0625 21:11:31.383139 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.14448 (* 1 = 1.14448 loss)
I0625 21:11:31.383155 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0107452 (* 1 = 0.0107452 loss)
I0625 21:11:31.383160 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.102946 (* 2 = 0.205892 loss)
I0625 21:11:31.383164 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.000410896 (* 3 = 0.00123269 loss)
I0625 21:11:31.383168 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00120034 (* 1 = 0.00120034 loss)
I0625 21:11:31.383172 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0118579 (* 1 = 0.0118579 loss)
I0625 21:11:31.383177 26920 sgd_solver.cpp:106] Iteration 720, lr = 0.0001
I0625 21:11:58.254760 26920 solver.cpp:229] Iteration 740, loss = 1.41376
I0625 21:11:58.313223 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.1831 (* 1 = 1.1831 loss)
I0625 21:11:58.313233 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0438076 (* 1 = 0.0438076 loss)
I0625 21:11:58.313238 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0962222 (* 2 = 0.192444 loss)
I0625 21:11:58.313242 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00131071 (* 3 = 0.00393214 loss)
I0625 21:11:58.313246 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0035292 (* 1 = 0.0035292 loss)
I0625 21:11:58.313251 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00950266 (* 1 = 0.00950266 loss)
I0625 21:11:58.313254 26920 sgd_solver.cpp:106] Iteration 740, lr = 0.0001
I0625 21:12:24.587612 26920 solver.cpp:229] Iteration 760, loss = 1.0363
I0625 21:12:24.644928 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.590374 (* 1 = 0.590374 loss)
I0625 21:12:24.644945 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0203915 (* 1 = 0.0203915 loss)
I0625 21:12:24.644953 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0238958 (* 2 = 0.0477915 loss)
I0625 21:12:24.644959 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00404098 (* 3 = 0.0121229 loss)
I0625 21:12:24.644966 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0157221 (* 1 = 0.0157221 loss)
I0625 21:12:24.644974 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0208408 (* 1 = 0.0208408 loss)
I0625 21:12:24.644981 26920 sgd_solver.cpp:106] Iteration 760, lr = 0.0001
I0625 21:12:49.885433 26920 solver.cpp:229] Iteration 780, loss = 1.34288
I0625 21:12:49.940982 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.483134 (* 1 = 0.483134 loss)
I0625 21:12:49.940994 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.253973 (* 1 = 0.253973 loss)
I0625 21:12:49.940999 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.111092 (* 2 = 0.222185 loss)
I0625 21:12:49.941002 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0065438 (* 3 = 0.0196314 loss)
I0625 21:12:49.941005 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0317603 (* 1 = 0.0317603 loss)
I0625 21:12:49.941009 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.107417 (* 1 = 0.107417 loss)
I0625 21:12:49.941025 26920 sgd_solver.cpp:106] Iteration 780, lr = 0.0001
speed: 1.317s / iter
I0625 21:13:19.146800 26920 solver.cpp:229] Iteration 800, loss = 1.40517
I0625 21:13:19.201645 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.612262 (* 1 = 0.612262 loss)
I0625 21:13:19.201660 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0453289 (* 1 = 0.0453289 loss)
I0625 21:13:19.201665 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.284002 (* 2 = 0.568004 loss)
I0625 21:13:19.201669 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00558347 (* 3 = 0.0167504 loss)
I0625 21:13:19.201673 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0263071 (* 1 = 0.0263071 loss)
I0625 21:13:19.201678 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0500442 (* 1 = 0.0500442 loss)
I0625 21:13:19.201683 26920 sgd_solver.cpp:106] Iteration 800, lr = 0.0001
I0625 21:13:45.825400 26920 solver.cpp:229] Iteration 820, loss = 1.52755
I0625 21:13:45.883291 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.381621 (* 1 = 0.381621 loss)
I0625 21:13:45.883306 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.319201 (* 1 = 0.319201 loss)
I0625 21:13:45.883311 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.310423 (* 2 = 0.620845 loss)
I0625 21:13:45.883314 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.110036 (* 3 = 0.330107 loss)
I0625 21:13:45.883318 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0077561 (* 1 = 0.0077561 loss)
I0625 21:13:45.883322 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0892483 (* 1 = 0.0892483 loss)
I0625 21:13:45.883327 26920 sgd_solver.cpp:106] Iteration 820, lr = 0.0001
I0625 21:14:10.477140 26920 solver.cpp:229] Iteration 840, loss = 1.44886
I0625 21:14:10.535295 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.659995 (* 1 = 0.659995 loss)
I0625 21:14:10.535312 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0446632 (* 1 = 0.0446632 loss)
I0625 21:14:10.535317 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.200277 (* 2 = 0.400553 loss)
I0625 21:14:10.535321 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0404041 (* 3 = 0.121212 loss)
I0625 21:14:10.535326 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0334986 (* 1 = 0.0334986 loss)
I0625 21:14:10.535331 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0543753 (* 1 = 0.0543753 loss)
I0625 21:14:10.535337 26920 sgd_solver.cpp:106] Iteration 840, lr = 0.0001
I0625 21:14:31.645867 26920 solver.cpp:229] Iteration 860, loss = 1.11725
I0625 21:14:31.702303 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.530196 (* 1 = 0.530196 loss)
I0625 21:14:31.702327 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0035792 (* 1 = 0.0035792 loss)
I0625 21:14:31.702332 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.107478 (* 2 = 0.214956 loss)
I0625 21:14:31.702335 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00982453 (* 3 = 0.0294736 loss)
I0625 21:14:31.702339 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0147056 (* 1 = 0.0147056 loss)
I0625 21:14:31.702345 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0740258 (* 1 = 0.0740258 loss)
I0625 21:14:31.702361 26920 sgd_solver.cpp:106] Iteration 860, lr = 0.0001
I0625 21:14:51.614168 26920 solver.cpp:229] Iteration 880, loss = 1.6356
I0625 21:14:51.673408 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.30182 (* 1 = 1.30182 loss)
I0625 21:14:51.673424 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.00396237 (* 1 = 0.00396237 loss)
I0625 21:14:51.673429 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.151197 (* 2 = 0.302393 loss)
I0625 21:14:51.673432 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0374835 (* 3 = 0.11245 loss)
I0625 21:14:51.673436 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00600239 (* 1 = 0.00600239 loss)
I0625 21:14:51.673441 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0082768 (* 1 = 0.0082768 loss)
I0625 21:14:51.673446 26920 sgd_solver.cpp:106] Iteration 880, lr = 0.0001
I0625 21:15:19.434211 26920 solver.cpp:229] Iteration 900, loss = 0.945364
I0625 21:15:19.492178 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.657418 (* 1 = 0.657418 loss)
I0625 21:15:19.492195 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0382576 (* 1 = 0.0382576 loss)
I0625 21:15:19.492200 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.075649 (* 2 = 0.151298 loss)
I0625 21:15:19.492204 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00410602 (* 3 = 0.0123181 loss)
I0625 21:15:19.492208 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00122175 (* 1 = 0.00122175 loss)
I0625 21:15:19.492213 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0252405 (* 1 = 0.0252405 loss)
I0625 21:15:19.492218 26920 sgd_solver.cpp:106] Iteration 900, lr = 0.0001
I0625 21:15:44.114156 26920 solver.cpp:229] Iteration 920, loss = 1.36311
I0625 21:15:44.170078 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.18608 (* 1 = 1.18608 loss)
I0625 21:15:44.170089 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.00545082 (* 1 = 0.00545082 loss)
I0625 21:15:44.170094 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.017254 (* 2 = 0.0345081 loss)
I0625 21:15:44.170097 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.000892871 (* 3 = 0.00267861 loss)
I0625 21:15:44.170101 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00205621 (* 1 = 0.00205621 loss)
I0625 21:15:44.170104 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00910905 (* 1 = 0.00910905 loss)
I0625 21:15:44.170120 26920 sgd_solver.cpp:106] Iteration 920, lr = 0.0001
I0625 21:16:07.853977 26920 solver.cpp:229] Iteration 940, loss = 1.20668
I0625 21:16:07.909585 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.03155 (* 1 = 1.03155 loss)
I0625 21:16:07.909605 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0325248 (* 1 = 0.0325248 loss)
I0625 21:16:07.909610 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0902233 (* 2 = 0.180447 loss)
I0625 21:16:07.909613 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.052332 (* 3 = 0.156996 loss)
I0625 21:16:07.909618 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00224511 (* 1 = 0.00224511 loss)
I0625 21:16:07.909622 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0292262 (* 1 = 0.0292262 loss)
I0625 21:16:07.909627 26920 sgd_solver.cpp:106] Iteration 940, lr = 0.0001
I0625 21:16:31.636663 26920 solver.cpp:229] Iteration 960, loss = 1.2251
I0625 21:16:31.692358 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.968287 (* 1 = 0.968287 loss)
I0625 21:16:31.692370 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.00369874 (* 1 = 0.00369874 loss)
I0625 21:16:31.692374 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0855845 (* 2 = 0.171169 loss)
I0625 21:16:31.692378 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00169136 (* 3 = 0.00507409 loss)
I0625 21:16:31.692382 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00164912 (* 1 = 0.00164912 loss)
I0625 21:16:31.692386 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0405067 (* 1 = 0.0405067 loss)
I0625 21:16:31.692401 26920 sgd_solver.cpp:106] Iteration 960, lr = 0.0001
I0625 21:16:54.736649 26920 solver.cpp:229] Iteration 980, loss = 1.58294
I0625 21:16:54.794920 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.846331 (* 1 = 0.846331 loss)
I0625 21:16:54.794955 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0277578 (* 1 = 0.0277578 loss)
I0625 21:16:54.794968 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.224662 (* 2 = 0.449325 loss)
I0625 21:16:54.794981 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0232238 (* 3 = 0.0696715 loss)
I0625 21:16:54.795022 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00218199 (* 1 = 0.00218199 loss)
I0625 21:16:54.795051 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0329522 (* 1 = 0.0329522 loss)
I0625 21:16:54.795080 26920 sgd_solver.cpp:106] Iteration 980, lr = 0.0001
speed: 1.296s / iter
I0625 21:17:21.886454 26920 solver.cpp:229] Iteration 1000, loss = 1.40685
I0625 21:17:21.943239 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.250155 (* 1 = 0.250155 loss)
I0625 21:17:21.943254 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.112745 (* 1 = 0.112745 loss)
I0625 21:17:21.943259 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.234718 (* 2 = 0.469436 loss)
I0625 21:17:21.943261 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.233773 (* 3 = 0.701318 loss)
I0625 21:17:21.943266 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00801461 (* 1 = 0.00801461 loss)
I0625 21:17:21.943269 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0113456 (* 1 = 0.0113456 loss)
I0625 21:17:21.943274 26920 sgd_solver.cpp:106] Iteration 1000, lr = 0.0001
I0625 21:17:45.452520 26920 solver.cpp:229] Iteration 1020, loss = 0.908561
I0625 21:17:45.508752 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.218927 (* 1 = 0.218927 loss)
I0625 21:17:45.508771 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0734587 (* 1 = 0.0734587 loss)
I0625 21:17:45.508778 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.163831 (* 2 = 0.327663 loss)
I0625 21:17:45.508785 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0932425 (* 3 = 0.279727 loss)
I0625 21:17:45.508791 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0276046 (* 1 = 0.0276046 loss)
I0625 21:17:45.508797 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.105423 (* 1 = 0.105423 loss)
I0625 21:17:45.508805 26920 sgd_solver.cpp:106] Iteration 1020, lr = 0.0001
I0625 21:18:12.374863 26920 solver.cpp:229] Iteration 1040, loss = 1.1177
I0625 21:18:12.430173 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.01352 (* 1 = 1.01352 loss)
I0625 21:18:12.430191 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.00601918 (* 1 = 0.00601918 loss)
I0625 21:18:12.430196 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0742368 (* 2 = 0.148474 loss)
I0625 21:18:12.430199 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00142317 (* 3 = 0.0042695 loss)
I0625 21:18:12.430204 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00110636 (* 1 = 0.00110636 loss)
I0625 21:18:12.430208 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0360011 (* 1 = 0.0360011 loss)
I0625 21:18:12.430214 26920 sgd_solver.cpp:106] Iteration 1040, lr = 0.0001
I0625 21:18:39.019126 26920 solver.cpp:229] Iteration 1060, loss = 1.19739
I0625 21:18:39.075793 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.857717 (* 1 = 0.857717 loss)
I0625 21:18:39.075819 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.00460651 (* 1 = 0.00460651 loss)
I0625 21:18:39.075824 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0458101 (* 2 = 0.0916202 loss)
I0625 21:18:39.075829 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.000565531 (* 3 = 0.00169659 loss)
I0625 21:18:39.075834 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00206639 (* 1 = 0.00206639 loss)
I0625 21:18:39.075848 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.009787 (* 1 = 0.009787 loss)
I0625 21:18:39.075855 26920 sgd_solver.cpp:106] Iteration 1060, lr = 0.0001
I0625 21:19:07.455343 26920 solver.cpp:229] Iteration 1080, loss = 1.04811
I0625 21:19:07.509085 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.317861 (* 1 = 0.317861 loss)
I0625 21:19:07.509101 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.373214 (* 1 = 0.373214 loss)
I0625 21:19:07.509105 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0956396 (* 2 = 0.191279 loss)
I0625 21:19:07.509109 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0454348 (* 3 = 0.136304 loss)
I0625 21:19:07.509114 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0117199 (* 1 = 0.0117199 loss)
I0625 21:19:07.509117 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0287872 (* 1 = 0.0287872 loss)
I0625 21:19:07.509122 26920 sgd_solver.cpp:106] Iteration 1080, lr = 0.0001
I0625 21:19:32.309744 26920 solver.cpp:229] Iteration 1100, loss = 0.893979
I0625 21:19:32.362993 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.599004 (* 1 = 0.599004 loss)
I0625 21:19:32.363008 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.00613521 (* 1 = 0.00613521 loss)
I0625 21:19:32.363013 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0175269 (* 2 = 0.0350539 loss)
I0625 21:19:32.363016 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00278825 (* 3 = 0.00836475 loss)
I0625 21:19:32.363020 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0220056 (* 1 = 0.0220056 loss)
I0625 21:19:32.363024 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0167087 (* 1 = 0.0167087 loss)
I0625 21:19:32.363029 26920 sgd_solver.cpp:106] Iteration 1100, lr = 0.0001
I0625 21:19:57.019431 26920 solver.cpp:229] Iteration 1120, loss = 0.911021
I0625 21:19:57.077536 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.879751 (* 1 = 0.879751 loss)
I0625 21:19:57.077549 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0547425 (* 1 = 0.0547425 loss)
I0625 21:19:57.077554 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.01949 (* 2 = 0.03898 loss)
I0625 21:19:57.077558 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00286925 (* 3 = 0.00860774 loss)
I0625 21:19:57.077563 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00153432 (* 1 = 0.00153432 loss)
I0625 21:19:57.077566 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00980752 (* 1 = 0.00980752 loss)
I0625 21:19:57.077582 26920 sgd_solver.cpp:106] Iteration 1120, lr = 0.0001
I0625 21:20:21.071728 26920 solver.cpp:229] Iteration 1140, loss = 0.981898
I0625 21:20:21.129385 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.683212 (* 1 = 0.683212 loss)
I0625 21:20:21.129410 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0193216 (* 1 = 0.0193216 loss)
I0625 21:20:21.129415 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.024898 (* 2 = 0.049796 loss)
I0625 21:20:21.129420 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0118228 (* 3 = 0.0354683 loss)
I0625 21:20:21.129423 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0323012 (* 1 = 0.0323012 loss)
I0625 21:20:21.129438 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0235329 (* 1 = 0.0235329 loss)
I0625 21:20:21.129443 26920 sgd_solver.cpp:106] Iteration 1140, lr = 0.0001
I0625 21:20:47.623700 26920 solver.cpp:229] Iteration 1160, loss = 2.2312
I0625 21:20:47.680450 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.333034 (* 1 = 0.333034 loss)
I0625 21:20:47.680462 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.1897 (* 1 = 0.1897 loss)
I0625 21:20:47.680467 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.108705 (* 2 = 0.217409 loss)
I0625 21:20:47.680471 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.108382 (* 3 = 0.325146 loss)
I0625 21:20:47.680475 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00396345 (* 1 = 0.00396345 loss)
I0625 21:20:47.680480 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0185158 (* 1 = 0.0185158 loss)
I0625 21:20:47.680485 26920 sgd_solver.cpp:106] Iteration 1160, lr = 0.0001
I0625 21:21:12.161459 26920 solver.cpp:229] Iteration 1180, loss = 1.56233
I0625 21:21:12.216972 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.559842 (* 1 = 0.559842 loss)
I0625 21:21:12.216985 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0533679 (* 1 = 0.0533679 loss)
I0625 21:21:12.216990 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.257133 (* 2 = 0.514266 loss)
I0625 21:21:12.216995 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00332056 (* 3 = 0.00996167 loss)
I0625 21:21:12.216998 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00332393 (* 1 = 0.00332393 loss)
I0625 21:21:12.217002 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0226769 (* 1 = 0.0226769 loss)
I0625 21:21:12.217007 26920 sgd_solver.cpp:106] Iteration 1180, lr = 0.0001
speed: 1.295s / iter
I0625 21:21:39.636632 26920 solver.cpp:229] Iteration 1200, loss = 1.5453
I0625 21:21:39.692061 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.346715 (* 1 = 0.346715 loss)
I0625 21:21:39.692073 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.332544 (* 1 = 0.332544 loss)
I0625 21:21:39.692076 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.183688 (* 2 = 0.367375 loss)
I0625 21:21:39.692080 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00378887 (* 3 = 0.0113666 loss)
I0625 21:21:39.692085 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.054134 (* 1 = 0.054134 loss)
I0625 21:21:39.692088 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0724193 (* 1 = 0.0724193 loss)
I0625 21:21:39.692103 26920 sgd_solver.cpp:106] Iteration 1200, lr = 0.0001
I0625 21:22:06.348407 26920 solver.cpp:229] Iteration 1220, loss = 1.46904
I0625 21:22:06.403363 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.82344 (* 1 = 0.82344 loss)
I0625 21:22:06.403381 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.00279441 (* 1 = 0.00279441 loss)
I0625 21:22:06.403386 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0366239 (* 2 = 0.0732478 loss)
I0625 21:22:06.403391 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.000774362 (* 3 = 0.00232309 loss)
I0625 21:22:06.403395 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00227207 (* 1 = 0.00227207 loss)
I0625 21:22:06.403399 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0243737 (* 1 = 0.0243737 loss)
I0625 21:22:06.403405 26920 sgd_solver.cpp:106] Iteration 1220, lr = 0.0001
I0625 21:22:34.943374 26920 solver.cpp:229] Iteration 1240, loss = 1.0508
I0625 21:22:35.000952 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.791811 (* 1 = 0.791811 loss)
I0625 21:22:35.000968 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0394674 (* 1 = 0.0394674 loss)
I0625 21:22:35.000972 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0748904 (* 2 = 0.149781 loss)
I0625 21:22:35.000977 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0127551 (* 3 = 0.0382654 loss)
I0625 21:22:35.000979 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00271226 (* 1 = 0.00271226 loss)
I0625 21:22:35.000983 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0317168 (* 1 = 0.0317168 loss)
I0625 21:22:35.000998 26920 sgd_solver.cpp:106] Iteration 1240, lr = 0.0001
I0625 21:23:02.836680 26920 solver.cpp:229] Iteration 1260, loss = 0.757764
I0625 21:23:02.895262 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.482586 (* 1 = 0.482586 loss)
I0625 21:23:02.895277 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.00795908 (* 1 = 0.00795908 loss)
I0625 21:23:02.895282 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.102352 (* 2 = 0.204705 loss)
I0625 21:23:02.895285 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0907229 (* 3 = 0.272169 loss)
I0625 21:23:02.895288 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0137786 (* 1 = 0.0137786 loss)
I0625 21:23:02.895292 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.00894075 (* 1 = 0.00894075 loss)
I0625 21:23:02.895308 26920 sgd_solver.cpp:106] Iteration 1260, lr = 0.0001
I0625 21:23:30.465517 26920 solver.cpp:229] Iteration 1280, loss = 1.54741
I0625 21:23:30.523275 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.99266 (* 1 = 0.99266 loss)
I0625 21:23:30.523291 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0084132 (* 1 = 0.0084132 loss)
I0625 21:23:30.523295 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0259548 (* 2 = 0.0519096 loss)
I0625 21:23:30.523299 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.129755 (* 3 = 0.389264 loss)
I0625 21:23:30.523303 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00306193 (* 1 = 0.00306193 loss)
I0625 21:23:30.523308 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0120621 (* 1 = 0.0120621 loss)
I0625 21:23:30.523322 26920 sgd_solver.cpp:106] Iteration 1280, lr = 0.0001
I0625 21:23:54.357555 26920 solver.cpp:229] Iteration 1300, loss = 0.846002
I0625 21:23:54.414165 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.515668 (* 1 = 0.515668 loss)
I0625 21:23:54.414182 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0260763 (* 1 = 0.0260763 loss)
I0625 21:23:54.414187 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.222904 (* 2 = 0.445808 loss)
I0625 21:23:54.414194 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.00712299 (* 3 = 0.021369 loss)
I0625 21:23:54.414199 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00507035 (* 1 = 0.00507035 loss)
I0625 21:23:54.414216 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0383126 (* 1 = 0.0383126 loss)
I0625 21:23:54.414222 26920 sgd_solver.cpp:106] Iteration 1300, lr = 0.0001
I0625 21:24:18.436468 26920 solver.cpp:229] Iteration 1320, loss = 2.18341
I0625 21:24:18.491616 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 1.27037 (* 1 = 1.27037 loss)
I0625 21:24:18.491628 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.048739 (* 1 = 0.048739 loss)
I0625 21:24:18.491632 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.470227 (* 2 = 0.940454 loss)
I0625 21:24:18.491636 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.191229 (* 3 = 0.573688 loss)
I0625 21:24:18.491641 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0244459 (* 1 = 0.0244459 loss)
I0625 21:24:18.491644 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0621862 (* 1 = 0.0621862 loss)
I0625 21:24:18.491649 26920 sgd_solver.cpp:106] Iteration 1320, lr = 0.0001
I0625 21:24:47.157850 26920 solver.cpp:229] Iteration 1340, loss = 0.785009
I0625 21:24:47.214468 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.709231 (* 1 = 0.709231 loss)
I0625 21:24:47.214484 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.00379256 (* 1 = 0.00379256 loss)
I0625 21:24:47.214488 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0206191 (* 2 = 0.0412383 loss)
I0625 21:24:47.214494 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.000751278 (* 3 = 0.00225383 loss)
I0625 21:24:47.214500 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00181503 (* 1 = 0.00181503 loss)
I0625 21:24:47.214506 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.029747 (* 1 = 0.029747 loss)
I0625 21:24:47.214511 26920 sgd_solver.cpp:106] Iteration 1340, lr = 0.0001
I0625 21:25:14.687916 26920 solver.cpp:229] Iteration 1360, loss = 1.60856
I0625 21:25:14.743904 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.6542 (* 1 = 0.6542 loss)
I0625 21:25:14.743927 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0268407 (* 1 = 0.0268407 loss)
I0625 21:25:14.743932 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.117725 (* 2 = 0.23545 loss)
I0625 21:25:14.743937 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.0185144 (* 3 = 0.0555431 loss)
I0625 21:25:14.743940 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0195889 (* 1 = 0.0195889 loss)
I0625 21:25:14.743945 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0684104 (* 1 = 0.0684104 loss)
I0625 21:25:14.743950 26920 sgd_solver.cpp:106] Iteration 1360, lr = 0.0001
I0625 21:25:41.072482 26920 solver.cpp:229] Iteration 1380, loss = 1.26879
I0625 21:25:41.130105 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.737266 (* 1 = 0.737266 loss)
I0625 21:25:41.130118 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.02373 (* 1 = 0.02373 loss)
I0625 21:25:41.130122 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.210686 (* 2 = 0.421372 loss)
I0625 21:25:41.130126 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.173567 (* 3 = 0.520702 loss)
I0625 21:25:41.130129 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.00348221 (* 1 = 0.00348221 loss)
I0625 21:25:41.130133 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0123764 (* 1 = 0.0123764 loss)
I0625 21:25:41.130138 26920 sgd_solver.cpp:106] Iteration 1380, lr = 0.0001
speed: 1.301s / iter
I0625 21:26:06.993150 26920 solver.cpp:229] Iteration 1400, loss = 1.25122
I0625 21:26:07.047962 26920 solver.cpp:245]     Train net output #0: cross_entropy_mean = 0.66634 (* 1 = 0.66634 loss)
I0625 21:26:07.047978 26920 solver.cpp:245]     Train net output #1: loss_attribute = 0.0250293 (* 1 = 0.0250293 loss)
I0625 21:26:07.047982 26920 solver.cpp:245]     Train net output #2: loss_bbox = 0.0752084 (* 2 = 0.150417 loss)
I0625 21:26:07.047986 26920 solver.cpp:245]     Train net output #3: loss_cls = 0.04008 (* 3 = 0.12024 loss)
I0625 21:26:07.047991 26920 solver.cpp:245]     Train net output #4: rpn_cls_loss = 0.0060823 (* 1 = 0.0060823 loss)
I0625 21:26:07.047993 26920 solver.cpp:245]     Train net output #5: rpn_loss_bbox = 0.0184163 (* 1 = 0.0184163 loss)
I0625 21:26:07.047998 26920 sgd_solver.cpp:106] Iteration 1400, lr = 0.0001
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:83: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:83: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 0::4] = np.maximum(np.minimum(boxes[:, 0::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:85: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:85: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 1::4] = np.maximum(np.minimum(boxes[:, 1::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:87: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:87: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 2::4] = np.maximum(np.minimum(boxes[:, 2::4], im_shape[1] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:89: RuntimeWarning: invalid value encountered in minimum
  boxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/fast_rcnn/bbox_transform.py:89: RuntimeWarning: invalid value encountered in maximum
  boxes[:, 3::4] = np.maximum(np.minimum(boxes[:, 3::4], im_shape[0] - 1), 0)
/home/fujenchu/projects/affordanceContext/affordance-net/tools/../lib/rpn/proposal_layer.py:187: RuntimeWarning: invalid value encountered in greater_equal
  keep = np.where((ws >= min_size) & (hs >= min_size))[0]
---- WARNING: filter_boxes() remove ALL proposal.
./experiments/scripts/faster_rcnn_end2end.sh: line 65: 26920 Floating point exception/usr/bin/python ./tools/train_net.py --gpu ${GPU_ID} --solver models/${PT_DIR}/${NET}/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb ${TRAIN_IMDB} --iters ${ITERS} --cfg experiments/cfgs/faster_rcnn_end2end.yml ${EXTRA_ARGS}
