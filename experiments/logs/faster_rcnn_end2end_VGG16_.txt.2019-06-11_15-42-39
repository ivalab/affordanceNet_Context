+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-11_15-42-39
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2019-06-11_15-42-39
+ /usr/bin/python ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2012_train --iters 2000000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2012_train', max_iters=2000000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'BBOX_XFORM_CLIP': 4.135166556742356,
 'DATA_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net/models/coco',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 7,
 'ROOT_DIR': '/home/fujenchu/projects/affordanceContext/affordance-net',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MASK_REG': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 1000,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False,
          'TEST_INSTANCE': True},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 48,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CLASS_NUM': 7,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'KLdivergence': True,
           'MASK_REG': True,
           'MASK_SIZE': 244,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 5000,
           'TRAINING_DATA': 'VOC_2012_train',
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2012_train` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
voc_2012_train gt roidb loaded from /home/fujenchu/projects/affordanceContext/affordance-net/data/cache/voc_2012_train_gt_roidb.pkl
done
Preparing training data...
done
41748 roidb entries
Output will be saved to `/home/fujenchu/projects/affordanceContext/affordance-net/output/faster_rcnn_end2end/voc_2012_train`
Filtered 0 roidb entries: 41748 -> 41748
cfg.TRAIN.BBOX_REG = True
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0611 15:42:46.263882 14324 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 49370
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0611 15:42:46.263903 14324 solver.cpp:81] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0611 15:42:46.265285 14324 net.cpp:49] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  top: "seg_mask_inds"
  top: "flipped"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 30
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 60
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16 \n\'scales\': !!python/tuple [2, 4, 8, 16, 32]"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "seg_mask_inds"
  bottom: "flipped"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  top: "mask_targets"
  top: "rois_pos"
  top: "attrArray"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 2"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "attr_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "attr_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_attribute"
  type: "SigmoidCrossEntropyLoss"
  bottom: "attr_score"
  bottom: "attrArray"
  top: "loss_attribute"
  loss_weight: 0.1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 2
}
layer {
  name: "roi_pool5_2"
  type: "ROIAlignment"
  bottom: "conv5_3"
  bottom: "rois_pos"
  top: "pool5_2"
  roi_alignment_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "pool5_2_conv"
  type: "Convolution"
  bottom: "pool5_2"
  top: "pool5_2_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv_relu"
  type: "ReLU"
  bottom: "pool5_2_conv"
  top: "pool5_2_conv_relu"
}
layer {
  name: "pool5_2_conv2"
  type: "Convolution"
  bottom: "pool5_2_conv_relu"
  top: "pool5_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv2_relu"
  type: "ReLU"
  bottom: "pool5_2_conv2"
  top: "pool5_2_conv2_relu"
}
layer {
  name: "mask_deconv1"
  type: "Deconvolution"
  bottom: "pool5_2_conv2_relu"
  top: "mask_deconv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv3"
  type: "Convolution"
  bottom: "mask_deconv1"
  top: "pool5_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv3_relu"
  type: "ReLU"
  bottom: "pool5_2_conv3"
  top: "pool5_2_conv3_relu"
}
layer {
  name: "pool5_2_conv4"
  type: "Convolution"
  bottom: "pool5_2_conv3_relu"
  top: "pool5_2_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv4_relu"
  type: "ReLU"
  bottom: "pool5_2_conv4"
  top: "pool5_2_conv4_relu"
}
layer {
  name: "query_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "query_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "key_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "key_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "value_conv"
  type: "Convolution"
  bottom: "pool5_2_conv4_relu"
  top: "value_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "query_conv_reshape"
  type: "Reshape"
  bottom: "query_conv"
  top: "query_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "key_conv_reshape"
  type: "Reshape"
  bottom: "key_conv"
  top: "key_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 64
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "value_conv_reshape"
  type: "Reshape"
  bottom: "value_conv"
  top: "value_conv_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 900
      dim: 1
    }
  }
}
layer {
  name: "query_conv_reshape_perm"
  type: "Permute"
  bottom: "query_conv_reshape"
  top: "query_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 2
    order: 1
  }
}
layer {
  name: "key_conv_reshape_perm"
  type: "Permute"
  bottom: "key_conv_reshape"
  top: "key_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "energy"
  type: "MatrixMultiplication"
  bottom: "query_conv_reshape_perm"
  bottom: "key_conv_reshape_perm"
  top: "energy"
}
layer {
  name: "attention"
  type: "Softmax"
  bottom: "energy"
  top: "attention"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "value_conv_reshape_perm"
  type: "Permute"
  bottom: "value_conv_reshape"
  top: "value_conv_reshape_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "attention_perm"
  type: "Permute"
  bottom: "attention"
  top: "attention_perm"
  permute_param {
    order: 0
    order: 1
    order: 2
    order: 3
  }
}
layer {
  name: "out"
  type: "MatrixMultiplication"
  bottom: "value_conv_reshape_perm"
  bottom: "attention_perm"
  top: "out"
}
layer {
  name: "out_reshape"
  type: "Reshape"
  bottom: "out"
  top: "out_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 512
      dim: 30
      dim: 30
    }
  }
}
layer {
  name: "out_reshape_scale"
  type: "Scale"
  bottom: "out_reshape"
  top: "out_reshape_scale"
  param {
    name: "scale_conv1_1"
    lr_mult: 1
  }
  scale_param {
    bias_term: false
  }
}
layer {
  name: "out_x"
  type: "Eltwise"
  bottom: "out_reshape_scale"
  bottom: "pool5_2_conv4_relu"
  top: "out_x"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "mask_deconv2"
  type: "Deconvolution"
  bottom: "out_x"
  top: "mask_deconv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 8
    group: 256
    stride: 4
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "pool5_2_conv5"
  type: "Convolution"
  bottom: "mask_deconv2"
  top: "pool5_2_conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv5_relu"
  type: "ReLU"
  bottom: "pool5_2_conv5"
  top: "pool5_2_conv5_relu"
}
layer {
  name: "pool5_2_conv6"
  type: "Convolution"
  bottom: "pool5_2_conv5_relu"
  top: "pool5_2_conv6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pool5_2_conv6_relu"
  type: "ReLU"
  bottom: "pool5_2_conv6"
  top: "pool5_2_conv6_relu"
}
layer {
  name: "mask_deconv3"
  type: "Deconvolution"
  bottom: "pool5_2_conv6_relu"
  top: "mask_deconv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 4
    group: 256
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "mask_score"
  type: "Convolution"
  bottom: "mask_deconv3"
  top: "mask_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 0
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_mask"
  type: "SoftmaxWithLoss"
  bottom: "mask_score"
  bottom: "mask_targets"
  top: "loss_mask"
  loss_weight: 3
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
I0611 15:42:46.265589 14324 layer_factory.hpp:77] Creating layer input-data
I0611 15:42:46.297860 14324 net.cpp:106] Creating Layer input-data
I0611 15:42:46.297876 14324 net.cpp:411] input-data -> data
I0611 15:42:46.297884 14324 net.cpp:411] input-data -> im_info
I0611 15:42:46.297888 14324 net.cpp:411] input-data -> gt_boxes
I0611 15:42:46.297894 14324 net.cpp:411] input-data -> seg_mask_inds
I0611 15:42:46.297896 14324 net.cpp:411] input-data -> flipped
RoiDataLayer: name_to_top: {'gt_boxes': 2, 'data': 0, 'seg_mask_inds': 3, 'im_info': 1, 'flipped': 4}
I0611 15:42:46.308935 14324 net.cpp:150] Setting up input-data
I0611 15:42:46.308959 14324 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 15:42:46.308974 14324 net.cpp:157] Top shape: 1 3 (3)
I0611 15:42:46.308976 14324 net.cpp:157] Top shape: 1 4 (4)
I0611 15:42:46.308979 14324 net.cpp:157] Top shape: 1 2 (2)
I0611 15:42:46.308981 14324 net.cpp:157] Top shape: 1 1 (1)
I0611 15:42:46.308984 14324 net.cpp:165] Memory required for data: 7200040
I0611 15:42:46.308990 14324 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0611 15:42:46.309001 14324 net.cpp:106] Creating Layer data_input-data_0_split
I0611 15:42:46.309005 14324 net.cpp:454] data_input-data_0_split <- data
I0611 15:42:46.309010 14324 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_0
I0611 15:42:46.309017 14324 net.cpp:411] data_input-data_0_split -> data_input-data_0_split_1
I0611 15:42:46.309038 14324 net.cpp:150] Setting up data_input-data_0_split
I0611 15:42:46.309042 14324 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 15:42:46.309046 14324 net.cpp:157] Top shape: 1 3 600 1000 (1800000)
I0611 15:42:46.309047 14324 net.cpp:165] Memory required for data: 21600040
I0611 15:42:46.309051 14324 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0611 15:42:46.309056 14324 net.cpp:106] Creating Layer im_info_input-data_1_split
I0611 15:42:46.309058 14324 net.cpp:454] im_info_input-data_1_split <- im_info
I0611 15:42:46.309062 14324 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0611 15:42:46.309065 14324 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0611 15:42:46.309072 14324 net.cpp:411] im_info_input-data_1_split -> im_info_input-data_1_split_2
I0611 15:42:46.309095 14324 net.cpp:150] Setting up im_info_input-data_1_split
I0611 15:42:46.309099 14324 net.cpp:157] Top shape: 1 3 (3)
I0611 15:42:46.309103 14324 net.cpp:157] Top shape: 1 3 (3)
I0611 15:42:46.309105 14324 net.cpp:157] Top shape: 1 3 (3)
I0611 15:42:46.309108 14324 net.cpp:165] Memory required for data: 21600076
I0611 15:42:46.309109 14324 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0611 15:42:46.309113 14324 net.cpp:106] Creating Layer gt_boxes_input-data_2_split
I0611 15:42:46.309115 14324 net.cpp:454] gt_boxes_input-data_2_split <- gt_boxes
I0611 15:42:46.309118 14324 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0611 15:42:46.309123 14324 net.cpp:411] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0611 15:42:46.309140 14324 net.cpp:150] Setting up gt_boxes_input-data_2_split
I0611 15:42:46.309144 14324 net.cpp:157] Top shape: 1 4 (4)
I0611 15:42:46.309146 14324 net.cpp:157] Top shape: 1 4 (4)
I0611 15:42:46.309150 14324 net.cpp:165] Memory required for data: 21600108
I0611 15:42:46.309152 14324 layer_factory.hpp:77] Creating layer conv1_1
I0611 15:42:46.309160 14324 net.cpp:106] Creating Layer conv1_1
I0611 15:42:46.309164 14324 net.cpp:454] conv1_1 <- data_input-data_0_split_0
I0611 15:42:46.309167 14324 net.cpp:411] conv1_1 -> conv1_1
I0611 15:42:46.503129 14324 net.cpp:150] Setting up conv1_1
I0611 15:42:46.503146 14324 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 15:42:46.503149 14324 net.cpp:165] Memory required for data: 175200108
I0611 15:42:46.503161 14324 layer_factory.hpp:77] Creating layer relu1_1
I0611 15:42:46.503170 14324 net.cpp:106] Creating Layer relu1_1
I0611 15:42:46.503173 14324 net.cpp:454] relu1_1 <- conv1_1
I0611 15:42:46.503187 14324 net.cpp:397] relu1_1 -> conv1_1 (in-place)
I0611 15:42:46.503307 14324 net.cpp:150] Setting up relu1_1
I0611 15:42:46.503314 14324 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 15:42:46.503316 14324 net.cpp:165] Memory required for data: 328800108
I0611 15:42:46.503319 14324 layer_factory.hpp:77] Creating layer conv1_2
I0611 15:42:46.503325 14324 net.cpp:106] Creating Layer conv1_2
I0611 15:42:46.503327 14324 net.cpp:454] conv1_2 <- conv1_1
I0611 15:42:46.503331 14324 net.cpp:411] conv1_2 -> conv1_2
I0611 15:42:46.505395 14324 net.cpp:150] Setting up conv1_2
I0611 15:42:46.505404 14324 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 15:42:46.505407 14324 net.cpp:165] Memory required for data: 482400108
I0611 15:42:46.505429 14324 layer_factory.hpp:77] Creating layer relu1_2
I0611 15:42:46.505436 14324 net.cpp:106] Creating Layer relu1_2
I0611 15:42:46.505442 14324 net.cpp:454] relu1_2 <- conv1_2
I0611 15:42:46.505445 14324 net.cpp:397] relu1_2 -> conv1_2 (in-place)
I0611 15:42:46.505570 14324 net.cpp:150] Setting up relu1_2
I0611 15:42:46.505576 14324 net.cpp:157] Top shape: 1 64 600 1000 (38400000)
I0611 15:42:46.505578 14324 net.cpp:165] Memory required for data: 636000108
I0611 15:42:46.505581 14324 layer_factory.hpp:77] Creating layer pool1
I0611 15:42:46.505587 14324 net.cpp:106] Creating Layer pool1
I0611 15:42:46.505590 14324 net.cpp:454] pool1 <- conv1_2
I0611 15:42:46.505594 14324 net.cpp:411] pool1 -> pool1
I0611 15:42:46.505625 14324 net.cpp:150] Setting up pool1
I0611 15:42:46.505630 14324 net.cpp:157] Top shape: 1 64 300 500 (9600000)
I0611 15:42:46.505632 14324 net.cpp:165] Memory required for data: 674400108
I0611 15:42:46.505635 14324 layer_factory.hpp:77] Creating layer conv2_1
I0611 15:42:46.505640 14324 net.cpp:106] Creating Layer conv2_1
I0611 15:42:46.505642 14324 net.cpp:454] conv2_1 <- pool1
I0611 15:42:46.505658 14324 net.cpp:411] conv2_1 -> conv2_1
I0611 15:42:46.507346 14324 net.cpp:150] Setting up conv2_1
I0611 15:42:46.507354 14324 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 15:42:46.507357 14324 net.cpp:165] Memory required for data: 751200108
I0611 15:42:46.507364 14324 layer_factory.hpp:77] Creating layer relu2_1
I0611 15:42:46.507369 14324 net.cpp:106] Creating Layer relu2_1
I0611 15:42:46.507371 14324 net.cpp:454] relu2_1 <- conv2_1
I0611 15:42:46.507375 14324 net.cpp:397] relu2_1 -> conv2_1 (in-place)
I0611 15:42:46.507843 14324 net.cpp:150] Setting up relu2_1
I0611 15:42:46.507850 14324 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 15:42:46.507853 14324 net.cpp:165] Memory required for data: 828000108
I0611 15:42:46.507855 14324 layer_factory.hpp:77] Creating layer conv2_2
I0611 15:42:46.507861 14324 net.cpp:106] Creating Layer conv2_2
I0611 15:42:46.507863 14324 net.cpp:454] conv2_2 <- conv2_1
I0611 15:42:46.507867 14324 net.cpp:411] conv2_2 -> conv2_2
I0611 15:42:46.509173 14324 net.cpp:150] Setting up conv2_2
I0611 15:42:46.509181 14324 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 15:42:46.509184 14324 net.cpp:165] Memory required for data: 904800108
I0611 15:42:46.509189 14324 layer_factory.hpp:77] Creating layer relu2_2
I0611 15:42:46.509193 14324 net.cpp:106] Creating Layer relu2_2
I0611 15:42:46.509196 14324 net.cpp:454] relu2_2 <- conv2_2
I0611 15:42:46.509199 14324 net.cpp:397] relu2_2 -> conv2_2 (in-place)
I0611 15:42:46.509326 14324 net.cpp:150] Setting up relu2_2
I0611 15:42:46.509332 14324 net.cpp:157] Top shape: 1 128 300 500 (19200000)
I0611 15:42:46.509335 14324 net.cpp:165] Memory required for data: 981600108
I0611 15:42:46.509337 14324 layer_factory.hpp:77] Creating layer pool2
I0611 15:42:46.509341 14324 net.cpp:106] Creating Layer pool2
I0611 15:42:46.509343 14324 net.cpp:454] pool2 <- conv2_2
I0611 15:42:46.509347 14324 net.cpp:411] pool2 -> pool2
I0611 15:42:46.509385 14324 net.cpp:150] Setting up pool2
I0611 15:42:46.509392 14324 net.cpp:157] Top shape: 1 128 150 250 (4800000)
I0611 15:42:46.509393 14324 net.cpp:165] Memory required for data: 1000800108
I0611 15:42:46.509395 14324 layer_factory.hpp:77] Creating layer conv3_1
I0611 15:42:46.509402 14324 net.cpp:106] Creating Layer conv3_1
I0611 15:42:46.509404 14324 net.cpp:454] conv3_1 <- pool2
I0611 15:42:46.509408 14324 net.cpp:411] conv3_1 -> conv3_1
I0611 15:42:46.511219 14324 net.cpp:150] Setting up conv3_1
I0611 15:42:46.511229 14324 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 15:42:46.511231 14324 net.cpp:165] Memory required for data: 1039200108
I0611 15:42:46.511238 14324 layer_factory.hpp:77] Creating layer relu3_1
I0611 15:42:46.511242 14324 net.cpp:106] Creating Layer relu3_1
I0611 15:42:46.511245 14324 net.cpp:454] relu3_1 <- conv3_1
I0611 15:42:46.511258 14324 net.cpp:397] relu3_1 -> conv3_1 (in-place)
I0611 15:42:46.511379 14324 net.cpp:150] Setting up relu3_1
I0611 15:42:46.511385 14324 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 15:42:46.511387 14324 net.cpp:165] Memory required for data: 1077600108
I0611 15:42:46.511389 14324 layer_factory.hpp:77] Creating layer conv3_2
I0611 15:42:46.511396 14324 net.cpp:106] Creating Layer conv3_2
I0611 15:42:46.511399 14324 net.cpp:454] conv3_2 <- conv3_1
I0611 15:42:46.511404 14324 net.cpp:411] conv3_2 -> conv3_2
I0611 15:42:46.513384 14324 net.cpp:150] Setting up conv3_2
I0611 15:42:46.513393 14324 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 15:42:46.513396 14324 net.cpp:165] Memory required for data: 1116000108
I0611 15:42:46.513401 14324 layer_factory.hpp:77] Creating layer relu3_2
I0611 15:42:46.513406 14324 net.cpp:106] Creating Layer relu3_2
I0611 15:42:46.513408 14324 net.cpp:454] relu3_2 <- conv3_2
I0611 15:42:46.513438 14324 net.cpp:397] relu3_2 -> conv3_2 (in-place)
I0611 15:42:46.513607 14324 net.cpp:150] Setting up relu3_2
I0611 15:42:46.513614 14324 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 15:42:46.513626 14324 net.cpp:165] Memory required for data: 1154400108
I0611 15:42:46.513629 14324 layer_factory.hpp:77] Creating layer conv3_3
I0611 15:42:46.513634 14324 net.cpp:106] Creating Layer conv3_3
I0611 15:42:46.513638 14324 net.cpp:454] conv3_3 <- conv3_2
I0611 15:42:46.513653 14324 net.cpp:411] conv3_3 -> conv3_3
I0611 15:42:46.515946 14324 net.cpp:150] Setting up conv3_3
I0611 15:42:46.515980 14324 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 15:42:46.515982 14324 net.cpp:165] Memory required for data: 1192800108
I0611 15:42:46.515990 14324 layer_factory.hpp:77] Creating layer relu3_3
I0611 15:42:46.516006 14324 net.cpp:106] Creating Layer relu3_3
I0611 15:42:46.516010 14324 net.cpp:454] relu3_3 <- conv3_3
I0611 15:42:46.516016 14324 net.cpp:397] relu3_3 -> conv3_3 (in-place)
I0611 15:42:46.516149 14324 net.cpp:150] Setting up relu3_3
I0611 15:42:46.516155 14324 net.cpp:157] Top shape: 1 256 150 250 (9600000)
I0611 15:42:46.516167 14324 net.cpp:165] Memory required for data: 1231200108
I0611 15:42:46.516170 14324 layer_factory.hpp:77] Creating layer pool3
I0611 15:42:46.516176 14324 net.cpp:106] Creating Layer pool3
I0611 15:42:46.516178 14324 net.cpp:454] pool3 <- conv3_3
I0611 15:42:46.516183 14324 net.cpp:411] pool3 -> pool3
I0611 15:42:46.516227 14324 net.cpp:150] Setting up pool3
I0611 15:42:46.516239 14324 net.cpp:157] Top shape: 1 256 75 125 (2400000)
I0611 15:42:46.516242 14324 net.cpp:165] Memory required for data: 1240800108
I0611 15:42:46.516244 14324 layer_factory.hpp:77] Creating layer conv4_1
I0611 15:42:46.516252 14324 net.cpp:106] Creating Layer conv4_1
I0611 15:42:46.516254 14324 net.cpp:454] conv4_1 <- pool3
I0611 15:42:46.516258 14324 net.cpp:411] conv4_1 -> conv4_1
I0611 15:42:46.520436 14324 net.cpp:150] Setting up conv4_1
I0611 15:42:46.520450 14324 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 15:42:46.520453 14324 net.cpp:165] Memory required for data: 1260000108
I0611 15:42:46.520460 14324 layer_factory.hpp:77] Creating layer relu4_1
I0611 15:42:46.520467 14324 net.cpp:106] Creating Layer relu4_1
I0611 15:42:46.520470 14324 net.cpp:454] relu4_1 <- conv4_1
I0611 15:42:46.520488 14324 net.cpp:397] relu4_1 -> conv4_1 (in-place)
I0611 15:42:46.520614 14324 net.cpp:150] Setting up relu4_1
I0611 15:42:46.520620 14324 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 15:42:46.520623 14324 net.cpp:165] Memory required for data: 1279200108
I0611 15:42:46.520625 14324 layer_factory.hpp:77] Creating layer conv4_2
I0611 15:42:46.520632 14324 net.cpp:106] Creating Layer conv4_2
I0611 15:42:46.520634 14324 net.cpp:454] conv4_2 <- conv4_1
I0611 15:42:46.520648 14324 net.cpp:411] conv4_2 -> conv4_2
I0611 15:42:46.525188 14324 net.cpp:150] Setting up conv4_2
I0611 15:42:46.525207 14324 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 15:42:46.525210 14324 net.cpp:165] Memory required for data: 1298400108
I0611 15:42:46.525221 14324 layer_factory.hpp:77] Creating layer relu4_2
I0611 15:42:46.525229 14324 net.cpp:106] Creating Layer relu4_2
I0611 15:42:46.525233 14324 net.cpp:454] relu4_2 <- conv4_2
I0611 15:42:46.525247 14324 net.cpp:397] relu4_2 -> conv4_2 (in-place)
I0611 15:42:46.525774 14324 net.cpp:150] Setting up relu4_2
I0611 15:42:46.525784 14324 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 15:42:46.525786 14324 net.cpp:165] Memory required for data: 1317600108
I0611 15:42:46.525789 14324 layer_factory.hpp:77] Creating layer conv4_3
I0611 15:42:46.525796 14324 net.cpp:106] Creating Layer conv4_3
I0611 15:42:46.525799 14324 net.cpp:454] conv4_3 <- conv4_2
I0611 15:42:46.525804 14324 net.cpp:411] conv4_3 -> conv4_3
I0611 15:42:46.530166 14324 net.cpp:150] Setting up conv4_3
I0611 15:42:46.530196 14324 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 15:42:46.530200 14324 net.cpp:165] Memory required for data: 1336800108
I0611 15:42:46.530207 14324 layer_factory.hpp:77] Creating layer relu4_3
I0611 15:42:46.530217 14324 net.cpp:106] Creating Layer relu4_3
I0611 15:42:46.530221 14324 net.cpp:454] relu4_3 <- conv4_3
I0611 15:42:46.530226 14324 net.cpp:397] relu4_3 -> conv4_3 (in-place)
I0611 15:42:46.530417 14324 net.cpp:150] Setting up relu4_3
I0611 15:42:46.530426 14324 net.cpp:157] Top shape: 1 512 75 125 (4800000)
I0611 15:42:46.530437 14324 net.cpp:165] Memory required for data: 1356000108
I0611 15:42:46.530441 14324 layer_factory.hpp:77] Creating layer pool4
I0611 15:42:46.530447 14324 net.cpp:106] Creating Layer pool4
I0611 15:42:46.530449 14324 net.cpp:454] pool4 <- conv4_3
I0611 15:42:46.530468 14324 net.cpp:411] pool4 -> pool4
I0611 15:42:46.530503 14324 net.cpp:150] Setting up pool4
I0611 15:42:46.530508 14324 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:42:46.530511 14324 net.cpp:165] Memory required for data: 1360903020
I0611 15:42:46.530524 14324 layer_factory.hpp:77] Creating layer conv5_1
I0611 15:42:46.530541 14324 net.cpp:106] Creating Layer conv5_1
I0611 15:42:46.530544 14324 net.cpp:454] conv5_1 <- pool4
I0611 15:42:46.530548 14324 net.cpp:411] conv5_1 -> conv5_1
I0611 15:42:46.535831 14324 net.cpp:150] Setting up conv5_1
I0611 15:42:46.535853 14324 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:42:46.535859 14324 net.cpp:165] Memory required for data: 1365805932
I0611 15:42:46.535871 14324 layer_factory.hpp:77] Creating layer relu5_1
I0611 15:42:46.535883 14324 net.cpp:106] Creating Layer relu5_1
I0611 15:42:46.535892 14324 net.cpp:454] relu5_1 <- conv5_1
I0611 15:42:46.535900 14324 net.cpp:397] relu5_1 -> conv5_1 (in-place)
I0611 15:42:46.536057 14324 net.cpp:150] Setting up relu5_1
I0611 15:42:46.536067 14324 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:42:46.536072 14324 net.cpp:165] Memory required for data: 1370708844
I0611 15:42:46.536079 14324 layer_factory.hpp:77] Creating layer conv5_2
I0611 15:42:46.536096 14324 net.cpp:106] Creating Layer conv5_2
I0611 15:42:46.536105 14324 net.cpp:454] conv5_2 <- conv5_1
I0611 15:42:46.536114 14324 net.cpp:411] conv5_2 -> conv5_2
I0611 15:42:46.541992 14324 net.cpp:150] Setting up conv5_2
I0611 15:42:46.542013 14324 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:42:46.542027 14324 net.cpp:165] Memory required for data: 1375611756
I0611 15:42:46.542037 14324 layer_factory.hpp:77] Creating layer relu5_2
I0611 15:42:46.542052 14324 net.cpp:106] Creating Layer relu5_2
I0611 15:42:46.542058 14324 net.cpp:454] relu5_2 <- conv5_2
I0611 15:42:46.542068 14324 net.cpp:397] relu5_2 -> conv5_2 (in-place)
I0611 15:42:46.542220 14324 net.cpp:150] Setting up relu5_2
I0611 15:42:46.542228 14324 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:42:46.542232 14324 net.cpp:165] Memory required for data: 1380514668
I0611 15:42:46.542246 14324 layer_factory.hpp:77] Creating layer conv5_3
I0611 15:42:46.542261 14324 net.cpp:106] Creating Layer conv5_3
I0611 15:42:46.542266 14324 net.cpp:454] conv5_3 <- conv5_2
I0611 15:42:46.542284 14324 net.cpp:411] conv5_3 -> conv5_3
I0611 15:42:46.546591 14324 net.cpp:150] Setting up conv5_3
I0611 15:42:46.546608 14324 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:42:46.546612 14324 net.cpp:165] Memory required for data: 1385417580
I0611 15:42:46.546631 14324 layer_factory.hpp:77] Creating layer relu5_3
I0611 15:42:46.546651 14324 net.cpp:106] Creating Layer relu5_3
I0611 15:42:46.546658 14324 net.cpp:454] relu5_3 <- conv5_3
I0611 15:42:46.546674 14324 net.cpp:397] relu5_3 -> conv5_3 (in-place)
I0611 15:42:46.546851 14324 net.cpp:150] Setting up relu5_3
I0611 15:42:46.546859 14324 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:42:46.546864 14324 net.cpp:165] Memory required for data: 1390320492
I0611 15:42:46.546867 14324 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0611 15:42:46.546875 14324 net.cpp:106] Creating Layer conv5_3_relu5_3_0_split
I0611 15:42:46.546880 14324 net.cpp:454] conv5_3_relu5_3_0_split <- conv5_3
I0611 15:42:46.546897 14324 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0611 15:42:46.546905 14324 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0611 15:42:46.546912 14324 net.cpp:411] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_2
I0611 15:42:46.546967 14324 net.cpp:150] Setting up conv5_3_relu5_3_0_split
I0611 15:42:46.546972 14324 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:42:46.546977 14324 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:42:46.546990 14324 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:42:46.546995 14324 net.cpp:165] Memory required for data: 1405029228
I0611 15:42:46.546999 14324 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0611 15:42:46.547024 14324 net.cpp:106] Creating Layer rpn_conv/3x3
I0611 15:42:46.547029 14324 net.cpp:454] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0611 15:42:46.547044 14324 net.cpp:411] rpn_conv/3x3 -> rpn/output
I0611 15:42:46.597368 14324 net.cpp:150] Setting up rpn_conv/3x3
I0611 15:42:46.597388 14324 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:42:46.597391 14324 net.cpp:165] Memory required for data: 1409932140
I0611 15:42:46.597402 14324 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0611 15:42:46.597446 14324 net.cpp:106] Creating Layer rpn_relu/3x3
I0611 15:42:46.597457 14324 net.cpp:454] rpn_relu/3x3 <- rpn/output
I0611 15:42:46.597474 14324 net.cpp:397] rpn_relu/3x3 -> rpn/output (in-place)
I0611 15:42:46.597633 14324 net.cpp:150] Setting up rpn_relu/3x3
I0611 15:42:46.597641 14324 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:42:46.597643 14324 net.cpp:165] Memory required for data: 1414835052
I0611 15:42:46.597646 14324 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0611 15:42:46.597651 14324 net.cpp:106] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0611 15:42:46.597654 14324 net.cpp:454] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0611 15:42:46.597657 14324 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0611 15:42:46.597673 14324 net.cpp:411] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0611 15:42:46.597733 14324 net.cpp:150] Setting up rpn/output_rpn_relu/3x3_0_split
I0611 15:42:46.597738 14324 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:42:46.597751 14324 net.cpp:157] Top shape: 1 512 38 63 (1225728)
I0611 15:42:46.597754 14324 net.cpp:165] Memory required for data: 1424640876
I0611 15:42:46.597756 14324 layer_factory.hpp:77] Creating layer rpn_cls_score
I0611 15:42:46.597775 14324 net.cpp:106] Creating Layer rpn_cls_score
I0611 15:42:46.597779 14324 net.cpp:454] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0611 15:42:46.597793 14324 net.cpp:411] rpn_cls_score -> rpn_cls_score
I0611 15:42:46.599442 14324 net.cpp:150] Setting up rpn_cls_score
I0611 15:42:46.599450 14324 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 15:42:46.599452 14324 net.cpp:165] Memory required for data: 1424928156
I0611 15:42:46.599457 14324 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0611 15:42:46.599463 14324 net.cpp:106] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0611 15:42:46.599467 14324 net.cpp:454] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0611 15:42:46.599481 14324 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0611 15:42:46.599488 14324 net.cpp:411] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0611 15:42:46.599545 14324 net.cpp:150] Setting up rpn_cls_score_rpn_cls_score_0_split
I0611 15:42:46.599550 14324 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 15:42:46.599562 14324 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 15:42:46.599565 14324 net.cpp:165] Memory required for data: 1425502716
I0611 15:42:46.599567 14324 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0611 15:42:46.599575 14324 net.cpp:106] Creating Layer rpn_bbox_pred
I0611 15:42:46.599576 14324 net.cpp:454] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0611 15:42:46.599582 14324 net.cpp:411] rpn_bbox_pred -> rpn_bbox_pred
I0611 15:42:46.601096 14324 net.cpp:150] Setting up rpn_bbox_pred
I0611 15:42:46.601104 14324 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 15:42:46.601107 14324 net.cpp:165] Memory required for data: 1426077276
I0611 15:42:46.601111 14324 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 15:42:46.601115 14324 net.cpp:106] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 15:42:46.601119 14324 net.cpp:454] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0611 15:42:46.601122 14324 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0611 15:42:46.601127 14324 net.cpp:411] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0611 15:42:46.601173 14324 net.cpp:150] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0611 15:42:46.601177 14324 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 15:42:46.601191 14324 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 15:42:46.601192 14324 net.cpp:165] Memory required for data: 1427226396
I0611 15:42:46.601194 14324 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0611 15:42:46.601200 14324 net.cpp:106] Creating Layer rpn_cls_score_reshape
I0611 15:42:46.601217 14324 net.cpp:454] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0611 15:42:46.601220 14324 net.cpp:411] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0611 15:42:46.601239 14324 net.cpp:150] Setting up rpn_cls_score_reshape
I0611 15:42:46.601253 14324 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 15:42:46.601256 14324 net.cpp:165] Memory required for data: 1427513676
I0611 15:42:46.601259 14324 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 15:42:46.601275 14324 net.cpp:106] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 15:42:46.601279 14324 net.cpp:454] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0611 15:42:46.601282 14324 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0611 15:42:46.601296 14324 net.cpp:411] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0611 15:42:46.601316 14324 net.cpp:150] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0611 15:42:46.601330 14324 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 15:42:46.601332 14324 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 15:42:46.601334 14324 net.cpp:165] Memory required for data: 1428088236
I0611 15:42:46.601348 14324 layer_factory.hpp:77] Creating layer rpn-data
I0611 15:42:46.601683 14324 net.cpp:106] Creating Layer rpn-data
I0611 15:42:46.601691 14324 net.cpp:454] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0611 15:42:46.601707 14324 net.cpp:454] rpn-data <- gt_boxes_input-data_2_split_0
I0611 15:42:46.601711 14324 net.cpp:454] rpn-data <- im_info_input-data_1_split_0
I0611 15:42:46.601716 14324 net.cpp:454] rpn-data <- data_input-data_0_split_1
I0611 15:42:46.601719 14324 net.cpp:411] rpn-data -> rpn_labels
I0611 15:42:46.601725 14324 net.cpp:411] rpn-data -> rpn_bbox_targets
I0611 15:42:46.601732 14324 net.cpp:411] rpn-data -> rpn_bbox_inside_weights
I0611 15:42:46.601737 14324 net.cpp:411] rpn-data -> rpn_bbox_outside_weights
===================================anchor_scales in AnchorTargetLayer:=============(2, 4, 8, 16, 32)
I0611 15:42:46.602576 14324 net.cpp:150] Setting up rpn-data
I0611 15:42:46.602584 14324 net.cpp:157] Top shape: 1 1 570 63 (35910)
I0611 15:42:46.602589 14324 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 15:42:46.602592 14324 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 15:42:46.602596 14324 net.cpp:157] Top shape: 1 60 38 63 (143640)
I0611 15:42:46.602597 14324 net.cpp:165] Memory required for data: 1429955556
I0611 15:42:46.602599 14324 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0611 15:42:46.602607 14324 net.cpp:106] Creating Layer rpn_loss_cls
I0611 15:42:46.602609 14324 net.cpp:454] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0611 15:42:46.602613 14324 net.cpp:454] rpn_loss_cls <- rpn_labels
I0611 15:42:46.602617 14324 net.cpp:411] rpn_loss_cls -> rpn_cls_loss
I0611 15:42:46.602632 14324 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0611 15:42:46.603260 14324 net.cpp:150] Setting up rpn_loss_cls
I0611 15:42:46.603267 14324 net.cpp:157] Top shape: (1)
I0611 15:42:46.603271 14324 net.cpp:160]     with loss weight 1
I0611 15:42:46.603279 14324 net.cpp:165] Memory required for data: 1429955560
I0611 15:42:46.603281 14324 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0611 15:42:46.603288 14324 net.cpp:106] Creating Layer rpn_loss_bbox
I0611 15:42:46.603291 14324 net.cpp:454] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0611 15:42:46.603296 14324 net.cpp:454] rpn_loss_bbox <- rpn_bbox_targets
I0611 15:42:46.603298 14324 net.cpp:454] rpn_loss_bbox <- rpn_bbox_inside_weights
I0611 15:42:46.603302 14324 net.cpp:454] rpn_loss_bbox <- rpn_bbox_outside_weights
I0611 15:42:46.603307 14324 net.cpp:411] rpn_loss_bbox -> rpn_loss_bbox
I0611 15:42:46.604394 14324 net.cpp:150] Setting up rpn_loss_bbox
I0611 15:42:46.604403 14324 net.cpp:157] Top shape: (1)
I0611 15:42:46.604408 14324 net.cpp:160]     with loss weight 1
I0611 15:42:46.604413 14324 net.cpp:165] Memory required for data: 1429955564
I0611 15:42:46.604415 14324 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0611 15:42:46.604421 14324 net.cpp:106] Creating Layer rpn_cls_prob
I0611 15:42:46.604425 14324 net.cpp:454] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0611 15:42:46.604430 14324 net.cpp:411] rpn_cls_prob -> rpn_cls_prob
I0611 15:42:46.604586 14324 net.cpp:150] Setting up rpn_cls_prob
I0611 15:42:46.604593 14324 net.cpp:157] Top shape: 1 2 570 63 (71820)
I0611 15:42:46.604595 14324 net.cpp:165] Memory required for data: 1430242844
I0611 15:42:46.604598 14324 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0611 15:42:46.604605 14324 net.cpp:106] Creating Layer rpn_cls_prob_reshape
I0611 15:42:46.604609 14324 net.cpp:454] rpn_cls_prob_reshape <- rpn_cls_prob
I0611 15:42:46.604614 14324 net.cpp:411] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0611 15:42:46.604632 14324 net.cpp:150] Setting up rpn_cls_prob_reshape
I0611 15:42:46.604636 14324 net.cpp:157] Top shape: 1 30 38 63 (71820)
I0611 15:42:46.604640 14324 net.cpp:165] Memory required for data: 1430530124
I0611 15:42:46.604642 14324 layer_factory.hpp:77] Creating layer proposal
I0611 15:42:46.605103 14324 net.cpp:106] Creating Layer proposal
I0611 15:42:46.605111 14324 net.cpp:454] proposal <- rpn_cls_prob_reshape
I0611 15:42:46.605118 14324 net.cpp:454] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0611 15:42:46.605121 14324 net.cpp:454] proposal <- im_info_input-data_1_split_1
I0611 15:42:46.605126 14324 net.cpp:411] proposal -> rpn_rois
=================================anchor_scales in ProposalLayer:=============(2, 4, 8, 16, 32)
I0611 15:42:46.605903 14324 net.cpp:150] Setting up proposal
I0611 15:42:46.605912 14324 net.cpp:157] Top shape: 1 5 (5)
I0611 15:42:46.605924 14324 net.cpp:165] Memory required for data: 1430530144
I0611 15:42:46.605928 14324 layer_factory.hpp:77] Creating layer roi-data
I0611 15:42:46.608222 14324 net.cpp:106] Creating Layer roi-data
I0611 15:42:46.608228 14324 net.cpp:454] roi-data <- rpn_rois
I0611 15:42:46.608232 14324 net.cpp:454] roi-data <- gt_boxes_input-data_2_split_1
I0611 15:42:46.608235 14324 net.cpp:454] roi-data <- im_info_input-data_1_split_2
I0611 15:42:46.608238 14324 net.cpp:454] roi-data <- seg_mask_inds
I0611 15:42:46.608242 14324 net.cpp:454] roi-data <- flipped
I0611 15:42:46.608255 14324 net.cpp:411] roi-data -> rois
I0611 15:42:46.608263 14324 net.cpp:411] roi-data -> labels
I0611 15:42:46.608268 14324 net.cpp:411] roi-data -> bbox_targets
I0611 15:42:46.608273 14324 net.cpp:411] roi-data -> bbox_inside_weights
I0611 15:42:46.608286 14324 net.cpp:411] roi-data -> bbox_outside_weights
I0611 15:42:46.608291 14324 net.cpp:411] roi-data -> mask_targets
I0611 15:42:46.608295 14324 net.cpp:411] roi-data -> rois_pos
I0611 15:42:46.608299 14324 net.cpp:411] roi-data -> attrArray
I0611 15:42:46.608585 14324 net.cpp:150] Setting up roi-data
I0611 15:42:46.608593 14324 net.cpp:157] Top shape: 1 5 (5)
I0611 15:42:46.608597 14324 net.cpp:157] Top shape: 1 1 (1)
I0611 15:42:46.608600 14324 net.cpp:157] Top shape: 1 8 (8)
I0611 15:42:46.608603 14324 net.cpp:157] Top shape: 1 8 (8)
I0611 15:42:46.608605 14324 net.cpp:157] Top shape: 1 8 (8)
I0611 15:42:46.608608 14324 net.cpp:157] Top shape: 1 244 244 (59536)
I0611 15:42:46.608611 14324 net.cpp:157] Top shape: 1 5 (5)
I0611 15:42:46.608614 14324 net.cpp:157] Top shape: 1 7 (7)
I0611 15:42:46.608616 14324 net.cpp:165] Memory required for data: 1430768456
I0611 15:42:46.608620 14324 layer_factory.hpp:77] Creating layer roi_pool5
I0611 15:42:46.608625 14324 net.cpp:106] Creating Layer roi_pool5
I0611 15:42:46.608629 14324 net.cpp:454] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0611 15:42:46.608633 14324 net.cpp:454] roi_pool5 <- rois
I0611 15:42:46.608636 14324 net.cpp:411] roi_pool5 -> pool5
I0611 15:42:46.608642 14324 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0611 15:42:46.608703 14324 net.cpp:150] Setting up roi_pool5
I0611 15:42:46.608707 14324 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 15:42:46.608711 14324 net.cpp:165] Memory required for data: 1430868808
I0611 15:42:46.608712 14324 layer_factory.hpp:77] Creating layer fc6
I0611 15:42:46.608717 14324 net.cpp:106] Creating Layer fc6
I0611 15:42:46.608721 14324 net.cpp:454] fc6 <- pool5
I0611 15:42:46.608723 14324 net.cpp:411] fc6 -> fc6
I0611 15:42:46.744500 14324 net.cpp:150] Setting up fc6
I0611 15:42:46.744525 14324 net.cpp:157] Top shape: 1 4096 (4096)
I0611 15:42:46.744529 14324 net.cpp:165] Memory required for data: 1430885192
I0611 15:42:46.744544 14324 layer_factory.hpp:77] Creating layer relu6
I0611 15:42:46.744554 14324 net.cpp:106] Creating Layer relu6
I0611 15:42:46.744558 14324 net.cpp:454] relu6 <- fc6
I0611 15:42:46.744572 14324 net.cpp:397] relu6 -> fc6 (in-place)
I0611 15:42:46.744771 14324 net.cpp:150] Setting up relu6
I0611 15:42:46.744778 14324 net.cpp:157] Top shape: 1 4096 (4096)
I0611 15:42:46.744781 14324 net.cpp:165] Memory required for data: 1430901576
I0611 15:42:46.744783 14324 layer_factory.hpp:77] Creating layer fc7
I0611 15:42:46.744789 14324 net.cpp:106] Creating Layer fc7
I0611 15:42:46.744792 14324 net.cpp:454] fc7 <- fc6
I0611 15:42:46.744796 14324 net.cpp:411] fc7 -> fc7
I0611 15:42:46.769644 14324 net.cpp:150] Setting up fc7
I0611 15:42:46.769667 14324 net.cpp:157] Top shape: 1 4096 (4096)
I0611 15:42:46.769671 14324 net.cpp:165] Memory required for data: 1430917960
I0611 15:42:46.769680 14324 layer_factory.hpp:77] Creating layer relu7
I0611 15:42:46.769690 14324 net.cpp:106] Creating Layer relu7
I0611 15:42:46.769695 14324 net.cpp:454] relu7 <- fc7
I0611 15:42:46.769701 14324 net.cpp:397] relu7 -> fc7 (in-place)
I0611 15:42:46.769884 14324 net.cpp:150] Setting up relu7
I0611 15:42:46.769892 14324 net.cpp:157] Top shape: 1 4096 (4096)
I0611 15:42:46.769896 14324 net.cpp:165] Memory required for data: 1430934344
I0611 15:42:46.769898 14324 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0611 15:42:46.769903 14324 net.cpp:106] Creating Layer fc7_relu7_0_split
I0611 15:42:46.769906 14324 net.cpp:454] fc7_relu7_0_split <- fc7
I0611 15:42:46.769910 14324 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0611 15:42:46.769922 14324 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0611 15:42:46.769927 14324 net.cpp:411] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0611 15:42:46.769970 14324 net.cpp:150] Setting up fc7_relu7_0_split
I0611 15:42:46.769974 14324 net.cpp:157] Top shape: 1 4096 (4096)
I0611 15:42:46.769978 14324 net.cpp:157] Top shape: 1 4096 (4096)
I0611 15:42:46.769980 14324 net.cpp:157] Top shape: 1 4096 (4096)
I0611 15:42:46.769982 14324 net.cpp:165] Memory required for data: 1430983496
I0611 15:42:46.769984 14324 layer_factory.hpp:77] Creating layer attr_score
I0611 15:42:46.769990 14324 net.cpp:106] Creating Layer attr_score
I0611 15:42:46.769994 14324 net.cpp:454] attr_score <- fc7_relu7_0_split_0
I0611 15:42:46.769999 14324 net.cpp:411] attr_score -> attr_score
I0611 15:42:46.770707 14324 net.cpp:150] Setting up attr_score
I0611 15:42:46.770714 14324 net.cpp:157] Top shape: 1 7 (7)
I0611 15:42:46.770726 14324 net.cpp:165] Memory required for data: 1430983524
I0611 15:42:46.770731 14324 layer_factory.hpp:77] Creating layer cls_score
I0611 15:42:46.770737 14324 net.cpp:106] Creating Layer cls_score
I0611 15:42:46.770740 14324 net.cpp:454] cls_score <- fc7_relu7_0_split_1
I0611 15:42:46.770745 14324 net.cpp:411] cls_score -> cls_score
I0611 15:42:46.770989 14324 net.cpp:150] Setting up cls_score
I0611 15:42:46.770994 14324 net.cpp:157] Top shape: 1 2 (2)
I0611 15:42:46.771006 14324 net.cpp:165] Memory required for data: 1430983532
I0611 15:42:46.771010 14324 layer_factory.hpp:77] Creating layer bbox_pred
I0611 15:42:46.771014 14324 net.cpp:106] Creating Layer bbox_pred
I0611 15:42:46.771018 14324 net.cpp:454] bbox_pred <- fc7_relu7_0_split_2
I0611 15:42:46.771021 14324 net.cpp:411] bbox_pred -> bbox_pred
I0611 15:42:46.771785 14324 net.cpp:150] Setting up bbox_pred
I0611 15:42:46.771790 14324 net.cpp:157] Top shape: 1 8 (8)
I0611 15:42:46.771801 14324 net.cpp:165] Memory required for data: 1430983564
I0611 15:42:46.771806 14324 layer_factory.hpp:77] Creating layer loss_attribute
I0611 15:42:46.771811 14324 net.cpp:106] Creating Layer loss_attribute
I0611 15:42:46.771822 14324 net.cpp:454] loss_attribute <- attr_score
I0611 15:42:46.771828 14324 net.cpp:454] loss_attribute <- attrArray
I0611 15:42:46.771833 14324 net.cpp:411] loss_attribute -> loss_attribute
I0611 15:42:46.771890 14324 net.cpp:150] Setting up loss_attribute
I0611 15:42:46.771894 14324 net.cpp:157] Top shape: (1)
I0611 15:42:46.771906 14324 net.cpp:160]     with loss weight 0.1
I0611 15:42:46.771916 14324 net.cpp:165] Memory required for data: 1430983568
I0611 15:42:46.771919 14324 layer_factory.hpp:77] Creating layer loss_cls
I0611 15:42:46.771924 14324 net.cpp:106] Creating Layer loss_cls
I0611 15:42:46.771937 14324 net.cpp:454] loss_cls <- cls_score
I0611 15:42:46.771942 14324 net.cpp:454] loss_cls <- labels
I0611 15:42:46.771947 14324 net.cpp:411] loss_cls -> loss_cls
I0611 15:42:46.771952 14324 layer_factory.hpp:77] Creating layer loss_cls
I0611 15:42:46.772645 14324 net.cpp:150] Setting up loss_cls
I0611 15:42:46.772653 14324 net.cpp:157] Top shape: (1)
I0611 15:42:46.772666 14324 net.cpp:160]     with loss weight 3
I0611 15:42:46.772670 14324 net.cpp:165] Memory required for data: 1430983572
I0611 15:42:46.772684 14324 layer_factory.hpp:77] Creating layer loss_bbox
I0611 15:42:46.772691 14324 net.cpp:106] Creating Layer loss_bbox
I0611 15:42:46.772696 14324 net.cpp:454] loss_bbox <- bbox_pred
I0611 15:42:46.772699 14324 net.cpp:454] loss_bbox <- bbox_targets
I0611 15:42:46.772704 14324 net.cpp:454] loss_bbox <- bbox_inside_weights
I0611 15:42:46.772706 14324 net.cpp:454] loss_bbox <- bbox_outside_weights
I0611 15:42:46.772711 14324 net.cpp:411] loss_bbox -> loss_bbox
I0611 15:42:46.772771 14324 net.cpp:150] Setting up loss_bbox
I0611 15:42:46.772775 14324 net.cpp:157] Top shape: (1)
I0611 15:42:46.772778 14324 net.cpp:160]     with loss weight 2
I0611 15:42:46.772784 14324 net.cpp:165] Memory required for data: 1430983576
I0611 15:42:46.772786 14324 layer_factory.hpp:77] Creating layer roi_pool5_2
I0611 15:42:46.772794 14324 net.cpp:106] Creating Layer roi_pool5_2
I0611 15:42:46.772799 14324 net.cpp:454] roi_pool5_2 <- conv5_3_relu5_3_0_split_2
I0611 15:42:46.772804 14324 net.cpp:454] roi_pool5_2 <- rois_pos
I0611 15:42:46.772809 14324 net.cpp:411] roi_pool5_2 -> pool5_2
I0611 15:42:46.772814 14324 roi_alignment_layer.cpp:32] Spatial scale: 0.0625
I0611 15:42:46.772882 14324 net.cpp:150] Setting up roi_pool5_2
I0611 15:42:46.772887 14324 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 15:42:46.772889 14324 net.cpp:165] Memory required for data: 1431083928
I0611 15:42:46.772894 14324 layer_factory.hpp:77] Creating layer pool5_2_conv
I0611 15:42:46.772908 14324 net.cpp:106] Creating Layer pool5_2_conv
I0611 15:42:46.772912 14324 net.cpp:454] pool5_2_conv <- pool5_2
I0611 15:42:46.772917 14324 net.cpp:411] pool5_2_conv -> pool5_2_conv
I0611 15:42:46.779618 14324 net.cpp:150] Setting up pool5_2_conv
I0611 15:42:46.779628 14324 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 15:42:46.779630 14324 net.cpp:165] Memory required for data: 1431184280
I0611 15:42:46.779646 14324 layer_factory.hpp:77] Creating layer pool5_2_conv_relu
I0611 15:42:46.779652 14324 net.cpp:106] Creating Layer pool5_2_conv_relu
I0611 15:42:46.779656 14324 net.cpp:454] pool5_2_conv_relu <- pool5_2_conv
I0611 15:42:46.779664 14324 net.cpp:411] pool5_2_conv_relu -> pool5_2_conv_relu
I0611 15:42:46.779827 14324 net.cpp:150] Setting up pool5_2_conv_relu
I0611 15:42:46.779834 14324 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 15:42:46.779837 14324 net.cpp:165] Memory required for data: 1431284632
I0611 15:42:46.779850 14324 layer_factory.hpp:77] Creating layer pool5_2_conv2
I0611 15:42:46.779858 14324 net.cpp:106] Creating Layer pool5_2_conv2
I0611 15:42:46.779862 14324 net.cpp:454] pool5_2_conv2 <- pool5_2_conv_relu
I0611 15:42:46.779867 14324 net.cpp:411] pool5_2_conv2 -> pool5_2_conv2
I0611 15:42:46.830308 14324 net.cpp:150] Setting up pool5_2_conv2
I0611 15:42:46.830327 14324 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 15:42:46.830329 14324 net.cpp:165] Memory required for data: 1431384984
I0611 15:42:46.830338 14324 layer_factory.hpp:77] Creating layer pool5_2_conv2_relu
I0611 15:42:46.830355 14324 net.cpp:106] Creating Layer pool5_2_conv2_relu
I0611 15:42:46.830360 14324 net.cpp:454] pool5_2_conv2_relu <- pool5_2_conv2
I0611 15:42:46.830365 14324 net.cpp:411] pool5_2_conv2_relu -> pool5_2_conv2_relu
I0611 15:42:46.830538 14324 net.cpp:150] Setting up pool5_2_conv2_relu
I0611 15:42:46.830544 14324 net.cpp:157] Top shape: 1 512 7 7 (25088)
I0611 15:42:46.830548 14324 net.cpp:165] Memory required for data: 1431485336
I0611 15:42:46.830549 14324 layer_factory.hpp:77] Creating layer mask_deconv1
I0611 15:42:46.830556 14324 net.cpp:106] Creating Layer mask_deconv1
I0611 15:42:46.830559 14324 net.cpp:454] mask_deconv1 <- pool5_2_conv2_relu
I0611 15:42:46.830574 14324 net.cpp:411] mask_deconv1 -> mask_deconv1
I0611 15:42:46.831400 14324 net.cpp:150] Setting up mask_deconv1
I0611 15:42:46.831406 14324 net.cpp:157] Top shape: 1 256 30 30 (230400)
I0611 15:42:46.831409 14324 net.cpp:165] Memory required for data: 1432406936
I0611 15:42:46.831413 14324 layer_factory.hpp:77] Creating layer pool5_2_conv3
I0611 15:42:46.831420 14324 net.cpp:106] Creating Layer pool5_2_conv3
I0611 15:42:46.831423 14324 net.cpp:454] pool5_2_conv3 <- mask_deconv1
I0611 15:42:46.831437 14324 net.cpp:411] pool5_2_conv3 -> pool5_2_conv3
I0611 15:42:46.857573 14324 net.cpp:150] Setting up pool5_2_conv3
I0611 15:42:46.857602 14324 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:42:46.857605 14324 net.cpp:165] Memory required for data: 1434250136
I0611 15:42:46.857614 14324 layer_factory.hpp:77] Creating layer pool5_2_conv3_relu
I0611 15:42:46.857623 14324 net.cpp:106] Creating Layer pool5_2_conv3_relu
I0611 15:42:46.857628 14324 net.cpp:454] pool5_2_conv3_relu <- pool5_2_conv3
I0611 15:42:46.857636 14324 net.cpp:411] pool5_2_conv3_relu -> pool5_2_conv3_relu
I0611 15:42:46.857801 14324 net.cpp:150] Setting up pool5_2_conv3_relu
I0611 15:42:46.857810 14324 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:42:46.857821 14324 net.cpp:165] Memory required for data: 1436093336
I0611 15:42:46.857825 14324 layer_factory.hpp:77] Creating layer pool5_2_conv4
I0611 15:42:46.857833 14324 net.cpp:106] Creating Layer pool5_2_conv4
I0611 15:42:46.857836 14324 net.cpp:454] pool5_2_conv4 <- pool5_2_conv3_relu
I0611 15:42:46.857841 14324 net.cpp:411] pool5_2_conv4 -> pool5_2_conv4
I0611 15:42:46.908625 14324 net.cpp:150] Setting up pool5_2_conv4
I0611 15:42:46.908644 14324 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:42:46.908648 14324 net.cpp:165] Memory required for data: 1437936536
I0611 15:42:46.908654 14324 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu
I0611 15:42:46.908674 14324 net.cpp:106] Creating Layer pool5_2_conv4_relu
I0611 15:42:46.908679 14324 net.cpp:454] pool5_2_conv4_relu <- pool5_2_conv4
I0611 15:42:46.908684 14324 net.cpp:411] pool5_2_conv4_relu -> pool5_2_conv4_relu
I0611 15:42:46.908846 14324 net.cpp:150] Setting up pool5_2_conv4_relu
I0611 15:42:46.908854 14324 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:42:46.908856 14324 net.cpp:165] Memory required for data: 1439779736
I0611 15:42:46.908859 14324 layer_factory.hpp:77] Creating layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 15:42:46.908864 14324 net.cpp:106] Creating Layer pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 15:42:46.908866 14324 net.cpp:454] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split <- pool5_2_conv4_relu
I0611 15:42:46.908871 14324 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0611 15:42:46.908886 14324 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0611 15:42:46.908891 14324 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0611 15:42:46.908907 14324 net.cpp:411] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split -> pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0611 15:42:46.908977 14324 net.cpp:150] Setting up pool5_2_conv4_relu_pool5_2_conv4_relu_0_split
I0611 15:42:46.908980 14324 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:42:46.908983 14324 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:42:46.908985 14324 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:42:46.908988 14324 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:42:46.908990 14324 net.cpp:165] Memory required for data: 1447152536
I0611 15:42:46.908993 14324 layer_factory.hpp:77] Creating layer query_conv
I0611 15:42:46.909011 14324 net.cpp:106] Creating Layer query_conv
I0611 15:42:46.909014 14324 net.cpp:454] query_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_0
I0611 15:42:46.909029 14324 net.cpp:411] query_conv -> query_conv
I0611 15:42:46.910656 14324 net.cpp:150] Setting up query_conv
I0611 15:42:46.910665 14324 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0611 15:42:46.910668 14324 net.cpp:165] Memory required for data: 1447382936
I0611 15:42:46.910673 14324 layer_factory.hpp:77] Creating layer key_conv
I0611 15:42:46.910681 14324 net.cpp:106] Creating Layer key_conv
I0611 15:42:46.910683 14324 net.cpp:454] key_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_1
I0611 15:42:46.910701 14324 net.cpp:411] key_conv -> key_conv
I0611 15:42:46.912547 14324 net.cpp:150] Setting up key_conv
I0611 15:42:46.912565 14324 net.cpp:157] Top shape: 1 64 30 30 (57600)
I0611 15:42:46.912569 14324 net.cpp:165] Memory required for data: 1447613336
I0611 15:42:46.912573 14324 layer_factory.hpp:77] Creating layer value_conv
I0611 15:42:46.912581 14324 net.cpp:106] Creating Layer value_conv
I0611 15:42:46.912585 14324 net.cpp:454] value_conv <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_2
I0611 15:42:46.912590 14324 net.cpp:411] value_conv -> value_conv
I0611 15:42:46.919342 14324 net.cpp:150] Setting up value_conv
I0611 15:42:46.919350 14324 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:42:46.919353 14324 net.cpp:165] Memory required for data: 1449456536
I0611 15:42:46.919358 14324 layer_factory.hpp:77] Creating layer query_conv_reshape
I0611 15:42:46.919365 14324 net.cpp:106] Creating Layer query_conv_reshape
I0611 15:42:46.919368 14324 net.cpp:454] query_conv_reshape <- query_conv
I0611 15:42:46.919384 14324 net.cpp:411] query_conv_reshape -> query_conv_reshape
I0611 15:42:46.919423 14324 net.cpp:150] Setting up query_conv_reshape
I0611 15:42:46.919430 14324 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0611 15:42:46.919431 14324 net.cpp:165] Memory required for data: 1449686936
I0611 15:42:46.919433 14324 layer_factory.hpp:77] Creating layer key_conv_reshape
I0611 15:42:46.919438 14324 net.cpp:106] Creating Layer key_conv_reshape
I0611 15:42:46.919441 14324 net.cpp:454] key_conv_reshape <- key_conv
I0611 15:42:46.919445 14324 net.cpp:411] key_conv_reshape -> key_conv_reshape
I0611 15:42:46.919483 14324 net.cpp:150] Setting up key_conv_reshape
I0611 15:42:46.919487 14324 net.cpp:157] Top shape: 1 64 900 1 (57600)
I0611 15:42:46.919489 14324 net.cpp:165] Memory required for data: 1449917336
I0611 15:42:46.919492 14324 layer_factory.hpp:77] Creating layer value_conv_reshape
I0611 15:42:46.919504 14324 net.cpp:106] Creating Layer value_conv_reshape
I0611 15:42:46.919507 14324 net.cpp:454] value_conv_reshape <- value_conv
I0611 15:42:46.919522 14324 net.cpp:411] value_conv_reshape -> value_conv_reshape
I0611 15:42:46.919548 14324 net.cpp:150] Setting up value_conv_reshape
I0611 15:42:46.919551 14324 net.cpp:157] Top shape: 1 512 900 1 (460800)
I0611 15:42:46.919564 14324 net.cpp:165] Memory required for data: 1451760536
I0611 15:42:46.919565 14324 layer_factory.hpp:77] Creating layer query_conv_reshape_perm
I0611 15:42:46.919585 14324 net.cpp:106] Creating Layer query_conv_reshape_perm
I0611 15:42:46.919589 14324 net.cpp:454] query_conv_reshape_perm <- query_conv_reshape
I0611 15:42:46.919592 14324 net.cpp:411] query_conv_reshape_perm -> query_conv_reshape_perm
I0611 15:42:46.919708 14324 net.cpp:150] Setting up query_conv_reshape_perm
I0611 15:42:46.919713 14324 net.cpp:157] Top shape: 1 1 900 64 (57600)
I0611 15:42:46.919715 14324 net.cpp:165] Memory required for data: 1451990936
I0611 15:42:46.919718 14324 layer_factory.hpp:77] Creating layer key_conv_reshape_perm
I0611 15:42:46.919721 14324 net.cpp:106] Creating Layer key_conv_reshape_perm
I0611 15:42:46.919723 14324 net.cpp:454] key_conv_reshape_perm <- key_conv_reshape
I0611 15:42:46.919726 14324 net.cpp:411] key_conv_reshape_perm -> key_conv_reshape_perm
I0611 15:42:46.919826 14324 net.cpp:150] Setting up key_conv_reshape_perm
I0611 15:42:46.919831 14324 net.cpp:157] Top shape: 1 1 64 900 (57600)
I0611 15:42:46.919832 14324 net.cpp:165] Memory required for data: 1452221336
I0611 15:42:46.919834 14324 layer_factory.hpp:77] Creating layer energy
I0611 15:42:46.919838 14324 net.cpp:106] Creating Layer energy
I0611 15:42:46.919840 14324 net.cpp:454] energy <- query_conv_reshape_perm
I0611 15:42:46.919843 14324 net.cpp:454] energy <- key_conv_reshape_perm
I0611 15:42:46.919847 14324 net.cpp:411] energy -> energy
I0611 15:42:46.919872 14324 net.cpp:150] Setting up energy
I0611 15:42:46.919888 14324 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 15:42:46.919889 14324 net.cpp:165] Memory required for data: 1455461336
I0611 15:42:46.919891 14324 layer_factory.hpp:77] Creating layer attention
I0611 15:42:46.919906 14324 net.cpp:106] Creating Layer attention
I0611 15:42:46.919909 14324 net.cpp:454] attention <- energy
I0611 15:42:46.919912 14324 net.cpp:411] attention -> attention
I0611 15:42:46.920094 14324 net.cpp:150] Setting up attention
I0611 15:42:46.920100 14324 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 15:42:46.920102 14324 net.cpp:165] Memory required for data: 1458701336
I0611 15:42:46.920104 14324 layer_factory.hpp:77] Creating layer value_conv_reshape_perm
I0611 15:42:46.920109 14324 net.cpp:106] Creating Layer value_conv_reshape_perm
I0611 15:42:46.920112 14324 net.cpp:454] value_conv_reshape_perm <- value_conv_reshape
I0611 15:42:46.920126 14324 net.cpp:411] value_conv_reshape_perm -> value_conv_reshape_perm
I0611 15:42:46.920222 14324 net.cpp:150] Setting up value_conv_reshape_perm
I0611 15:42:46.920228 14324 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0611 15:42:46.920229 14324 net.cpp:165] Memory required for data: 1460544536
I0611 15:42:46.920231 14324 layer_factory.hpp:77] Creating layer attention_perm
I0611 15:42:46.920234 14324 net.cpp:106] Creating Layer attention_perm
I0611 15:42:46.920238 14324 net.cpp:454] attention_perm <- attention
I0611 15:42:46.920240 14324 net.cpp:411] attention_perm -> attention_perm
I0611 15:42:46.920332 14324 net.cpp:150] Setting up attention_perm
I0611 15:42:46.920336 14324 net.cpp:157] Top shape: 1 1 900 900 (810000)
I0611 15:42:46.920337 14324 net.cpp:165] Memory required for data: 1463784536
I0611 15:42:46.920341 14324 layer_factory.hpp:77] Creating layer out
I0611 15:42:46.920343 14324 net.cpp:106] Creating Layer out
I0611 15:42:46.920346 14324 net.cpp:454] out <- value_conv_reshape_perm
I0611 15:42:46.920348 14324 net.cpp:454] out <- attention_perm
I0611 15:42:46.920362 14324 net.cpp:411] out -> out
I0611 15:42:46.920388 14324 net.cpp:150] Setting up out
I0611 15:42:46.920403 14324 net.cpp:157] Top shape: 1 1 512 900 (460800)
I0611 15:42:46.920405 14324 net.cpp:165] Memory required for data: 1465627736
I0611 15:42:46.920408 14324 layer_factory.hpp:77] Creating layer out_reshape
I0611 15:42:46.920421 14324 net.cpp:106] Creating Layer out_reshape
I0611 15:42:46.920423 14324 net.cpp:454] out_reshape <- out
I0611 15:42:46.920428 14324 net.cpp:411] out_reshape -> out_reshape
I0611 15:42:46.920462 14324 net.cpp:150] Setting up out_reshape
I0611 15:42:46.920477 14324 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:42:46.920480 14324 net.cpp:165] Memory required for data: 1467470936
I0611 15:42:46.920482 14324 layer_factory.hpp:77] Creating layer out_reshape_scale
I0611 15:42:46.920500 14324 net.cpp:106] Creating Layer out_reshape_scale
I0611 15:42:46.920503 14324 net.cpp:454] out_reshape_scale <- out_reshape
I0611 15:42:46.920507 14324 net.cpp:411] out_reshape_scale -> out_reshape_scale
I0611 15:42:46.920598 14324 net.cpp:150] Setting up out_reshape_scale
I0611 15:42:46.920603 14324 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:42:46.920604 14324 net.cpp:165] Memory required for data: 1469314136
I0611 15:42:46.920619 14324 layer_factory.hpp:77] Creating layer out_x
I0611 15:42:46.920626 14324 net.cpp:106] Creating Layer out_x
I0611 15:42:46.920630 14324 net.cpp:454] out_x <- out_reshape_scale
I0611 15:42:46.920634 14324 net.cpp:454] out_x <- pool5_2_conv4_relu_pool5_2_conv4_relu_0_split_3
I0611 15:42:46.920639 14324 net.cpp:411] out_x -> out_x
I0611 15:42:46.920657 14324 net.cpp:150] Setting up out_x
I0611 15:42:46.920662 14324 net.cpp:157] Top shape: 1 512 30 30 (460800)
I0611 15:42:46.920665 14324 net.cpp:165] Memory required for data: 1471157336
I0611 15:42:46.920666 14324 layer_factory.hpp:77] Creating layer mask_deconv2
I0611 15:42:46.920673 14324 net.cpp:106] Creating Layer mask_deconv2
I0611 15:42:46.920677 14324 net.cpp:454] mask_deconv2 <- out_x
I0611 15:42:46.920683 14324 net.cpp:411] mask_deconv2 -> mask_deconv2
I0611 15:42:46.921517 14324 net.cpp:150] Setting up mask_deconv2
I0611 15:42:46.921524 14324 net.cpp:157] Top shape: 1 256 122 122 (3810304)
I0611 15:42:46.921525 14324 net.cpp:165] Memory required for data: 1486398552
I0611 15:42:46.921531 14324 layer_factory.hpp:77] Creating layer pool5_2_conv5
I0611 15:42:46.921538 14324 net.cpp:106] Creating Layer pool5_2_conv5
I0611 15:42:46.921541 14324 net.cpp:454] pool5_2_conv5 <- mask_deconv2
I0611 15:42:46.921550 14324 net.cpp:411] pool5_2_conv5 -> pool5_2_conv5
I0611 15:42:46.947911 14324 net.cpp:150] Setting up pool5_2_conv5
I0611 15:42:46.947929 14324 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 15:42:46.947933 14324 net.cpp:165] Memory required for data: 1516880984
I0611 15:42:46.947940 14324 layer_factory.hpp:77] Creating layer pool5_2_conv5_relu
I0611 15:42:46.947948 14324 net.cpp:106] Creating Layer pool5_2_conv5_relu
I0611 15:42:46.947963 14324 net.cpp:454] pool5_2_conv5_relu <- pool5_2_conv5
I0611 15:42:46.947969 14324 net.cpp:411] pool5_2_conv5_relu -> pool5_2_conv5_relu
I0611 15:42:46.948145 14324 net.cpp:150] Setting up pool5_2_conv5_relu
I0611 15:42:46.948153 14324 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 15:42:46.948154 14324 net.cpp:165] Memory required for data: 1547363416
I0611 15:42:46.948158 14324 layer_factory.hpp:77] Creating layer pool5_2_conv6
I0611 15:42:46.948166 14324 net.cpp:106] Creating Layer pool5_2_conv6
I0611 15:42:46.948169 14324 net.cpp:454] pool5_2_conv6 <- pool5_2_conv5_relu
I0611 15:42:46.948184 14324 net.cpp:411] pool5_2_conv6 -> pool5_2_conv6
I0611 15:42:47.000581 14324 net.cpp:150] Setting up pool5_2_conv6
I0611 15:42:47.000600 14324 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 15:42:47.000603 14324 net.cpp:165] Memory required for data: 1577845848
I0611 15:42:47.000622 14324 layer_factory.hpp:77] Creating layer pool5_2_conv6_relu
I0611 15:42:47.000632 14324 net.cpp:106] Creating Layer pool5_2_conv6_relu
I0611 15:42:47.000638 14324 net.cpp:454] pool5_2_conv6_relu <- pool5_2_conv6
I0611 15:42:47.000643 14324 net.cpp:411] pool5_2_conv6_relu -> pool5_2_conv6_relu
I0611 15:42:47.001224 14324 net.cpp:150] Setting up pool5_2_conv6_relu
I0611 15:42:47.001232 14324 net.cpp:157] Top shape: 1 512 122 122 (7620608)
I0611 15:42:47.001235 14324 net.cpp:165] Memory required for data: 1608328280
I0611 15:42:47.001250 14324 layer_factory.hpp:77] Creating layer mask_deconv3
I0611 15:42:47.001269 14324 net.cpp:106] Creating Layer mask_deconv3
I0611 15:42:47.001273 14324 net.cpp:454] mask_deconv3 <- pool5_2_conv6_relu
I0611 15:42:47.001279 14324 net.cpp:411] mask_deconv3 -> mask_deconv3
I0611 15:42:47.001677 14324 net.cpp:150] Setting up mask_deconv3
I0611 15:42:47.001683 14324 net.cpp:157] Top shape: 1 256 244 244 (15241216)
I0611 15:42:47.001685 14324 net.cpp:165] Memory required for data: 1669293144
I0611 15:42:47.001700 14324 layer_factory.hpp:77] Creating layer mask_score
I0611 15:42:47.001708 14324 net.cpp:106] Creating Layer mask_score
I0611 15:42:47.001713 14324 net.cpp:454] mask_score <- mask_deconv3
I0611 15:42:47.001718 14324 net.cpp:411] mask_score -> mask_score
I0611 15:42:47.002337 14324 net.cpp:150] Setting up mask_score
I0611 15:42:47.002346 14324 net.cpp:157] Top shape: 1 8 244 244 (476288)
I0611 15:42:47.002358 14324 net.cpp:165] Memory required for data: 1671198296
I0611 15:42:47.002363 14324 layer_factory.hpp:77] Creating layer loss_mask
I0611 15:42:47.002370 14324 net.cpp:106] Creating Layer loss_mask
I0611 15:42:47.002373 14324 net.cpp:454] loss_mask <- mask_score
I0611 15:42:47.002378 14324 net.cpp:454] loss_mask <- mask_targets
I0611 15:42:47.002383 14324 net.cpp:411] loss_mask -> loss_mask
I0611 15:42:47.002393 14324 layer_factory.hpp:77] Creating layer loss_mask
I0611 15:42:47.003821 14324 net.cpp:150] Setting up loss_mask
I0611 15:42:47.003829 14324 net.cpp:157] Top shape: (1)
I0611 15:42:47.003842 14324 net.cpp:160]     with loss weight 3
I0611 15:42:47.003849 14324 net.cpp:165] Memory required for data: 1671198300
I0611 15:42:47.003851 14324 net.cpp:226] loss_mask needs backward computation.
I0611 15:42:47.003855 14324 net.cpp:226] mask_score needs backward computation.
I0611 15:42:47.003857 14324 net.cpp:226] mask_deconv3 needs backward computation.
I0611 15:42:47.003860 14324 net.cpp:226] pool5_2_conv6_relu needs backward computation.
I0611 15:42:47.003863 14324 net.cpp:226] pool5_2_conv6 needs backward computation.
I0611 15:42:47.003866 14324 net.cpp:226] pool5_2_conv5_relu needs backward computation.
I0611 15:42:47.003870 14324 net.cpp:226] pool5_2_conv5 needs backward computation.
I0611 15:42:47.003872 14324 net.cpp:226] mask_deconv2 needs backward computation.
I0611 15:42:47.003875 14324 net.cpp:226] out_x needs backward computation.
I0611 15:42:47.003880 14324 net.cpp:226] out_reshape_scale needs backward computation.
I0611 15:42:47.003882 14324 net.cpp:226] out_reshape needs backward computation.
I0611 15:42:47.003885 14324 net.cpp:226] out needs backward computation.
I0611 15:42:47.003888 14324 net.cpp:226] attention_perm needs backward computation.
I0611 15:42:47.003891 14324 net.cpp:226] value_conv_reshape_perm needs backward computation.
I0611 15:42:47.003895 14324 net.cpp:226] attention needs backward computation.
I0611 15:42:47.003898 14324 net.cpp:226] energy needs backward computation.
I0611 15:42:47.003901 14324 net.cpp:226] key_conv_reshape_perm needs backward computation.
I0611 15:42:47.003904 14324 net.cpp:226] query_conv_reshape_perm needs backward computation.
I0611 15:42:47.003907 14324 net.cpp:226] value_conv_reshape needs backward computation.
I0611 15:42:47.003911 14324 net.cpp:226] key_conv_reshape needs backward computation.
I0611 15:42:47.003914 14324 net.cpp:226] query_conv_reshape needs backward computation.
I0611 15:42:47.003916 14324 net.cpp:226] value_conv needs backward computation.
I0611 15:42:47.003919 14324 net.cpp:226] key_conv needs backward computation.
I0611 15:42:47.003922 14324 net.cpp:226] query_conv needs backward computation.
I0611 15:42:47.003926 14324 net.cpp:226] pool5_2_conv4_relu_pool5_2_conv4_relu_0_split needs backward computation.
I0611 15:42:47.003931 14324 net.cpp:226] pool5_2_conv4_relu needs backward computation.
I0611 15:42:47.003935 14324 net.cpp:226] pool5_2_conv4 needs backward computation.
I0611 15:42:47.003939 14324 net.cpp:226] pool5_2_conv3_relu needs backward computation.
I0611 15:42:47.003942 14324 net.cpp:226] pool5_2_conv3 needs backward computation.
I0611 15:42:47.003947 14324 net.cpp:226] mask_deconv1 needs backward computation.
I0611 15:42:47.003952 14324 net.cpp:226] pool5_2_conv2_relu needs backward computation.
I0611 15:42:47.003954 14324 net.cpp:226] pool5_2_conv2 needs backward computation.
I0611 15:42:47.003958 14324 net.cpp:226] pool5_2_conv_relu needs backward computation.
I0611 15:42:47.003963 14324 net.cpp:226] pool5_2_conv needs backward computation.
I0611 15:42:47.003967 14324 net.cpp:226] roi_pool5_2 needs backward computation.
I0611 15:42:47.003970 14324 net.cpp:226] loss_bbox needs backward computation.
I0611 15:42:47.003974 14324 net.cpp:226] loss_cls needs backward computation.
I0611 15:42:47.003980 14324 net.cpp:226] loss_attribute needs backward computation.
I0611 15:42:47.003984 14324 net.cpp:226] bbox_pred needs backward computation.
I0611 15:42:47.003989 14324 net.cpp:226] cls_score needs backward computation.
I0611 15:42:47.003993 14324 net.cpp:226] attr_score needs backward computation.
I0611 15:42:47.003998 14324 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0611 15:42:47.004000 14324 net.cpp:226] relu7 needs backward computation.
I0611 15:42:47.004005 14324 net.cpp:226] fc7 needs backward computation.
I0611 15:42:47.004009 14324 net.cpp:226] relu6 needs backward computation.
I0611 15:42:47.004010 14324 net.cpp:226] fc6 needs backward computation.
I0611 15:42:47.004014 14324 net.cpp:226] roi_pool5 needs backward computation.
I0611 15:42:47.004017 14324 net.cpp:226] roi-data needs backward computation.
I0611 15:42:47.004024 14324 net.cpp:226] proposal needs backward computation.
I0611 15:42:47.004030 14324 net.cpp:226] rpn_cls_prob_reshape needs backward computation.
I0611 15:42:47.004034 14324 net.cpp:226] rpn_cls_prob needs backward computation.
I0611 15:42:47.004037 14324 net.cpp:226] rpn_loss_bbox needs backward computation.
I0611 15:42:47.004042 14324 net.cpp:226] rpn_loss_cls needs backward computation.
I0611 15:42:47.004047 14324 net.cpp:226] rpn-data needs backward computation.
I0611 15:42:47.004052 14324 net.cpp:226] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0611 15:42:47.004056 14324 net.cpp:226] rpn_cls_score_reshape needs backward computation.
I0611 15:42:47.004060 14324 net.cpp:226] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0611 15:42:47.004062 14324 net.cpp:226] rpn_bbox_pred needs backward computation.
I0611 15:42:47.004065 14324 net.cpp:226] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0611 15:42:47.004070 14324 net.cpp:226] rpn_cls_score needs backward computation.
I0611 15:42:47.004072 14324 net.cpp:226] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0611 15:42:47.004076 14324 net.cpp:226] rpn_relu/3x3 needs backward computation.
I0611 15:42:47.004079 14324 net.cpp:226] rpn_conv/3x3 needs backward computation.
I0611 15:42:47.004083 14324 net.cpp:226] conv5_3_relu5_3_0_split needs backward computation.
I0611 15:42:47.004086 14324 net.cpp:226] relu5_3 needs backward computation.
I0611 15:42:47.004089 14324 net.cpp:226] conv5_3 needs backward computation.
I0611 15:42:47.004092 14324 net.cpp:226] relu5_2 needs backward computation.
I0611 15:42:47.004096 14324 net.cpp:226] conv5_2 needs backward computation.
I0611 15:42:47.004101 14324 net.cpp:226] relu5_1 needs backward computation.
I0611 15:42:47.004103 14324 net.cpp:226] conv5_1 needs backward computation.
I0611 15:42:47.004106 14324 net.cpp:226] pool4 needs backward computation.
I0611 15:42:47.004109 14324 net.cpp:226] relu4_3 needs backward computation.
I0611 15:42:47.004112 14324 net.cpp:226] conv4_3 needs backward computation.
I0611 15:42:47.004115 14324 net.cpp:226] relu4_2 needs backward computation.
I0611 15:42:47.004122 14324 net.cpp:226] conv4_2 needs backward computation.
I0611 15:42:47.004123 14324 net.cpp:226] relu4_1 needs backward computation.
I0611 15:42:47.004127 14324 net.cpp:226] conv4_1 needs backward computation.
I0611 15:42:47.004130 14324 net.cpp:226] pool3 needs backward computation.
I0611 15:42:47.004133 14324 net.cpp:226] relu3_3 needs backward computation.
I0611 15:42:47.004137 14324 net.cpp:226] conv3_3 needs backward computation.
I0611 15:42:47.004140 14324 net.cpp:226] relu3_2 needs backward computation.
I0611 15:42:47.004144 14324 net.cpp:226] conv3_2 needs backward computation.
I0611 15:42:47.004148 14324 net.cpp:226] relu3_1 needs backward computation.
I0611 15:42:47.004153 14324 net.cpp:226] conv3_1 needs backward computation.
I0611 15:42:47.004155 14324 net.cpp:228] pool2 does not need backward computation.
I0611 15:42:47.004160 14324 net.cpp:228] relu2_2 does not need backward computation.
I0611 15:42:47.004163 14324 net.cpp:228] conv2_2 does not need backward computation.
I0611 15:42:47.004168 14324 net.cpp:228] relu2_1 does not need backward computation.
I0611 15:42:47.004171 14324 net.cpp:228] conv2_1 does not need backward computation.
I0611 15:42:47.004175 14324 net.cpp:228] pool1 does not need backward computation.
I0611 15:42:47.004179 14324 net.cpp:228] relu1_2 does not need backward computation.
I0611 15:42:47.004184 14324 net.cpp:228] conv1_2 does not need backward computation.
I0611 15:42:47.004186 14324 net.cpp:228] relu1_1 does not need backward computation.
I0611 15:42:47.004190 14324 net.cpp:228] conv1_1 does not need backward computation.
I0611 15:42:47.004194 14324 net.cpp:228] gt_boxes_input-data_2_split does not need backward computation.
I0611 15:42:47.004199 14324 net.cpp:228] im_info_input-data_1_split does not need backward computation.
I0611 15:42:47.004202 14324 net.cpp:228] data_input-data_0_split does not need backward computation.
I0611 15:42:47.004209 14324 net.cpp:228] input-data does not need backward computation.
I0611 15:42:47.004211 14324 net.cpp:270] This network produces output loss_attribute
I0611 15:42:47.004216 14324 net.cpp:270] This network produces output loss_bbox
I0611 15:42:47.004220 14324 net.cpp:270] This network produces output loss_cls
I0611 15:42:47.004225 14324 net.cpp:270] This network produces output loss_mask
I0611 15:42:47.004227 14324 net.cpp:270] This network produces output rpn_cls_loss
I0611 15:42:47.004231 14324 net.cpp:270] This network produces output rpn_loss_bbox
I0611 15:42:47.004284 14324 net.cpp:283] Network initialization done.
I0611 15:42:47.004469 14324 solver.cpp:60] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0611 15:42:51.970643 14324 net.cpp:816] Ignoring source layer pool5
I0611 15:42:52.043123 14324 net.cpp:816] Ignoring source layer drop6
I0611 15:42:52.054497 14324 net.cpp:816] Ignoring source layer drop7
I0611 15:42:52.054512 14324 net.cpp:816] Ignoring source layer fc8
I0611 15:42:52.054514 14324 net.cpp:816] Ignoring source layer prob
Solving...
[[ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.9127284   0.18459737
   2.7877066   0.47901857]
 [ 0.          0.          0.          0.          0.14915434 -0.28977406
  -0.02566686 -1.3722175 ]
 [ 0.          0.          0.          0.         -0.3749028   0.31186482
  -1.7365049   0.486255  ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]]
[[ 0.          0.          0.          0.          1.2724843  -0.68565464
  -2.3967326  -0.4199539 ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.         -0.29763606  1.7401562
  -0.30591357  0.22887744]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]
 [ 0.          0.          0.          0.          0.          0.
   0.          0.        ]]
